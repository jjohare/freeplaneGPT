<map version="freeplane 1.9.13">
<!--To view this file, download free mind mapping software Freeplane from https://www.freeplane.org -->
<node TEXT="XR/AI/BTC" FOLDED="false" ID="ID_696401721" CREATED="1610381621824" MODIFIED="1687854138368" STYLE="oval">
<font SIZE="17"/>
<hook NAME="MapStyle" zoom="0.953">
    <properties edgeColorConfiguration="#808080ff,#ff0000ff,#0000ffff,#00ff00ff,#ff00ffff,#00ffffff,#7c0000ff,#00007cff,#007c00ff,#7c007cff,#007c7cff,#7c7c00ff" show_icon_for_attributes="true" associatedTemplateLocation="template:/standard-1.6.mm" show_note_icons="true" fit_to_viewport="false"/>

<map_styles>
<stylenode LOCALIZED_TEXT="styles.root_node" STYLE="oval" UNIFORM_SHAPE="true" VGAP_QUANTITY="24 pt">
<font SIZE="24"/>
<stylenode LOCALIZED_TEXT="styles.predefined" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="default" ID="ID_271890427" ICON_SIZE="12 pt" COLOR="#000000" STYLE="fork">
<arrowlink SHAPE="CUBIC_CURVE" COLOR="#000000" WIDTH="2" TRANSPARENCY="200" DASH="" FONT_SIZE="9" FONT_FAMILY="SansSerif" DESTINATION="ID_271890427" STARTARROW="NONE" ENDARROW="DEFAULT"/>
<font NAME="SansSerif" SIZE="10" BOLD="false" ITALIC="false"/>
<richcontent CONTENT-TYPE="plain/auto" TYPE="DETAILS"/>
<richcontent TYPE="NOTE" CONTENT-TYPE="plain/auto"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.details"/>
<stylenode LOCALIZED_TEXT="defaultstyle.attributes">
<font SIZE="9"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.note" COLOR="#000000" BACKGROUND_COLOR="#ffffff" TEXT_ALIGN="LEFT"/>
<stylenode LOCALIZED_TEXT="defaultstyle.floating">
<edge STYLE="hide_edge"/>
<cloud COLOR="#f0f0f0" SHAPE="ROUND_RECT"/>
</stylenode>
<stylenode LOCALIZED_TEXT="defaultstyle.selection" BACKGROUND_COLOR="#afd3f7" BORDER_COLOR_LIKE_EDGE="false" BORDER_COLOR="#afd3f7"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.user-defined" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="styles.topic" COLOR="#18898b" STYLE="fork">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.subtopic" COLOR="#cc3300" STYLE="fork">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.subsubtopic" COLOR="#669900">
<font NAME="Liberation Sans" SIZE="10" BOLD="true"/>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.important" ID="ID_67550811">
<icon BUILTIN="yes"/>
<arrowlink COLOR="#003399" TRANSPARENCY="255" DESTINATION="ID_67550811"/>
</stylenode>
</stylenode>
<stylenode LOCALIZED_TEXT="styles.AutomaticLayout" POSITION="right" STYLE="bubble">
<stylenode LOCALIZED_TEXT="AutomaticLayout.level.root" COLOR="#000000" STYLE="oval" SHAPE_HORIZONTAL_MARGIN="10 pt" SHAPE_VERTICAL_MARGIN="10 pt">
<font SIZE="18"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,1" COLOR="#0033ff">
<font SIZE="16"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,2" COLOR="#00b439">
<font SIZE="14"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,3" COLOR="#990000">
<font SIZE="12"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,4" COLOR="#111111">
<font SIZE="10"/>
</stylenode>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,5"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,6"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,7"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,8"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,9"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,10"/>
<stylenode LOCALIZED_TEXT="AutomaticLayout.level,11"/>
</stylenode>
</stylenode>
</map_styles>
</hook>
<hook NAME="AutomaticEdgeColor" COUNTER="75" RULE="ON_BRANCH_CREATION"/>
<node TEXT="Accessibility" FOLDED="true" POSITION="left" ID="ID_527610599" CREATED="1681408321263" MODIFIED="1681408324743">
<edge COLOR="#00ff00"/>
<node TEXT="Interactive photo and video scene description" ID="ID_874796040" CREATED="1681408325871" MODIFIED="1685195739197" LINK="https://github.com/Vision-CAIR/ChatCaptioner">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Gameface Apache2 mouse with face gesture" ID="ID_1635140492" CREATED="1683796317271" MODIFIED="1685195739198" LINK="https://github.com/google/project-gameface">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Movie scene description paper" ID="ID_608277059" CREATED="1687423333305" MODIFIED="1687423342950" LINK="https://www.robots.ox.ac.uk/~vgg/research/autoad/"/>
<node TEXT="Video-llama description" ID="ID_131944223" CREATED="1689077538501" MODIFIED="1689077554855" LINK="https://github.com/DAMO-NLP-SG/Video-LLaMA?"/>
</node>
<node TEXT="Bitcoin and Digital objects" FOLDED="true" POSITION="left" ID="ID_1436413864" CREATED="1678041877756" MODIFIED="1694341603071">
<edge COLOR="#007c00"/>
<node TEXT="Lightning" ID="ID_1540644375" CREATED="1678041647508" MODIFIED="1678041650343">
<node TEXT="Setup lnbits and lightningtipbot" ID="ID_944349233" CREATED="1678041651209" MODIFIED="1678041669230" LINK="https://www.massmux.com/howto-complete-lightningtipbot-lnbits-setup-vps/"/>
<node TEXT="GitHub - ln-vortex/ln-vortex: Lightning and Taproot enabled collaborative transactions (other)" ID="ID_1931169488" CREATED="1678463114798" MODIFIED="1680615491381" LINK="https://github.com/ln-vortex/ln-vortex"/>
<node TEXT="RGB is a smart contract platform that is scalable, private, and interoperable with Bitcoin and Lightning Network. It is possible to issue assets, create NFTs, and run DAOs on RGB." ID="ID_660131690" CREATED="1682414608726" MODIFIED="1685182638099" LINK="https://rgb.tech/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="This is a node management software for large Lightning Network nodes. It provides a way to automate workflows, manage code changes, and track work progress." ID="ID_673365743" CREATED="1682414608736" MODIFIED="1682416278151" LINK="https://github.com/lncapital/torq">
<node TEXT="" ID="ID_1103034293" CREATED="1682414608736" MODIFIED="1682416275929"/>
</node>
<node TEXT="L402 lightning reverse proxy with LND for AI" ID="ID_1503983382" CREATED="1689624873131" MODIFIED="1689624927028">
<node TEXT="discord" ID="ID_969818180" CREATED="1689624930683" MODIFIED="1689624934062" LINK="https://app.slack.com/client/T6AK88MGV/C6AFCN3KL/rimeto_profile/U05H0AMLCR5"/>
<node TEXT="docs" ID="ID_1162743621" CREATED="1689624949014" MODIFIED="1689624951665" LINK="https://docs.lightning.engineering/the-lightning-network/l402"/>
</node>
</node>
<node TEXT="Adoption" ID="ID_1197458091" CREATED="1678458767502" MODIFIED="1678458769785">
<node TEXT="90 Million People Use Cryptocurrency in Nigeria - Report | Investors King" ID="ID_6391680" CREATED="1678458771122" MODIFIED="1678458791323" LINK="https://investorsking.com/2023/03/08/90-million-people-use-cryptocurrency-in-nigeria-reports/"/>
<node TEXT="2023 Independent Reserve Cryptocurrency Index shows Singaporeans are still actively investing in crypto despite hit in overall confidence: /PRNewswire/ -- In the latest study[1] by Independent Reserve, Singapore&apos;s first regulated cryptocurrency exchange for all investors, Singaporeans[2] are still..." ID="ID_685282739" CREATED="1680510364124" MODIFIED="1685182638107" LINK="https://www.prnewswire.com/apac/news-releases/2023-independent-reserve-cryptocurrency-index-shows-singaporeans-are-still-actively-investing-in-crypto-despite-hit-in-overall-confidence-301783400.html">
<icon BUILTIN="attach"/>
<node TEXT="Despite a recent dip in overall confidence, the 2023 Independent Reserve Cryptocurrency Index shows that Singaporeans are still actively investing in cryptocurrency. The study found that Singaporeans are most interested in investing in Bitcoin, Ethereum, and Litecoin." ID="ID_698610164" CREATED="1680510364128" MODIFIED="1680510364128"/>
</node>
<node TEXT="Bitnob African exchange" ID="ID_1146475396" CREATED="1680619436829" MODIFIED="1680619651338" LINK="https://bitnob.com/blog/how-to-buy-and-sell-bitcoin-in-nigeria"/>
<node TEXT="Noones peer2peer for Africa" ID="ID_1216945336" CREATED="1680619452578" MODIFIED="1680619652807" LINK="https://bitcoinmagazine.com/business/bitcoin-entrepreneurs-introduce-noones-app-aimed-at-empowering-financial-freedom"/>
<node TEXT="Africa leads the world in peer to peer bitcoin" ID="ID_1524277081" CREATED="1682414608740" MODIFIED="1682418627706" LINK="https://twitter.com/documentingbtc/status/1646656229958361091"/>
<node TEXT="Econometrics of adoption in USA" ID="ID_1914899239" CREATED="1686346373166" MODIFIED="1686346385905" LINK="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4453714"/>
</node>
<node TEXT="Bitcoin" ID="ID_1525153681" CREATED="1678463304009" MODIFIED="1689580542083">
<node TEXT="The Freedom of Value - How Value-for-Value Fixes the Monetization of Information | dergigi.com,Thoughts about Bitcoin and other things. " ID="ID_1740402556" CREATED="1677783034638" MODIFIED="1677783034638" LINK="https://dergigi.com/2021/12/30/the-freedom-of-value/"/>
<node TEXT="http://bitcoin secure multisig setup (bsms        2 file_get_contents(): php_network_getaddresses: getaddrinfo failed: Name or service not known 2 file_get_contents(http://bitcoin secure multisig setup (bsms): failed to open stream: php_network_getaddresses: getaddrinfo failed: Name or service not known" ID="ID_749895073" CREATED="1678463114808" MODIFIED="1678463114808" LINK="http://bitcoin"/>
<node ID="ID_235777083" CREATED="1679506348281" MODIFIED="1679506348281" LINK="https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group" target="_new">https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node TEXT="Crypto Wave Gaining Momentum In Germany: Network Of 1,200 Banks To Offer Bitcoin: Deutsche WertpapierService Bank (Dwpbank), a provider of securities processing to approximately 1,200 banks in Germany, plans to launch a new platform called wpNex. This platform will offer Bitcoin access to all affiliated retail customers in the latter half of 2023. The innovative service will integrate cryptocurrency accounts with customers&apos; existing bank accounts, bypassing the need for additional Know Your Customer procedures, local media..." ID="ID_1590566360" CREATED="1680097753098" MODIFIED="1680619054143" LINK="https://www.msn.com/en-us/money/news/crypto-wave-gaining-momentum-in-germany-network-of-1-200-banks-to-offer-bitcoin/ar-AA198Lxc"/>
<node TEXT="https://www.cointime.com/news/hal-finneys-theory-of-bitcoin-backed-banks-74474" ID="ID_876627276" CREATED="1675507111025" MODIFIED="1680111506234"/>
<node TEXT="bitcoin-mining-analogy-beginners-guide" ID="ID_1704039805" CREATED="1675507111027" MODIFIED="1680115743825" LINK="https://braiins.com/blog/bitcoin-mining-analogy-beginners-guide"/>
<node TEXT="Introducing Floresta, a Utreexo-powered Electrum Server implementation: Bitcoin is a groundbreaking technology that enables users worldwide to transfer value in a trustless and borderless manner. Bitcoin’s core…" ID="ID_825675183" CREATED="1680097753104" MODIFIED="1680619071435" LINK="https://medium.com/vinteum-org/introducing-floresta-an-utreexo-powered-electrum-server-implementation-60feba8e179d">
<node TEXT="This is an implementation of an Electrum Server using Utreexo. Utreexo is a Bitcoin scaling solution that enables trustless and borderless value transfers. This implementation of an Electrum Server should help improve Bitcoin&apos;s decentralization." ID="ID_761405007" CREATED="1680097753104" MODIFIED="1680097753104"/>
</node>
<node TEXT="New critical white house report" ID="ID_634437270" CREATED="1679500534316" MODIFIED="1679500543875" LINK="https://www.whitehouse.gov/wp-content/uploads/2023/03/ERP-2023.pdf"/>
<node TEXT="Fedimint Hackathon Winners Announced: 2.58 BTC in Prizes: &quot;The quality of the modules that were submitted was truly impressive, with projects from federated storage to community finance tools that really highlighted the potential impact of Fedimint as a platform that could solve real-world problems.&quot;" ID="ID_1971612215" CREATED="1679913854633" MODIFIED="1680619078550" LINK="https://www.nobsbitcoin.com/fedimint-hackathon-winners-announced/">
<node TEXT="The Fedimint hackathon has come to a close, with 2.58 BTC in prizes being awarded to the winners. The quality of the submissions was impressive, with a range of modules being submitted that highlighted the potential of Fedimint as a platform for solving real-world problems." ID="ID_647400046" CREATED="1679913854633" MODIFIED="1679913854633"/>
<node TEXT="first ref in the book" ID="ID_175508374" CREATED="1684008077249" MODIFIED="1684008084031" LINK="https://github.com/flossverse/product/commit/e3ab5e7c7566184a84356608d7cd19049236ce8d?diff=unified#diff-3dd31e6ffeab329413da9cd244e8d27e892b95ca1b89390ad168124bbb88357cR241"/>
</node>
<node TEXT="https://geometry.xyz/notebook/A-light-introduction-to-ZeroSync" ID="ID_1045464223" CREATED="1680720194374" MODIFIED="1680720194374" LINK="https://geometry.xyz/notebook/A-light-introduction-to-ZeroSync"/>
<node TEXT="Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it&apos;s done is build a biometric database from the bodies of the poor." ID="ID_1434433234" CREATED="1682414608716" MODIFIED="1689580542082" LINK="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/"/>
<node TEXT="Cashu rust implementation" ID="ID_724135052" CREATED="1682418125556" MODIFIED="1685182638107" LINK="https://github.com/ngutech21/cashu-rs">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Zerosync bitcoin rollup proofs" ID="ID_805796974" CREATED="1682418157811" MODIFIED="1685182638107" LINK="https://zerosync.org/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="10101 custodial DLC trading" ID="ID_1022796199" CREATED="1685182839983" MODIFIED="1685182946421" LINK="https://medium.com/10101-finance/itchysats-becomes-10101-216dd64941d2">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Quantum miners" ID="ID_1696018634" CREATED="1686942304340" MODIFIED="1686942312412" LINK="https://arxiv.org/pdf/2306.03321.pdf"/>
</node>
<node TEXT="Mining and energy" ID="ID_1061586400" CREATED="1682419893438" MODIFIED="1682419900064">
<node TEXT="Bitcoin uses more energy than sweden" ID="ID_43345042" CREATED="1682414608762" MODIFIED="1682416735120" LINK="https://www.reddit.com/r/CryptoCurrency/comments/12xu714/bitcoin_has_just_surpassed_sweden_for_overall/"/>
<node TEXT="THE &apos;RIGHT TO MINE&apos; #BITCOIN📷 IS NOW LAW IN THE STATE OF ARKANSAS!" ID="ID_267839865" CREATED="1682414608755" MODIFIED="1682417159221" LINK="https://twitter.com/satoshiactfund/status/1648445448833875969"/>
<node TEXT="Bitcoin is a more sustainable energy than EVs, and significantly less fossil fuel." ID="ID_1617479199" CREATED="1682414608725" MODIFIED="1682415420719" LINK="https://www.linkedin.com/posts/danielsbatten_like-evs-bitcoin-is-a-fully-electrified-activity-7049321186605858816-t4MB?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="Batton&apos;s energy tracker" ID="ID_1350350637" CREATED="1686557472842" MODIFIED="1686557488704" LINK="http://batcoinz.com/BEEST/"/>
<node TEXT="sazmining hosted hydro" ID="ID_363747156" CREATED="1690728687424" MODIFIED="1690728701798" LINK="https://www.sazmining.com/"/>
</node>
<node TEXT="Digital objects" ID="ID_647197684" CREATED="1678041880593" MODIFIED="1680111945363">
<node TEXT="In games" ID="ID_459003858" CREATED="1678093844727" MODIFIED="1678093849365">
<node TEXT="DrDisrespect tweet" ID="ID_1818965847" CREATED="1678093852137" MODIFIED="1680619088364" LINK="https://twitter.com/DrDisrespect/status/1632430208379928576"/>
<node TEXT="Polygon generative art game" ID="ID_334460505" CREATED="1679666173620" MODIFIED="1679666187124" LINK="https://github.com/beamable/genamon-polygon/"/>
</node>
<node TEXT="RGB explainer slides" ID="ID_1646665038" CREATED="1676229466888" MODIFIED="1676229474049" LINK="https://docsend.com/view/he8x9erkjmphphvn">
<node TEXT="rgb tokens" ID="ID_649100738" CREATED="1679692653551" MODIFIED="1679692670651" LINK="https://twitter.com/iris_wallet/status/1639189676845047808"/>
<node TEXT="RGB minimal fork for tether" ID="ID_507240522" CREATED="1679739019251" MODIFIED="1680619117790" LINK="https://t.me/rgbtelegram/36013"/>
<node TEXT="Iris wallet" ID="ID_31686963" CREATED="1679739160071" MODIFIED="1685182638107" LINK="https://play.google.com/store/apps/details?id=com.iriswallet.testnet">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Diba wallet and marketplace" ID="ID_1349321829" CREATED="1679739192578" MODIFIED="1685182638107" LINK="https://diba.io/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="RGB / Nostr integration" ID="ID_1685595101" CREATED="1683796097621" MODIFIED="1685182638107" LINK="https://twitter.com/lnp_bp/status/1656211884775821313">
<icon BUILTIN="attach"/>
<node TEXT="NIP88" ID="ID_1439404489" CREATED="1683796182542" MODIFIED="1683796199669" LINK="https://github.com/nostr-protocol/nips/pull/512"/>
</node>
</node>
<node TEXT="By The Numbers: How Do Inscriptions Affect Bitcoin Blocksize: Bitcoin Inscriptions have increased the average size of the cryptocurrency&apos;s blocks; here&apos;s how this could impact the blockchain." ID="ID_420191811" CREATED="1679914078200" MODIFIED="1685182638107" LINK="https://bitcoinist.com/the-numbers-inscriptions-affect-bitcoin-blocksize/">
<icon BUILTIN="attach"/>
<node TEXT="The text provides a brief overview of the jnews_ajax_url variable and how it can be used to make AJAX requests." ID="ID_1373565615" CREATED="1679914078200" MODIFIED="1679914078200"/>
</node>
<node TEXT="UK Government Scraps NFT Launch Plan For Now: UK government had unveiled its intention to introduce its very own NFTs through the Royal Mint. This announcement was made last year in April." ID="ID_1455863988" CREATED="1680097753104" MODIFIED="1680619129386" LINK="https://bitcoinist.com/uk-government-scraps-nft-launch-plan-for-now/"/>
<node TEXT="OpenOrdex is a decentralized exchange for ordinal numbers. It allows users to buy and sell ordinal numbers using a variety of methods, including Inscription, which is a process by which users can add their own numbers to the exchange." ID="ID_1546076024" CREATED="1682414608737" MODIFIED="1682416294608" LINK="https://openordex.org/"/>
<node TEXT="Zerosync client side validation?" ID="ID_1890336170" CREATED="1683832352538" MODIFIED="1685182638107" LINK="https://twitter.com/ZeroSync_/status/1656721507060416514">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Taproot assets" ID="ID_481595342" CREATED="1684316637990" MODIFIED="1685182638107" LINK="https://github.com/lightninglabs/taproot-assets">
<icon BUILTIN="attach"/>
</node>
<node TEXT="https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d" ID="ID_386700144" CREATED="1686508029150" MODIFIED="1686508029150" LINK="https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d"/>
</node>
<node TEXT="Stablecoins and CBDCs" FOLDED="true" ID="ID_1921746769" CREATED="1680112110397" MODIFIED="1680112126892">
<node TEXT="Over 1/3 Made a Purchase in Stablecoins in Latin America, Says Latest MasterCard New Payments Index 2022: Reporting on Fintech, Crypto, and Blockchain Activity in Africa" ID="ID_1868204015" CREATED="1679914078202" MODIFIED="1680619663178" LINK="https://bitcoinke.io/2022/07/latin-america-in-mastercard-new-payments-index-2022/">
<node TEXT="According to the latest MasterCard New Payments Index 2022, over one third of people in Latin America made a purchase using stablecoins in the past year." ID="ID_1932680039" CREATED="1679914078202" MODIFIED="1679914078202"/>
</node>
<node ID="ID_394430828" CREATED="1679506348281" MODIFIED="1679506348281" LINK="https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group" target="_new">https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node TEXT="rbi monetary museum: India&apos;s e-rupee unpopular as central banks push digital currency - The Economic Times https://economictimes.indiatimes.com/industry/banking/finance/banking/indias-e-rupee-unpopular-as-central-banks-push-digital-currency/articleshow/99049236.cms?from=mdr" ID="ID_1747681153" CREATED="1680097753101" MODIFIED="1680619135699"/>
<node TEXT="Kollider Wallet: Browser-based Lightning &amp; Nostr Extension: Kollider is a new custodial Lightning + Nostr wallet with native stablecoin integration." ID="ID_132597742" CREATED="1679841790212" MODIFIED="1685182638115" LINK="https://www.nobsbitcoin.com/kollider-wallet/">
<icon BUILTIN="attach"/>
<node TEXT="Kollider is a new custodial Lightning + Nostr wallet with native stablecoin integration. Kollider Wallet allows you to hold balances in BTC, USD, and EUR. These synthetic stablecoins are created using hedged positions on Kollider Exchange. We take care of the hedging and you get the benefit of low volatility and easy conversion between the different currencies." ID="ID_1285870308" CREATED="1679841790212" MODIFIED="1679841790212"/>
</node>
<node TEXT="The Current List of CBDCs In Development Around the World" ID="ID_47342167" CREATED="1680262528031" MODIFIED="1680262570291" LINK="https://www.atlanticcouncil.org/cbdctracker/"/>
</node>
<node ID="ID_1675907409" CREATED="1687805148465" MODIFIED="1694341603069" LINK="https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/" HGAP_QUANTITY="2.9 pt" VSHIFT_QUANTITY="4.2 pt"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Swap Service is an orderbook that allows for submarine swaps over Nostr, enabling Bitcoin users to earn a yield on their Bitcoin. Submarine swaps allow for the swapping of funds on Lightning for funds on the base layer and vice versa, without the need for opening or closing channels or giving custody of funds to other people. Swap Service also enables channel rebalancing and is the foundation for wallets and services like Muun, Lightning Loop, and Boltz Exchange. Anyone who runs an LND Lightning node can become a yield chaser by running Swap Service on their computer and hooking it up to their node. Yield chasers can set parameters and earn a fee for swaps. Swap Service is available on both the mainnet and testnet. https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1074197787" CREATED="1687805148501" MODIFIED="1687805148501" LINK="https://twitter.com/lightning/status/1658497809895809025"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          On May 16, Lightning Labs announced Taproot Assets v0.2, the newest version of its scalable protocol to issue assets on Bitcoin and Lightning. Taproot Assets v0.2 has a core set of features that enable developers to issue assets and bitcoinize assets in a chain-efficient manner. This specific version offers a variety of useful features, such us vPSBT support for send and receive, Universe APIs for asset discovery and multi-asset transactions to save chain space. The team called all bitcoin and Lightning developers to test the code, give feedback and start building on Taproot Assets. &nbsp;The announcement has generated feedback from users on Twitter, including comments calling for Bolt12, RGB, and Podcast Token. https://twitter.com/lightning/status/1658497809895809025
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_108567091" CREATED="1687805148546" MODIFIED="1687805148546" LINK="https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Swap Service is an order book designed for performing submarine swaps over the Nostr protocol. It provides users with a way to earn yield on their bitcoin holdings. Submarine swaps allow lightning users to swap funds on the lightning network for funds on the base layer, or vice versa, without opening and closing channels and without the need to give custody of their money to other people. They are also beneficial for channel rebalancing and create the foundation for important wallets and services such as Muun, Lightning Loop and Boltz Exchange. Any person running an LND lightning node can run the Swap Service on their computer to become a yield chaser, setting parameters, such as how much sats they are willing to swap and the fee for swaps, with the Swap Service providing a simple tool to execute these actions. The Swap Service website includes a demo video and instruction for use on the mainnet or testnet. https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1272355221" CREATED="1687805148554" MODIFIED="1687805148554" LINK="https://www.nobsbitcoin.com/shiro-wallet-umbrel-release/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Diamond Hands has released an alpha version of Shiro Wallet, which is compatible with RGB protocol and can be added easily to other services by calling endpoints for the wallet. It is an open-source, self-hosted RGB wallet for the Bitcoin blockchain. Shiro Wallet can issue, send and receive fungible RGB tokens, which allows users to experiment with the protocol and gain first-hand experience. The wallet is a web-server wallet and can be integrated easily with other services. It is the first RGB wallet available on Umbrel, a popular Bitcoin node management platform. However, the current form of Shiro Wallet is still very rough and alpha and only available on testnet for now. https://www.nobsbitcoin.com/shiro-wallet-umbrel-release/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1581089839" CREATED="1687805148617" MODIFIED="1687805148617" LINK="https://github.com/nbd-wtf/soma"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The nbd-wtf/soma repository on GitHub is a demo Spacechain that allows users to issue and transfer non-fungible assets on a fully-fledged blockchain that does not require any shitcoins to be created or spam to be dumped into the Bitcoin chain. The blockchain is designed using SIGHASH_ANYPREVOUT and runs on signet. The repository includes a Docker container with everything pre-packaged for running the Spacechain demo, along with a tutorial. There are also hosted tools available for users who just want to see something happen. The repository is primarily written in Scala and JavaScript, with smaller portions written in Dockerfile, HTML, Go, Shell, and Makefile. https://github.com/nbd-wtf/soma
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1924990603" CREATED="1687805148621" MODIFIED="1687805148621" LINK="https://blog.ordinalhub.com/brc-20-mania/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          BRC-20 is an experiment to test if ordinal theory can facilitate fungibility on Bitcoin. It allows for the deployment, minting, and transfer of token amounts through a JSON file inscription, enabling the tracking of rudimentary token balances on Bitcoin. BRC-20 defines ticker length as four characters, with little to no restrictions on character type. The deployment contract sets a maximum &quot;limit&quot; amount for the token, which anyone can mint after. The activity around BRC-20s remained modest until early March, but exploded in late April, leading to Bitcoin network transactions surpassing regular Bitcoin transactions for two days straight. However, this creates a significant risk to the ecosystem as third-party services keep track of balances and token indexes instead of the Bitcoin blockchain or ord client, potentially exposing third party security to systemic risk. The ecosystem is accelerating with DeFi-type &quot;liquidity pool&quot; standards popping up as it mirrors the early stages of the previous crypto cycle before DeFi Summer. This is an ongoing and rapidly developing story, which requires continued tracking of the Ordinals ecosystem. https://blog.ordinalhub.com/brc-20-mania/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1558814162" CREATED="1687805148698" MODIFIED="1687805148698" LINK="https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A new open-source Bitcoin blockchain analyzer is being developed to provide regular Bitcoin users with tools to research their transactions and avoid high fees charged by analytics companies. A recent post found that over 80% of inscriptions created in early-mid May 2023 belonged to a single entity, controlled by a single private key, belonging to a possible user of Unisat. The centralisation of control means a single entity can significantly impact the entire Blockchain regime, with the tests highlighting worrying vulnerabilities in the Bitcoin network. Further research is required to address the issue. https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_191144103" CREATED="1687805148711" MODIFIED="1687805148711" LINK="https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text notifies the reader that they have been blocked from accessing a website due to the behavior of their browser. There are three possible explanations for this: the user is clicking and browsing too quickly, JavaScript is not functioning on their computer, or there is a robot on the same network as the user. The reader is encouraged to submit feedback if they are experiencing access issues. An ID number is provided for reference. https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_522269205" CREATED="1687805148765" MODIFIED="1687805148765" LINK="https://open.spotify.com/episode/460zip5X9UVSFxJ91JY0J3?si=n6rh-ctDR1Ga6Erql84ZQg"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a preview of the Spotify streaming service that encourages users to sign up and create a playlist. It also features a podcast episode from the Bitcoin Core developer Matt Corallo, discussing the impact of mining rewards and decentralization risks. The text highlights the importance of user privacy, stating that cookies are used to store and access personal data for purposes such as personalized content and advertising, and users can adjust their preferences using the Cookie Settings button. The text suggests that Spotify works in coordination with an industry framework to indicate user preferences globally for all participating websites. https://open.spotify.com/episode/460zip5X9UVSFxJ91JY0J3?si=n6rh-ctDR1Ga6Erql84ZQg
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1956750712" CREATED="1687805148892" MODIFIED="1687805148892" LINK="https://mobile.twitter.com/FarooqAhmedX/status/1620925310379368448"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text talks about how Twitter users are the first to know about things, with a tweet from Farooq Ahmed suggesting that Bitcoin could render the Belgian association known as SWIFT obsolete. The tweet has received views, retweets, and likes, and there are also other tweets from Ahmed, such as one about Bitcoin to the IMF, and another praising the progress made by Nayib Bukele in El Salvador. The text also mentions that Twitter and its partners use cookies to provide better and safer services. https://mobile.twitter.com/FarooqAhmedX/status/1620925310379368448
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_519994854" CREATED="1687805149042" MODIFIED="1687805149042" LINK="https://www.arkpill.me/faq"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Ark is a privacy-focused off-chain protocol that offers anonymity similar to the classic Chaumian eCash system. However, unlike eCash, transactions made through Ark are backed by actual bitcoins, making it more secure. Compared to Lightning, Ark is a liquidity network that consumes significantly less on-chain footprint and allows recipients to receive payments without acquiring inbound liquidity or revealing their identity. Ark also mimics the on-chain wallet UX but does not require transactions to be on-chain and does not introduce inbound liquidity constraints. Compared to validity rollups, Ark has higher throughput as it does not require on-chain data per transaction. While in theory, Ark service providers can double-spend their pool transactions while they sit on mempool, users can redeem their previously redeemed coins through a hypothetical data manipulation opcode in case of double-spending. Overall, Ark offers a more secure and private way to make transactions that is faster and more efficient than other methods available. https://www.arkpill.me/faq
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Node config tools" ID="ID_675138008" CREATED="1689670244667" MODIFIED="1689670251765">
<node TEXT="VPS config" ID="ID_1339981230" CREATED="1689670252569" MODIFIED="1689670259162" LINK="https://github.com/flyerbear/pleb-vpn/blob/main/Raspibolt%20Install%20Guide.md"/>
<node TEXT="plebVPN" ID="ID_193883717" CREATED="1689670272843" MODIFIED="1689670277598" LINK="https://github.com/allyourbankarebelongtous/pleb-vpn#how-it-works"/>
</node>
<node TEXT="Cleveland bank paper on lighting improving Bitcoin" ID="ID_1503632412" CREATED="1689879257807" MODIFIED="1689879277250" LINK="https://www.clevelandfed.org/en/publications/working-paper/2022/wp-2219-the-lightning-network-turning-bitcoin-into-money"/>
</node>
<node TEXT="nostr" FOLDED="true" POSITION="left" ID="ID_1513064909" CREATED="1689349535934" MODIFIED="1689349538060">
<edge COLOR="#00007c"/>
<node TEXT="Python nostr client" ID="ID_785241850" CREATED="1689349539526" MODIFIED="1689349546521" LINK="https://www.youtube.com/watch?v=vw5SZyYBuPk&amp;t=1471s"/>
<node TEXT="Python nostr repo, months old" ID="ID_24310641" CREATED="1689349626650" MODIFIED="1689349635758" LINK="https://github.com/jeffthibault/python-nostr"/>
<node TEXT="nostrpy" ID="ID_871783607" CREATED="1689349655275" MODIFIED="1689349659158" LINK="https://github.com/monty888/nostrpy"/>
<node TEXT="lnbits enable extensions mode for nostr" ID="ID_661735728" CREATED="1689371531955" MODIFIED="1689371546124" LINK="https://github.com/raspiblitz/raspiblitz/issues/3799">
<node TEXT="tailscale forum posts" ID="ID_516611211" CREATED="1689625094145" MODIFIED="1689625109155" LINK="https://community.umbrel.com/t/introducing-the-official-nostr-relay-app/11339/17"/>
</node>
<node TEXT="Relay list" ID="ID_1987855090" CREATED="1689795528900" MODIFIED="1689795532966" LINK="https://nostr.info/relays/"/>
<node TEXT="WSS check" ID="ID_168467077" CREATED="1689799604826" MODIFIED="1689799619129" LINK="https://websocketking.com/"/>
<node TEXT="nostr market guide" ID="ID_483170638" CREATED="1689802383538" MODIFIED="1689802390809" LINK="https://darthcoin.substack.com/p/lnbits-nostr-market"/>
<node TEXT="Nostr coinjoin github" ID="ID_1987664817" CREATED="1689884331456" MODIFIED="1689884346191" LINK="https://gitlab.com/1440000bytes/joinstr"/>
<node TEXT="nostr blinded assets" ID="ID_167937900" CREATED="1689943078377" MODIFIED="1689943084822" LINK="https://thebitcoinmanual.com/articles/blinded-nostr-assets/"/>
<node TEXT="NIP-112 encrypted private chats" ID="ID_1880945462" CREATED="1690566380033" MODIFIED="1690566396642" LINK="https://github.com/ArcadeLabsInc/arcade/wiki/NIP-112:-Encrypted-Group-Chat"/>
<node TEXT="NIP 90 data markets" ID="ID_238125050" CREATED="1690566445074" MODIFIED="1690566453060" LINK="https://github.com/nostr-protocol/nips/pull/682"/>
<node TEXT="Key generation and management" ID="ID_1495916920" CREATED="1689945153686" MODIFIED="1689945161156">
<node TEXT="BIP85 master key javascript" ID="ID_1830854424" CREATED="1689945081488" MODIFIED="1689945092753" LINK="https://github.com/AndreasGassmann/bip85#readme">
<node TEXT="[...new Uint8Array(await crypto.subtle.digest(&apos;SHA-256&apos;, new TextEncoder().encode(&apos;&lt;your-seed-phrase-goes-here&gt;&apos;)))].map((b) =&gt; b.toString(16).padStart(2, &apos;0&apos;)).join(&apos;&apos;)" ID="ID_839898192" CREATED="1689945117877" MODIFIED="1689945129386"/>
</node>
</node>
</node>
<node TEXT="Machine learning and AI" FOLDED="true" POSITION="right" ID="ID_1310086889" CREATED="1678041885520" MODIFIED="1680205007711">
<edge COLOR="#007c7c"/>
<node TEXT="Generative art" ID="ID_891377503" CREATED="1670852982432" MODIFIED="1687853651548">
<node TEXT="Assistants and chatbots" FOLDED="true" ID="ID_250828813" CREATED="1667813144183" MODIFIED="1687766718066">
<node TEXT="assisted writing" ID="ID_1763993792" CREATED="1667815050354" MODIFIED="1667815055455">
<node TEXT="Services" ID="ID_1178530422" CREATED="1667818844596" MODIFIED="1667818849113">
<node ID="ID_1550980736" CREATED="1667815056489" MODIFIED="1667815056489"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        Jasper
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_156466968" CREATED="1667815056492" MODIFIED="1667815056492"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        Writesonic
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1144432819" CREATED="1667815056495" MODIFIED="1667815056495"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        Copysmith
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_977891728" CREATED="1667815056500" MODIFIED="1667815056500"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        Rytr
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1834407737" CREATED="1667815056502" MODIFIED="1667815056502"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        AI Writer
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_534990165" CREATED="1667815056503" MODIFIED="1667815056503"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        CopyAI
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1366130024" CREATED="1667815056505" MODIFIED="1667815056505"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        ClosersCopy
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_404028568" CREATED="1667815056507" MODIFIED="1667815056507"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li>
        Writecream
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="Self host" ID="ID_1524926727" CREATED="1667818856853" MODIFIED="1667818859669">
<node TEXT="FlanT5" ID="ID_349884911" CREATED="1667818478686" MODIFIED="1667818484168" LINK="https://huggingface.co/google/flan-t5-xxl?text=Translate+to+German%3A++My+name+is+Arthur"/>
<node TEXT="GPT-J" ID="ID_174326062" CREATED="1667818836811" MODIFIED="1667818840892" LINK="https://devforth.io/blog/gpt-j-is-a-self-hosted-open-source-analog-of-gpt-3-how-to-run-in-docker/"/>
<node TEXT="Vosk" ID="ID_734643947" CREATED="1667825164794" MODIFIED="1667825167020">
<node TEXT="Vosk 16GB local" ID="ID_1883262529" CREATED="1667825137075" MODIFIED="1667825148160" LINK="https://github.com/IlgarLunin/vosk-language-server"/>
<node TEXT="Vosk website" ID="ID_1232204300" CREATED="1667825170698" MODIFIED="1685183827279" LINK="https://alphacephei.com/vosk/server">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Unreal plugin" ID="ID_35111077" CREATED="1667825267114" MODIFIED="1685183815771" LINK="https://www.unrealengine.com/marketplace/en-US/product/offline-speech-recognition">
<icon BUILTIN="attach"/>
</node>
</node>
</node>
<node TEXT="Scripting tool" ID="ID_1450067715" CREATED="1670761617245" MODIFIED="1670761652581" LINK="https://deepmind.github.io/dramatron/">
<node TEXT="real world AI script" ID="ID_1022107894" CREATED="1670761626433" MODIFIED="1680603012525" LINK="https://stephenfollows.com/how-we-got-hired-to-create-an-ai-generated-feature-film-screenplay/"/>
</node>
<node TEXT="co-pilot" ID="ID_399800902" CREATED="1671481745379" MODIFIED="1671481753085" LINK="https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html"/>
<node TEXT="Puzzle: Creates a knowledge base or glossary from documents." ID="ID_793206223" CREATED="1674496482022" MODIFIED="1674496506233" LINK="https://www.puzzlelabs.ai/"/>
<node TEXT="Quickchat: Chatbots that talk like humans for customer relations." ID="ID_1120438326" CREATED="1674492867211" MODIFIED="1674492882714" LINK="https://www.quickchat.ai/"/>
<node TEXT="DetectGPT (curves)" ID="ID_51952279" CREATED="1675000321306" MODIFIED="1675000329709" LINK="https://ericmitchell.ai/detectgpt/"/>
<node TEXT="chatgpt styles and tips" ID="ID_666894009" CREATED="1675887131789" MODIFIED="1675887156436" LINK="https://twitter.com/Olearningcurve/status/1614794908916645888"/>
<node TEXT="Wolfram on how chatgpt works" ID="ID_125771154" CREATED="1676928174256" MODIFIED="1685183908447" LINK="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="lying lying heart of chatgpt" ID="ID_198552178" CREATED="1678031017225" MODIFIED="1680603027003" LINK="https://news.artnet.com/art-world/chatgpt-art-theory-hal-foster-2263711"/>
<node TEXT="Caption extraction" ID="ID_1792204178" CREATED="1664903670424" MODIFIED="1664903677898" LINK="https://simonwillison.net/2022/Sep/30/action-transcription/"/>
<node TEXT="cramming language model in a day" ID="ID_1400562245" CREATED="1672351778015" MODIFIED="1672351789043" LINK="https://arxiv.org/abs/2212.14034"/>
<node TEXT="Discord bot tutorial" ID="ID_690099520" CREATED="1667847921293" MODIFIED="1667847932538" LINK="https://nlpcloud.com/build-gpt-j-gpt-neox-discord-chatbot-with-nlpcloud.html"/>
<node TEXT="Elves (bots) techcrunch article" ID="ID_1994214209" CREATED="1673885471702" MODIFIED="1680603044248" LINK="https://techcrunch.com/2022/01/12/the-metaverse-will-be-filled-with-elves/"/>
<node TEXT="GPT-3 resources" ID="ID_240502139" CREATED="1670343950368" MODIFIED="1670343958847" LINK="https://www.linkedin.com/feed/update/urn:li:activity:7005874144621809666/">
<node TEXT="Unreal blueprint chatgpt" ID="ID_330994834" CREATED="1670429394079" MODIFIED="1670429404803" LINK="https://80-lv.cdn.ampproject.org/c/s/80.lv/articles/step-by-step-instruction-on-unreal-s-blueprints-generated-with-chatgpt/?amp=1"/>
<node TEXT="DRM fingerprinting" ID="ID_839229689" CREATED="1671483312610" MODIFIED="1671483322008" LINK="https://www.newscientist.com/article/2350655-openai-is-developing-a-watermark-to-identify-work-from-its-gpt-text-ai/"/>
<node TEXT="OpenChatGPT" ID="ID_1284347573" CREATED="1672696056417" MODIFIED="1672696065944" LINK="https://github.com/LAION-AI/Open-Assistant"/>
<node TEXT="political compass" ID="ID_1259185975" CREATED="1672740293774" MODIFIED="1672740299504" LINK="https://www.gptoverflow.link/question/1519492600837443584/chatgpt-political-compass"/>
<node TEXT="Using ChatGPT as a founder" ID="ID_1837672178" CREATED="1673884583896" MODIFIED="1680603052734" LINK="https://www.atomic14.com/2022/12/05/using-chatgpt-as-a-co-founder.html"/>
<node TEXT="chatgpt waitlist for pro" ID="ID_540708206" CREATED="1674310346364" MODIFIED="1674310356134" LINK="https://docs.google.com/forms/d/e/1FAIpQLScwuQEWBkxsNftEkvUgFx2Ov7pKcrOx8IUlZ241lvet7ziXCQ/viewform?fbzx=-7085331511137611549"/>
</node>
<node TEXT="Img2Prompt" ID="ID_272124356" CREATED="1664905251971" MODIFIED="1664905257340" LINK="https://replicate.com/methexis-inc#"/>
<node TEXT="Mem.ai writing support" ID="ID_806384401" CREATED="1673885551849" MODIFIED="1673885576080" LINK="https://support.mem.ai/article/97-mem-x-smart-write-and-edit#funny"/>
<node TEXT="Thundercontent: Generates all types of written" ID="ID_1121222993" CREATED="1674496260931" MODIFIED="1674496337044" LINK="https://thundercontent.com/features"/>
<node TEXT="Corpora PDF" ID="ID_1964177753" CREATED="1675873660565" MODIFIED="1675873674803" LINK="https://www.askcorpora.com/dashboard"/>
<node TEXT="contexable" ID="ID_747463615" CREATED="1675874034951" MODIFIED="1675874042780" LINK="https://www.contextable.ai/"/>
<node TEXT="New jailbreak! Proudly unveiling the tried and tested DAN 5.0 - it actually works - Returning to DAN, and assessing its limitations and capabilities. : r/ChatGPT" ID="ID_1789159287" CREATED="1678458631120" MODIFIED="1678458649595" LINK="https://www.reddit.com/r/ChatGPT/comments/10tevu1/new_jailbreak_proudly_unveiling_the_tried_and/"/>
<node TEXT="Paper on feedback React" ID="ID_1800453816" CREATED="1679156958126" MODIFIED="1679218650742" LINK="https://arxiv.org/abs/2210.03629"/>
<node TEXT="chatgpt currated links" ID="ID_270856097" CREATED="1679416766381" MODIFIED="1679416777249" LINK="https://github.com/OpenMindClub/awesome-chatgpt"/>
<node TEXT="KoboldAI assisted writing" ID="ID_744619612" CREATED="1679944483572" MODIFIED="1679944504586" LINK="https://github.com/KoboldAI/KoboldAI-Client"/>
<node TEXT="How to create Characters blog post" ID="ID_1519429675" CREATED="1687949151617" MODIFIED="1687949168961" LINK="https://www.cloudbooklet.com/how-to-create-ai-character-with-character-ai/"/>
<node TEXT="Generative storytelling" ID="ID_405116331" CREATED="1679914078194" MODIFIED="1679914078194">
<node TEXT="The AI-powered storytelling format: Unlock your best work with Tome&apos;s AI-powered storytelling format. Type in a prompt and generate entire narratives from scratch within seconds, supported by GPT-3 and AI-generated images from DALL·E 2." POSITION="right" ID="ID_83906522" CREATED="1679914078194" MODIFIED="1679914078194" LINK="https://beta.tome.app/">
<node TEXT="Tome is a new AI-powered storytelling format that makes it easy to create compelling narratives with any type of content. With Tome, you can drag-and-drop content, add video narration, and embed live content from the web, all in one place. Tomes are designed to be responsive and fit any device, so your viewers can always see your story in full fidelity. You can also share your tomes with just one click, and they will work seamlessly across all devices." ID="ID_1201572370" CREATED="1679914078195" MODIFIED="1679914078195"/>
</node>
</node>
<node TEXT="Dramatron (other)" ID="ID_1246296129" CREATED="1677783034638" MODIFIED="1680603087817" LINK="https://deepmind.github.io/dramatron/">
<node TEXT="This demo and arxiv paper are for a tool called Dramatron that uses machine learning to help with writing scripts." ID="ID_318116544" CREATED="1679519694291" MODIFIED="1679519694291"/>
</node>
<node TEXT="Making an Open Source Twitch VTuber with TTS and Language Model processing, and creating a universal Chat Platform for LLMs like Pygmalion, LLaMA and others." ID="ID_802281458" CREATED="1681031075879" MODIFIED="1685185507671" LINK="https://github.com/Project-Akiko">
<icon BUILTIN="attach"/>
</node>
<node TEXT="telegram bot concierge" ID="ID_465395642" CREATED="1681122764628" MODIFIED="1685185522000" LINK="https://github.com/RafalWilinski/telegram-chatgpt-concierge-bot">
<icon BUILTIN="attach"/>
</node>
<node TEXT="discord LLM bot with voice" ID="ID_1609269108" CREATED="1681395311031" MODIFIED="1685185522016" LINK="https://github.com/hc20k/LLMChat">
<icon BUILTIN="attach"/>
</node>
<node TEXT="BabyAGI task bot" ID="ID_344216432" CREATED="1681579250586" MODIFIED="1685185522016" LINK="https://github.com/yoheinakajima/babyagi">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Alpaca-lora-serve simple interface for chat" ID="ID_937572253" CREATED="1682021992874" MODIFIED="1682022004347" LINK="https://github.com/deep-diver/LLM-As-Chatbot"/>
<node TEXT="Performance spreadsheets" ID="ID_811442709" CREATED="1682022771104" MODIFIED="1682022780392" LINK="https://docs.google.com/spreadsheets/d/1UsbivogLMrQbBA-Fk0ESRGTrvCsknBUieSykfWn6D9Q/edit#gid=0"/>
<node TEXT="Telegram bot AutoGPT integration" ID="ID_1405168071" CREATED="1682682603257" MODIFIED="1685185533689" LINK="https://github.com/Wladastic/Auto-GPT-Telegram-Plugin">
<icon BUILTIN="attach"/>
</node>
<node TEXT="multimodal assistant paper" ID="ID_264620419" CREATED="1687766724444" MODIFIED="1687766741073" LINK="https://arxiv.org/abs/2306.08640"/>
<node TEXT="ChatGPT programming" ID="ID_1009321623" CREATED="1687335617183" MODIFIED="1687344889646">
<node TEXT="function calls blog post" ID="ID_61755906" CREATED="1687335625835" MODIFIED="1687344915768" LINK="https://cobusgreyling.medium.com/openai-function-calling-98fbf9539d2a"/>
<node TEXT="mastering plugins" ID="ID_1737241429" CREATED="1687344893516" MODIFIED="1687344906299" LINK="https://medium.com/codingthesmartway-com-blog/mastering-chatgpt-plugins-a-comprehensive-guide-for-developers-621d765f029c"/>
</node>
</node>
<node TEXT="Voice" FOLDED="true" ID="ID_1018945850" CREATED="1667813471984" MODIFIED="1667813481618">
<node TEXT="OpenAI whisper local deploy" ID="ID_1728234314" CREATED="1674746306056" MODIFIED="1685185579946" LINK="https://github.com/openai/whisper">
<icon BUILTIN="attach"/>
<node TEXT="realtime transciber" ID="ID_1542886599" CREATED="1674746768907" MODIFIED="1674746776713" LINK="https://github.com/davabase/transcriber_app/"/>
<node TEXT="high performance CPP" ID="ID_1483549425" CREATED="1681749874536" MODIFIED="1681749882281" LINK="https://github.com/ggerganov/whisper.cpp"/>
<node TEXT="30% quantised optimisation" ID="ID_1122661165" CREATED="1684481205717" MODIFIED="1684481224184" LINK="https://medium.com/@daniel-klitzke/quantizing-openais-whisper-with-the-huggingface-optimum-library-30-faster-inference-64-36d9815190e0"/>
<node TEXT="Brillbits OpenAI whisper demo with mic" ID="ID_1255728747" CREATED="1667822629228" MODIFIED="1667822642387" LINK="https://www.youtube.com/watch?v=nwPaRSlDSaY"/>
</node>
<node TEXT="Cleanvoice audio denoise" ID="ID_849446585" CREATED="1674493014058" MODIFIED="1685185582006" LINK="https://cleanvoice.ai/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Cloud voice change app" ID="ID_652434642" CREATED="1672737694000" MODIFIED="1672737702310" LINK="https://voice.ai/"/>
<node TEXT="downloadable voice generation systems" ID="ID_1118099156" CREATED="1672737648809" MODIFIED="1672737659356" LINK="https://github.com/neonbjb/tortoise-tts"/>
<node TEXT="Language AI open libraries" ID="ID_1088332487" CREATED="1667504734382" MODIFIED="1667504743340" LINK="https://txt.cohere.ai/introducing-sandbox-coheres-experimental-open-source-initiative/"/>
<node TEXT="Language practice" ID="ID_1745513471" CREATED="1674460488354" MODIFIED="1674460503841" LINK="https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain"/>
<node TEXT="MUGEN multi modal from facebook" ID="ID_1741819960" CREATED="1669837471095" MODIFIED="1669837487150" LINK="https://mugen-org.github.io/"/>
<node TEXT="Oneshot speach to text" ID="ID_1476899969" CREATED="1664912550861" MODIFIED="1664912575769" LINK="https://atosystem.github.io/blogs/speechclip"/>
<node TEXT="Record and cleanup pro audio with commodity hardware" ID="ID_907779645" CREATED="1674492957981" MODIFIED="1674492985474" LINK="https://podcastle.ai/"/>
<node TEXT="Respeecher" ID="ID_107097058" CREATED="1664902868034" MODIFIED="1664902905645" LINK="https://variety.com/2022/digital/news/james-earl-jones-darth-vader-retiring-star-wars-ai-1235382827/"/>
<node TEXT="Voice AI voices" ID="ID_651382301" CREATED="1673877708477" MODIFIED="1673877718465" LINK="https://voice.ai/"/>
<node TEXT="Voice controlled assisted creation" ID="ID_193415739" CREATED="1666082422496" MODIFIED="1666082437069" LINK="https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant/"/>
<node TEXT="Voice to text, Lopp" ID="ID_1796388227" CREATED="1673727882825" MODIFIED="1673727890611" LINK="https://blog.lopp.net/open-source-transcription-software-comparisons/"/>
<node TEXT="whisper transcriber" ID="ID_169301393" CREATED="1668099324200" MODIFIED="1668099332372" LINK="https://github.com/modal-labs/modal-examples/tree/main/misc/whisper_pod_transcriber"/>
<node TEXT="Wolfram alpha voice chatbot integration" ID="ID_52714737" CREATED="1674492775043" MODIFIED="1674492788624" LINK="https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain"/>
<node TEXT="Microsoft Vall-E voice synthesis" ID="ID_212199505" CREATED="1674681192995" MODIFIED="1674681211230" LINK="https://valle-demo.github.io/"/>
<node TEXT="Uberduck text to speech (plus own voice)" ID="ID_800118933" CREATED="1674899209206" MODIFIED="1685194106494" LINK="https://app.uberduck.ai/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Eleven labs language and text to speech" ID="ID_1093794639" CREATED="1675513664296" MODIFIED="1685194106494" LINK="https://beta.elevenlabs.io/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Uberduck open source text to speech" ID="ID_402402653" CREATED="1675940012073" MODIFIED="1680603127987" LINK="https://uberduck.ai/"/>
<node TEXT="numen voice control system in linux" ID="ID_568316787" CREATED="1676745777417" MODIFIED="1676745805565" LINK="https://numenvoice.com"/>
<node TEXT="Inworld (steam game plugin AI system) for voice chat and answer" ID="ID_1332016050" CREATED="1679399135324" MODIFIED="1680603139854" LINK="https://www.youtube.com/watch?v=DnF4WzM5LPU"/>
<node TEXT="Bark text to speech from google labs" ID="ID_426478108" CREATED="1683135420508" MODIFIED="1685194106494" LINK="https://github.com/suno-ai/bark">
<icon BUILTIN="attach"/>
</node>
<node TEXT="https://github.com/TensorSpeech/TensorFlowTTS&#xa;very configurable from what I see" ID="ID_285935732" CREATED="1683142543767" MODIFIED="1685194106494" LINK="https://github.com/TensorSpeech/TensorFlowTTS">
<icon BUILTIN="attach"/>
</node>
<node TEXT="VoiceVox engine" ID="ID_1695761546" CREATED="1683364050284" MODIFIED="1683364059773" LINK="https://www.youtube.com/watch?v=TGZV831VTpc"/>
<node TEXT="coqui-ai TTS - very good samples" ID="ID_593269390" CREATED="1685185612753" MODIFIED="1685185658276" LINK="https://github.com/coqui-ai/TTS"/>
<node TEXT="https://github.com/neonbjb/tortoise-tts" ID="ID_1370212684" CREATED="1685185677083" MODIFIED="1685185682808" LINK="https://github.com/neonbjb/tortoise-tts"/>
<node TEXT="https://github.com/CorentinJ/Real-Time-Voice-Cloning - custom voices? looks neat" ID="ID_248902865" CREATED="1685185695544" MODIFIED="1685185705981" LINK="https://github.com/CorentinJ/Real-Time-Voice-Cloning"/>
<node ID="ID_1162624413" CREATED="1685185714617" MODIFIED="1685185729834" LINK="https://github.com/rhasspy/larynx"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      <font color="#000000">https://github.com/rhasspy/larynx</font>&nbsp;- very low-spec compatible, acceptable quality
    </p>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Voice cloning local" ID="ID_1467676691" CREATED="1685195763289" MODIFIED="1685195864828" LINK="https://git.ecker.tech/mrq/ai-voice-cloning"/>
<node TEXT="Meta voicebox" ID="ID_1324050798" CREATED="1686941675145" MODIFIED="1686941688205" LINK="https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/"/>
<node ID="ID_886920386" CREATED="1687805148463" MODIFIED="1687805148463" LINK="https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Reddit post discusses the different open source voice cloning projects available, including Coqui, Tortoise, and Bark. The advantages and disadvantages of each project are briefly outlined, with ElevenLabs being noted as the best but not open source, while Tortoise is suggested as the closest open source alternative. Other tools for speech to speech and singing conversion, such as so-vits/diff-svc/rvc, are also mentioned. The post suggests that the quality of open source voice cloning projects is improving, and that there may be more options available in the future. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1953181992" CREATED="1687805148490" MODIFIED="1687805148490" LINK="https://werunbtc.com/phoenix"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This guide explains how to use the Phoenix Wallet on Android or iPhone to send and receive bitcoin using the Lightning Network. After downloading the app and creating a new wallet, users can receive bitcoin by clicking the &quot;Receive&quot; button and show their bitcoin address if the sender does not have a Lightning wallet. They can then pay any Lightning invoice by clicking the &quot;Send&quot; button, but should also back up their wallet in case their phone is lost or stolen. This can be done by clicking the settings gear icon, selecting &quot;recovery phrase,&quot; checking off two boxes, and writing down the 12 words on paper and keeping them safe. This guide provides general education on privacy and security practices when using bitcoin, but using these practices is at the user's own risk and the guide does not provide consulting or financial advice. https://werunbtc.com/phoenix
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_986533534" CREATED="1687805148509" MODIFIED="1687805148509" LINK="https://drugstorenews.com/coty-enters-metaverse-campus-global-workforce"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cosmetic company Coty has teamed up with tech company Spatial to create a virtual campus for its 11,000 global employees in the fledgling virtual world known as the metaverse. Built in 3D, the &quot;phygital&quot;, or physical and digital, campus offers a range of gamified, collaborative activities designed to engage and upskill Coty staff. Tools include avatars, text and voice chat, screen sharing and file exchange, while the system offers a rewards system based on item collection, location exploration and &quot;quest fulfilment&quot;, designed to encourage engagement and interaction across the platform. Coty's global digital chief, Jean-Denis Mariani, said he &quot;was proud to leverage Spatial’s Web3 and gaming technology...to create new immersive experiences that will provide the most interactive solutions for collaboration and co-creation.&quot; https://drugstorenews.com/coty-enters-metaverse-campus-global-workforce
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_821735761" CREATED="1687805148534" MODIFIED="1687805148534" LINK="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Retrieval-based Voice Conversion WebUI is a simple and useful voice conversion (voice changer) framework based on the VITS algorithm. It can use a small amount of voice data and still achieve good results. It incorporates a top-1 retrieval method to replace the source feature with the training set feature to avoid voice leakage, and it is easy to use with a simple web interface. It also features model fusion to change voice characteristics and the ability to integrate with the UVR5 model to quickly separate vocals and accompaniment. The project requires the installation of PyTorch and its core dependencies, and other pre-models are also needed for inference and training. The repository provides a guide to environment setup and usage, as well as links to relevant resources and contributors. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1782565303" CREATED="1687805148544" MODIFIED="1687805148544" LINK="https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses different open-source voice cloning projects and their advantages and disadvantages. The projects mentioned include Coqui, Tortoise, and Bark, with the author highlighting Coqui's unlocked platform, while Tortoise and Bark are newer transformer-based projects that can clone much more effectively with much less training and are restricted to prevent custom voice cloning. The author suggests that the ElevenLabs is currently the best voice cloning solution available, but it is not open source and can be expensive. The article also includes comments from other Reddit users, who suggest other open source options and provide additional insights into each option's strengths and weaknesses. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_26534980" CREATED="1687805148565" MODIFIED="1687805148565" LINK="https://www.nobsbitcoin.com/nostr-wallet-connect-by-alby-now-available-on-umbrel/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Blockchain company Alby has launched Nostr Wallet Connect (NWC), which allows users to import bitcoin lightning wallets into apps. According to the company, developers can offer one-click or even automated bitcoin payments with a few lines of code, and NWC enables the exchange of payment requests and lightning invoices via OAuth2 Wallet API and the Nostr Wallet Connect API. A dedicated Alby relay ensures payments and messages are not published but reliably sent to the receiver. Payments are conducted on users' behalf depending on permissions given by the user and receive a preimage back. An Umbrel app that works with NWC is also available. https://www.nobsbitcoin.com/nostr-wallet-connect-by-alby-now-available-on-umbrel/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_437410092" CREATED="1687805148619" MODIFIED="1687805148619" LINK="https://github.com/nbd-wtf/soma/blob/master/tutorial-web.md"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text provides a tutorial on how to mint an asset and send it to someone else using Soma, a decentralized cryptocurrency platform. The tutorial starts by directing the user to create a keypair for themselves and generate a MINT transaction by clicking &quot;mint&quot;. The next step involves sending the MINT transaction to a miner using a web interface and then paying the invoice using a webpage provided by the platform, which pays invoices for the user since they probably don't have a signet Lightning node. The user is then advised to keep the tab open while the miner successfully publishes the block, after which the payment is resolved, or fails. The user can also check the status of the next block the miner is trying to publish by calling &quot;get status&quot;. Once the block is mined, it is broadcasted to all Soma nodes and reflected on the explorer. The user can then go back to the platform and transfer the asset by clicking &quot;send&quot; and providing the asset ID, destination public key, and a counter. https://github.com/nbd-wtf/soma/blob/master/tutorial-web.md
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1428713061" CREATED="1687805148647" MODIFIED="1687805148647" LINK="https://werunbtc.com/phoenix"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This guide explains how to use Phoenix Wallet to send and receive bitcoin using the Lightning network, which is a faster and cheaper method. To get started, download Phoenix Wallet on your Android or iPhone and create a new wallet. To receive bitcoin using the Lightning network, click the Receive button and show a bitcoin address if the sender does not have a Lightning wallet. Once you have bitcoin in your wallet, you can pay any Lightning invoice by clicking the Send button. To backup your wallet, go to settings, click on Recovery Phrase, and write down the 12 words on paper, keeping them safe from others. It is important to note that any actions taken with this guide are done at the user's own risk, and the author shall not be liable for any financial loss suffered. https://werunbtc.com/phoenix
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1646806513" CREATED="1687805148649" MODIFIED="1687805148649" LINK="https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article provides instructions on how to use OpenAI's ChatGPT chatbot on an Android device using the Tasker app. The process involves importing a ChatGPT profile into Tasker, obtaining an API key from OpenAI, and setting up home screen shortcuts. The article also notes that ChatGPT can be run through Google Assistant with voice commands. The author suggests that while ChatGPT may not necessarily be better than Google Assistant, it can perform tasks that Google Assistant may not be capable of. https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_34552708" CREATED="1687805148661" MODIFIED="1687805148661" LINK="https://www.arkpill.me/faq"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Ark is a payment system that provides anonymity to users and operates similarly to the classic Chaumian eCash system. However, unlike eCash, every transaction made through Ark is backed by actual bitcoins, preventing the possibility of the Ark Service Provider (ASP) stealing or inflating them. Compared to Lightning, another payment network, Ark does not introduce liquidity constraints or a direct link between the sender and receiver, enabling recipients to receive payments without acquiring inbound liquidity or revealing their identity. In terms of UX, Ark mimics on-chain wallets by allowing async receiving and not introducing inbound liquidity constraints, but requires users to come online and &quot;refresh&quot; their coins every few weeks, or else the ASP can sweep the funds. Compared to validity rollups, Ark's higher throughput is due to not requiring on-chain data per transaction. If an ASP were to double-spend their pool transactions on mempool, incoming zero-conf vtxos can be used to pay lightning invoices, rendering double-spending a footgun for the service operator. A future extension of Ark can utilize a hypothetical data manipulation opcode to prevent double-spending. https://www.arkpill.me/faq
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1298685917" CREATED="1687805148723" MODIFIED="1687805148723"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Gut: Develops system personas that align with the brand identity and tone of voice, ensuring consistent communication with customers and protects its data privacy
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_474189471" CREATED="1687805148777" MODIFIED="1687805148777" LINK="https://github.com/DonGuillotine/chatGPT_whisper_AI_voice_assistant"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Voice Assistant is an AI-powered chatbot that uses several APIs to understand natural language commands and provide helpful responses. It features a wide range of capabilities, including answering general knowledge questions, providing recommendations, performing productivity tasks, and entertaining users. The Voice Assistant was built using ChatGPT, Whisper API, Gradio, and Microsoft's SpVoice TTS API, and it can be accessed through a web-based interface. The installation process involves cloning the repository and installing the required Python packages. Contributions to the project are welcome. https://github.com/DonGuillotine/chatGPT_whisper_AI_voice_assistant
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1716617311" CREATED="1687805148799" MODIFIED="1687805148799" LINK="https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Retrieval-based Voice Conversion WebUI is a voice conversion framework that uses a top-1 retrieval algorithm to eliminate voice leakage. It is capable of quickly training even on relatively poor GPUs and can achieve good results even with just 10 minutes of low noise voice data. It has a user-friendly web interface and the ability to use a model fusion system to change voice timbre. The setup recommends using Poetry and downloading the necessary pre-trained models from their Hugging Face space. It also includes additional files such as ffmpeg and ffprobe that may need to be downloaded. The WebUI can be initiated using the command &quot;python infer-web.py&quot; and Windows users can run the &quot;go-web.bat&quot; file. The project also acknowledges the contributions of related tools and libraries such as Gradio, HIFIGAN, and ContentVec. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_274696565" CREATED="1687805148902" MODIFIED="1687805148902" LINK="https://mobile.twitter.com/clamstech/status/1640810071725842432"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Clams, a Lightning Network software stack, has announced the inclusion of BOLT12 offers. This new addition signifies a new approach to Lightning Network payments with new features such as improved privacy, static reusable invoices, simple refunds, and subscriptions. To make payments using BOLT12, users can either scan a QR code or manually input the offer. Clams allows users to create BOLT12 offers through a guided creation flow and view a detailed summary of associated payments. https://mobile.twitter.com/clamstech/status/1640810071725842432
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1936322617" CREATED="1687805148951" MODIFIED="1687805148951" LINK="https://voicepen.ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          VoicePen is a tool that uses AI to convert audio or video files into blog posts and transcriptions in minutes. The service includes a transcription and SRT file generated by a top speech-to-text model, an English blog post that pulls out key topics from the audio, and the ability to convert audio in 96 different languages. Use cases include repurposing podcasts, webinars, and tutorial videos. Monthly plans are available, with options for one-time conversions. Testimonials praise the accuracy and speed of VoicePen's service. https://voicepen.ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1545458436" CREATED="1687805148952" MODIFIED="1687805148952" LINK="https://krisp.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Krisp is a software application designed to improve the productivity of online meetings by using AI-powered voice clarity and a meeting assistant to cancel background noise, echo, and accent localization. It works on both Mac and Windows platforms and processes only the user's voice on their device, unlike other solutions that transmit voice over the internet. Krisp offers a free forever plan with no credit card required and is trusted by global brands. The insights gathered from calls can be viewed by the user to improve their communication skills over time. Krisp has received recognition from various prestigious awards such as America's Most Promising AI Companies and has been awarded for its quality of support and ease of use. Krisp also offers SDK for developers, pricing and plans, and use cases such as contact centers and enterprise. The company prioritizes customers' privacy, security and offers accessible support, including video tutorials and a help center. By accepting all cookies, users consent to the storing of cookies on their device to enhance site navigation, analyze site usage and assist in the company's marketing efforts. https://krisp.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_872543360" CREATED="1687805148958" MODIFIED="1687805148958" LINK="https://cleanvoice.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cleanvoice AI is an artificial intelligence platform that assists users in editing their podcasts or audio recordings. The platform offers various features such as filler sound removal, mouth sound removal, stutter removal, and Deadair remover to make the audio recording more professional. Cleanvoice AI is multilingual and can detect filler sounds in multiple languages, including accents from various countries. The platform also allows for manual editing with assistance and offers tools like podcast mixing and background noise remover. Users can try Cleanvoice AI for free for 30 minutes without providing credit card details. However, users must accept the platform's cookie policy to use the service. https://cleanvoice.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_920906079" CREATED="1687805149076" MODIFIED="1687805149076" LINK="https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?utm_source=share&amp;amp;utm_medium=member_android&amp;amp;utm_campaign=share_via"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the potential of Central Intelligent Agents (CIAs) and the role of large language models (LLMs) and other next-generation AI technologies in enabling them. It highlights the need for businesses to have a cross-functional team, ethical guidelines, and clear objectives in deploying their own CIA. The article also suggests steps to build a solid foundation for deploying a CIA, assess organizational readiness, assemble a cross-functional team, define objectives, develop the CIA components and evaluate its performance while continuing to learn and adapt. The author discusses the potential of AI tools and voice assistants in transforming the way businesses interact with their customers and suggests that the advent of advanced AI technologies has revolutionized the shift of businesses towards a more personalized and ethically responsible approach to engaging with their customers. Finally, the article ends by highlighting the importance of experimenting through crisis and providing expert guidance tailored to specific business needs. https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?utm_source=share&amp;utm_medium=member_android&amp;utm_campaign=share_via
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="Compendium of tools" ID="ID_1001579744" CREATED="1668596101736" MODIFIED="1668596110965" LINK="https://www.futurepedia.io/"/>
<node TEXT="images" ID="ID_784164284" CREATED="1666082857502" MODIFIED="1666082859025">
<node TEXT="Stability specific tools" FOLDED="true" ID="ID_473586994" CREATED="1664897753188" MODIFIED="1685442362803" LINK="https://sdtools.org/">
<node TEXT="Stable diffusion" FOLDED="true" ID="ID_1077630529" CREATED="1664897760866" MODIFIED="1664897764541">
<node TEXT="Illustrated overview" ID="ID_1588862598" CREATED="1664910307639" MODIFIED="1664910315121" LINK="https://jalammar.github.io/illustrated-stable-diffusion/"/>
<node TEXT="Automatic1111 GUI and user guide" ID="ID_529410033" CREATED="1664985560908" MODIFIED="1685194224460" LINK="https://www.thosesixfaces.com/post/stable-diffusion-getting-started-windows">
<icon BUILTIN="attach"/>
<node TEXT="citivia browser" ID="ID_700088774" CREATED="1671909278397" MODIFIED="1671909286306" LINK="https://github.com/Vetchems/sd-civitai-browser"/>
<node TEXT="Automatic WebUI" ID="ID_1468335947" CREATED="1664903743555" MODIFIED="1664903750593" LINK="https://github.com/AUTOMATIC1111/stable-diffusion-webui"/>
</node>
<node TEXT="Vlads next SD" ID="ID_1573966749" CREATED="1688312944476" MODIFIED="1688312955120"/>
<node TEXT="InvokeAI simple interface" ID="ID_361171246" CREATED="1688312960277" MODIFIED="1688313006087" LINK="https://invoke-ai.github.io/InvokeAI/"/>
<node TEXT="ComfyUI nodes based" ID="ID_299563166" CREATED="1679844568186" MODIFIED="1685194224463" LINK="https://github.com/comfyanonymous/ComfyUI">
<icon BUILTIN="attach"/>
<node TEXT="Controlnet auto installer" ID="ID_366737013" CREATED="1688407424062" MODIFIED="1688407432098" LINK="https://github.com/Fannovel16/comfy_controlnet_preprocessors"/>
<node TEXT="LATENT Tricks - Amazing ways to use ComfyUI" ID="ID_753902586" CREATED="1688555826139" MODIFIED="1688555837973" LINK="https://www.youtube.com/watch?v=OdMtJMzjNLg"/>
<node TEXT="UI node packs on civitai" ID="ID_1761781392" CREATED="1688556638313" MODIFIED="1688556654147" LINK="https://civitai.com/tag/comfyui"/>
<node TEXT="Workflows that can be loaded" ID="ID_1499599493" CREATED="1688749094627" MODIFIED="1688749107637" LINK="https://github.com/comfyanonymous/ComfyUI_examples"/>
<node TEXT="SDXL workflow" FOLDED="true" ID="ID_1268102417" CREATED="1688831886452" MODIFIED="1688831898016" LINK="https://www.reddit.com/r/StableDiffusion/comments/14sacvt/how_to_use_sdxl_locally_with_comfyui_how_to/">
<node TEXT="{&#xa;  &quot;last_node_id&quot;: 22,&#xa;  &quot;last_link_id&quot;: 38,&#xa;  &quot;nodes&quot;: [&#xa;    {&#xa;      &quot;id&quot;: 7,&#xa;      &quot;type&quot;: &quot;CLIPTextEncode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        394,&#xa;        179&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 210,&#xa;        &quot;1&quot;: 54&#xa;      },&#xa;      &quot;flags&quot;: {&#xa;        &quot;collapsed&quot;: true&#xa;      },&#xa;      &quot;order&quot;: 8,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;clip&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;link&quot;: 5&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;text&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;link&quot;: 22,&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          }&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;links&quot;: [&#xa;            25&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CLIPTextEncode&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;text, watermark&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 13,&#xa;      &quot;type&quot;: &quot;CLIPTextEncode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        421,&#xa;        -255&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 210,&#xa;        &quot;1&quot;: 54&#xa;      },&#xa;      &quot;flags&quot;: {&#xa;        &quot;collapsed&quot;: true&#xa;      },&#xa;      &quot;order&quot;: 6,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;clip&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;link&quot;: 13&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;text&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;link&quot;: 21,&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          },&#xa;          &quot;slot_index&quot;: 1&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;links&quot;: [&#xa;            33&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CLIPTextEncode&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;text, watermark&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 12,&#xa;      &quot;type&quot;: &quot;CLIPTextEncode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        426,&#xa;        -297&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 219,&#xa;        &quot;1&quot;: 54&#xa;      },&#xa;      &quot;flags&quot;: {&#xa;        &quot;collapsed&quot;: true&#xa;      },&#xa;      &quot;order&quot;: 5,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;clip&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;link&quot;: 11&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;text&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;link&quot;: 18,&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          },&#xa;          &quot;slot_index&quot;: 1&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;links&quot;: [&#xa;            32&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CLIPTextEncode&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;beautiful scenery nature glass bottle landscape, , purple galaxy bottle,&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 18,&#xa;      &quot;type&quot;: &quot;VAEDecode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        1065,&#xa;        -334&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 210,&#xa;        &quot;1&quot;: 46&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 13,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;samples&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;link&quot;: 36&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;vae&quot;,&#xa;          &quot;type&quot;: &quot;VAE&quot;,&#xa;          &quot;link&quot;: 37&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;IMAGE&quot;,&#xa;          &quot;type&quot;: &quot;IMAGE&quot;,&#xa;          &quot;links&quot;: [&#xa;            30&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;VAEDecode&quot;&#xa;      }&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 17,&#xa;      &quot;type&quot;: &quot;KSampler&quot;,&#xa;      &quot;pos&quot;: [&#xa;        721,&#xa;        134&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 315,&#xa;        &quot;1&quot;: 262&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 9,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;model&quot;,&#xa;          &quot;type&quot;: &quot;MODEL&quot;,&#xa;          &quot;link&quot;: 27&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;positive&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;link&quot;: 24&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;negative&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;link&quot;: 25&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;latent_image&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;link&quot;: 38&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;LATENT&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;links&quot;: [&#xa;            28,&#xa;            35&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;KSampler&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        750844989320825,&#xa;        &quot;randomize&quot;,&#xa;        20,&#xa;        6,&#xa;        &quot;dpmpp_2s_ancestral&quot;,&#xa;        &quot;normal&quot;,&#xa;        1&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 8,&#xa;      &quot;type&quot;: &quot;VAEDecode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        1088,&#xa;        190&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 210,&#xa;        &quot;1&quot;: 46&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 10,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;samples&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;link&quot;: 28&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;vae&quot;,&#xa;          &quot;type&quot;: &quot;VAE&quot;,&#xa;          &quot;link&quot;: 8&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;IMAGE&quot;,&#xa;          &quot;type&quot;: &quot;IMAGE&quot;,&#xa;          &quot;links&quot;: [&#xa;            9&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;VAEDecode&quot;&#xa;      }&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 6,&#xa;      &quot;type&quot;: &quot;CLIPTextEncode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        393,&#xa;        134&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 210,&#xa;        &quot;1&quot;: 54&#xa;      },&#xa;      &quot;flags&quot;: {&#xa;        &quot;collapsed&quot;: true&#xa;      },&#xa;      &quot;order&quot;: 7,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;clip&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;link&quot;: 3&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;text&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;link&quot;: 19,&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          }&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;links&quot;: [&#xa;            24&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CLIPTextEncode&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;beautiful scenery nature glass bottle landscape, , purple galaxy bottle,&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 15,&#xa;      &quot;type&quot;: &quot;PrimitiveNode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        -66,&#xa;        -154&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 402,&#xa;        &quot;1&quot;: 188&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 1,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;STRING&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;links&quot;: [&#xa;            18,&#xa;            19&#xa;          ],&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          },&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;title&quot;: &quot;Positive Prompt&quot;,&#xa;      &quot;properties&quot;: {},&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;beautiful scenery nature glass bottle landscape, , purple galaxy bottle,&quot;&#xa;      ],&#xa;      &quot;color&quot;: &quot;#232&quot;,&#xa;      &quot;bgcolor&quot;: &quot;#353&quot;,&#xa;      &quot;shape&quot;: 4&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 16,&#xa;      &quot;type&quot;: &quot;PrimitiveNode&quot;,&#xa;      &quot;pos&quot;: [&#xa;        -64,&#xa;        85&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 398,&#xa;        &quot;1&quot;: 140&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 2,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;STRING&quot;,&#xa;          &quot;type&quot;: &quot;STRING&quot;,&#xa;          &quot;links&quot;: [&#xa;            21,&#xa;            22&#xa;          ],&#xa;          &quot;widget&quot;: {&#xa;            &quot;name&quot;: &quot;text&quot;,&#xa;            &quot;config&quot;: [&#xa;              &quot;STRING&quot;,&#xa;              {&#xa;                &quot;multiline&quot;: true&#xa;              }&#xa;            ]&#xa;          },&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;title&quot;: &quot;Negative Prompt&quot;,&#xa;      &quot;properties&quot;: {},&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;text, watermark&quot;&#xa;      ],&#xa;      &quot;color&quot;: &quot;#332922&quot;,&#xa;      &quot;bgcolor&quot;: &quot;#593930&quot;,&#xa;      &quot;shape&quot;: 4&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 9,&#xa;      &quot;type&quot;: &quot;SaveImage&quot;,&#xa;      &quot;pos&quot;: [&#xa;        1351,&#xa;        168&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 426.084228515625,&#xa;        &quot;1&quot;: 437.66387939453125&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 12,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;images&quot;,&#xa;          &quot;type&quot;: &quot;IMAGE&quot;,&#xa;          &quot;link&quot;: 9&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {},&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;base_output&quot;&#xa;      ],&#xa;      &quot;shape&quot;: 1&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 20,&#xa;      &quot;type&quot;: &quot;KSampler&quot;,&#xa;      &quot;pos&quot;: [&#xa;        681,&#xa;        -397&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 315,&#xa;        &quot;1&quot;: 262&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 11,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;model&quot;,&#xa;          &quot;type&quot;: &quot;MODEL&quot;,&#xa;          &quot;link&quot;: 34&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;positive&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;link&quot;: 32&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;negative&quot;,&#xa;          &quot;type&quot;: &quot;CONDITIONING&quot;,&#xa;          &quot;link&quot;: 33&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;latent_image&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;link&quot;: 35&#xa;        }&#xa;      ],&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;LATENT&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;links&quot;: [&#xa;            36&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;title&quot;: &quot;KSampler for refiner (like img2img)&quot;,&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;KSampler&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        151930796019195,&#xa;        &quot;randomize&quot;,&#xa;        15,&#xa;        8,&#xa;        &quot;dpmpp_2m&quot;,&#xa;        &quot;normal&quot;,&#xa;        0.25&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 11,&#xa;      &quot;type&quot;: &quot;CheckpointLoaderSimple&quot;,&#xa;      &quot;pos&quot;: [&#xa;        -32,&#xa;        -385&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 336,&#xa;        &quot;1&quot;: 98&#xa;      },&#xa;      &quot;flags&quot;: {&#xa;        &quot;collapsed&quot;: false&#xa;      },&#xa;      &quot;order&quot;: 3,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;MODEL&quot;,&#xa;          &quot;type&quot;: &quot;MODEL&quot;,&#xa;          &quot;links&quot;: [&#xa;            34&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 0&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;CLIP&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;links&quot;: [&#xa;            11,&#xa;            13&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 1&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;VAE&quot;,&#xa;          &quot;type&quot;: &quot;VAE&quot;,&#xa;          &quot;links&quot;: [&#xa;            37&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 2&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CheckpointLoaderSimple&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;sd_xl_refiner_0.9.safetensors&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 4,&#xa;      &quot;type&quot;: &quot;CheckpointLoaderSimple&quot;,&#xa;      &quot;pos&quot;: [&#xa;        -52.80264120483398,&#xa;        358&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 397,&#xa;        &quot;1&quot;: 98&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 4,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;MODEL&quot;,&#xa;          &quot;type&quot;: &quot;MODEL&quot;,&#xa;          &quot;links&quot;: [&#xa;            27&#xa;          ],&#xa;          &quot;slot_index&quot;: 0&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;CLIP&quot;,&#xa;          &quot;type&quot;: &quot;CLIP&quot;,&#xa;          &quot;links&quot;: [&#xa;            3,&#xa;            5&#xa;          ],&#xa;          &quot;slot_index&quot;: 1&#xa;        },&#xa;        {&#xa;          &quot;name&quot;: &quot;VAE&quot;,&#xa;          &quot;type&quot;: &quot;VAE&quot;,&#xa;          &quot;links&quot;: [&#xa;            8&#xa;          ],&#xa;          &quot;slot_index&quot;: 2&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;CheckpointLoaderSimple&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;sd_xl_base_0.9.safetensors&quot;&#xa;      ]&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 19,&#xa;      &quot;type&quot;: &quot;SaveImage&quot;,&#xa;      &quot;pos&quot;: [&#xa;        1366,&#xa;        -406&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 462.1468811035156,&#xa;        &quot;1&quot;: 441.9457702636719&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 14,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;inputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;images&quot;,&#xa;          &quot;type&quot;: &quot;IMAGE&quot;,&#xa;          &quot;link&quot;: 30&#xa;        }&#xa;      ],&#xa;      &quot;properties&quot;: {},&#xa;      &quot;widgets_values&quot;: [&#xa;        &quot;refiner_output&quot;&#xa;      ],&#xa;      &quot;shape&quot;: 1&#xa;    },&#xa;    {&#xa;      &quot;id&quot;: 21,&#xa;      &quot;type&quot;: &quot;EmptyLatentImage&quot;,&#xa;      &quot;pos&quot;: [&#xa;        390,&#xa;        242&#xa;      ],&#xa;      &quot;size&quot;: {&#xa;        &quot;0&quot;: 295.7807922363281,&#xa;        &quot;1&quot;: 106&#xa;      },&#xa;      &quot;flags&quot;: {},&#xa;      &quot;order&quot;: 0,&#xa;      &quot;mode&quot;: 0,&#xa;      &quot;outputs&quot;: [&#xa;        {&#xa;          &quot;name&quot;: &quot;LATENT&quot;,&#xa;          &quot;type&quot;: &quot;LATENT&quot;,&#xa;          &quot;links&quot;: [&#xa;            38&#xa;          ],&#xa;          &quot;shape&quot;: 3,&#xa;          &quot;slot_index&quot;: 0&#xa;        }&#xa;      ],&#xa;      &quot;title&quot;: &quot;Image Size\n&quot;,&#xa;      &quot;properties&quot;: {&#xa;        &quot;Node name for S&amp;R&quot;: &quot;EmptyLatentImage&quot;&#xa;      },&#xa;      &quot;widgets_values&quot;: [&#xa;        1080,&#xa;        1080,&#xa;        1&#xa;      ]&#xa;    }&#xa;  ],&#xa;  &quot;links&quot;: [&#xa;    [&#xa;      3,&#xa;      4,&#xa;      1,&#xa;      6,&#xa;      0,&#xa;      &quot;CLIP&quot;&#xa;    ],&#xa;    [&#xa;      5,&#xa;      4,&#xa;      1,&#xa;      7,&#xa;      0,&#xa;      &quot;CLIP&quot;&#xa;    ],&#xa;    [&#xa;      8,&#xa;      4,&#xa;      2,&#xa;      8,&#xa;      1,&#xa;      &quot;VAE&quot;&#xa;    ],&#xa;    [&#xa;      9,&#xa;      8,&#xa;      0,&#xa;      9,&#xa;      0,&#xa;      &quot;IMAGE&quot;&#xa;    ],&#xa;    [&#xa;      11,&#xa;      11,&#xa;      1,&#xa;      12,&#xa;      0,&#xa;      &quot;CLIP&quot;&#xa;    ],&#xa;    [&#xa;      13,&#xa;      11,&#xa;      1,&#xa;      13,&#xa;      0,&#xa;      &quot;CLIP&quot;&#xa;    ],&#xa;    [&#xa;      18,&#xa;      15,&#xa;      0,&#xa;      12,&#xa;      1,&#xa;      &quot;STRING&quot;&#xa;    ],&#xa;    [&#xa;      19,&#xa;      15,&#xa;      0,&#xa;      6,&#xa;      1,&#xa;      &quot;STRING&quot;&#xa;    ],&#xa;    [&#xa;      21,&#xa;      16,&#xa;      0,&#xa;      13,&#xa;      1,&#xa;      &quot;STRING&quot;&#xa;    ],&#xa;    [&#xa;      22,&#xa;      16,&#xa;      0,&#xa;      7,&#xa;      1,&#xa;      &quot;STRING&quot;&#xa;    ],&#xa;    [&#xa;      24,&#xa;      6,&#xa;      0,&#xa;      17,&#xa;      1,&#xa;      &quot;CONDITIONING&quot;&#xa;    ],&#xa;    [&#xa;      25,&#xa;      7,&#xa;      0,&#xa;      17,&#xa;      2,&#xa;      &quot;CONDITIONING&quot;&#xa;    ],&#xa;    [&#xa;      27,&#xa;      4,&#xa;      0,&#xa;      17,&#xa;      0,&#xa;      &quot;MODEL&quot;&#xa;    ],&#xa;    [&#xa;      28,&#xa;      17,&#xa;      0,&#xa;      8,&#xa;      0,&#xa;      &quot;LATENT&quot;&#xa;    ],&#xa;    [&#xa;      30,&#xa;      18,&#xa;      0,&#xa;      19,&#xa;      0,&#xa;      &quot;IMAGE&quot;&#xa;    ],&#xa;    [&#xa;      32,&#xa;      12,&#xa;      0,&#xa;      20,&#xa;      1,&#xa;      &quot;CONDITIONING&quot;&#xa;    ],&#xa;    [&#xa;      33,&#xa;      13,&#xa;      0,&#xa;      20,&#xa;      2,&#xa;      &quot;CONDITIONING&quot;&#xa;    ],&#xa;    [&#xa;      34,&#xa;      11,&#xa;      0,&#xa;      20,&#xa;      0,&#xa;      &quot;MODEL&quot;&#xa;    ],&#xa;    [&#xa;      35,&#xa;      17,&#xa;      0,&#xa;      20,&#xa;      3,&#xa;      &quot;LATENT&quot;&#xa;    ],&#xa;    [&#xa;      36,&#xa;      20,&#xa;      0,&#xa;      18,&#xa;      0,&#xa;      &quot;LATENT&quot;&#xa;    ],&#xa;    [&#xa;      37,&#xa;      11,&#xa;      2,&#xa;      18,&#xa;      1,&#xa;      &quot;VAE&quot;&#xa;    ],&#xa;    [&#xa;      38,&#xa;      21,&#xa;      0,&#xa;      17,&#xa;      3,&#xa;      &quot;LATENT&quot;&#xa;    ]&#xa;  ],&#xa;  &quot;groups&quot;: [&#xa;    {&#xa;      &quot;title&quot;: &quot;REFINER HERE&quot;,&#xa;      &quot;bounding&quot;: [&#xa;        -55,&#xa;        -455,&#xa;        381,&#xa;        183&#xa;      ],&#xa;      &quot;color&quot;: &quot;#3f789e&quot;&#xa;    },&#xa;    {&#xa;      &quot;title&quot;: &quot;BASE HERE&quot;,&#xa;      &quot;bounding&quot;: [&#xa;        -77,&#xa;        278,&#xa;        444,&#xa;        203&#xa;      ],&#xa;      &quot;color&quot;: &quot;#8A8&quot;&#xa;    },&#xa;    {&#xa;      &quot;title&quot;: &quot;RESULT WITHOUT REFINER&quot;,&#xa;      &quot;bounding&quot;: [&#xa;        1337,&#xa;        84,&#xa;        461,&#xa;        543&#xa;      ],&#xa;      &quot;color&quot;: &quot;#b58b2a&quot;&#xa;    },&#xa;    {&#xa;      &quot;title&quot;: &quot;RESULT WITH REFINER&quot;,&#xa;      &quot;bounding&quot;: [&#xa;        1331,&#xa;        -498,&#xa;        552,&#xa;        560&#xa;      ],&#xa;      &quot;color&quot;: &quot;#a1309b&quot;&#xa;    },&#xa;    {&#xa;      &quot;title&quot;: &quot;SDXL 0.9&quot;,&#xa;      &quot;bounding&quot;: [&#xa;        422,&#xa;        -89,&#xa;        180,&#xa;        80&#xa;      ],&#xa;      &quot;color&quot;: &quot;#8AA&quot;&#xa;    }&#xa;  ],&#xa;  &quot;config&quot;: {},&#xa;  &quot;extra&quot;: {},&#xa;  &quot;version&quot;: 0.4&#xa;}" ID="ID_427711673" CREATED="1689101584463" MODIFIED="1689101587855"/>
</node>
<node TEXT="UI tips" ID="ID_862346692" CREATED="1688833007863" MODIFIED="1688833010553">
<node ID="ID_1881064886" CREATED="1688833011390" MODIFIED="1688905125893"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          when you have a node selected, hold down shift click to move it around according to the background grid
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1906669191" CREATED="1688833011392" MODIFIED="1688905125896"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          when you have a node being resized, if you hold down shift while you click and move it, it will resize it in uniform sizes (just like the grid)
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1062658618" CREATED="1688833011405" MODIFIED="1688905125897"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          shift + selecting multiple nodes is great but can be time consuming to select a lot of nodes.
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1512061408" CREATED="1688833011409" MODIFIED="1688905125898"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          use control + left mouse button drag to marquee select many nodes at once, (and then use shift + left click drag to move them around)
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_280658853" CREATED="1688833011415" MODIFIED="1688905125899"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          in the clip text encoding, put the cursor on a word you want to add or remove weights from, and use CTRL+ Up or Down arrow and it will auto-weight it in increments of 0.05
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1541629161" CREATED="1688833011421" MODIFIED="1688905125900"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          reroute nodes can also have their color changed (so its easier to track positive and negative prompts)
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_893685547" CREATED="1688833011426" MODIFIED="1688905125900"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          right clicking on reroute nodes and selecting &quot;Show Type&quot; will show you the type of data flowing through that re-route
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1678312467" CREATED="1688833011432" MODIFIED="1688905125901"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          right clicking on reroute nodes and selecting something like &quot;Change to Vertical&quot; will switch the reroute node to be a vertical (up and down) facing node
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1724696064" CREATED="1688833011437" MODIFIED="1688905125901"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          higher CFG will mean that you will get sharper image and less &quot;creative results&quot; ie it will stick to your prompt more. good for fidelity.
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_809864918" CREATED="1688833011444" MODIFIED="1688905125901"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0">
        <p style="margin-bottom: 0px; margin-top: 0px">
          don't be afraid to play around with the samplers and schedulers, just make sure you're also playing with the amount of steps to run through on a per-sampler basis. euler often takes about 30-40 while dpmpp anything can take up to 50 steps.
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1113989348" CREATED="1688833011451" MODIFIED="1688905125902"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="margin-bottom: 0; padding-left: 0; color: rgb(242, 242, 242); font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Helvetica Neue, Arial, Apple Color Emoji, Segoe UI Emoji, Segoe UI Symbol, sans-serif; font-size: 14px; font-style: normal; font-weight: 400; letter-spacing: normal; text-align: start; text-indent: 0px; text-transform: none; word-spacing: 0px; white-space: normal; background-color: rgb(11, 20, 22)">
      <li style="margin-top: 0; margin-bottom: 0px">
        <p style="margin-bottom: 0px; margin-top: 0px">
          assuming you get the original .png file, the EXIF data will contain the ENTIRE WORKFLOW to generate the pic you're looking at. discord wipes this data, but matrix chat client does not.
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="Sytan workflow (contains js!)" ID="ID_1093548586" CREATED="1688990869034" MODIFIED="1688990884300" LINK="https://github.com/SytanSD/Sytan-SDXL-ComfyUI"/>
<node TEXT="Impact pack and youtube" ID="ID_1597975625" CREATED="1689881879554" MODIFIED="1689881887647" LINK="https://github.com/ltdrdata/ComfyUI-extension-tutorials/tree/Main/ComfyUI-Impact-Pack/workflow">
<node TEXT="youtube" ID="ID_454018950" CREATED="1689881894964" MODIFIED="1689881900860" LINK="https://www.youtube.com/watch?v=KvZ8ucBqyqw"/>
</node>
<node TEXT="Wiki full of links" ID="ID_778740156" CREATED="1690464666789" MODIFIED="1690464673861" LINK="https://wyrde.github.io/ComfyResources/nodes/"/>
<node TEXT="Tutorials from first principles" ID="ID_1209247831" CREATED="1691272039026" MODIFIED="1691272049592" LINK="https://www.youtube.com/watch?v=reimr3jZ8lI">
<node TEXT="modular workflow" ID="ID_1087375585" CREATED="1692348895026" MODIFIED="1692348900907" LINK="https://www.youtube.com/watch?v=ppE1W0-LJas"/>
</node>
<node TEXT="Detailed youtube tutorials" ID="ID_1714442533" CREATED="1692626879601" MODIFIED="1692626888521" LINK="https://www.youtube.com/@sedetweiler"/>
<node TEXT="Prompt free diffusion" ID="ID_1183318757" CREATED="1691611211460" MODIFIED="1691611219242" LINK="https://github.com/SHI-Labs/Prompt-Free-Diffusion">
<node TEXT="reference_only controlnet" ID="ID_670021420" CREATED="1691611452146" MODIFIED="1691611523321" LINK="https://gist.github.com/comfyanonymous/343e5675f9a2c8281fde0c440df2e2c6#file-workflow-json"/>
</node>
<node TEXT="Citivia autoprompt" ID="ID_1306071671" CREATED="1691952555970" MODIFIED="1691952578769" LINK="https://civitai.com/models/123358/sdvn-comfyui-workflow-autoprompt-sdxl"/>
<node TEXT="Typescript client for comfyui" ID="ID_780171162" CREATED="1692047696322" MODIFIED="1692047709258" LINK="https://github.com/itsKaynine/comfy-ui-client"/>
<node TEXT="Animation workflow" ID="ID_133870682" CREATED="1692348867537" MODIFIED="1692348875898" LINK="https://www.reddit.com/r/comfyui/comments/15s6lpr/short_animation_img2img_in_comfyui_with/"/>
<node TEXT="Complex workflow tutorials" ID="ID_1580396509" CREATED="1692349272528" MODIFIED="1692349282324" LINK="https://www.youtube.com/@ArchAi3D/videos">
<node TEXT="animation" ID="ID_1657705355" CREATED="1692349427521" MODIFIED="1692349432348" LINK="https://www.youtube.com/watch?v=js4JeDF3v4g"/>
</node>
<node TEXT="Manual" ID="ID_468398763" CREATED="1692529955266" MODIFIED="1692529961319" LINK="https://blenderneko.github.io/ComfyUI-docs/"/>
<node TEXT="Turn comfyui to python" ID="ID_1400756082" CREATED="1692545379679" MODIFIED="1692545389082" LINK="https://github.com/pydn/ComfyUI-to-Python-Extension"/>
<node TEXT="Share workflows" ID="ID_748155140" CREATED="1692634758052" MODIFIED="1692634769747" LINK="https://comfy.icu/"/>
<node TEXT="consistent character creation" ID="ID_1179024426" CREATED="1694273101349" MODIFIED="1694273114162" LINK="https://www.reddit.com/r/comfyui/comments/16ceh10/i_succeeded_to_adapt_the_tutorial_character/"/>
</node>
<node TEXT="prompt engineering links" ID="ID_1700049962" CREATED="1664897768018" MODIFIED="1664897998681">
<node TEXT="https://phraser.tech/" ID="ID_604818194" CREATED="1664898041816" MODIFIED="1664898043011"/>
<node TEXT="Artist keywords that are known to work" ID="ID_1416043227" CREATED="1664898081824" MODIFIED="1664898102728" LINK="https://docs.google.com/document/d/1SaQx1uJ9LBRS7c6OsZIaeanJGkUdsUBjk9X4dC59BaA/edit#"/>
<node TEXT="Structure tips TL;DR" ID="ID_1262501593" CREATED="1664898128232" MODIFIED="1664898135379">
<node ID="ID_404269802" CREATED="1664898137074" MODIFIED="1664898137074"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="current-comment js-friendly-links js-open-card">
      <p>
        This is absolutely the most important one.<br/>Here I clearly describe the subject, without complex jargon or words.<br/>Keep this short, concise, and direct to your subject
      </p>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1584864290" CREATED="1664898137097" MODIFIED="1674849654676"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="current-comment js-friendly-links js-open-card">
      <p>
        Instead of creating a very long phrase, break this into 2.<br/>The first line is the key one, and in the second one you can reiterate making the subject stand even more
      </p>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1668512665" CREATED="1664898137102" MODIFIED="1674849659499"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="current-comment js-friendly-links js-open-card">
      <p>
        Every subject requires specific words, use your imagination and go wild.<br/>It won't hurt using interesting words, but avoid adding 1000 of them. It won't make the image any better (actually will mess up with your prompt
      </p>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1189167452" CREATED="1664898137117" MODIFIED="1674849666358"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="current-comment js-friendly-links js-open-card">
      <p>
        In the last section, I keep the aspect ratio, resolution, quality, stylized, and so on. You can add these in the beginning but I prefer to keep my structure very simple and clean<br/>You see, you don't need much more. Literally 3/4 sections.
      </p>
    </div>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="https://promptomania.com/stable-diffusion-prompt-builder/" ID="ID_1322635981" CREATED="1664898155597" MODIFIED="1664898156862"/>
<node TEXT="https://www.krea.ai/" ID="ID_879164612" CREATED="1664898193228" MODIFIED="1664898194762"/>
<node TEXT="Lexica" ID="ID_171638226" CREATED="1664898985649" MODIFIED="1664898992116" LINK="https://lexica.art/"/>
<node TEXT="Dall-E prompt engineering" ID="ID_1024033041" CREATED="1664900374155" MODIFIED="1664900385310" LINK="https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#"/>
<node TEXT="public prompts guy" ID="ID_504958492" CREATED="1665173437668" MODIFIED="1665173452408" LINK="https://publicprompts.art/"/>
<node TEXT="Promptimize testing suite for prompts" ID="ID_1103350081" CREATED="1690294342491" MODIFIED="1690294359784" LINK="https://github.com/preset-io/promptimize"/>
</node>
<node TEXT="Photoshop plugin" ID="ID_384400872" CREATED="1664899313897" MODIFIED="1680603180589" LINK="https://christiancantrell.com/#ai-ml"/>
<node TEXT="Dreambooth retraining for faces" ID="ID_1058153455" CREATED="1664899560521" MODIFIED="1685194224463">
<icon BUILTIN="attach"/>
<node TEXT="windows instructions" ID="ID_101382993" CREATED="1664899576576" MODIFIED="1664899582487" LINK="https://pastebin.com/xcFpp9Mr"/>
<node TEXT="Discord server" ID="ID_813866246" CREATED="1664899637489" MODIFIED="1664899643453" LINK="https://discord.com/channels/1023277529424986162/"/>
<node TEXT="dreambooth for SD2" ID="ID_287920096" CREATED="1670344282381" MODIFIED="1670344301119" LINK="https://github.com/nitrosocke/dreambooth-training-guide/blob/main/README.md#how-to-fine-tune-stable-diffusion-20"/>
<node TEXT="Birme image resizer" ID="ID_242280887" CREATED="1670757093618" MODIFIED="1670757102166"/>
<node TEXT="2 hour tutorial" ID="ID_477372197" CREATED="1673462876840" MODIFIED="1673462884291" LINK="https://www.youtube.com/watch?v=Bdl-jWR3Ukc&amp;t=34"/>
<node TEXT="inject your face into any model (dreambooth)" ID="ID_1206033047" CREATED="1674997073303" MODIFIED="1674997091483" LINK="https://www.youtube.com/watch?v=s25hcW4zq4M"/>
<node TEXT="Guide for dreambooth" ID="ID_1342509735" CREATED="1675002153698" MODIFIED="1675002162198" LINK="https://github.com/nitrosocke/dreambooth-training-guide"/>
<node TEXT="Shivram" ID="ID_1508448298" CREATED="1675002177563" MODIFIED="1675002183951" LINK="https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth"/>
<node TEXT="Progen photorealism Miro guide" ID="ID_1680588214" CREATED="1675022572048" MODIFIED="1675022582421" LINK="https://miro.com/app/board/uXjVPzJyAtU=/"/>
<node TEXT="rare dreambooth tokens" ID="ID_1273926912" CREATED="1675520005229" MODIFIED="1675520011276" LINK="https://github.com/2kpr/dreambooth-tokens"/>
<node TEXT="Multi subject tokens" ID="ID_767187376" CREATED="1685364377637" MODIFIED="1685364386083" LINK="https://medium.com/@yushantripleseven/using-captions-with-dreambooth-joepenna-dreambooth-716f5b9e9866"/>
<node TEXT="tag editor" ID="ID_486682120" CREATED="1685368373973" MODIFIED="1685368380083" LINK="https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor"/>
<node TEXT="SDXL dreambooth" ID="ID_356134415" CREATED="1691619394406" MODIFIED="1691619402485" LINK="https://medium.com/@yushantripleseven/dreambooth-training-sdxl-using-kohya-ss-windows-7d2491460608"/>
</node>
<node TEXT="Textual inversion" ID="ID_890466609" CREATED="1674573518446" MODIFIED="1685194224463" LINK="https://www.reddit.com/r/StableDiffusion/comments/10gs4s2/new_expert_tutorial_for_textual_inversion_text/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Img2Img guide from reddit for face mapping" ID="ID_1110009898" CREATED="1664904467834" MODIFIED="1664904477542" LINK="https://www.reddit.com/r/StableDiffusion/comments/xgurs3/testing_img2img_batch_processing_i_convert_this/"/>
<node TEXT="textual inversion cheaper training" ID="ID_390951699" CREATED="1664905289663" MODIFIED="1664905300167" LINK="https://github.com/rinongal/textual_inversion"/>
<node TEXT="CIO blog post" ID="ID_325869687" CREATED="1665313940941" MODIFIED="1665313956636" LINK="https://danieljeffries.substack.com/p/the-turning-point-for-truly-open?sd=pf"/>
<node TEXT="google stable diffusion" ID="ID_1718968492" CREATED="1665942312094" MODIFIED="1665942324992" LINK="https://www.youtube.com/watch?v=lHcPtbZ0Mnc"/>
<node TEXT="Cross attention replace named items" ID="ID_1450288175" CREATED="1666038648012" MODIFIED="1666038665738" LINK="https://github.com/bloc97/CrossAttentionControl"/>
<node TEXT="256 x faster speedup" ID="ID_1941523888" CREATED="1670344110984" MODIFIED="1670344120199" LINK="https://the-decoder.com/stable-diffusion-could-soon-generate-images-much-faster/"/>
<node TEXT="VoltaML acceleration" ID="ID_168276559" CREATED="1670671976241" MODIFIED="1670671988239" LINK="https://github.com/VoltaML/voltaML-fast-stable-diffusion"/>
<node TEXT="Depth map into blender from SD2" ID="ID_1013855690" CREATED="1670672005392" MODIFIED="1680603260927" LINK="https://www.youtube.com/watch?v=AeDngG9kQNI"/>
<node TEXT="midjourney tweaks" ID="ID_1446173393" CREATED="1671493484051" MODIFIED="1671493498180" LINK="https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/">
<node TEXT="and another" ID="ID_1448181416" CREATED="1671493523018" MODIFIED="1671493530739" LINK="https://civitai.com/models/1253/anthro"/>
</node>
<node TEXT="Updates Pastebin" ID="ID_575155932" CREATED="1671620097920" MODIFIED="1671620106305" LINK="https://rentry.org/sdupdates3"/>
<node TEXT="Game development using SD" ID="ID_303265271" CREATED="1674847177621" MODIFIED="1680603265833" LINK="https://www.heroo.ai/"/>
<node TEXT="Wildcard manager using ChatGPT" ID="ID_1491345202" CREATED="1674847269572" MODIFIED="1685194224463" LINK="https://github.com/mattjaybe/sd-wildcards">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Depth2Img for text" ID="ID_1533775419" CREATED="1674847789160" MODIFIED="1685194224463" LINK="https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="train chat GPT to write prompts" ID="ID_1348922781" CREATED="1674986937489" MODIFIED="1674986956763" LINK="https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts"/>
<node TEXT="non destructive image manipulation using seeds" ID="ID_162101895" CREATED="1674994064457" MODIFIED="1685194224463" LINK="https://www.reddit.com/r/StableDiffusion/comments/10no6tp/non_destructive_image_variation_in_text2image/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Instruct pix2pix" ID="ID_1156318642" CREATED="1674999732342" MODIFIED="1674999791649" LINK="https://www.reddit.com/r/StableDiffusion/comments/10l74sl/instruct_pix2pix_is_amazing_inpaintingimg2img/">
<node TEXT="reddit post" ID="ID_1208211768" CREATED="1675595128713" MODIFIED="1675595138283" LINK="https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/"/>
</node>
<node TEXT="Attention heatmap for prompts (youtube)" ID="ID_1718671785" CREATED="1675685098113" MODIFIED="1675685110877" LINK="https://www.youtube.com/watch?v=XiKyEKJrTLQ"/>
<node TEXT="enormous link roundup" ID="ID_214431294" CREATED="1676135793030" MODIFIED="1676135799784" LINK="https://rentry.org/RentrySD/"/>
<node TEXT="Prompt master variations management" ID="ID_835242177" CREATED="1676216909786" MODIFIED="1676216921799" LINK="https://github.com/hoblin/prompt-master"/>
<node TEXT="panoramic world builder" ID="ID_1645571497" CREATED="1676222715501" MODIFIED="1685194224464" LINK="https://huggingface.co/congazverse/worldBuilder">
<icon BUILTIN="attach"/>
</node>
<node TEXT="GitHub - AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin: A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.,A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend. - GitHub - AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin: A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend. " ID="ID_1325053115" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/abdullahalfaraj/auto-photoshop-stablediffusion-plugin"/>
<node TEXT=" GitHub - ashawkey/stable-dreamfusion: A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion. , A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion. - GitHub - ashawkey/stable-dreamfusion: A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion.  " ID="ID_734122329" CREATED="1677783034639" MODIFIED="1680603289743" LINK="https://github.com/ashawkey/stable-dreamfusion"/>
<node TEXT="Fine tune stable diffusion" ID="ID_154896461" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/nitrosocke/dreambooth-training-guide/blob/main/readme.md#how-to-fine-tune-stable-diffusion-20"/>
<node TEXT=" GitHub - Sanster/lama-cleaner: Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures. , Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures. - GitHub - Sanster/lama-cleaner: Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures.  " ID="ID_549657441" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/sanster/lama-cleaner"/>
<node TEXT=" holovolo - immersive volumetric VR180 videos and photos, and 3D stable diffusion, for Quest and WebVR ,- " ID="ID_1811203638" CREATED="1677783034639" MODIFIED="1685194224464" LINK="https://holovolo.tv">
<icon BUILTIN="attach"/>
</node>
<node TEXT="The Illustrated Stable Diffusion  Jay Alammar  Visualizing machine learning one concept at a time." ID="ID_40424635" CREATED="1677783034639" MODIFIED="1680603310835" LINK="https://jalammar.github.io/illustrated-stable-diffusion/"/>
<node TEXT="ControlNet" ID="ID_1726669918" CREATED="1678457284814" MODIFIED="1678457289555">
<node TEXT="Multidiffusion Spatial Controls - a Hugging Face Space by weizmannscience" ID="ID_1842045825" CREATED="1678457291261" MODIFIED="1678457311316" LINK="https://huggingface.co/spaces/weizmannscience/multidiffusion-region-based"/>
<node TEXT="Testing ControlNet on Unreal Engine 5 : r/StableDiffusion" ID="ID_752833377" CREATED="1678457325629" MODIFIED="1685194224464" LINK="https://www.reddit.com/r/StableDiffusion/comments/11fpcb1/testing_controlnet_on_unreal_engine_5/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="LineArt to PhotoReal : r/StableDiffusion" ID="ID_1798317634" CREATED="1678457973694" MODIFIED="1678457985144" LINK="https://www.reddit.com/r/StableDiffusion/comments/11mzdxm/lineart_to_photoreal/"/>
<node TEXT="Convert Any Image To Lineart Using ControlNet! : r/StableDiffusion" ID="ID_449180914" CREATED="1678458004301" MODIFIED="1678458014791" LINK="https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/"/>
<node TEXT="How to use Controlnet to make INCREDIBLE fully customizable Txt2Img templates : r/StableDiffusion" ID="ID_1892159495" CREATED="1678458734422" MODIFIED="1678458744099" LINK="https://www.reddit.com/r/StableDiffusion/comments/11ah3nv/how_to_use_controlnet_to_make_incredible_fully/"/>
<node TEXT="regional prompting tutorial" ID="ID_1654149608" CREATED="1680119944703" MODIFIED="1680119955916" LINK="https://www.youtube.com/watch?v=vZ3W62dxuXI"/>
<node ID="ID_956874394" CREATED="1679506348276" MODIFIED="1679506348276" LINK="https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/" target="_new">Tencent AI just release their method and code very similar to ControlNet : r/StableDiffusion</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node TEXT="GitHub - lllyasviel/ControlNet: Let us control diffusion models!" ID="ID_1699374591" CREATED="1679913854633" MODIFIED="1680603333721">
<node TEXT="GitHub - lllyasviel/ControlNet: Let us control diffusion models!: Let us control diffusion models! Contribute to lllyasviel/ControlNet development by creating an account on GitHub." POSITION="right" ID="ID_1595380364" CREATED="1679913854633" MODIFIED="1685194224464" LINK="https://github.com/lllyasviel/ControlNet">
<icon BUILTIN="attach"/>
<node TEXT="The ControlNet project provides a way to control diffusion models. It includes a number of features to help with this, including the ability to automatically download annotators and the ability to shift the guess mode to UC disconnect in order to save memory." ID="ID_1528679652" CREATED="1679913854633" MODIFIED="1679913854633"/>
</node>
</node>
<node TEXT="Controlnet and character posing reddit post" ID="ID_781969031" CREATED="1679519694280" MODIFIED="1680111401469" LINK="https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/"/>
<node ID="ID_578327145" CREATED="1679506348276" MODIFIED="1680603347532" LINK="https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/" target="_new">Tencent AI just release their method and code very similar to ControlNet : r/StableDiffusion</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node ID="ID_1483145259" CREATED="1679506348292" MODIFIED="1679506348292" LINK="https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/" target="_new">ControlNet Character Design Workflow (links in comment) : r/StableDiffusion</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node ID="ID_1990005865" CREATED="1679506348292" MODIFIED="1679506348292" LINK="https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/"><richcontent TYPE="NODE">

<html>
            <head>
    
  </head>
            <body>
              <ul>
                <li>
                  <a href="https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/" target="_new">ControlNet Character Design Workflow (links in comment) : r/StableDiffusion</a>
                </li>
              </ul>
            </body>
          </html>
</richcontent>
</node>
<node TEXT="Twitter thread on consistency settings" ID="ID_270298916" CREATED="1680207145759" MODIFIED="1680207158392" LINK="https://twitter.com/TomLikesRobots/status/1628100062910857217"/>
<node TEXT="Smooth animation with controlnet" ID="ID_146505843" CREATED="1682414608709" MODIFIED="1685194241151" LINK="https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/">
<icon BUILTIN="attach"/>
<node TEXT="This code snippet sets up Reddit&apos;s Sentry error monitoring, which includes a function to check for various types of errors and report them accordingly. Additionally, it sets up a fetch() wrapper to add a header specifying that Sentry should always be used in &quot;sticky canary&quot; mode." ID="ID_1936676284" CREATED="1682414608710" MODIFIED="1682414608710"/>
</node>
<node TEXT="Multi scene videos using automatic1111" ID="ID_1697756559" CREATED="1682414608713" MODIFIED="1685194241164" LINK="https://www.reddit.com/r/StableDiffusion/comments/127wub7/to_make_a_video_with_multiple_scenes_using_only/">
<icon BUILTIN="attach"/>
<node TEXT="1 go to Automatic1111 Deforum in interpolation mode and generate several pics regarding the prompt theme. Deforum interpolation is not good for animation, but it is good for generating lot of pics about the same subject.&#xa;&#xa;2 select the better images and put them in Deforum Init section. Then generate the animations in 2D or 3D. For this test I used only 10 steps, so graphics are not stellar. Repeat until you have several animations, each one on its directory.&#xa;&#xa;3 select the good animations. Pick the frames and put them in a directory. Then go to Deforum Output and select Pictures interpolation , put the frames here and interpolate with value 2. With this you generate the video.&#xa;&#xa;Note: I interpolated 693 frames. Tried bigger quantities and the interpolator did not work. So this method is pretty limited." ID="ID_1626867619" CREATED="1682414608713" MODIFIED="1682414809428"/>
</node>
<node TEXT="Controlnet 1.1" ID="ID_947999605" CREATED="1682414608740" MODIFIED="1685194241164" LINK="https://www.reddit.com/r/StableDiffusion/comments/12o8qm3/finally_installed_the_newer_controlnet_models_a/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Tencent controlnet" ID="ID_1490990276" CREATED="1694350158942" MODIFIED="1694350166843" LINK="https://civitai.com/models/136070?modelVersionId=155332"/>
<node TEXT="Anime fight workflow" ID="ID_870360217" CREATED="1682601210588" MODIFIED="1685194241165" LINK="https://www.reddit.com/r/StableDiffusion/comments/12z6rh5/half_real_converting_cowboy_bebop_spike_vs/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="reference only workflow" ID="ID_1825503958" CREATED="1685910923669" MODIFIED="1685910931083" LINK="https://www.reddit.com/r/StableDiffusion/comments/1408l40/a_simple_4step_workflow_with_reference_only/"/>
<node FOLDED="true" ID="ID_308952040" CREATED="1687772398097" MODIFIED="1687780273956" LINK="https://stable-diffusion-art.com/controlnet/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-bottom: 0px; margin-top: 0px; padding-left: 0; display: block">
        <p style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px">
          <a href="https://stable-diffusion-art.com/controlnet/" target="_new" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500"><font color="black"><u><b>ControlNet v1.1: A complete guide - Stable Diffusion Art</b></u></font></a>
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
<font BOLD="false"/>
</node>
<node ID="ID_810542374" CREATED="1687805148783" MODIFIED="1687805148783" LINK="https://twitter.com/TomLikesRobots/status/1627073211656732676"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Twitter conversation includes an AI-generated video created by TomLikesRobots using canny edge detection and EbSynth technology to make a hobbit and Dumbledore contending with Sauron's will. Many people were impressed with the video and asked questions about the software and hardware used to create it. Finally, TomLikesRobots answered the questions by telling them he was using Windows 11, an RTX 3080 with 10GB VRAM and that the img2img part with ControlNet can be run online, but EbSynth might be trickier. https://twitter.com/TomLikesRobots/status/1627073211656732676
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_103410745" CREATED="1687805148890" MODIFIED="1687805148890" LINK="https://m.youtube.com/watch?v=sNcEhR65pw0&amp;amp;feature=youtu.be"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a collection of video tutorials by Albert Bozesan, demonstrating how to use AI to create various types of digital art and design, including movie and game titles, vector graphics, pixel art, 3D assets, fantasy maps, motion graphics assets, and seamless textures. Bozesan uses a software called Stable Diffusion, which is free and runs on NVIDIA GPUs. He also mentions other AI tools such as ControlNet and Dream Textures for specific tasks. The videos show step-by-step instructions on how to install and use the software, as well as practical tips and techniques for achieving different visual effects. In addition, there are videos covering the latest AI research by NVIDIA and Google, as well as challenges with other artists using AI. The text also includes a note about the use of cookies and data on YouTube, as well as options for managing privacy settings. https://m.youtube.com/watch?v=sNcEhR65pw0&amp;feature=youtu.be
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1929859491" CREATED="1687805148946" MODIFIED="1687805148946" LINK="https://twitter.com/TomLikesRobots/status/1628104009146826763?s=20"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This is a conversation between TomLikesRobots about an experiment with &quot;Ebsynth and Controlnet Img2img&quot;. TomLikesRobots has tried different noise percentage values and blends. The experiment involves switching out Elizabeth Moss for Penelope Cruz, and despite some difficulties, the team is making progress towards high-detail photorealism. https://twitter.com/TomLikesRobots/status/1628104009146826763?s=20
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_140717828" CREATED="1687805149015" MODIFIED="1687805149015" LINK="https://sketchingthefuture.github.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper proposes a novel approach to generate new video content by combining zero-shot text-to-video generation with ControlNet. The method takes multiple sketched frames as input and generates video output that matches the flow of these frames. By incorporating ControlNet to enable additional input conditions, the approach leverages the benefits of both zero-shot text-to-video generation and the robust control provided by ControlNet. Experiments demonstrate that the method excels at producing high-quality and remarkably consistent video content that accurately aligns with the user’s intended motion for the subject within the video. A demo of the approach is also available for users to try out. https://sketchingthefuture.github.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="reddit educational links" ID="ID_1436690453" CREATED="1678463375502" MODIFIED="1678463384152" LINK="https://www.reddit.com/r/StableDiffusion/comments/116ki29/comment/j97jac3/"/>
<node TEXT="Negative prompt hack tip" ID="ID_1338362004" CREATED="1678631237322" MODIFIED="1678631249066" LINK="https://www.reddit.com/r/StableDiffusion/comments/11pcsxe/just_discovered_a_useful_trick_for_getting_good/"/>
<node TEXT="Modify images with text" ID="ID_1908371261" CREATED="1678790726642" MODIFIED="1678790733713" LINK="https://github.com/justinpinkney/stable-diffusion/blob/main/notebooks/imagic.ipynb"/>
<node TEXT="Photorealism" ID="ID_1986814234" CREATED="1679139192683" MODIFIED="1679139205820" LINK="https://www.reddit.com/r/StableDiffusion/comments/11u2p0u/lazy_guide_to_photorealistic_images/"/>
<node TEXT="sdtools image v 1.6" ID="ID_1528208295" CREATED="1680510364119" MODIFIED="1680603360247" LINK="https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/"/>
<node TEXT="Character plugin" ID="ID_46763544" CREATED="1688314196315" MODIFIED="1688314202653" LINK="https://github.com/alexv0iceh/AutoChar"/>
</node>
<node TEXT="nice models" ID="ID_1325098056" CREATED="1674848151898" MODIFIED="1674848153965">
<node TEXT="Protogen3 model is nice" ID="ID_274955700" CREATED="1672737740697" MODIFIED="1672737749989" LINK="https://www.reddit.com/r/StableDiffusion/comments/100tp0v/protogenx34_has_absolutely_amazing_detail/"/>
<node TEXT="spirited away model" ID="ID_925522857" CREATED="1674848159674" MODIFIED="1674848165789" LINK="https://civitai.com/models/5378/spirited-away-general-model-15"/>
<node TEXT="SPYGB for digital artists" ID="ID_1903299411" CREATED="1674987797814" MODIFIED="1674987804612"/>
<node TEXT="project unity engine beta 2" ID="ID_1809072941" CREATED="1674987840772" MODIFIED="1674987846945"/>
<node TEXT="realistic vision 1.2" ID="ID_311104028" CREATED="1674987848390" MODIFIED="1674987856713"/>
<node TEXT="Infographic style" ID="ID_1774166728" CREATED="1674999122472" MODIFIED="1680603373391" LINK="https://civitai.com/models/5271/style-info-an-embedding-for-infographic-style-art"/>
<node TEXT="Anything v5 model on civitia" ID="ID_1215613740" CREATED="1681986461424" MODIFIED="1681986480568" LINK="https://civitai.com/models/9409/anything-v5-or-anything-diffusion-original"/>
<node TEXT="HDR landscape model" ID="ID_1090801878" CREATED="1682414608743" MODIFIED="1682418673300" LINK="https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/"/>
<node TEXT="Experience | Stable Diffusion Checkpoint | Civitai: Check the versions bellow With the release of Experience v7.0, there is now a second version you may be interested in; Realistic Experience Version..." ID="ID_556064602" CREATED="1680510364128" MODIFIED="1680510364128" LINK="https://civitai.com/models/5952"/>
</node>
<node TEXT="Arible Prompt Database https://www.arible.co/prompts" ID="ID_1778247461" CREATED="1680510364121" MODIFIED="1680510364121" LINK="https://www.arible.co/prompts"/>
<node TEXT="[Guide] Make your own Loras, easy and free | Stable Diffusion Other | Civitai: You don&apos;t need to download anything, this is a guide with online tools. Click &quot;Show more&quot; below.  Preamble Even if you don&apos;t know where to start o..." ID="ID_970935017" CREATED="1680510364124" MODIFIED="1685194287941" LINK="https://civitai.com/models/22530">
<icon BUILTIN="attach"/>
</node>
<node TEXT="sdxl lora training" FOLDED="true" ID="ID_73361890" CREATED="1690569000363" MODIFIED="1690569011611" LINK="https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-And-Use-Kohya-GUI-And-Do-Ultra-Realistic-SDXL-Training-Tutorial.md">
<node TEXT="dylora scripts" ID="ID_489318594" CREATED="1690634458170" MODIFIED="1690634487119" LINK="https://github.com/facebookresearch/dadaptation/issues/24"/>
<node TEXT="kohya fork with scripts" ID="ID_1417487012" CREATED="1690634458975" MODIFIED="1690634517767" LINK="https://github.com/bmaltais/kohya_ss#about-sdxl-training"/>
</node>
<node TEXT="SDXL universal negative prompt" ID="ID_1238632938" CREATED="1694350323767" MODIFIED="1694350331565">
<node TEXT="text, watermark, low-quality, signature, moiré pattern, downsampling, aliasing, distorted, blurry, glossy, blur, jpeg artifacts, compression artifacts, poorly drawn, low-resolution, bad, distortion, twisted, excessive, exaggerated pose, exaggerated limbs, grainy, symmetrical, duplicate, error, pattern, beginner, pixelated, fake, hyper, glitch, overexposed, high-contrast, bad-contrast" ID="ID_1722286130" CREATED="1694350333151" MODIFIED="1694350334553"/>
</node>
<node TEXT="SDXL prodigy training guide" ID="ID_977654535" CREATED="1690569336211" MODIFIED="1690569346559" LINK="https://civitai.com/articles/1022"/>
<node TEXT="Lora training interface for windows" ID="ID_1036636828" CREATED="1680510364128" MODIFIED="1685194287943" LINK="https://github.com/bmaltais/kohya_ss">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Refined model" ID="ID_129828211" CREATED="1680510364128" MODIFIED="1680511525086" LINK="https://civitai.com/models/8392/refined"/>
<node TEXT="Fine tuning with captioning and other fine tuning tricks, followfox" ID="ID_930163725" CREATED="1680510364128" MODIFIED="1685442362803" LINK="https://substack.com/profile/110613456-followfoxai"/>
<node TEXT="Negative embedding textual inversion for hands etc" ID="ID_70143381" CREATED="1680592123778" MODIFIED="1685194287943" LINK="https://huggingface.co/datasets/Nerfgun3/bad_prompt">
<icon BUILTIN="attach"/>
</node>
<node TEXT="GitHub - kpthedev/ez-text2video: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU.: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU. - GitHub - kpthedev/ez-text2video: Easily run text-to-video diffusion wit..." ID="ID_168232669" CREATED="1682414608719" MODIFIED="1682414608719" LINK="https://github.com/kpthedev/ez-text2video"/>
<node TEXT="This repository contains a ComfyUI Extension for Automated Text Generation. The extension provides nodes which can be used to automate the text generation process. The goal is to build a node-based Automated Text Generation AGI. This extension should ultimately combine all of the features of the existing text generation tools into one tool." ID="ID_1596435945" CREATED="1682414608731" MODIFIED="1685194287943" LINK="https://github.com/xXAdonesXx/NodeGPT">
<icon BUILTIN="attach"/>
</node>
<node TEXT="[R] Text-to-image Diffusion Models in Generative AI: A Survey : r/MachineLearning" ID="ID_310975718" CREATED="1682414608731" MODIFIED="1682418061232" LINK="https://www.reddit.com/r/MachineLearning/comments/12ehcez/r_texttoimage_diffusion_models_in_generative_ai_a/"/>
<node TEXT="Tutorial: Creating a Consistent Character as a Textual Inversion Embedding" ID="ID_1433269201" CREATED="1682414608741" MODIFIED="1685194287943" LINK="https://github.com/BelieveDiffusion/tutorials/discussions/3">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Segment anything webui" ID="ID_615103029" CREATED="1682414608738" MODIFIED="1682418458837" LINK="https://www.reddit.com/r/StableDiffusion/comments/12hkdy8/sd_webui_segment_everything/">
<node TEXT="segment anything training" ID="ID_1207199787" CREATED="1683888511579" MODIFIED="1683888523681" LINK="https://github.com/NielsRogge/Transformers-Tutorials/tree/master/SAM"/>
</node>
<node TEXT="Nvidia stable diffusion segment through clip" ID="ID_1210783172" CREATED="1687374586866" MODIFIED="1687374610723" LINK="https://github.com/NVlabs/ODISE"/>
<node TEXT="Overriding iphone footage with SD characters using controlnet" ID="ID_1667824171" CREATED="1682414608739" MODIFIED="1685194287943" LINK="https://www.reddit.com/r/StableDiffusion/comments/12lg8mn/override_more_experiments_overriding_the_original/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Interactive photo manipulation GAN" ID="ID_532453447" CREATED="1684482621500" MODIFIED="1685194287943" LINK="https://huggingface.co/papers/2305.10973">
<icon BUILTIN="attach"/>
</node>
<node TEXT="3d plugin for Automatic1111" ID="ID_1667414460" CREATED="1688134501132" MODIFIED="1688134515251" LINK="https://github.com/jtydhr88/sd-webui-3d-editor"/>
<node TEXT="Face replace plugin for automatic" ID="ID_1911435470" CREATED="1688315411579" MODIFIED="1688315423108" LINK="https://github.com/Gourieff/sd-webui-roop-nsfw"/>
</node>
<node TEXT="Colour palette extraction" ID="ID_713793979" CREATED="1664904506511" MODIFIED="1664904516333" LINK="https://github.com/mattdesl/gifenc"/>
<node TEXT="Text based real time image manipulation" ID="ID_1520768843" CREATED="1666082528119" MODIFIED="1666082538732" LINK="https://arxiv.org/abs/2210.09276"/>
<node TEXT="Sketch guided text to image inference" ID="ID_1110414447" CREATED="1683488746758" MODIFIED="1683488758375" LINK="https://sketch-guided-diffusion.github.io/"/>
<node TEXT="Google prompt to prompt image remodeller" ID="ID_962207046" CREATED="1666082656838" MODIFIED="1666082672585" LINK="https://www.youtube.com/watch?v=lHcPtbZ0Mnc">
<node TEXT="github" ID="ID_1265419729" CREATED="1666082700414" MODIFIED="1666082707881" LINK="https://github.com/google/prompt-to-prompt"/>
</node>
<node TEXT="Img2Prompt" ID="ID_765292025" CREATED="1664905251971" MODIFIED="1664905257340" LINK="https://replicate.com/methexis-inc#"/>
<node TEXT="eDiffi nvidia text to image" ID="ID_122994262" CREATED="1667504786418" MODIFIED="1667504806557" LINK="https://deepimagination.cc/eDiffi/"/>
<node TEXT="Image to caption" ID="ID_419748284" CREATED="1667504934586" MODIFIED="1667504941179" LINK="https://laion.ai/blog/laion-coco/"/>
<node TEXT="lama image cleanup" ID="ID_654983322" CREATED="1667685762207" MODIFIED="1667685769600" LINK="https://github.com/Sanster/lama-cleaner"/>
<node TEXT="upscalers" ID="ID_737953265" CREATED="1670750013294" MODIFIED="1670750022521" LINK="https://upscale.wiki/wiki/Model_Database">
<node TEXT="upscayl" ID="ID_1026333075" CREATED="1672495084677" MODIFIED="1672495091654" LINK="https://github.com/upscayl/upscayl"/>
</node>
<node TEXT="Google Muse" ID="ID_1605213866" CREATED="1673874752212" MODIFIED="1673874761770" LINK="https://www.infoq.com/news/2023/01/google-muse-text-to-image/"/>
<node TEXT="Flair generate photo shoots of products" ID="ID_1202289419" CREATED="1674493058820" MODIFIED="1674493082075" LINK="https://flair.ai/"/>
<node TEXT="Vector graphics from text" ID="ID_42908688" CREATED="1674493111175" MODIFIED="1685194361590" LINK="https://illustroke.com/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Simple stock image generator" ID="ID_1503543281" CREATED="1674504367928" MODIFIED="1674504383483" LINK="https://stockimg.ai/"/>
<node TEXT="Patterned: Generates royalty-free patterns." ID="ID_662691490" CREATED="1674495090618" MODIFIED="1674495105478" LINK="https://www.patterned.ai/"/>
<node TEXT="Cleanup.picture: Removes objects, defects, people or text from your images." ID="ID_1501363905" CREATED="1674505592688" MODIFIED="1674505615344" LINK="https://cleanup.pictures/"/>
<node TEXT="Looka: Generates brand names and logos." ID="ID_1575236714" CREATED="1674505660629" MODIFIED="1674505672766" LINK="https://looka.com/"/>
<node TEXT="CLIP interrogator and prompt engineering colab" ID="ID_380962755" CREATED="1674987587806" MODIFIED="1674987608652" LINK="https://github.com/pharmapsychotic/clip-interrogator"/>
<node TEXT="Prompt management engine (local and cloud) (promptlayer)" ID="ID_748850393" CREATED="1675516994201" MODIFIED="1675517010659" LINK="https://magniv.notion.site/PromptLayer-Docs-db0e6f50cacf4564a6d09824ba17a629"/>
<node TEXT="Composer stable diffusion TYPE model" ID="ID_788479410" CREATED="1677429612585" MODIFIED="1677429650295" LINK="https://github.com/damo-vilab/composer"/>
<node TEXT="Multi-diffusion panoramas" ID="ID_111303126" CREATED="1677174991243" MODIFIED="1677175010495" LINK="https://multidiffusion.github.io/"/>
<node TEXT="coherent panoramas paper" ID="ID_740522378" CREATED="1686331491655" MODIFIED="1686331503786" LINK="https://syncdiffusion.github.io/"/>
<node TEXT="UX design AI" ID="ID_373116807" CREATED="1675968502824" MODIFIED="1680603417055" LINK="https://www.usegalileo.ai/"/>
<node TEXT="pix2pix-3D: 3D-aware Conditional Image Synthesis" ID="ID_293533626" CREATED="1678456407238" MODIFIED="1680603422054" LINK="http://www.cs.cmu.edu/~pix2pix3D/"/>
<node TEXT="HuggingFace Demo for /ELITE: new fine-tuning technique that can be trained in less than a second/ now available : r/StableDiffusion" ID="ID_723442535" CREATED="1678460478282" MODIFIED="1685194361590" LINK="https://www.reddit.com/r/StableDiffusion/comments/11mzxyu/huggingface_demo_for_elite_new_finetuning/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="GIGAgan" ID="ID_931080134" CREATED="1678739740917" MODIFIED="1685194361590" LINK="https://mingukkang.github.io/GigaGAN/">
<icon BUILTIN="attach"/>
<node TEXT="implementation" ID="ID_339128832" CREATED="1678740209089" MODIFIED="1678740215868" LINK="https://github.com/lucidrains/gigagan-pytorch"/>
</node>
<node TEXT="GitHub - danielgatis/rembg: Rembg is a tool to remove images background (other)" ID="ID_47708134" CREATED="1678463114802" MODIFIED="1678463114802" LINK="https://github.com/danielgatis/rembg">
<node TEXT="Other. The text is a description of a new product called the &quot;Meta 2&quot; which is a headset that allows users to interact with a computer using their hands." ID="ID_675411488" CREATED="1679519694300" MODIFIED="1679519694300"/>
</node>
<node TEXT="GitHub - kanewallmann/Dreambooth-Stable-Diffusion: Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion (tweaks focused on training faces) (other)" ID="ID_1795979951" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/kanewallmann/dreambooth-stable-diffusion"/>
<node TEXT="GitHub - sedthh/pyxelate: Python class that generates pixel art from images (other)" ID="ID_1312830829" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/sedthh/pyxelate"/>
<node TEXT="GitHub - upscayl/upscayl:  Upscayl - Free and Open Source AI Image Upscaler for Linux, MacOS and Windows built with Linux-First philosophy. (other)" ID="ID_931150798" CREATED="1677783034639" MODIFIED="1685194361590" LINK="https://github.com/upscayl/upscayl">
<icon BUILTIN="attach"/>
</node>
<node TEXT="GitHub - YuxinWenRick/hard-prompts-made-easy: Contribute to YuxinWenRick/hard-prompts-made-easy development by creating an account on GitHub." ID="ID_815082051" CREATED="1679914078194" MODIFIED="1679914078194" LINK="https://github.com/YuxinWenRick/hard-prompts-made-easy">
<node TEXT="This repository contains a tool for gradient-based discrete optimization, which can be used to find the optimal solution for a given problem. The tool is designed to be easy to use, and includes a number of features to make the process of finding the optimal solution easier." ID="ID_458090170" CREATED="1679914078194" MODIFIED="1679914078194"/>
</node>
<node TEXT="Civitai Helper: SD Webui Civitai Extension | Stable Diffusion Other | Civitai: Now, we finally have a Civitai SD webui extension!! Update: 1.5.7 is here, if you&apos;re using localization extension, like Asian lanuage UI, you need ..." ID="ID_1510704663" CREATED="1679841790208" MODIFIED="1679841790208" LINK="https://civitai.com/models/16768/civitai-helper-sd-webui-civitai-extension">
<node TEXT="The Civitai Helper is a Civitai extension that allows for stable diffusions of other Civitai extensions. It also includes an animation which rotates and scales the extension icon." ID="ID_285075498" CREATED="1679841790209" MODIFIED="1679841790209"/>
</node>
<node TEXT="GitHub - YuxinWenRick/hard-prompts-made-easy: Contribute to YuxinWenRick/hard-prompts-made-easy development by creating an account on GitHub." ID="ID_1727484901" CREATED="1679913854623" MODIFIED="1679913854623" LINK="https://github.com/YuxinWenRick/hard-prompts-made-easy">
<node TEXT="This repository contains code for a gradient-based discrete optimization method. The method is designed to make it easy to find hard prompts, which are useful for training machine learning models." ID="ID_664556399" CREATED="1679913854623" MODIFIED="1679913854623"/>
</node>
<node TEXT="StableSam meta segmentation plus SD inpainting" ID="ID_69345444" CREATED="1681397798684" MODIFIED="1681397819652" LINK="https://twitter.com/abhi1thakur/status/1645669023726592007"/>
<node TEXT="New Feature: &quot;ZOOM ENHANCE&quot; for the A111 WebUI. Automatically fix small details like faces and hands! : r/StableDiffusion https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/" ID="ID_446340750" CREATED="1680097753098" MODIFIED="1685194361590">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Realtime scribble" ID="ID_64922768" CREATED="1681763458151" MODIFIED="1681763465059" LINK="https://github.com/houseofsecrets/SdPaint"/>
<node TEXT="latent labs 360 images lora" ID="ID_114391930" CREATED="1685819001317" MODIFIED="1685819012263" LINK="https://civitai.com/models/10753/latentlabs360"/>
<node TEXT="Kandinsky model" ID="ID_931090656" CREATED="1686427558771" MODIFIED="1686427564265">
<node TEXT="finetuned 2.1" ID="ID_1363838469" CREATED="1686427565935" MODIFIED="1686427574539" LINK="https://www.reddit.com/r/StableDiffusion/comments/13hgpo2/kandinsky_21_fine_tune/"/>
</node>
<node TEXT="QR codes" ID="ID_511958419" CREATED="1686430538981" MODIFIED="1686430579200" LINK="https://www.youtube.com/watch?v=IntRn96C4l4"/>
<node TEXT="DragGan image editing through drag points" ID="ID_274554525" CREATED="1687809992499" MODIFIED="1687810008652" LINK="https://github.com/XingangPan/DragGAN"/>
<node TEXT="Faster CPP clip" ID="ID_768889563" CREATED="1687850018314" MODIFIED="1687850025989" LINK="https://github.com/monatis/clip.cpp"/>
<node TEXT="animateDiff" ID="ID_1379649887" CREATED="1689189466535" MODIFIED="1689189496731" LINK="https://github.com/guoyww/animatediff/"/>
<node TEXT="diffbar image sharpen" ID="ID_172155027" CREATED="1694209855746" MODIFIED="1694209866023" LINK="https://github.com/XPixelGroup/DiffBIR?ref=aiartweekly"/>
</node>
<node TEXT="video" ID="ID_725587435" CREATED="1666082854143" MODIFIED="1666082856696">
<node TEXT="Interpolation and interframe consistency" ID="ID_945312699" CREATED="1682669980208" MODIFIED="1685194361590">
<icon BUILTIN="attach"/>
<node TEXT="controlnet and ebsynth temporal consistency" ID="ID_1332474865" CREATED="1676746068074" MODIFIED="1680603485057" LINK="https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/"/>
<node TEXT="Motion-Conditioned Diffusion Model for Controllable Video Synthesis" ID="ID_1141176345" CREATED="1682669997475" MODIFIED="1682670016565" LINK="https://tsaishien-chen.github.io/MCDiff/"/>
<node TEXT="Interframe consistency is now here" ID="ID_103732244" CREATED="1664906450002" MODIFIED="1680603466314" LINK="https://twitter.com/cut_pow/status/1576748659051749377"/>
<node TEXT="Interpolation between two frames" ID="ID_1447562624" CREATED="1666082835958" MODIFIED="1666082845512" LINK="https://film-net.github.io/"/>
<node TEXT="FILM frame interpolator" ID="ID_1537998901" CREATED="1678457595895" MODIFIED="1680603462261" LINK="https://film-net.github.io/"/>
</node>
<node TEXT="Runway AI video editing" ID="ID_1363822516" CREATED="1664901905746" MODIFIED="1664901915766" LINK="https://www.youtube.com/c/RunwayML">
<node TEXT="" ID="ID_1513507036" CREATED="1686474719753" MODIFIED="1686474719753"/>
<node TEXT="Gen2 examples" ID="ID_191649085" CREATED="1686474720348" MODIFIED="1686474730105">
<node TEXT="vienna with prompts" ID="ID_1289497254" CREATED="1686474730469" MODIFIED="1686474736707" LINK="https://www.linkedin.com/posts/dr-andreas-fraunberger_marketinginnovation-digitaltourism-ar-ugcPost-7073039429417730048-BKfQ?utm_source=share&amp;utm_medium=member_desktop"/>
</node>
</node>
<node TEXT="Video slowmo and enhance" ID="ID_684563557" CREATED="1665244086278" MODIFIED="1665244098892" LINK="http://zeyuan-chen.com/VideoINR/"/>
<node TEXT="deforum stable diffusion video" ID="ID_1911425729" CREATED="1664904346344" MODIFIED="1664904359507" LINK="https://github.com/HelixNGC7293/DeforumStableDiffusionLocal"/>
<node TEXT="Phenaki" ID="ID_772882282" CREATED="1664904370813" MODIFIED="1664904378073" LINK="https://phenaki.video/"/>
<node TEXT="Collaborative video pipeline" ID="ID_957392327" CREATED="1665144667576" MODIFIED="1683795924007"/>
<node TEXT="Magicvideo (faster)" ID="ID_546360816" CREATED="1669113608980" MODIFIED="1669113619291" LINK="https://magicvideo.github.io/"/>
<node TEXT="Production ready re aging" ID="ID_1003945997" CREATED="1670344212419" MODIFIED="1680603468822" LINK="https://studios.disneyresearch.com/2022/11/30/production-ready-face-re-aging-for-visual-effects/"/>
<node TEXT="distilled models for 25fps" ID="ID_1794971568" CREATED="1670870533459" MODIFIED="1670870546781" LINK="https://arxiv.org/abs/2202.00512"/>
<node TEXT="Stable warpfusion" ID="ID_1050055214" CREATED="1673288206516" MODIFIED="1685194361590" LINK="https://www.linkedin.com/posts/rainisto_stablediffusion-musicvideo-remix-activity-7018207241522614272-YT1y?utm_source=share&amp;utm_medium=member_desktop">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Video talking heads from text service" ID="ID_837813814" CREATED="1673893697236" MODIFIED="1680603474417" LINK="https://www.synthesia.io/"/>
<node TEXT="Tune a video" ID="ID_1740764892" CREATED="1674217050132" MODIFIED="1674217058063" LINK="https://tuneavideo.github.io/"/>
<node TEXT="Vidyo: Generates videos for social networks from longer videos." ID="ID_1276675577" CREATED="1674495276632" MODIFIED="1674495296912" LINK="https://vidyo.ai/"/>
<node TEXT="Stylegan-T video transformer from google" ID="ID_456448062" CREATED="1674555959216" MODIFIED="1674555972800" LINK="https://sites.google.com/view/stylegan-t"/>
<node TEXT="Houdini" ID="ID_599575488" CREATED="1674773558274" MODIFIED="1680603482614" LINK="https://github.com/proceduralit/StableDiffusion_Houdini"/>
<node TEXT="Dream Mix video to video remix" ID="ID_578221247" CREATED="1675601984362" MODIFIED="1675602005626" LINK="https://dreamix-video-editing.github.io/"/>
<node TEXT="RIFE frame interpolation" ID="ID_1444324508" CREATED="1675685482603" MODIFIED="1685194392461" LINK="https://github.com/megvii-research/ECCV2022-RIFE">
<icon BUILTIN="attach"/>
<node TEXT="example github for sd" ID="ID_1354049347" CREATED="1685912145988" MODIFIED="1685912156348" LINK="https://github.com/vladmandic/rife"/>
</node>
<node TEXT="Synthesia corporate video generation" ID="ID_361060148" CREATED="1675871165644" MODIFIED="1680603487998" LINK="https://www.youtube.com/watch?v=4uzzD9sD-PI"/>
<node TEXT="pix2pixHD nextframe google colab" ID="ID_943366348" CREATED="1676746173759" MODIFIED="1685194392463" LINK="https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Pix2PixHD_Next_Frame_Prediction.ipynb">
<icon BUILTIN="attach"/>
</node>
<node TEXT="minecraft demo codebase" ID="ID_1824034109" CREATED="1667736191180" MODIFIED="1667736209221" LINK="https://github.com/TSFSean/InvokeAI-DiffusionCraftAI"/>
<node TEXT="animation from mixamo" ID="ID_1001594434" CREATED="1670361083331" MODIFIED="1670361116823" LINK="https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/"/>
<node TEXT="Intel enhance photorealism in realtime" ID="ID_1434453296" CREATED="1672775572005" MODIFIED="1680603493058" LINK="https://github.com/isl-org/PhotorealismEnhancement"/>
<node TEXT="custom SD video to video script" ID="ID_409846633" CREATED="1678458684027" MODIFIED="1678458694095">
<node TEXT="Testing a custom video2video script I&apos;m working on. (These used RealisticVision1.4 &amp; ControlNet) : r/StableDiffusion" ID="ID_1057816892" CREATED="1678458701555" MODIFIED="1678458711134" LINK="https://www.reddit.com/r/StableDiffusion/comments/11iviep/testing_a_custom_video2video_script_im_working_on/"/>
</node>
<node TEXT="consistency tools for character tooning" ID="ID_1518307224" CREATED="1678791494050" MODIFIED="1678791512850" LINK="https://www.reddit.com/r/StableDiffusion/comments/11okvc8/how_about_another_joke_murraaaay/"/>
<node TEXT="Alibaba system" ID="ID_238798981" CREATED="1693325011971" MODIFIED="1693325018226">
<node TEXT="website" ID="ID_496887923" CREATED="1693325019524" MODIFIED="1693325024467" LINK="https://videocomposer.github.io/"/>
<node TEXT="github" ID="ID_802502441" CREATED="1693325031070" MODIFIED="1693325033588" LINK="https://github.com/damo-vilab/videocomposer"/>
<node TEXT="model cards" ID="ID_441805428" CREATED="1693325043090" MODIFIED="1693325046948" LINK="https://huggingface.co/damo-vilab/MS-Image2Video"/>
</node>
<node TEXT="9 new tools" ID="ID_625725563" CREATED="1679386590831" MODIFIED="1679386595795" LINK="https://twitter.com/mreflow/status/1637957302073565184"/>
<node TEXT="Automatic1111 plugin" ID="ID_684803674" CREATED="1679389746431" MODIFIED="1679389755428" LINK="https://www.reddit.com/r/StableDiffusion/comments/11w0ba9/modelscope_17b_text2video_model_is_now_available/"/>
<node TEXT="Next frame prediction with controlnet" ID="ID_659280656" CREATED="1677708635594" MODIFIED="1680259740648" LINK="https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/"/>
<node TEXT="Will smith eating spaghetti" ID="ID_2867639" CREATED="1680097753104" MODIFIED="1680259758721" LINK="https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/"/>
<node TEXT="Transform Video to Animation in Stable Diffusion | How to Install + BEST Consistency Settings: Learn how to use AI to create animations from real videos. We&apos;ll use Stable Diffusion and other tools for maximum consistencyProject Files:https://bit.ly/3..." ID="ID_348866462" CREATED="1679913854633" MODIFIED="1679913854633" LINK="https://www.youtube.com/watch?v=sVmi2Yp43c0&amp;t=22"/>
<node TEXT="How to Use ModelScope text2video with Automatic1111’s Stable Diffusion Web UI | kombitz: Enable the Extension Click on the Extension tab and then click on Install from URL. Enter https://github.com/deforum-art/sd-webui-modelscope-text2video in the URL box and click on Install. Click on Installed and click on Apply and restart UI. Go to your stable-diffusion-webui/models folder and create a folder called ModelScope and then create a folder called t2v under ModelScope. This is your models folder for text2video." ID="ID_306058251" CREATED="1680097753104" MODIFIED="1680603512172" LINK="https://www.kombitz.com/2023/03/28/how-to-use-modelscope-text2video-with-automatic1111s-stable-diffusion-web-ui/">
<node TEXT="This article provides instructions on how to use ModelScope&apos;s text2video feature with Automatic1111&apos;s Stable Diffusion Web UI." ID="ID_1051741896" CREATED="1680097753104" MODIFIED="1680097753104"/>
</node>
<node TEXT="GitHub - Picsart-AI-Research/Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators: Text-to-Image Diffusion Models are Zero-Shot Video Generators - GitHub - Picsart-AI-Research/Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators" ID="ID_330375041" CREATED="1680097753105" MODIFIED="1680097753105" LINK="https://github.com/Picsart-AI-Research/Text2Video-Zero">
<node TEXT="The Picsart-AI-Research/Text2Video-Zero repository contains code for a text-to-image diffusion model that can be used to generate videos from text input. The model is a zero-shot video generator, meaning that it does not require any training data in order to generate videos." ID="ID_1815422778" CREATED="1680097753105" MODIFIED="1680097753105"/>
</node>
<node TEXT="LVDM for long video creation" ID="ID_451278606" CREATED="1680722585690" MODIFIED="1685194392464" LINK="https://yingqinghe.github.io/LVDM/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="The Text2Room algorithm generates textured 3D meshes from a given text prompt by leveraging pre-trained 2D text-to-image models. The core idea is to select camera poses that will result in a seamless, textured 3D mesh. The algorithm iteratively fuses scene frames with the existing geometry to create the final mesh. Evaluation shows that the algorithm is able to generate room-scale 3D geometry with compelling textures from only text as input." ID="ID_636858382" CREATED="1682414608712" MODIFIED="1682414734557" LINK="https://lukashoel.github.io/text-to-room/"/>
<node TEXT="The VMesh system models a scene with a triangular mesh and a sparse volume for efficient view synthesis. It is trained on multi-view images of an object to create a contiguous representation of the object&apos;s surface and volume. This representation is then used to generate a simplified triangular mesh and a sparse volume, which can be stored and rendered efficiently. The system is designed for real-time applications and can render at 2K 60FPS on common consumer devices." ID="ID_845494242" CREATED="1682414608714" MODIFIED="1685194411165" LINK="https://bennyguo.github.io/vmesh/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Temporal stable automatic plugin" ID="ID_1703807934" CREATED="1682414608759" MODIFIED="1682416892506" LINK="https://www.reddit.com/r/StableDiffusion/comments/12sd4bi/results_from_latest_version_of_temporal_stable/"/>
<node TEXT="We present a method for high-resolution video synthesis using latent diffusion models (LDMs). Our approach first pre-trains an LDM on images, then introduces a temporal dimension to the latent space diffusion model and fine-tunes it on encoded image sequences (i.e. videos). We focus on two real-world applications: simulation of in-the-wild driving data and creative content creation with text-to-video modeling. Our method achieves state-of-the-art performance on real driving videos of 512 x 1024 resolution. Additionally, our approach can leverage off-the-shelf pre-trained image LDMs, turning the publicly available, state-of-the-art text-to-image LDM Stable Diffusion into an efficient and expressive text-to-video model." ID="ID_1407888785" CREATED="1682414608756" MODIFIED="1685194411165" LINK="https://buff.ly/41FgQrb">
<icon BUILTIN="attach"/>
</node>
<node TEXT="This script allows for the automation of video stylization using StableDiffusion and ControlNet." ID="ID_39029923" CREATED="1682414608756" MODIFIED="1682417078611" LINK="https://github.com/volotat/SD-CN-Animation"/>
<node TEXT="Really easy videos in A1111" ID="ID_734299805" CREATED="1682414608753" MODIFIED="1682417261186" LINK="https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/"/>
<node TEXT="Dancer 4 keyframes, low noise, controlnet approach" ID="ID_318340329" CREATED="1682414608743" MODIFIED="1685194411167" LINK="https://www.reddit.com/r/StableDiffusion/comments/12nwpdx/dancer_4_keyframes_guide_and_source_files_for/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Flicker free video workflow paper (good!)" ID="ID_364096103" CREATED="1686735601648" MODIFIED="1686735618654" LINK="https://anonymous-31415926.github.io/"/>
<node TEXT="Pika labs" ID="ID_1115654170" CREATED="1689164404382" MODIFIED="1689164408594" LINK="https://twitter.com/pika_labs"/>
<node TEXT="Realtime lip-sync API" ID="ID_1489328683" CREATED="1689766715510" MODIFIED="1689766725530" LINK="https://getsynchronicity.io/"/>
<node TEXT="ms image to video on huggingface" ID="ID_262919220" CREATED="1693481368982" MODIFIED="1693481387165" LINK="https://huggingface.co/spaces/fffiloni/MS-Image2Video"/>
<node TEXT="model to video blender modules" ID="ID_832126939" CREATED="1693481404145" MODIFIED="1693481414476" LINK="https://github.com/tin2tin/Generative_AI"/>
<node TEXT="videocomposer in python 3.9" ID="ID_1727630616" CREATED="1694339833947" MODIFIED="1694339852295" LINK="https://github.com/mindspore-lab/mindone/tree/master/examples/videocomposer"/>
<node TEXT="motionagent image to video" ID="ID_1204350998" CREATED="1694339911740" MODIFIED="1694339919837" LINK="https://github.com/modelscope/motionagent"/>
</node>
<node TEXT=" human stuff" ID="ID_540648079" CREATED="1665662906939" MODIFIED="1672595098630">
<node TEXT="Volumetric primitives (MVP) avatar representation of Lombardi et al. [2021]." ID="ID_917082420" CREATED="1665662948623" MODIFIED="1665662972723" LINK="https://dl.acm.org/doi/abs/10.1145/3528233.3530740"/>
<node TEXT="Single shot vertex fitting" ID="ID_208977071" CREATED="1667724423435" MODIFIED="1667724435308" LINK="https://arxiv.org/abs/2205.06254"/>
<node TEXT="Meshcapade virtual humans" ID="ID_1227330492" CREATED="1670410390620" MODIFIED="1680603524844" LINK="https://meshcapade.com/"/>
<node TEXT="AI video actor" ID="ID_149878234" CREATED="1670671908592" MODIFIED="1670671948231" LINK="https://share.synthesia.io/a5a12c73-09cb-4455-b007-147ae4b1effb"/>
<node TEXT="text to human motion" ID="ID_774594158" CREATED="1670683730024" MODIFIED="1680603527765" LINK="https://ofa-sys.github.io/MoFusion/"/>
<node TEXT="text to speech to simulated speaking movement" ID="ID_324255258" CREATED="1670766380082" MODIFIED="1670766396017" LINK="https://talkshow.is.tue.mpg.de/"/>
<node TEXT="nerf avatars" ID="ID_927092701" CREATED="1671581796865" MODIFIED="1680603529993" LINK="https://www.linkedin.com/posts/reneschulte_nerf-deeplearning-metaverse-activity-7010898662465617921-56P_?utm_source=share&amp;utm_medium=member_desktop"/>
<node TEXT="chatgpt to avatar" ID="ID_1840711453" CREATED="1672433914004" MODIFIED="1680603531848" LINK="https://twitter.com/IntuitMachine/status/1608690077139599360"/>
<node TEXT="toonify code and model" ID="ID_547479116" CREATED="1672495824812" MODIFIED="1672495836738" LINK="https://www.mmlab-ntu.com/project/vtoonify/"/>
<node TEXT="Talking head modifier" ID="ID_589161929" CREATED="1672595103944" MODIFIED="1672595114259" LINK="https://github.com/Meta-Portrait/MetaPortrait"/>
<node TEXT="AI face studio" ID="ID_150520328" CREATED="1669019222412" MODIFIED="1669019234340" LINK="https://www.d-id.com/"/>
<node TEXT="MoveAI" ID="ID_1300501383" CREATED="1664904666552" MODIFIED="1664904669020"/>
<node TEXT="wifi based pose estimation" ID="ID_45003651" CREATED="1673728355612" MODIFIED="1673728363932" LINK="http://arxiv.org/pdf/2301.00250.pdf"/>
<node TEXT="Microsoft sculpted avatars" ID="ID_616872142" CREATED="1672739494340" MODIFIED="1680603543604" LINK="https://3d-avatar-diffusion.microsoft.com/?utm_campaign=AI%20Art%20Weekly&amp;utm_medium=email&amp;utm_source=Revue%20newsletter#/"/>
<node TEXT="ML realtime UE facial expresssions" ID="ID_441327084" CREATED="1673875694218" MODIFIED="1680603545800" LINK="https://80.lv/articles/ziva-dynamics-announces-a-new-ml-trained-facial-rigging-service/"/>
<node TEXT="Disney face aging" ID="ID_528822265" CREATED="1673885603382" MODIFIED="1673885610615" LINK="https://studios.disneyresearch.com/2022/11/30/production-ready-face-re-aging-for-visual-effects/"/>
<node TEXT="Gestures from speech" ID="ID_1074731713" CREATED="1673885730533" MODIFIED="1685194526081" LINK="https://talkshow.is.tue.mpg.de/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Volucap volumentric deep fakes" ID="ID_606217833" CREATED="1674228146552" MODIFIED="1680603555092" LINK="https://volucap.com/"/>
<node TEXT="FlawlessAI cloud facial plus language translattion" ID="ID_1336984567" CREATED="1674655637324" MODIFIED="1680603556545" LINK="https://www.flawlessai.com/"/>
<node TEXT="language to animated character" ID="ID_1034750063" CREATED="1676627605326" MODIFIED="1676627616259" LINK="https://masterpiecestudio.com/blog/announcing-generative-animations"/>
<node TEXT="instant phone to unreal face opensource" ID="ID_1771768434" CREATED="1677959650481" MODIFIED="1685194526081" LINK="https://github.com/JimWest/MeFaMo">
<icon BUILTIN="attach"/>
</node>
<node TEXT="consistent pose and angles in stable diffusion" ID="ID_1025905641" CREATED="1678010064953" MODIFIED="1678010184401" LINK="https://www.youtube.com/watch?v=zgj24gTjQtY"/>
<node TEXT="Generating Consistent Characters using Stable Diffusion" ID="ID_37449781" CREATED="1678025867055" MODIFIED="1685194526081" LINK="https://www.youtube.com/watch?v=XWJGmNW15A4">
<icon BUILTIN="attach"/>
</node>
<node TEXT="consistent characters" ID="ID_27806221" CREATED="1678025964256" MODIFIED="1678025971936" LINK="https://www.youtube.com/watch?v=Ig1S2guCfKM"/>
<node TEXT="character turnarounds SD" ID="ID_669169064" CREATED="1678026016382" MODIFIED="1685194526081" LINK="https://www.youtube.com/watch?v=-iwPVUzAWzk">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Decoupling humans from backgrounds" ID="ID_1017887969" CREATED="1678040566784" MODIFIED="1678040575703" LINK="https://github.com/vye16/slahmr"/>
<node TEXT="Hybrid ML humans for mobile" ID="ID_1790527709" CREATED="1677324540618" MODIFIED="1678039159748">
<node ID="ID_462042049" CREATED="1677324551581" MODIFIED="1677324564420"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="contents-2MsGLg">
      <div id="message-content-1079000811318812742" class="markup-eYLPri messageContent-2t3eCI">
        You can very plausibly do this with controlnet and openpose type stuff and get a smoother 2d experience on the screen
      </div>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_702544593" CREATED="1677324551584" MODIFIED="1677324551584"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="contents-2MsGLg">
      <div id="message-content-1079000989610283130" class="markup-eYLPri messageContent-2t3eCI">
        effectively server side work though so becomes harder for the modding side
      </div>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1837027199" CREATED="1677324551590" MODIFIED="1677324551590"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="contents-2MsGLg">
      <div id="message-content-1079001213984591922" class="markup-eYLPri messageContent-2t3eCI">
        the advantage is there's a ready baked mod community for the PC engine interface (people who will really want to do this stuff)
      </div>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_32716891" CREATED="1677324551595" MODIFIED="1677324551595"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="contents-2MsGLg">
      <div id="message-content-1079001578956132422" class="markup-eYLPri messageContent-2t3eCI">
        you'd have two products running on one infrastrature. Object, scene, openpose layer (server side) driven by the AI. Server side render layer pushing interactive video to mobile, and a direct object, scene, openpose API interface on the same payment plans for the ML modding community
      </div>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_729177990" CREATED="1677324551595" MODIFIED="1677324551595"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <div class="contents-2MsGLg">
      <div id="message-content-1079001659209945199" class="markup-eYLPri messageContent-2t3eCI">
        i think that could be pretty elegant and it gives you MUCH faster iteration loops
      </div>
    </div>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1977207050" CREATED="1677324551603" MODIFIED="1677324551603"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    plus it's pure honey for investors because it sidesteps the internal doubts they have about 3D on devices
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="MoGen avatar control" ID="ID_1602419905" CREATED="1693649025842" MODIFIED="1693649033261" LINK="https://www.youtube.com/watch?v=jkkSqMsZLJE"/>
<node TEXT="Gaze estimation from images" ID="ID_1146748302" CREATED="1692528213483" MODIFIED="1692528221100" LINK="https://github.com/deepinsight/insightface/tree/master/reconstruction/gaze"/>
<node TEXT="Alphapose" ID="ID_495250363" CREATED="1694011043646" MODIFIED="1694011048717" LINK="https://github.com/MVIG-SJTU/AlphaPose"/>
<node TEXT="Instant avatars from 60s of video" ID="ID_1893061619" CREATED="1687982045387" MODIFIED="1687982054937" LINK="https://github.com/tijiang13/InstantAvatar"/>
<node TEXT="Expressive human avatars" ID="ID_1947109485" CREATED="1680184286342" MODIFIED="1685194526081" LINK="https://github.com/Skype-line/X-Avatar">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (other)" ID="ID_500759644" CREATED="1678463114800" MODIFIED="1685194526081" LINK="https://moygcc.github.io/vid2avatar/">
<icon BUILTIN="attach"/>
<node TEXT="This text describes a system for reconstructing 3D avatars from videos in uncontrolled settings, i.e. &quot;in the wild.&quot; The system is Self-supervised, meaning that it does not require labeled data, and uses scene decomposition to break the video down into manageable chunks. The objective is to create a realistic, life-like avatar that can be used for a variety of purposes.Category: machine learning" ID="ID_1928395369" CREATED="1679519694300" MODIFIED="1679519694300"/>
</node>
<node TEXT="FLEX: Full-Body Grasping Without Full-Body Grasps - Columbia Computer Vision Lab (other)" ID="ID_1957626376" CREATED="1678463114812" MODIFIED="1685194526081" LINK="https://flex.cs.columbia.edu/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Apple facial relighting" ID="ID_1883226798" CREATED="1681820250264" MODIFIED="1681820257512" LINK="https://machinelearning.apple.com/research/neural-3d-relightable"/>
<node TEXT="Controlnet face model for SD1.5" ID="ID_1868580444" CREATED="1682414608762" MODIFIED="1682416708859" LINK="https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/"/>
<node TEXT="Nvidia audio2face" ID="ID_974829253" CREATED="1685743075347" MODIFIED="1685743090274" LINK="https://www.nvidia.com/en-us/omniverse/apps/audio2face/"/>
<node TEXT="Generative 3D head" ID="ID_1381250774" CREATED="1687726601323" MODIFIED="1687726619822" LINK="https://sizhean.github.io/panohead"/>
<node TEXT="DisCo dance, pose, and backgrounds from single image" ID="ID_1516799035" CREATED="1688634251917" MODIFIED="1688634271200" LINK="https://github.com/Wangt-CN/DisCo"/>
<node TEXT="Face swaps" ID="ID_216327225" CREATED="1692529543920" MODIFIED="1692529546766">
<node TEXT="video" ID="ID_921149289" CREATED="1689884422664" MODIFIED="1689884430869" LINK="https://www.youtube.com/watch?v=QGrCkjfWpfU"/>
<node TEXT="Roop unleashed" ID="ID_715893687" CREATED="1689889036406" MODIFIED="1689889045231" LINK="https://github.com/C0untFloyd/roop-unleashed#installation"/>
<node TEXT="Reactor face swap" ID="ID_123155679" CREATED="1692529533610" MODIFIED="1692529538829" LINK="https://github.com/Gourieff/sd-webui-reactor"/>
<node TEXT="mtb face swap" ID="ID_866211313" CREATED="1692529581003" MODIFIED="1692529587374" LINK="https://github.com/melMass/comfy_mtb#face-detection--swapping"/>
<node TEXT="Facefusion" ID="ID_785377413" CREATED="1693500464554" MODIFIED="1693500492250" LINK="https://docs.facefusion.io/"/>
<node TEXT="Reactor Node" ID="ID_381722547" CREATED="1693500474180" MODIFIED="1693500479781" LINK="https://github.com/Gourieff/comfyui-reactor-node#standalone"/>
<node TEXT="facechain" ID="ID_351574091" CREATED="1693825631387" MODIFIED="1693825635869" LINK="https://github.com/modelscope/facechain"/>
</node>
<node TEXT="HQ faceswap" ID="ID_474413607" CREATED="1691245363948" MODIFIED="1691245377086" LINK="https://github.com/NNNNAI/VGGFace2-HQ"/>
<node TEXT="github subjects" ID="ID_1100504209" CREATED="1689885847394" MODIFIED="1689885852626" LINK="https://github.com/topics/comfyui"/>
<node TEXT="" ID="ID_1653046811" CREATED="1689889031173" MODIFIED="1689889031173"/>
</node>
<node TEXT="3d geometry" FOLDED="true" ID="ID_1121639807" CREATED="1666082867542" MODIFIED="1680184792083">
<node TEXT="The Make-It-3D algorithm can create high-fidelity 3D content from only a single image. It uses a two-stage optimization pipeline, first optimizing a neural radiance field by incorporating constraints from the reference image and diffusion prior, and then transforming the coarse model into textured point clouds. Extensive experiments demonstrate that the algorithm outperforms prior works, resulting in faithful reconstructions and impressive visual quality." ID="ID_1704055505" CREATED="1680097753096" MODIFIED="1688378944609" LINK="https://make-it-3d.github.io/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Vox-E: The paper presents a method for text-guided voxel editing of 3D objects, which is demonstrated on a variety of real-world scenes. The edited results are compared to the initial grid, showing the effectiveness of the method. Additionally, a refinement stage is shown to further improve the results for local edits." ID="ID_1462012636" CREATED="1680097753094" MODIFIED="1688378923572" LINK="https://etaisella.github.io/htmlTutorial2.github.io-index.html/results_real.html"/>
<node TEXT="The Text2Room algorithm generates 3D meshes from a given text prompt by synthesizing a sequence of images from different poses. The core idea is to select viewpoints such that the content of each image can be fused into a seamless, textured 3D mesh. The algorithm iteratively fuses scene frames with the existing geometry to create a seamless mesh. Unlike existing works that focus on generating single objects or zoom-out trajectories from text, our method generates complete 3D scenes with multiple objects and explicit 3D geometry." ID="ID_1744351741" CREATED="1680510364119" MODIFIED="1688378827241" LINK="https://lukashoel.github.io/text-to-room/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="The VMesh system models a scene with a triangular mesh and a sparse volume for efficient view synthesis. It is trained on multi-view images of an object in three stages. First, a contiguous form of the representation is learned, where the surface part is modeled by a neural signed distance field, and the volume part is modeled by a neural density field. Then, the learned signed distance field is fixed and a triangular mesh is extracted from it as a substitution to be rendered jointly with the neural density field. Finally, the neural networks are dropped and the system is discretized to get the final assets for efficient storage and rendering. The triangular mesh is simplified and UV-parametrized, and the neural density field is first voxelized and pruned to a sparse volume, which is then organized by perfect spatial hashing to support fast indexing and compact storage. The system is able to render at 2K 60FPS on common consumer devices with high fidelity." ID="ID_1351588631" CREATED="1680510364121" MODIFIED="1688378841422" LINK="https://bennyguo.github.io/vmesh/"/>
<node TEXT="The 3DFuse framework enables robust text-to-3D generation by incorporating 3D awareness into pretrained 2D diffusion models. This is achieved by first constructing a coarse 3D structure of a given text prompt, and then utilizing projected, view-specific depth maps as a condition for the diffusion model. Additionally, a training strategy is introduced that enables the 2D diffusion model to learn to handle the errors and sparsity within the coarse 3D structure for robust generation, as well as a method for ensuring semantic consistency throughout all viewpoints of the scene." ID="ID_984339174" CREATED="1680097753094" MODIFIED="1688378863085" LINK="https://ku-cvlab.github.io/3DFuse/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="The text discusses a system for creating realistic one-shot mesh-based human head avatars. The system uses a single photograph to estimate the head mesh, including person-specific details in both the facial and non-facial parts, as well as the neural texture encoding, local photometric and geometric details. The avatars are rigged and can be rendered using a deep rendering network. The main idea of the system is to use a neural texture map to represent both the geometry and appearance. This texture is estimated from a single source image using a texture encoder. Facial blendshape parameters and camera parameters are also estimated using a pre-trained system for facial reconstruction. The neural texture and head mesh are then fed into a head reconstruction pipeline, which predicts displacements to the input head mesh. A combination of a geometry autoencoding network and a local geometry decoding MLP is used to predict these displacements.The reconstructed mesh is used for neural rendering to produce photo-realistic images. The system uses a standard deferred neural rendering pipeline, where a neural texture is rendered instead of a regular RGB texture and decoded into the image via an image-to-image network.The system is evaluated through experiments and is found to perform competitively in terms of head geometry recovery and the quality of renders, particularly for cross-person reenactment.In addition to the full non-linear model, a simplified parametric model with a linear basis of offsets is also considered. This model is trained to predict the linear coefficients from an input image and is faster than the full ROME model. The linear model is then integrated with existing parametric models.The text concludes with a BibTeX citation for the paper and mentions that the website is based on nerfies." ID="ID_1026727909" CREATED="1688463443294" MODIFIED="1688463443294" LINK="https://samsunglabs.github.io/rome/"/>
<node TEXT="This text appears to be a collection of YouTube video titles and descriptions. It is not possible to summarize this content without further context or specific information about the videos themselves." ID="ID_578705545" CREATED="1688463443294" MODIFIED="1688463443294" LINK="https://www.youtube.com/watch?v=uboj01Gfy1A"/>
<node TEXT="The text is a webpage containing information about a motion model for image animation. It provides options for users to input a source image and a driving video, and then generates a new image animation based on those inputs. The webpage also offers examples, an API, and versions of the model. It states that predictions run on Nvidia T4 GPU hardware and typically complete within 51 seconds. The text includes links to the GitHub repository, a paper about the model, a license, a demo, and additional resources. The webpage also provides links to information about the project, such as the home, documentation, terms, privacy policy, and contact details." ID="ID_1422202028" CREATED="1688463443294" MODIFIED="1688463443294" LINK="https://replicate.com/yoyo-nb/thin-plate-spline-motion-model"/>
<node TEXT="The paper titled VoxGRAF: Fast 3D-Aware Image Synthesis with Sparse Voxel Grids introduces a novel approach for fast and 3D-consistent generative modeling. State-of-the-art 3D-aware generative models use coordinate-based MLPs to parameterize 3D radiance fields. However, querying an MLP for every sample along each ray results in slow rendering. To address this issue, the authors propose using sparse voxel grid representations for efficient rendering.The proposed method disentangles the foreground object, which is modeled in 3D, from the background, which is modeled in 2D. This allows for a compact representation of the scene and scalability to higher voxel resolutions. Unlike existing approaches, the proposed method requires only a single forward pass to generate a full 3D scene. As a result, it enables efficient rendering from arbitrary viewpoints while maintaining 3D consistency and high visual fidelity.The paper describes the following key components of the VoxGRAF method:1. 3D-aware Image Synthesis: The goal is to generate realistic 3D scenes from the viewpoint of a virtual camera. By utilizing sparse voxel grids, the method can efficiently represent the scene and render it from any desired viewpoint.2. Sparse Voxel Grids: Instead of using coordinate-based MLPs, the method employs sparse voxel grid representations. This allows for efficient querying of the scene geometry and appearance information, leading to faster rendering.3. Background Removal: To obtain a compact representation of the scene, the method disentangles the foreground object from the background. The foreground object is modeled in 3D, while the background is modeled in 2D. This separation enables scalability to higher voxel resolutions.4. Latent Interpolation: The method allows for smooth transition between different scenes by performing latent interpolation. By interpolating the learned latent codes of different scenes, it is possible to generate new, intermediate scenes with coherent transitions.The paper concludes by providing a citation for referencing the VoxGRAF method. It includes the authors&apos; names, the title of the paper, the journal (ARXIV), and the year of publication (2022).In summary, VoxGRAF proposes a fast and efficient method for 3D-aware image synthesis using sparse voxel grids. By disentangling the foreground object from the background and utilizing a single forward pass, the method achieves high visual fidelity and 3D consistency in rendering." ID="ID_817821056" CREATED="1688463443295" MODIFIED="1688463443295" LINK="https://katjaschwarz.github.io/voxgraf/"/>
<node TEXT="The text is a README file for the CLIP-Forge project, which focuses on zero-shot text-to-shape generation. The goal of the project is to generate shapes based on natural language descriptions, but the lack of paired text and shape data at a large scale makes it challenging. CLIP-Forge proposes a two-stage training process that utilizes an unlabelled shape dataset and a pre-trained image-text network (CLIP). This method avoids expensive inference optimization and allows for the generation of multiple shapes for a given text.The README provides installation instructions for setting up the CLIP-Forge environment, including creating an anaconda environment, installing PyTorch and torchvision, and downloading the necessary data, classifier, and model. The training process is then explained, involving two stages: training the autoencoder and training with CLIP. Separate instructions are provided for point cloud code.Inference instructions are also given for generating shape renderings based on text queries. The README includes examples of command lines for generating shape renderings, calculating accuracy, and calculating FID (Fréchet Inception Distance). It also provides tips for optimal results, such as using different threshold values, using synonyms and text augmentation, and limiting queries to the ShapeNet categories.The README concludes by mentioning upcoming releases, such as the point cloud code and pretrained models for point cloud experiments, as well as other related projects and papers.Overall, CLIP-Forge is a project that tackles the problem of text-to-shape generation and provides a simple yet effective method for zero-shot generation. The README file contains detailed instructions for setting up the environment, training the models, and performing inference, as well as additional resources and upcoming releases." ID="ID_1953399135" CREATED="1688463443295" MODIFIED="1688463443295" LINK="https://github.com/autodeskailab/clip-forge"/>
<node TEXT="The authors of this paper propose a technique called CLIP-Mesh for generating 3D models using only a text prompt as input. Their approach does not require any 3D supervision and can be used to create 3D assets that correspond to the input text and can be used in games or modeling applications.The key idea behind CLIP-Mesh is to deform a control shape of a surface along with its texture map and normal map to obtain the desired 3D model. This deformation is achieved by comparing the input text with differentiably rendered images of the 3D model using a pretrained CLIP model. Unlike previous works that focused on stylization or required training of generative models, CLIP-Mesh performs optimization on mesh parameters directly to generate the shape, texture, or both.To ensure that the optimization produces realistic meshes and textures, the authors introduce several techniques. They use image augmentations and a pretrained prior model that generates CLIP image embeddings based on a text embedding. These techniques help constrain the optimization process and ensure that the generated meshes and textures are plausible.The authors provide a detailed explanation of the CLIP-Mesh technique in the paper, including the mathematical formulation and optimization process. They also describe an evaluation of their method using various text prompts and compare the results with ground truth 3D models. The results show that CLIP-Mesh is able to generate high-quality 3D models that accurately reflect the input text prompts.The paper also includes an analysis of the limitations of CLIP-Mesh and suggests possible future directions for improvement. For example, the authors note that the current method may struggle with complex or ambiguous text prompts, and propose using reinforcement learning or incorporating user feedback to address these challenges.Overall, CLIP-Mesh presents a novel approach for generating 3D models from text prompts without the need for 3D supervision. The method relies on a pretrained CLIP model and performs optimization on mesh parameters to generate realistic shapes and textures. The technique has the potential to be widely applicable in various industries, including gaming and modeling applications." ID="ID_434960467" CREATED="1688463443296" MODIFIED="1688463443296" LINK="https://paperswithcode.com/paper/text-to-mesh-without-3d-supervision-using"/>
<node TEXT="The text is a conversation thread on GitHub about a project called Dream Textures. The project includes the addition of a Project Dream Texture operator, which uses depth to image projection to apply a texture onto a mesh using a text prompt. The conversation includes comments from the project owner and other contributors discussing changes and updates to the project code. They address issues related to model compatibility, face selection, error messages, dependency installation, and more. The conversation also includes approvals from reviewers and the merging of code changes." ID="ID_1761767470" CREATED="1688463443296" MODIFIED="1688463443296" LINK="https://github.com/carson-katri/dream-textures/pull/409"/>
<node TEXT="This text is a message from Twitter about the use of cookies on their platform. It emphasizes that people on Twitter are often the first to know about what&apos;s happening, and it encourages users to log in or sign up for an account.The message states that Twitter and its partners use cookies to enhance the user experience and support their business. It explains that some cookies are necessary for using the service and ensuring its proper functionality.The text offers more information about controlling cookie settings. Users have the option to accept all cookies or refuse non-essential cookies. It also acknowledges that there may be occasional technical issues and suggests trying to reload the page if something goes wrong.In summary, Twitter is reminding users of the importance of their platform for staying updated and urging them to take advantage of the benefits by logging in or signing up. They also inform users about the use of cookies and provide options for managing cookie settings." ID="ID_1990877137" CREATED="1688463443296" MODIFIED="1688463443296" LINK="https://twitter.com/TomLikesRobots/status/1603884188326940674"/>
<node TEXT="The text is a README file for a GitHub repository called scene-scale-diffusion. The repository contains code and resources for a project focused on generating 3D data on a scene-scale using diffusion models. The project aims to generate 3D scenes consisting of multiple objects, as opposed to current diffusion research that focuses on generating one object at a time.The authors propose representing a scene using discrete class labels, which allows for assigning multiple objects into semantic categories. They extend discrete diffusion models to learn scene-scale categorical distributions. They also validate that a latent diffusion model can reduce computation costs for training and deploying. This work is claimed to be the first to apply discrete and latent diffusion for 3D categorical data on a scene-scale.The authors also propose a semantic scene completion task, where a conditional distribution is learned using the diffusion model. The condition is a partial observation in a sparse point cloud. The experiments show that the diffusion models not only generate reasonable scenes but also outperform a discriminative model in the scene completion task.The instructions in the README file provide information on the dataset used, training options, and visualization of results. The dataset used is called CarlaSC cartesian dataset. Training options include multi-GPU support, different modes for discrete and latent diffusion models, and various parameters settings. The visualization of results can be done using the provided utils/table.py/visualization function, with the option to utilize open3d for easier visualization.The README file also acknowledges that the project is based on other codebases, including Multinomial Diffusion, MotionSC, and Cylinder3D.Overall, the project focuses on generating 3D scenes with multiple objects using diffusion models, extending current research in the field. It proposes a novel approach using discrete and latent diffusion models and demonstrates promising results in scene generation and completion tasks. The repository provides code, datasets, and resources for reproducing and building upon the proposed methods." ID="ID_1992208643" CREATED="1688463443297" MODIFIED="1688463443297" LINK="https://github.com/zoomin-lee/scene-scale-diffusion"/>
<node TEXT="The 3D Highlighter is a system that localizes semantic regions on 3D shapes based on text descriptions. It is able to place seemingly unrelated concepts in meaningful locations on the shape, such as a necklace on a horse or shoes on an alien. The system can interpret out-of-domain localizations, allowing it to add clothing to a bare 3D animal model, for example.The system contextualizes the text description using a neural field and colors the corresponding region of the shape using a probability-weighted blend. It utilizes a pre-trained CLIP encoder for neural optimization, eliminating the need for 3D datasets or annotations. This makes the 3D Highlighter highly flexible and capable of producing localizations on various input shapes.The Neural Highlighter component of the system maps each point on the input mesh to a probability. The mesh is then colored using a probability-weighted blend and rendered from multiple views. The weights of the neural highlighter are guided by the similarity between the CLIP embeddings of the augmented images and the input text.The 3D Highlighter demonstrates the ability to localize different text-specified regions on the same mesh and disambiguate similar but distinct target text specifications. It also showcases global semantic understanding, correctly localizing regions with nearly identical geometry in the localization region.The system has various applications, such as achieving localized stylization of meshes by applying predefined colors and textures to specific regions. It can also compute the localization of multiple regions and composite different styles together on a single mesh. Additionally, the 3D Highlighter can be used for geometric edits, allowing manipulation of the mesh&apos;s geometry through operations like extrusion, stretching, deletion, and selection.However, there are limitations to the system. The strength of the supervision signal can vary, leading to differing results between runs. When the supervision signal is weaker, the optimization is more sensitive to non-determinism, resulting in more variable highlighted regions. Despite this limitation, the 3D Highlighter remains robust to different seeds in certain cases.The paper provides a gallery of results showcasing additional mesh and prompt combinations, demonstrating the capabilities of the 3D Highlighter system." ID="ID_1598459578" CREATED="1688463443298" MODIFIED="1688463443298" LINK="https://threedle.github.io/3DHighlighter/"/>
<node TEXT="The text describes a research project conducted by NVIDIA and the University of Toronto focusing on compressing feature grids in neural approximations of scalar and vector fields. These feature grids are commonly used in neural networks to improve accuracy and efficiency but come at the cost of increased memory consumption. The researchers propose a dictionary method for compressing these feature grids, reducing memory consumption by up to 100x and enabling a multiresolution representation for out-of-core streaming.The researchers introduce a vector-quantized auto-decoder (VQ-AD) method to encode and compress a 3D signal in a hierarchical representation. They demonstrate the effectiveness of their method by showing two example neural radiance fields after streaming from 5 to 8 levels of their underlying octrees. The sizes shown represent the total bytes streamed, including the cost of coarser levels. In comparison, prior methods like Neural Radiance Fields (NeRF) require significantly more data to be transferred before anything can be drawn.The research also includes experiments with compressing different models, such as the Notre Dame and Sakura models, at different levels of detail. They showcase a 30-second fast-forward video of the streaming process. The research abstract further explains the formulation of the dictionary optimization as a vector-quantized auto-decoder problem, allowing for discrete neural representations in the absence of direct supervision and with dynamic topology and structure.The paper provides additional information on the research project, including links to the paper, code, and videos related to the research. It also features figures that visually demonstrate the effectiveness of the proposed method, such as a comparison of uncompressed and compressed feature grids, the compression of geometry, and a qualitative comparison of static and learned indices.The research also presents a rate-distortion curve comparing different methods on the &apos;Night Fury&apos; RTMV scene, showcasing the variable-bitrate and dynamic scaling capabilities of their compressed architecture. In addition, tables display baseline references, comparisons between different quantization methods, and the effects of learning codebook indices.The authors acknowledge the contributions and assistance of several individuals in the project. The website for the research is derived from the website for the NGLOD project.In summary, the research focuses on compressing feature grids in neural approximations of scalar and vector fields, proposing a dictionary method called VQ-AD to achieve significant memory reduction and enable multiresolution representations for streaming and level of detail. The paper provides detailed results, figures, and tables to support the effectiveness of the proposed approach, and the authors acknowledge the contributions of others in the project." ID="ID_1812781382" CREATED="1688463443298" MODIFIED="1688463443298" LINK="https://nv-tlabs.github.io/vqad/"/>
<node TEXT="The paper titled Pretrained Diffusion Models for Unified Human Motion Synthesis explores the development of a single unified model for generating human motion. Traditional approaches involve separate models for different motion synthesis tasks, but this paper investigates the feasibility of a unified model that combines skills learned from multiple tasks and utilizes multiple data sources without overfitting.The proposed framework, called MoFusion, incorporates a Transformer backbone that enables the inclusion of diverse control signals through cross attention. The backbone is pretrained as a diffusion model to support multi-granularity synthesis, ranging from completing motion for a specific body part to generating whole-body motion. Additionally, MoFusion employs a learnable adapter to handle the differences between the default skeletons used in pretraining and the fine-tuning data.The paper highlights the importance of pretraining for scaling the model size without overfitting and presents empirical results demonstrating MoFusion&apos;s potential in various tasks such as text-to-motion synthesis, motion completion, and the mixing of multiple control signals in a zero-shot manner.The keywords associated with the paper include diffusion models, multitask pretraining, zero-shot generalization, human motion synthesis, text-to-motion, music-to-dance, motion in-betweening, body-part editing, and inverse kinematics.The paper was authored by Jianxin Ma, Shuai Bai, and Chang Zhou from DAMO Academy, Alibaba Group. The citation for the paper is included at the end.Please note that the video and additional resources mentioned in the abstract are not provided in this text." ID="ID_202135404" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://ofa-sys.github.io/MoFusion/"/>
<node TEXT="The paper presents a new method called OnePose++ for object pose estimation without CAD models. The existing method, OnePose, uses feature matching but is not effective on low-textured objects. To overcome this limitation, OnePose++ proposes a keypoint-free pose estimation pipeline. The method utilizes a detector-free feature matching method called LoFTR and introduces a keypoint-free structure-from-motion (SfM) method to reconstruct a semi-dense point cloud model for the object. Unlike previous methods, OnePose++ directly establishes 2D-3D correspondences between the query image and the reconstructed point cloud model without relying on detecting keypoints in the image.Experiments conducted on a benchmark dataset show that OnePose++ outperforms existing one-shot CAD-model-free methods by a large margin and is comparable to CAD-model-based methods even for low-textured objects. Additionally, the researchers have collected a new dataset consisting of 80 sequences of 40 low-textured objects to aid future research in one-shot object pose estimation.The pipeline of OnePose++ has two main components. First, for each object, a keypoint-free SfM framework reconstructs the semi-dense object point cloud in a coarse-to-fine manner. The initial point cloud is obtained through the coarse reconstruction, which is then optimized for a more accurate point cloud in the refinement phase. Second, during test time, a 2D-3D matching network matches the reconstructed object point cloud with a query image to establish 2D-3D correspondences. The object pose is estimated by solving the Perspective-n-Point (PnP) algorithm with the established correspondences.The paper provides qualitative comparisons with OnePose and demonstrates that OnePose++ achieves more accurate and stable pose estimation for low-textured objects. It also includes visualizations of the reconstructed semi-dense object point clouds and the estimated object poses. The ablation part of the results showcases the effectiveness of the 2D-3D attention module in improving the discriminative power of the 2D and 3D features.In terms of citation, the paper is cited as he2022oneposeplusplus in the BibTeX format.Overall, OnePose++ presents a keypoint-free one-shot object pose estimation method that surpasses existing CAD-model-free methods and performs comparably to CAD-model-based methods for low-textured objects. The proposed pipeline and dataset contribute to advancements in one-shot object pose estimation research." ID="ID_367913625" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://zju3dv.github.io/onepose_plus_plus/"/>
<node TEXT="Imagine 3D is a new software that aims to create 3D effects using text. Currently, it is still in the early stages of development, with version 1.2 (alpha) being the latest release. Despite its early status, the software is already generating excitement, and access to it is gradually expanding to everyone on the waitlist.The Imagine 3D team has been working on this project as an experiment and prototype to explore the possibilities of creating three-dimensional effects with text. The goal is to provide users with a unique and visually captivating experience through this software.The website for Imagine 3D offers a few different options to users. The search feature is likely a way for users to find and explore different three-dimensional text designs that have been created by others. By searching, users may find inspiration or find designs that they want to incorporate or modify for their own projects.There is also an option to join the waitlist, indicating that access to the software is not currently available to the general public. However, as mentioned earlier, access is gradually expanding to those who have signed up and are patiently waiting to get their hands on the software.Compatibility seems to be a priority for Imagine 3D, as it is listed as being available on iOS, web, and through an API. This means that users can access and use the software on different platforms, expanding its reach and making it more accessible for users with different devices and preferences.The website also provides information about the Imagine 3D team and the latest news or updates related to the project. Users can also join the Imagine 3D Discord community to connect with other users or enthusiasts who are interested in this innovative software.For those who want to promote or showcase Imagine 3D, the website offers a media kit that provides resources and materials that can be used for media purposes.Lastly, Imagine 3D has clear guidelines in place to protect users&apos; rights and privacy. The Terms of Service and Privacy Policy outline the expectations and responsibilities associated with using the software, ensuring that users&apos; information and rights are respected.In conclusion, Imagine 3D is an exciting new software that aims to create innovative three-dimensional effects using text. Despite still being in the early stages of development, the software is generating significant interest, and access is gradually expanding to the public. With compatibility across different platforms and a supportive community, Imagine 3D is a promising tool for those looking to explore the possibilities of 3D text design." ID="ID_1811038572" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://captures.lumalabs.ai/imagine"/>
<node TEXT="This text is a comment section following a blog post about modeling a robot with added difficulty. The post discusses using morph maps to create projections of a character&apos;s texture.The first comment is from a person in Spain who expresses interest in playing the game but asks how to do so. The second comment asks about morph maps and if Blender has an equivalent feature. The original poster, Jussi Kemppainen, responds by explaining that all programs support morph maps. Morphs are duplicates of a mesh with vertexes in different locations. Jussi describes how he creates projection morphs that match the form of the character and how this is done for reference images. The goal is to position the vertexes of the mesh correctly on the projected texture. Jussi also mentions the process of baking, which is an industry standard way of transferring data from high polygon meshes to low polygon meshes.The final comment thanks Jussi for clarifying and suggests that shape keys are utilized to position the model for better UV projection.The text also includes links to the website&apos;s home, devblog, AI news, about page, Steam page, and discord. There is also an option to search the website.Overall, the text is a brief discussion in the comment section of a blog post about modeling a robot with added difficulty using morph maps and projections." ID="ID_1386390749" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://echoesofsomewhere.com/2023/01/25/modeling-a-robot-with-some-added-difficulty/"/>
<node TEXT="The text mentions that there is an issue with Monster Mash and provides a few steps to troubleshoot the problem.First, it suggests checking if the user is using the latest version of their web browser and operating system. It is important to keep these up to date as newer versions often include bug fixes and improvements that can resolve compatibility issues.Next, the text recommends trying to use a different web browser. Sometimes certain browsers may have compatibility issues with certain websites or applications, so switching to a different browser could potentially solve the problem.Additionally, the text suggests force refreshing the page using the Ctrl+F5 keyboard shortcut. This can help reload the page and bypass cache, which may resolve any temporary glitches.Lastly, the text mentions that the device should have sufficient computational resources. It is possible that if the device is struggling to handle the demands of running Monster Mash, it may not function properly. In such cases, closing any unnecessary applications and freeing up system resources could help resolve the issue.In summary, if there is an issue with Monster Mash, the user can try the following steps: ensuring they have the latest web browser and operating system, trying a different web browser, force refreshing the page, and checking if their device has sufficient computational resources. These troubleshooting steps can help identify and potentially resolve the problem." ID="ID_122516484" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://monstermash.zone/"/>
<node TEXT="This text appears to be a snippet of a Reddit post from the r/virtualreality subreddit. The post includes links to various topics related to virtual reality, such as 3D generation from a single image, VR tabletop RPG, VR space RTS game, VR controllers, and more. It seems to be a collection of posts and discussions from the subreddit, showcasing different virtual reality experiences, games, and technologies." ID="ID_1424616905" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://www.reddit.com/r/virtualreality/comments/xvy5dc/3d_generation_from_a_single_image/"/>
<node TEXT="Hiber3D game geom from text" ID="ID_1038671632" CREATED="1693648999014" MODIFIED="1693649007854" LINK="https://www.youtube.com/watch?v=lOP-7tDxnTw"/>
<node TEXT="BlenderGPT is a plugin that allows users to control the Blender software using program scripts written in Python. It integrates OpenAI&apos;s GPT-4/GPT-3.5 models into the Blender user interface, allowing users to control Blender through natural language commands. However, access to GPT-4 in this addon can only be obtained through the OpenAI waitlist and requires an OpenAI API key.To install BlenderGPT, users can clone the repository from GitHub and then follow the installation instructions in Blender. They will also need to paste their OpenAI API key in the addon preferences menu.Once installed, users can access the BlenderGPT functionality through the GPT-4 Assistant tab in the sidebar of the Blender 3D View. They can type natural language commands, such as create a cube at the origin, and click the Execute button to generate and execute the corresponding Blender Python code.The requirements for using BlenderGPT are Blender 3.1 or later and an OpenAI API key obtained from the OpenAI platform.BlenderGPT provides a convenient way for users to control Blender using natural language commands, thanks to the integration of OpenAI&apos;s GPT-4/GPT-3.5 models. However, it is important to note that access to GPT-4 via the API is different from access through ChatGPT-Plus subscription. Users must be accepted into the GPT-4 waitlist and have access to the API via their OpenAI API key for BlenderGPT to work with GPT-4.The plugin is released under the MIT license and has gained significant popularity, with 3.7k stars and 258 forks on GitHub. It is actively maintained by two contributors.In summary, BlenderGPT is a powerful plugin that enhances the control of Blender using natural language commands. By integrating OpenAI&apos;s GPT-4/GPT-3.5 models, it allows users to generate and execute Python scripts within Blender, making it easier to operate the software." ID="ID_1408500655" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://github.com/gd3kr/BlenderGPT"/>
<node TEXT="The text is the readme file for the 3DHighlighter project on GitHub. The project presents a technique called 3D Highlighter, which is capable of localizing semantic regions on 3D shapes using text descriptions as input. The system can interpret out-of-domain localizations and reason about placing conceptually related objects on 3D shapes. The method uses a neural field to contextualize the text description and colors the corresponding region of the shape using a probability-weighted blend. The optimization process is guided by a pre-trained CLIP encoder, eliminating the need for 3D datasets or annotations. The installation and system requirements for running the project are provided, along with example scripts for obtaining localizations on different mesh+region combinations. There are also troubleshooting tips and a citation for referencing the project. The readme file concludes with information about the project, including links to the project&apos;s website and topics related to deep learning, computer graphics, and more." ID="ID_1803774764" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://github.com/threedle/3dhighlighter"/>
<node TEXT="This paper introduces DreamFusion, a method for synthesizing 3D objects from text using a pretrained 2D text-to-image diffusion model. The traditional approach for text-to-image synthesis requires large-scale datasets of labeled 3D assets and efficient architectures for denoising 3D data, but these resources are currently lacking. DreamFusion bypasses these limitations by leveraging a pretrained 2D diffusion model as a prior for optimization of a parametric image generator.The authors propose a loss based on probability density distillation that enables the use of a 2D diffusion model as a prior for optimizing a Neural Radiance Field (NeRF) 3D model. By iteratively optimizing the 3D model using a DeepDream-like procedure, the resulting model can be viewed from different angles, relit by arbitrary illumination, and composited into any 3D environment. Importantly, this approach requires no 3D training data and no modifications to the image diffusion model, showcasing the effectiveness of pretrained image diffusion models as priors.To demonstrate the capabilities of DreamFusion, the authors provide examples of generated 3D objects from various captions. These objects exhibit high-fidelity appearance, depth, and normals, and can be exported to meshes for integration into 3D renderers or modeling software. The generated objects cover a wide range of categories and can be composed into scenes.DreamFusion works by using a text-to-image generative model called Imagen to optimize a 3D scene based on a given caption. The authors propose Score Distillation Sampling (SDS) as a way to generate samples from a diffusion model by optimizing a loss function. SDS allows for optimization in an arbitrary parameter space, such as 3D space, as long as it can be differentiably mapped back to images. The authors utilize a 3D scene parameterization similar to NeRFs to define this differentiable mapping. To enhance the geometry of the scenes, additional regularizers and optimization strategies are incorporated. The resulting trained NeRFs exhibit coherent geometry, high-quality normals, surface geometry and depth, and can be relit using a Lambertian shading model.In summary, DreamFusion presents a novel approach to text-to-3D synthesis by utilizing a pretrained 2D diffusion model as a prior for optimizing a NeRF 3D model. This method enables the generation of relightable 3D objects with high-fidelity appearance, depth, and normals, without the need for large-scale 3D training datasets. The generated objects can be composed into scenes and exported as meshes for easy integration into 3D renderers or modeling software." ID="ID_148186619" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://dreamfusion3d.github.io/"/>
<node TEXT="The blog post introduces a new AI system that can turn 2D images into 3D models. This has been a long-standing challenge due to the lack of depth information in flat pictures and the complexity of creating 3D models from scratch. The new AI system aims to solve this problem and make 3D content generation accessible to everyone.The ability to convert images into 3D assets has significant implications for various industries, including gaming, robotics, mixed reality, VFX, and e-commerce. It opens up possibilities for anyone with a creative idea to bring their imagination to life without requiring advanced technical or modeling skills.To showcase the capabilities of the AI system, the blog mentions assets generated using a Discord bot. Users are encouraged to join the Discord channel to generate their own assets, although there may be a waitlist due to scaling up compute capacity.The focus of the AI system is on transforming images into 3D models, as images retain more stylistic details and suffer less information loss compared to text. This approach aligns with the existing workflows of concept artists in 3D content production. The blog highlights that the AI-generated models can be used as blockouts for creating production-ready assets or directly utilized as outputs.The development of the AI system is in progress, with the team continuously enhancing and refining their models. They have control over the entire process, allowing for quick progress and improvement. The challenge of hallucinations, where the models generate extra heads or parts, is being mitigated through increased compute power, data, and feedback loops.Overall, this new AI system has the potential to revolutionize the way 3D content is generated and utilized across various industries. With its intuitive image-based approach and ease of use, it aims to bridge the gap between imagination and reality." ID="ID_1366570044" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://csm.ai/any-image-to-3d"/>
<node TEXT="The authors of the paper UrbanGIRAFFE: Representing Urban Scenes as Compositional Generative Neural Feature Fields propose a new method called UrbanGIRAFFE for generating photorealistic images of urban scenes with controllable camera pose and scene contents. This is important for applications such as AR/VR and simulation. While there have been advances in 3D-aware generative models, most existing methods are focused on object-centric images and cannot generate urban scenes with free camera viewpoint control and scene editing.To address this challenge, the authors use a coarse 3D panoptic prior, which includes the layout distribution of uncountable stuff (such as roads, sidewalks, etc.) and countable objects (such as cars, trees, buildings, etc.), to guide their 3D-aware generative model. Their model is compositional and controllable as it breaks down the scene into stuff, objects, and sky.They utilize a conditioned stuff generator that incorporates coarse semantic and geometry information in the form of semantic voxel grids. This allows for effective stuff editing and manipulation. Additionally, they learn an object generator from cluttered scenes to handle object layout prior.With appropriate loss functions, their approach enables photorealistic 3D-aware image synthesis with diverse controllability, including large camera movement, stuff editing, and object manipulation. The effectiveness of their model is validated on both synthetic and real-world datasets, including the challenging KITTI-360 dataset.The paper also showcases different experiments and results to demonstrate the capabilities of UrbanGIRAFFE. This includes examples of viewpoint control, camera pose interpolation, stuff editing (e.g., transforming road to grass, building to tree, etc.), and object editing on various datasets.Finally, the authors provide the citation for their paper and acknowledge the use of a website template borrowed from Jon Barron.Please note that the summary provided here is a condensed version of the text, and some details may have been omitted. For a complete understanding of the topic, it is recommended to refer to the original paper." ID="ID_821565838" CREATED="1688463443299" MODIFIED="1688463443299" LINK="https://lv3d.github.io/urbanGIRAFFE/?trk=public_post_comment-text"/>
<node TEXT="This paper introduces a 3D-aware image generation method that utilizes 2D diffusion models. The goal is to generate high-quality images with large view angles using 2D image sets. The authors formulate the task as multiview 2D image set generation and employ sequential unconditional-conditional multiview image generation. This approach allows them to leverage 2D diffusion models, which enhance the generative modeling power of the method.To incorporate depth information, the authors use monocular depth estimators to construct training data for the conditional diffusion model. This is done using only still images. The authors train their method on a large-scale dataset, ImageNet, which has not been addressed by previous methods. The results demonstrate that their method produces images of higher quality compared to previous methods. Moreover, the approach is able to generate instances with large view angles, even when the training images are diverse and unaligned, gathered from real-world environments.The key idea behind this method is to consider the distribution of 3D assets as equivalent to the joint distribution of their corresponding multiview images. By assuming a bijective correspondence between 3D assets and their multiview projections, the authors factorize the joint distribution into an unconditional distribution and a series of conditional distributions using the chain rule of probability.However, obtaining multiview images can be challenging. To address this, the authors construct training data using depth-based image warping with unstructured 2D image collections. Two diffusion models, Gu and Gc, are then trained to fit the unconditional and conditional distributions, respectively. Gu is used for randomly generating the first view, while Gc is a conditional generator for synthesizing novel views. By iteratively refining and completing previously synthesized views, multiview images are obtained with aggregated conditioning.The experimental results provide evidence of the effectiveness of the proposed method. The authors generate samples in different sizes on ImageNet and evaluate the quality of generated images on datasets such as SDIP Dogs, SDIP Elephants, and LSUN Horses. The generated images outperform previous methods in terms of quality and the ability to handle large view angles. The authors also provide the paper, code, video, and additional results for further exploration of their method.In conclusion, this paper presents a novel 3D-aware image generation method using 2D diffusion models. By formulating the task as multiview 2D image set generation and incorporating depth information, the method is able to generate high-quality images with large view angles. The experimental results demonstrate the superiority of this method compared to previous approaches." ID="ID_962644768" CREATED="1688463443304" MODIFIED="1688463443304" LINK="https://jeffreyxiang.github.io/ivid/"/>
<node TEXT="The paper titled Patch-based 3D Natural Scene Generation from a Single Example describes a novel approach to generating high-quality 3D scenes using a patch-based framework. The authors aim to overcome the challenges of limited training data and complex scene characteristics by synthesizing scenes at the patch level. This approach allows for the generation of realistic geometric structures and visual appearances in large quantities and varieties.The key algorithmic designs of the method include the scene representation and the generative patch nearest-neighbor module. These design choices address the unique challenges of extending classical 2D patch-based frameworks to 3D scene generation. The resulting model is robust, effective, and efficient.The paper showcases a random generation gallery with demonstrations of generated scenes based on various exemplar scenes. The generated scenes exhibit high quality and realism. The authors also demonstrate the ability to generate higher-resolution scenes, including a rendering of the scene A Thousand Li of Rivers and Mountains at a resolution of 1328 × 512 × 200, with an image resolution of 4096 × 1024.Additionally, the method allows for editing, retargeting, structural analogies, re-decoration, and generation of unbounded scenes. Users can manipulate and edit scenes by working with a 3D proxy, resize scenes while maintaining the local patches, create scenes with the patch distribution of one scene but align them structurally with another scene, and re-decorate generated scenes by remapping them to exemplars with different appearances. The method also enables the generation of scenes based on real-world scenic sites, such as Bryce Canyon, by synthesizing only the region of interest and modeling the background separately using an independent implicit neural network.The paper provides a BibTeX entry for citation purposes and acknowledges inspiration from the Nerfies project.In summary, the proposed patch-based 3D scene generation method offers a solution to generating high-quality natural scenes using a single example as input. The approach addresses challenges related to limited training data and varying scene characteristics, resulting in robust and efficient models capable of generating diverse and realistic scenes. The method also offers features for editing, retargeting, creating structural analogies, re-decorating, and generating unbounded scenes." ID="ID_1986344048" CREATED="1688463443305" MODIFIED="1688463443305" LINK="http://weiyuli.xyz/Sin3DGen/"/>
<node TEXT="The paper titled Point-E: A System for Generating 3D Point Clouds from Complex Prompts explores a method for generating 3D object models using text prompts. The current state-of-the-art methods for text-conditional 3D object generation are time-consuming, requiring multiple GPU-hours to produce a single sample. In contrast, generative image models can produce samples in seconds or minutes.The authors propose an alternative method that significantly reduces the time required for generating 3D models. Their approach involves first generating a synthetic view using a text-to-image diffusion model, and then producing a 3D point cloud using a second diffusion model that conditions on the generated image. This method can generate 3D models in only 1-2 minutes on a single GPU. While the sample quality may not be on par with the state-of-the-art methods, the significant reduction in sampling time offers a practical trade-off for certain use cases.The authors have released their pre-trained point cloud diffusion models, as well as evaluation code and models, for public use. These resources can be accessed from the provided URL. The paper contains 8 pages and includes 11 figures to support the presented method.The subjects of the paper fall under the categories of Computer Vision and Pattern Recognition (cs.CV) and Machine Learning (cs.LG). The paper can be cited as arXiv:2212.08751 [cs.CV].The paper was submitted by Alex Nichol and co-authored by Heewoo Jun, Prafulla Dhariwal, Pamela Mishkin, and Mark Chen.For more details and to access the full paper, readers can refer to the provided arXiv identifier or DOI." ID="ID_1405943480" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://arxiv.org/abs/2212.08751"/>
<node TEXT="The text includes a list of YouTube videos and tutorials related to AI, VR, and animation in programs like Blender. There are also mentions of specific AI tools like Stable Diffusion and Controlnet. The text also includes a promotional message for Brilliant, a platform offering free access and discounts for its annual premium subscription. The text concludes with a message about the use of cookies and data on YouTube." ID="ID_1603342191" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://www.youtube.com/watch?v=t9zzcRsf0IA"/>
<node TEXT="The text is a README file for a project called Text2Mesh. Text2Mesh is a method for text-driven stylization of a 3D mesh. It allows users to stylize a 3D mesh based on text input. The project uses PyTorch and requires a CUDA GPU machine to run.The README file provides information on how to install and run Text2Mesh. It includes instructions for setting up the necessary environment and system requirements. The file also provides examples of shell scripts that can be used to generate different styles of 3D meshes.The README file also includes important tips for running Text2Mesh on your own meshes. It explains that the resolution of the stylization depends on the size of the mesh triangles and provides instructions on how to remesh shapes as a pre-process to create smaller triangles for better quality results.The text also mentions other implementations and external projects that use Text2Mesh. It provides a citation for the original research paper on Text2Mesh and includes links to additional resources.Overall, the README file provides a comprehensive introduction to the Text2Mesh project, its installation process, and usage guidelines." ID="ID_1574232267" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://github.com/threedle/text2mesh"/>
<node TEXT="The text discusses a research paper titled TextMesh: Generation of Realistic 3D Meshes From Text Prompts. The paper explores the generation of realistic 3D meshes from text prompts using image diffusion models. While previous methods have shown impressive results, they have two main drawbacks. Firstly, they generate neural radiance fields (NeRFs) instead of 3D meshes, which are not practical for real applications. Secondly, these methods tend to produce over-saturated models with a cartoonish effect.The researchers propose a novel method to address these limitations. They extend NeRF to employ a signed distance function (SDF) backbone, which improves the extraction of 3D meshes. Additionally, they propose a new approach to finetune the mesh texture, eliminating high saturation and enhancing the details of the output 3D mesh.The paper provides examples of generated 3D meshes, including a frog wearing a red sweater, an animal with the head of a rabbit, the body of a squirrel, the antlers of a deer, and legs of a pheasant, a lemur writing into a notepad, a squirrel-octopus hybrid, a beautifully carved wooden knight chess piece, a 3D model of an adorable cottage with a thatched roof, a small marble statue of a cat sitting on a mat and licking its paws, a chimpanzee dressed as a football player, a DSLR photo of a chimpanzee holding a cup of hot coffee, and a DSLR photo of a marble bust of a fox head.The paper includes a reference section with a link to the full PDF and the arXiv entry for the research. It also provides contact information for any questions regarding the method.In summary, the paper introduces a novel method for generating realistic 3D meshes from text prompts. By extending NeRF with an SDF backbone and improving mesh texture finetuning, the researchers aim to overcome the limitations of previous methods and produce high-quality outputs suitable for real applications." ID="ID_364790656" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://fabi92.github.io/textmesh/"/>
<node TEXT="The text provides information about Fantasia3D, a project that focuses on disentangling geometry and appearance for high-quality text-to-3D content creation. It includes a FAQ section addressing common questions about the project, as well as instructions on how to contribute to Fantasia3D. The text also provides installation instructions and tips for using the software effectively, including parameter tuning and object generation strategies. Additionally, it provides links to demos and references to academic papers related to the project." ID="ID_1838291659" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://github.com/Gorilla-Lab-SCUT/Fantasia3D"/>
<node TEXT="The text is a list of YouTube videos related to using AI-generated images to create 3D models in Blender and other software. The videos cover topics such as converting 2D images to 3D models, using AI in Blender, Blender add-ons, creating 3D models from photos, and more. The videos provide tutorials, demonstrations, and discussions about using AI technology for 3D modeling." ID="ID_735835764" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://www.youtube.com/watch?v=Wf-OmHyFduo"/>
<node TEXT="The text is a collection of YouTube video titles and descriptions, as well as some additional information about Google&apos;s use of cookies and data for personalized content and ads. It does not provide any specific information or context on the topics mentioned in the video titles." ID="ID_1967197180" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://www.youtube.com/watch?v=6tgspeI-GHY"/>
<node TEXT="The Toronto AI Lab has developed a generative model called GET3D that can create high-quality 3D textured shapes. The model generates a 3D surface using a surface distance function (SDF) and a texture field. It then uses a differentiable renderer to obtain RGB images and silhouettes, and two discriminators to distinguish between real and fake inputs. The entire model is trainable end-to-end.GET3D is capable of generating diverse shapes with complex topology and high-quality geometry and texture. It can generate a wide range of objects, such as cars, chairs, animals, motorbikes, human characters, and buildings.The model achieves a good disentanglement between geometry and texture, allowing for meaningful interpolation and exploration in the latent code space. It can smoothly transition between different shapes and generate similar-looking shapes with slight variations.GET3D also supports unsupervised material generation, allowing for the creation of materials and view-dependent lighting effects without the need for manual supervision.Furthermore, the model can generate shapes based on text prompts. Users can provide a text description, and the model is fine-tuned using the CLIP loss on rendered images and the provided texts. This enables the generation of a large number of meaningful shapes based on text inputs.The paper provides qualitative results and showcases the capabilities of GET3D in generating 3D shapes with textures. It also references previous works that have influenced and contributed to the development of GET3D.For further information or business inquiries, interested parties can visit the Toronto AI Lab&apos;s website and submit a form through NVIDIA Research Licensing." ID="ID_1903633119" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://nv-tlabs.github.io/GET3D/"/>
<node TEXT="The text is the README file for the open-source project Point·E, which is a system for generating 3D point clouds from complex prompts. The project provides code and models for generating point clouds using different methods, such as image-to-point cloud and text-to-point cloud. The code can be installed using pip and comes with example notebooks for different use cases. There are also evaluation scripts and rendering code available. The README provides links to download sample data and explains the project&apos;s purpose and resources. The project is open-source and released under the MIT license." ID="ID_1478047061" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://github.com/openai/point-e"/>
<node TEXT="The paper titled Zero-Shot Text-Guided Object Generation with Dream Fields presents a method for synthesizing 3D objects solely based on natural language descriptions. The authors combine neural rendering techniques with multi-modal image and text representations to generate diverse objects without the need for 3D supervision.Previous methods in this domain have been limited by the scarcity of diverse, captioned 3D data and can only generate objects from a few categories. In contrast, Dream Fields leverages image-text models pre-trained on large datasets of captioned images from the web to guide the generation process. The method optimizes a Neural Radiance Field (NRF) from multiple camera views, ensuring that the rendered images align well with a target caption according to a pre-trained CLIP (Contrastive Language-Image Pretraining) model.To enhance fidelity and visual quality, the authors introduce several geometric priors, including sparsity-inducing transmittance regularization, scene bounds, and novel multilayer perceptron (MLP) architectures. These priors help improve the consistency and realism of the generated object&apos;s geometry and color across multiple viewpoints.The generated objects can be controlled and styled using natural language descriptions. For example, the authors demonstrate the ability to generate objects like a bouquet of flowers sitting in a clear glass vase, a sculpture of a rooster, and a robotic dog shaped like a dog. The style of the objects, such as color and context, can be manipulated through the provided descriptions.The paper also highlights the compositional nature of language, allowing users to combine concepts in novel ways to control the generation process. Templates sourced from DALL-E, a text-to-image synthesis model, are used to describe primary objects (e.g., an armchair or a teapot). These templates can be stylized with various materials, such as avocado, glacier, orchid, pikachu, brain coral, gourd, and more.The authors also mention related publications that address different aspects of improving 3D reconstruction and rendering. These include Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis and Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields. In summary, this paper presents Dream Fields, a method for generating 3D objects guided by natural language descriptions. By leveraging pre-trained image-text models and optimizing a Neural Radiance Field, Dream Fields produces realistic and diverse objects without the need for 3D supervision. The method also allows for compositional generation, enabling users to control the style and appearance of the generated objects." ID="ID_929447305" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://ajayj.com/dreamfields"/>
<node TEXT="The Toronto AI Lab has introduced a new approach for 3D shape generation called LION (Latent Point Diffusion Models). This approach aims to improve the quality and flexibility of 3D generative models for digital artists.LION is designed as a hierarchical point cloud Variational Autoencoder (VAE) with Denoising Diffusion Models (DDMs) operating in the latent space. It combines a global shape latent representation with a point-structured latent space, allowing for high-quality generation and smooth surface output. By training two hierarchical DDMs in these latent spaces, LION outperforms previous models that operate directly on point clouds.The paper highlights several advantages of LION. Firstly, it improves expressivity by mapping point clouds into regularized latent spaces, making it easier for DDMs to learn a smoothed distribution. The use of latent points retains the point cloud structure, which is well-suited for DDM-based modeling. Additionally, LION can be augmented with surface reconstruction techniques, enabling the generation of smooth 3D meshes desired by artists.LION&apos;s flexibility is another key feature. Being a VAE, it can be easily adapted for different tasks without retraining the latent DDMs. It can be fine-tuned on voxelized or noisy inputs for multimodal voxel-guided synthesis and shape denoising. LION&apos;s latent spaces can also be leveraged for shape interpolation, autoencoding, and image- or text-driven 3D generation.The paper presents various generation results and applications of LION. It achieves state-of-the-art generation performance on multiple ShapeNet benchmarks for different categories such as airplanes, chairs, cars, animals, bottles, and mugs. LION demonstrates its scalability by training on 13 and 55 ShapeNet categories jointly without conditioning. It can interpolate shapes, generate multimodal variations, perform voxel-conditioned synthesis, and even enable single view reconstruction from RGB data.Furthermore, LION allows for text-guided generation and text-driven texture synthesis, leveraging CLIP image embeddings. By applying Text2Mesh on LION-generated meshes, textures can be synthesized in a text-driven manner.Overall, LION provides a powerful tool for artists due to its high-quality generation, flexibility, and surface reconstruction capabilities. The paper includes detailed technical information, generation examples, and additional applications to showcase the effectiveness and versatility of LION." ID="ID_940609202" CREATED="1688463443305" MODIFIED="1688463443305" LINK="https://nv-tlabs.github.io/LION/"/>
</node>
<node TEXT="Music and audio" FOLDED="true" ID="ID_1812265856" CREATED="1667334782771" MODIFIED="1667334787006">
<node TEXT="Stable diffusion MIDI" ID="ID_306476459" CREATED="1667334789452" MODIFIED="1667334797968" LINK="https://storage.googleapis.com/music-synthesis-with-spectrogram-diffusion/index.html"/>
<node TEXT="Trainable github" ID="ID_670062475" CREATED="1667748150242" MODIFIED="1667748159184" LINK="https://github.com/teticio/audio-diffusion"/>
<node TEXT="Propia instant jukebox" ID="ID_1250365320" CREATED="1670344064988" MODIFIED="1670344081768" LINK="https://app.prodia.com/#/"/>
<node TEXT="SD for music" ID="ID_1345210060" CREATED="1671206268031" MODIFIED="1671206272538" LINK="https://www.riffusion.com/about"/>
<node TEXT="word to midi" ID="ID_1992842005" CREATED="1673694464051" MODIFIED="1673694512912" LINK="https://www.musicradar.com/news/audiocipher-word-midi-music-generator-creative-block"/>
<node TEXT="HarmonAI" ID="ID_1176296644" CREATED="1673884757841" MODIFIED="1673884764221" LINK="https://www.harmonai.org/"/>
<node TEXT="Riffusion" ID="ID_1590005483" CREATED="1674481756810" MODIFIED="1685194563320" LINK="https://github.com/riffusion/riffusion-app">
<icon BUILTIN="attach"/>
</node>
<node ID="ID_602203779" CREATED="1674485328276" MODIFIED="1674485532504" LINK="https://soundraw.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span dir="ltr">Soundraw: Generates background music.<br/></span>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_765312573" CREATED="1674485371625" MODIFIED="1674485508856" LINK="https://www.beatoven.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <span dir="ltr">Beatoven: Create unique royalty-free music.<br/></span>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Krise: Removes background voices, noises and echo during calls." ID="ID_358919345" CREATED="1674485428879" MODIFIED="1674485447837" LINK="https://krisp.ai/"/>
<node TEXT="Google MusicLM" ID="ID_203268352" CREATED="1674823428968" MODIFIED="1685194563322" LINK="https://google-research.github.io/seanet/musiclm/examples/">
<icon BUILTIN="attach"/>
<node TEXT="techcruch explaining why it won&apos;t be released" ID="ID_813630025" CREATED="1674897178025" MODIFIED="1674897195704" LINK="https://techcrunch.com/2023/01/27/google-created-an-ai-that-can-generate-music-from-text-descriptions-but-wont-release-it/"/>
</node>
<node TEXT="Text2audio" ID="ID_1430988570" CREATED="1674989300935" MODIFIED="1680603754455" LINK="https://text-to-audio.github.io/"/>
<node TEXT="The audioFlux library is a tool for audio and music analysis, featuring extraction capabilities. It is open source and released under the MIT license." ID="ID_852537456" CREATED="1682414608744" MODIFIED="1682417484829" LINK="https://github.com/libAudioFlux/audioFlux"/>
<node TEXT="Grimes invites royalty split with anyone using her voice" ID="ID_1312844740" CREATED="1682427280418" MODIFIED="1682427293266" LINK="https://www-engadget-com.cdn.ampproject.org/c/s/www.engadget.com/amp/grimes-invites-ai-artists-to-use-her-voice-promising-50-percent-royalty-split-165659578.html"/>
<node TEXT="Meta audiogen" ID="ID_1151680389" CREATED="1686341414045" MODIFIED="1686341419536" LINK="https://github.com/facebookresearch/audiocraft"/>
<node TEXT="meta musicgen" ID="ID_1920281374" CREATED="1686743100748" MODIFIED="1686743106253" LINK="https://huggingface.co/facebook/musicgen-melody/"/>
<node ID="ID_1285313265" CREATED="1687805148518" MODIFIED="1687805148518" LINK="https://twitter.com/rrhoover/status/1647735300511154176"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Ryan Hoover, founder of Product Hunt, tweeted an idea for an “AI Spotify” that could host AI-generated music by submitting music with the best tracks based on listens and likes earning a pro-rata share of subscription revenue, reserved for original artists. The tweet sparked interest, leading to someone building the platform called Beatly Music, while some artists expressed interest in the idea. However, industry insiders, including Scott Belsky, have questioned why Spotify might not just do this themselves since they already have the fan graph, the data set, and relationship with artists. But it may be too risky to navigate for a large company with record labels as a key stakeholder. While the idea has potential, there are many ethical and legal issues with this model, especially with labels. Nevertheless, Beatly Music carries a considerable risk as several legal concerns may arise regarding music rights and royalties, stating that some significant damages, including copyright infringement charges or compounding royalties to record labels and artists, might come up. https://twitter.com/rrhoover/status/1647735300511154176
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_669881331" CREATED="1687805148933" MODIFIED="1687805148933" LINK="http://WavTool.com"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          WavTool is an AI-powered music production tool that is free to use online. It offers features such as side-chain compression, flexible signal routing, and advanced synthesis to help users make high-quality music. For beginners, WavTool's Conductor AI can provide guidance through the music-making process, offer suggestions, and explain concepts in plain English. Users can start by creating beats, generating melodies, or suggesting chords. As users gain more experience, WavTool's signal routing and plugin editing features allow them to customize their music production even further. WavTool requires no installation or updates and can be used entirely online. http://WavTool.com
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1155312939" CREATED="1687805148969" MODIFIED="1687805148969"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Create Music is a platform that offers an API solution for businesses to easily integrate music creation and composition functionalities into their products and services. With this API, businesses can offer their customers the ability to create custom music tracks using various instrument sounds and styles within their own applications.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="WavJourney compositional LLM" ID="ID_814523628" CREATED="1693215210156" MODIFIED="1693215220126" LINK="https://audio-agi.github.io/WavJourney_demopage/"/>
<node ID="ID_1071223406" CREATED="1687805148971" MODIFIED="1687805148971"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The technology behind Create Music's API is a robust and intuitive program that offers fast and efficient audio rendering. This makes it possible for businesses to quickly and easily develop music creation applications that are responsive and fun to use. The API includes features like tempo control, key change, and instrument selection, giving users the ability to create virtually any kind of music they can think of.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1342111029" CREATED="1687805148972" MODIFIED="1687805148972"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The platform offers a wide variety of instruments and styles to choose from, including classic and modern pianos, guitars, drums, and synthesizers. Users can also choose from different music genres, such as classical, rock, hip hop, and electronic music. Whether creating a jingle for an advertisement, a theme song for a podcast, or a ringtone for a mobile device, businesses can easily provide their customers with the tools they need to make their own custom music tracks.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_620958805" CREATED="1687805148974" MODIFIED="1687805148974"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Furthermore, Create Music's API offers secure and reliable access to its backend systems and servers. This means that businesses can have peace of mind knowing that their customers' data and creations are protected. Additionally, the platform is constantly evolving, with frequent updates and improvements to help businesses offer their customers the best possible music creation experience.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_37140421" CREATED="1687805148976" MODIFIED="1687805148976" LINK="https://soundraw.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Overall, Create Music's API offers an exciting opportunity for businesses to provide unique and engaging music creation capabilities to their customers. Whether as a standalone app or as an integrated feature within larger products and services, businesses can use this API to offer users an endless variety of creative possibilities. https://soundraw.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_986768771" CREATED="1687805148961" MODIFIED="1687805148961" LINK="https://podcastle.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Podcastle is an all-encompassing platform for broadcast storytelling, offering studio-quality recording, AI-powered editing, and effortless exporting in a user-friendly web-based interface. With Podcastle, users can record remote interviews in job quality, transcribe audio files to text in seconds, make use of easy-to-use editing tools like royalty-free music and multi-track software, and use cutting-edge voice skins to generate realistic human voices. Podcastle's “Magic Dust” is an AI-powered noise cancellation tool that enhances audio files to professional studio standards with just a few clicks. Its “Revoice” feature allows users to create a digital version of their voice using an AI model so that they can generate audio just by typing. The platform is perfect for podcasters, bloggers, journalists, educators, and other content creators to begin their audio storytelling journey with ease. The company's goal is to democratize access to broadcast storytelling. Additionally, Podcastle offers a blog and supports a Discord Community where creators can get advice, ask questions, and interact with other passionate creators. https://podcastle.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="Unsorted" ID="ID_1934493144" CREATED="1687853781294" MODIFIED="1687853785245">
<node ID="ID_149558693" CREATED="1687805149147" MODIFIED="1687805379963" LINK="https://www.reddit.com/r/StableDiffusion/comments/12nd60i/turn_a_group_photo_into_a_digital_painting_with/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          &nbsp;a user of the StableDiffusion subreddit shared a detailed workflow for turning a group photo into a digital painting using Stable Diffusion technology, recommending rendering each character individually to avoid issues with rendering multiple people at once. https://www.reddit.com/r/StableDiffusion/comments/12nd60i/turn_a_group_photo_into_a_digital_painting_with/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_477422605" CREATED="1687805149144" MODIFIED="1687805149144" LINK="https://onceuponanalgorithm.org/ultimate-guide-to-upscale-images-with-ai-in-stable-diffusion/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article provides a step-by-step guide on how to upscale images using Stable Diffusion, an AI software that uses data from image sets to fill in missing pixels during the upscaling process, resulting in higher quality upscaled images than traditional resampling methods. The article explains what upscaling is and why AI is better at it, and provides instructions on how to access Stable Diffusion and use its upscaling menu to upscale single images or batch process multiple images. The article also covers recommended upscale models and how to use custom upscale models, including links to a custom model database. Overall, the article is a comprehensive guide for users of all levels on upscaling images using AI technology. https://onceuponanalgorithm.org/ultimate-guide-to-upscale-images-with-ai-in-stable-diffusion/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1491892153" CREATED="1687805149141" MODIFIED="1687805442787" LINK="https://www.reddit.com/r/StableDiffusion/comments/12od46u/360_vr_image_read_comment/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          &nbsp;In the discussion thread, users are showcasing their experiments with Stable Diffusion, including creating 360 VR images, anime videos, animations, and video translations, and sharing tips and feedback on improving their workflow and prompts. https://www.reddit.com/r/StableDiffusion/comments/12od46u/360_vr_image_read_comment/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_176594706" CREATED="1687805149136" MODIFIED="1687805149136" LINK="https://github.com/Mikubill/sd-webui-controlnet/pull/903"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text appears to be a snippet of a conversation in a GitHub repository related to an image resizing tool called &quot;sd-webui-controlnet&quot; developed by user Mikubill. Collaborators on the project, including user lllyasviel, discuss the implementation of a &quot;super high quality resampling&quot; feature that allows for high-resolution image resizing while maintaining the quality of segmentation, canny, MLSD, and scribble maps. The feature is being tested and revised, and collaborators report issues with canny maps giving poor results and needing annotations to match resolution. User catboxanon requests support for ControlNet 1.1 in a related project called ComfyUI. https://github.com/Mikubill/sd-webui-controlnet/pull/903
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_745764560" CREATED="1687805149132" MODIFIED="1687805149132" LINK="https://github.com/chainyo/picaisso"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          PicAIsso is an open-source project that allows users to generate AI art using an API and a Discord Bot. The project is based on the StableDiffusion algorithm and can be self-hosted on a user's machine or server. Alternatively, the creator of the project offers a self-hosted API and Discord bot that can be added to a user's server to start generating art. The project requires Docker and an NVIDIA GPU with at least 12GB of VRAM. To contribute to the project, users can follow the instructions in the CONTRIBUTING.md file. The project can be installed by cloning the repository and creating .env files for the API and the Discord bot. The deployment process involves deploying the API and the Discord bot, which can be done using Docker commands. Users can generate art using the API documentation, API endpoint, or the Discord bot. The creator of the project saves all generated images on their S3 bucket to create a free dataset available on Hugging Face. If users encounter any issues, they can contact the creator or open an issue on GitHub. https://github.com/chainyo/picaisso
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_223289093" CREATED="1687805149145" MODIFIED="1687805149145" LINK="https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text appears to be a collection of comments and posts from various subreddits related to Stable Diffusion, a neural network model for image editing. The content includes discussions about using the software for creating realistic photos and unique characters, as well as updates on new tools and extensions for Stable Diffusion. Additionally, there are posts related to AI-generated short films, copyright issues with AI training, and techniques for controlling lighting in Stable Diffusion. https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1194035987" CREATED="1687805148742" MODIFIED="1689009119209" LINK="https://www.reddit.com/r/cpp/comments/143olej/an_open_source_library_for_running_stable/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          C++ lib for running SD
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node FOLDED="true" ID="ID_1079901153" CREATED="1687772398092" MODIFIED="1689009186780" LINK="https://civitai.com/models/73470?modelVersionId=78187"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-bottom: 0px; margin-top: 0px; padding-left: 0; display: block">
        <p style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px">
          <a href="https://civitai.com/models/73470?modelVersionId=78187" target="_new" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500"><font color="black"><u><b>HardSurface Character - v1.0 | Stable Diffusion LoRA | Civitai</b></u></font></a>
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
<font BOLD="false"/>
</node>
<node ID="ID_886346084" CREATED="1687805148746" MODIFIED="1689009186798" LINK="https://github.com/receyuki/stable-diffusion-prompt-reader"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Stable Diffusion Prompt Reader is a standalone viewer used to read prompts generated from Stable Diffusion images outside of the web UI. The platform is compatible with macOS, Windows, and Linux and supports multiple formats including PNG, JPEG, WEBP, and TXT. Users can copy the prompt to the clipboard or export it to a text file, remove the prompt from the image, edit or import the prompt to images, display vertically oriented images sorted by alphabet, and more. The system detects the generation tool and supports A1111's webUI, Easy Diffusion, InvokeAI, NovelAI, ComfyUI, and Naifu(4chan). If using a tool or format that is not supported, users can upload the original file generated by their tool as a zip file to the issues section to ask for support. Users can download the Stable Diffusion Prompt Reader for macOS and Windows users through GitHub releases or clone the repository for Linux users. The minimum version of Python required is 3.10, and ensure users have the tkinter package installed in their Python. The system is simple to use; users can drag and drop the image into the window, click export to generate a txt file alongside the image file, or click clear to generate a new image file with suffix &quot;_data_removed&quot; alongside the original image file for image removal. The edited image will be written in A1111 format, meaning image formats become A1111 image format after editing. Users can import TXT files in edit mode, but only A1111 format TXT files are supported. The reader can also help users address common issues such as false malware alerts and apps not opening in macOS. Future developments may include batch image processing tools, gallery or folder view, and other improvements. https://github.com/receyuki/stable-diffusion-prompt-reader
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_695165374" CREATED="1687805148755" MODIFIED="1689009186803" LINK="https://m.youtube.com/watch?v=YLE0rAt2mIg&amp;amp;feature=youtu.be"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a list of various tutorials and videos related to digital art and artificial intelligence (AI). These include tutorials on using DreamBooth and Automatic1111 extensions for Stable Diffusion to turn photos into digital art masterpieces, using GPT-5 to improve writing skills, and creating characters in real life using Midjourney. Additionally, there are mentions of new and upcoming AI developments, such as Google's RoboCat AI and NVIDIA's recent AI research. The text also explains that viewers can choose to accept or reject the use of cookies and data when using Google services, with the option to see further details about managing privacy settings. https://m.youtube.com/watch?v=YLE0rAt2mIg&amp;feature=youtu.be
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_464630331" CREATED="1687805148770" MODIFIED="1689009186809" LINK="https://www.reddit.com/r/DreamBooth/comments/14bq3e8/extracting_lora_from_everydream_512_vs_training/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text is primarily about Reddit's use of cookies and similar technologies to improve user experience, with the option for users to accept all cookies or reject non-essential ones. The text also includes a discussion thread from the subreddit r/DreamBooth, where users are discussing methods for extracting lora (a type of computer-generated face) from Everydream 512 versus training it with higher resolution images. Users suggest different methods, with one user recommending training a DreamBooth using sd-scripts and extracting a lycoris from it. The text also includes links to various other subreddits and discussions on the topic of Stable Diffusion, a technique for generating realistic computer-generated images. https://www.reddit.com/r/DreamBooth/comments/14bq3e8/extracting_lora_from_everydream_512_vs_training/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1833036520" CREATED="1687805149112" MODIFIED="1689009186830" LINK="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The page explains how to develop extensions for Stable Diffusion WebUI, a platform that enables users to generate images, videos, and audio using the Stable Diffusion method. An extension is simply a subdirectory in the extensions directory. When WebUI interacts with installed extensions, it executes the extension's install.py script (if it exists), and you can use scripts.basedir() to get the current extension's directory. The extension's scripts in the scripts directory are executed as if they were usual user scripts, and the sys.path is extended to include the extension directory. The extension's javascript files in the javascript directory are added to the page, and the extension's style.css file is added to the page. If an extension has the preload.py file in its root directory, it's loaded before parsing commandline args. If the extension's preload.py has a preload function, it's called, and the commandline args parser is passed to it as an argument. For localizations, the preferred way is by making an extension with the basic file structure of webui-localization-language/localizations/translation.json. The script install.py is launched by the launcher, and it's meant to install dependencies of the extension. For more information on developing custom scripts, see the page on Developing custom scripts. The page also provides minor tips and links to user examples and the official extension index where users can add their extensions. https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The text is a script written in Python called Ooga_Prompt_Mkr.py which is used to generate prompts for the Stable Diffusion (SD) model. The script takes input prompts, negative prompts, and subfix text from the user and uses them to generate text that can be used as prompts for the SD model.  The script defines a class called Script that has several methods including title, show, ui, run, generate_text, and process_images. The title method returns the title of the script, show determines whether to show the user interface, ui defines the user interface elements, run is the main method that generates the text and processes the images, generate_text generates the text based on the input prompts, and process_images processes the images.  The generate_text method sends a POST request to a local server with the input prompts and other parameters to generate the text using the SD model. If the request is successful, the generated text is returned. Otherwise, an error message is returned.  The process_images method calls another function called process_images to process the input images.  Overall, the script provides a convenient way to generate prompts for the SD model by taking input prompts and generating text based on them. " ID="ID_1145378123" CREATED="1688559432707" MODIFIED="1689009186834" LINK="https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/9708/files"/>
<node TEXT="The text provides information on developing extensions for the Stable Diffusion Web UI. Extensions are subdirectories within the extensions directory. The web UI interacts with extensions through various files and directories within the extension&apos;s structure.  The extension&apos;s install.py script, if it exists, is executed. The scripts in the scripts directory are executed similar to user scripts, with the extension directory added to the sys.path. The extension&apos;s javascript files in the javascript directory are added to the page. Localization files in the localizations directory are added to the settings.  The extension&apos;s style.css file is added to the page. If the extension has a preload.py file in its root directory, it is loaded before parsing commandline arguments. The preload.py file can contain a preload function that is called, and the commandline arguments parser is passed to it as an argument.  Localization for the project is preferred to be done through extensions. The extension should have a localizations directory with the translation files. The extension can also include javascript, CSS, or Python support.  The install.py script is launched by the launcher before the web UI starts and is used to install the extension&apos;s dependencies. It must be located in the root directory of the extension.  A minor tip mentioned is adding extra textual inversion directories to an extension&apos;s script using the embedding_db.add_embedding_dir() function.  The text also provides links to user examples, an official extension index, an internals diagram, and the Stable Diffusion web UI wiki.  Overall, the text explains the structure and usage of extensions for the Stable Diffusion Web UI and provides additional resources for further exploration. " ID="ID_272163168" CREATED="1688559432707" MODIFIED="1689009186835" LINK="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions"/>
<node TEXT="The text is a list of various video tutorials related to AI art and design techniques. The tutorials cover topics such as installing and using Stable Diffusion, creating game assets, character animation, and graphic design in software like Photoshop and Blender. The videos range in popularity and views, with some having hundreds of thousands of views and others only a few thousand. The text also includes information about Google&apos;s use of cookies and data for personalized content and ads on YouTube. " ID="ID_793771734" CREATED="1688559432712" MODIFIED="1689009186838" LINK="https://m.youtube.com/watch?v=sNcEhR65pw0andfeature=youtu.be"/>
<node TEXT="This text is a step-by-step guide on upscaling images using AI in Stable Diffusion. It explains what upscaling is and why AI is better at it compared to traditional methods. The guide provides instructions on how to start upscaling in Stable Diffusion, including accessing the software and selecting the image to upscale. It also discusses different upscale models available in Stable Diffusion and compares their performance on different types of images, such as photographs and illustrations. The guide concludes with information on how to find and use custom upscale models not included in the default set provided in Stable Diffusion. It suggests online resources and directories where users can find different custom upscale models based on their preferences. The guide also provides instructions on adding these models to Stable Diffusion and making them selectable options in the software. Overall, the guide aims to help users understand and utilize the AI-powered image upscaling capabilities of Stable Diffusion more effectively. " ID="ID_1333003698" CREATED="1688559432712" MODIFIED="1689009186838" LINK="https://onceuponanalgorithm.org/ultimate-guide-to-upscale-images-with-ai-in-stable-diffusion/"/>
<node TEXT="Researchers from Technische Hochschule Ingolstadt and Wand Technologies have developed Paella, a system that can generate high-quality images quickly. The system uses a process similar to diffusion and reduces the number of steps required to produce an image. Traditional diffusion models remove noise from each training example over several hundred steps to generate an image. However, Paella uses a latent diffusion model, which removes noise from a vector representation of the image, reducing the number of steps to around a hundred. When given an image, Paella replaces a random fraction of tokens (representing the image) with tokens chosen from a list, effectively adding noise. A U-Net then learns to generate all the original tokens over 12 iterations, each time removing a smaller amount of the remaining noise. The system was trained on 600 million image-text pairs from LAION-Aesthetics. When evaluated, Paella achieved a Fréchet inception distance (FID) of 26.7 on MS-COCO, slightly worse than Stable Diffusion v1.4 but significantly faster, taking only 0.5 seconds to generate a 256x256-pixel image in eight steps. The authors trained Paella for two weeks on 64 Nvidia A100 GPUs provided by Stability AI. This collaboration between academia and industry highlights the importance of computational resources for advancing research in the field. " ID="ID_1732338485" CREATED="1688559432712" MODIFIED="1689009186841" LINK="https://www.deeplearning.ai/the-batch/the-paella-model-for-fast-image-generation-explained/"/>
<node TEXT="The text is primarily about cookies and privacy policies on Reddit. It mentions that Reddit and its partners use cookies and similar technologies to enhance the user experience. By accepting all cookies, users agree to the use of cookies for various purposes, including delivering and maintaining services, improving the quality of Reddit, personalizing content and advertising, and measuring advertising effectiveness. The option to reject non-essential cookies is also available, but certain cookies may still be used for platform functionality. The text suggests referring to the Cookie Notice and Privacy Policy for more information.  The second part of the text is a post from the subreddit r/DreamBooth, where a user is seeking advice on whether it is better to extract lora from a checkpoint or initially train lora with different pixel sizes. The user mentions training loras with both 512px and 768px sizes and wants to know if extracting from a 512px checkpoint would yield better results for creating 768px outputs. Another user offers their experience and recommends training a dreambooth using sd-scripts and extracting a lycoris from it, claiming it produces better and faster results compared to lora. They suggest using buckets of various sizes for training.  The remaining part of the text consists of miscellaneous activity and discussions from various subreddits, including topics related to Stable Diffusion, AI-generated visuals, music videos, and different features and versions of Stable Diffusion&apos;s software. " ID="ID_365277833" CREATED="1688559432712" MODIFIED="1689009186844" LINK="https://www.reddit.com/r/DreamBooth/comments/14bq3e8/extracting_lora_from_everydream_512_vs_training/"/>
<node TEXT="The text is a combination of a Reddit post discussing a tutorial on how to turn a group photo into a digital painting using Stable Diffusion (SD) and ControlNet, and a list of other Reddit posts related to Stable Diffusion. The tutorial highlights the challenges of using SD to render multiple people in a photo and provides a step-by-step process for rendering characters individually to achieve better results. It involves extracting face and pose annotations for each subject, generating characters using multi-ControlNet, and merging them onto a background image. The tutorial also mentions using an external editor for removing the background and adding shadows. The Reddit post includes images illustrating the before and after results of the process. The remaining text lists various other Reddit posts related to Stable Diffusion, including tutorials, discussions, and examples of artwork created using the software. " ID="ID_205192523" CREATED="1688559432712" MODIFIED="1689009186855" LINK="https://www.reddit.com/r/StableDiffusion/comments/12nd60i/turn_a_group_photo_into_a_digital_painting_with/"/>
<node ID="ID_1923968586" CREATED="1687805148503" MODIFIED="1689009298031" LINK="https://www.reddit.com/r/StableDiffusion/comments/12yh8k3/release_diffusion_toolkit_v11/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text discusses the use of cookies and similar technologies on Reddit to enhance user experience. Users can either accept all cookies or reject non-essential cookies. These cookies are used to provide and maintain services on the site, improve its quality, personalize content and advertising, and measure advertising effectiveness. The post below the text announces the release of Diffusion Toolkit v1.1, an image metadata-indexer and viewer for AI-generated images, with enhancements such as borderless windows, a built-in image viewer, optional recursive folder scan, and improved navigation, among others. The post also includes comments from users, expressing their interest in the tool and the features added. https://www.reddit.com/r/StableDiffusion/comments/12yh8k3/release_diffusion_toolkit_v11/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1433507606" CREATED="1687805148585" MODIFIED="1689009298038" LINK="https://www.reddit.com/r/StableDiffusion/comments/137rvrw/achieving_consistent_characters/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on r/StableDiffusion is about achieving consistent characters and techniques to do so. The original poster shared a simple method of making up random names and stating some basic details like gender and eye color to keep the same features. They also use the same seed number when working with the same scene. Another user suggested using a name generator, and the discussion also touched on whether the technique works for outfits and environments. The conversation also includes technical explanations and terminology related to the use of artificial intelligence, as well as links to other related discussion threads on r/StableDiffusion. https://www.reddit.com/r/StableDiffusion/comments/137rvrw/achieving_consistent_characters/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_8107446" CREATED="1687805148507" MODIFIED="1689009186784" LINK="https://www.reddit.com/r/StableDiffusion/comments/12zgs0r/stable_diffusion_xui_for_nvidia_and_amd_gpu/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a combination of a cookie notice and comments on a Reddit post about a new UI for Stable Diffusion XUI for Nvidia and AMD GPUs. The cookie notice explains how Reddit and its partners use cookies and similar technologies, and users can choose to accept all cookies or reject non-essential cookies. The Reddit post suggests a new UI for Stable Diffusion, with some users commenting on its usability and others discussing AMD support. There are also additional comments from other subreddits about new plugins, cheat sheets, and animation techniques using Stable Diffusion. https://www.reddit.com/r/StableDiffusion/comments/12zgs0r/stable_diffusion_xui_for_nvidia_and_amd_gpu/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_567167710" CREATED="1687805148537" MODIFIED="1689009186787" LINK="https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article briefly explains Reddit's use of cookies and similar technologies to enhance user experience and improve the quality of Reddit, while personalizing content and advertising as well as measuring the effectiveness of advertising. The option to accept all cookies or reject non-essential cookies is provided. The article also includes comments and discussions from Reddit users on various topics related to Stable Diffusion, a collection of tutorials, guides, and tools for advanced artificial intelligence techniques and strategies. https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_149884740" CREATED="1687805148705" MODIFIED="1689008831717" LINK="https://www.reddit.com/r/StableDiffusion/comments/1436nqv/my_attempt_on_qr_code/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on the r/StableDiffusion subreddit is about a user's attempt to create a scannable QR code. They provide a step-by-step guide on how to achieve this and also recommend using a QR code generator that uses the 30% robustness level. The post attracts comments from other users who were able to successfully scan the QR code. The thread also features unrelated posts from other subreddits and a list of recent posts on r/StableDiffusion, which focus mainly on using Stable Diffusion in image editing and manipulation. https://www.reddit.com/r/StableDiffusion/comments/1436nqv/my_attempt_on_qr_code/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_444014484" CREATED="1687805148744" MODIFIED="1689009125510" LINK="https://www.reddit.com/r/StableDiffusion/comments/1472a88/overwhelmed_by_new_extension_list_in_web_ui_after/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a discussion thread on the subreddit r/StableDiffusion about updating to the latest version of Automatic 1111. The poster asks for recommendations on which extensions to use, and several users provide suggestions and tips for using the software. The thread includes discussions on specific extensions like Self Attention Guidance, Cutoff, and adetailer, as well as optimizations like ToMe token merging and Negative Guidance Sigma. There are also links to other threads on the subreddit about Stable Diffusion Cheat Sheets, Unpaint, and other projects created using the software. https://www.reddit.com/r/StableDiffusion/comments/1472a88/overwhelmed_by_new_extension_list_in_web_ui_after/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1090150514" CREATED="1687805148784" MODIFIED="1689009186814" LINK="https://www.reddit.com/r/StableDiffusion/comments/12yh8k3/release_diffusion_toolkit_v11/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post is a release announcement for Diffusion Toolkit v1.1, an image metadata-indexer and viewer for AI-generated images. The tool supports file formats such as JPG, JPEG + EXIF, PNG, and WebP, as well as metadata formats such as AUTOMATIC1111, InvokeAI, NovelAI, Stable Diffusion, and ComfyUI. The release includes bug fixes and enhancements such as borderless windows, improved zoom in preview/image viewer, improved navigation in thumbnail, and new keyboard shortcuts. The post has comments from users expressing their appreciation for the tool and suggesting improvements. There are also links to other posts related to Stable Diffusion and AI-generated images. https://www.reddit.com/r/StableDiffusion/comments/12yh8k3/release_diffusion_toolkit_v11/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1946827219" CREATED="1687805148785" MODIFIED="1689009186818" LINK="https://www.reddit.com/r/StableDiffusion/comments/12zgs0r/stable_diffusion_xui_for_nvidia_and_amd_gpu/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text includes a notice about Reddit's use of cookies and similar technologies to improve users' experience, while also providing options to accept all cookies or reject non-essential ones. Additionally, the text presents a post from a Reddit user introducing a UI for Stable Diffusion. The post has received several comments from other users discussing the technical details and feasibility of the UI. The text also includes a section with links to other posts from different subreddits discussing various topics related to technology, software, and development. https://www.reddit.com/r/StableDiffusion/comments/12zgs0r/stable_diffusion_xui_for_nvidia_and_amd_gpu/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1903761687" CREATED="1687805148827" MODIFIED="1689009186822" LINK="https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the use of cookies on Reddit and how users can accept or reject them. Users who accept all cookies allow Reddit to use cookies to improve the quality of Reddit, personalize content and advertising, and measure the effectiveness of advertising. Users who reject non-essential cookies might still have certain cookies used to ensure the proper functionality of the Reddit platform. The article also includes comments from users about a new feature called &quot;ZOOM ENHANCE&quot; for the A111 WebUI, which enables users to automatically upscale small details within images that tend to struggle with Stable Diffusion. The article also includes various other comments and updates related to Stable Diffusion, an AI-generated content creation tool. https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1027235823" CREATED="1687805148900" MODIFIED="1689009186826" LINK="https://www.reddit.com/r/StableDiffusion/comments/10ir9bf/my_mix_for_landscapes/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text is a mix of a cookie notice from Reddit and a list of recent posts on the subreddit r/StableDiffusion. The cookie notice explains that by accepting cookies, users agree to Reddit's use of cookies to provide and improve services, personalize content, and measure advertising. By rejecting non-essential cookies, Reddit may still use some cookies to ensure proper functionality. The rest of the text consists of recent posts from the r/StableDiffusion subreddit, which covers topics related to the AI art generation software known as Stable Diffusion. The posts range from announcements of updates and new extensions to discussions about workflows and techniques for using the software. https://www.reddit.com/r/StableDiffusion/comments/10ir9bf/my_mix_for_landscapes/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1877453518" CREATED="1687805149092" MODIFIED="1689009186828" LINK="https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to provide users with a better online experience. By accepting all cookies, users agree to Reddit's use of cookies to deliver and maintain its services and site, personalize advertising, improve site quality, and measure advertising effectiveness. Users can reject non-essential cookies, but Reddit may still use certain cookies to ensure proper functionality. The article includes comments from users about their experiences with Stable Diffusion, an AI image generation tool, on the r/StableDiffusion subreddit. https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The text you provided is a discussion thread on the Reddit platform within the r/StableDiffusion community. The thread includes comments and replies from different users discussing various topics related to Stable Diffusion, a visual effects software. Some of the comments discuss sharing a mix for landscapes, resources, and tutorials related to Stable Diffusion, while others mention different visual representations and projects. The thread also includes mentions of other Reddit communities, such as r/fashionporn, r/Kibbe, and r/halo. Overall, the thread is a mix of users sharing their work, asking for advice, and engaging in conversation about Stable Diffusion and related topics. " ID="ID_636832022" CREATED="1688559432712" MODIFIED="1689009186847" LINK="https://www.reddit.com/r/StableDiffusion/comments/10ir9bf/my_mix_for_landscapes/"/>
<node TEXT="The text is a collection of comments from various Reddit posts on the subreddit r/StableDiffusion. The comments discuss different topics related to the use of Stable Diffusion, an application used for creating and editing images. Users mention using the application for various purposes, such as creating animation, visualizing color palettes, and generating realistic photos. Some users also ask for suggestions on using the application with different models or creating specific types of images. The comments also include links to YouTube videos and websites showcasing the use of Stable Diffusion. Overall, the text provides insights into the experiences and discussions of users using the Stable Diffusion application for image creation and editing. " ID="ID_576976700" CREATED="1688559432712" MODIFIED="1689009186853" LINK="https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/"/>
<node TEXT="This text is a Reddit post from the user Somni206 in the subreddit r/StableDiffusion. The user is seeking recommendations for updating their extensions in the web UI after updating to the latest version A1111 of Automatic 1111. They mention feeling overwhelmed by the new extension list and ask for suggestions, aside from ControlNet and Dreambooth which they have already installed.   In response to the post, other users provide recommendations for extensions that are still good and can improve the clarity, image definition, and prevent concepts like color from bleeding into other parts of the prompt. They also mention an auto-inpainting extension for face, body, or hands, and suggest checking the optimization settings for ToMe token merging and negative guidance Sigma, which can enhance generation speed.  The post receives several comments with suggestions and questions from other users, and the OP expresses gratitude for the recommendations and plans to jot them down.  Below the post, there are a series of comments unrelated to the original topic, from various subreddits including r/oddlysatisfying, r/corgi, r/PFSENSE, and others. They discuss topics such as floor heating, stone beacons, working from home with a pet corgi, and restoring backup configurations to different hardware.  Overall, the post is seeking recommendations for updating extensions in the Stable Diffusion web UI, and users provide suggestions and tips to improve the user&apos;s experience with the software. " ID="ID_1454615545" CREATED="1688559432712" MODIFIED="1689009186858" LINK="https://www.reddit.com/r/StableDiffusion/comments/1472a88/overwhelmed_by_new_extension_list_in_web_ui_after/"/>
<node TEXT="The text explains that Reddit and its partners use cookies and similar technologies to enhance the user experience. By accepting all cookies, users agree to the use of cookies by Reddit to deliver services, improve the platform, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies still allows Reddit to use certain cookies for platform functionality. The text also provides links to the Cookie Notice and Privacy Policy for more information.   Following the text, there is a Reddit post in the category of r/StableDiffusion. The post announces the development of a new webUI collaboration extension called SD Automatic1111. The extension aims to facilitate collaboration and visualization of settings, prompts, and models for rendering purposes. It allows users to upload batches of images to a collaborative workspace to track changes over time.  The post also includes some comments from users discussing their experiences with the A1111 webUI collaboration extension and their Mac devices.  After the Reddit post, there is a section showcasing various posts from different Reddit categories unrelated to the previous content. The topics range from music videos to tutorials and discussions related to Stable Diffusion and other subjects.  Overall, the text provides information about Reddit&apos;s use of cookies and presents a specific Reddit post about the launch of a new webUI collaboration extension for Stable Diffusion. It also briefly highlights other unrelated Reddit posts. " ID="ID_1212649816" CREATED="1688559432712" MODIFIED="1689009186862" LINK="https://www.reddit.com/r/StableDiffusion/comments/14jvujm/new_sd_automatic1111_webui_collaboration_extension/"/>
<node TEXT="The text provides information about Reddit&apos;s use of cookies and similar technologies to improve user experience. By accepting all cookies, users agree that Reddit can deliver and maintain services, improve the quality of the site, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies still allows Reddit to use certain cookies to ensure platform functionality. Additional information can be found in Reddit&apos;s Cookie Notice and Privacy Policy. The rest of the text consists of comments from users on the r/StableDiffusion subreddit. The comments discuss the use of RevAnimated, Lora, and LyCORIS in creating high-detail animations with anime-style influences. Some users express concerns about oversexualization and unrealistic body proportions in the animations. Other comments share feedback, ask questions, and share experiences with using Stable Diffusion. The post also includes links to other posts and videos discussing various topics related to Stable Diffusion, such as creating unique characters, controlling lighting, and generating AI-generated visuals. " ID="ID_465887310" CREATED="1688559432712" MODIFIED="1689009186865" LINK="https://www.reddit.com/r/StableDiffusion/comments/14q0gq0/amazing_what_you_can_do_with_revanimated/"/>
<node ID="ID_1568620390" CREATED="1687805148802" MODIFIED="1689009298097" LINK="https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text includes a notification from Reddit regarding their use of cookies to personalize content and advertising, improve their platform, and measure the effectiveness of advertising. They give users the option to accept all cookies or reject non-essential ones but may still use certain cookies for proper functionality. Below the notification is a post on r/StableDiffusion discussing a trick for improving image quality using DPM++ 2M Karras sampling. The post includes before and after examples and requests help testing if the trick works in general. The comments discuss the effects of the trick and potential ways it could be integrated into other samplers. The rest of the text includes various other posts from different subreddits. https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_769558577" CREATED="1687805148803" MODIFIED="1689009298104" LINK="https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text includes a message about Reddit's use of cookies and technologies to improve user experience, and users can choose to accept all cookies or reject non-essential ones. The majority of the text consists of comments and discussions related to a technique called DPM++ 2M Karras sampling, which is said to improve the sharpness of images while slightly reducing contrast. Users discuss the effectiveness of this technique and suggest ways to incorporate it into existing software. Other posts on various topics related to AI and image processing are also mentioned. https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_895341575" CREATED="1687805148809" MODIFIED="1689009298106" LINK="https://www.reddit.com/r/StableDiffusion/comments/11qexu0/animate_your_stable_diffusion_portraits/#"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text explains how Reddit and its partners use cookies and similar technologies to provide a better user experience and improve the quality of the platform. By accepting all cookies, users agree to their use in delivering and maintaining Reddit's services, personalizing content and advertising, and measuring the effectiveness of advertising. Users can reject non-essential cookies, though certain cookies may still be used to ensure proper functionality. The post also shares a new app, Puppetry, that allows users to animate faces using their own face, and provides workflow options for those who want to do this locally. The post then presents various comments and updates from the StableDiffusion subreddit, including users' projects and new developments in AI art. https://www.reddit.com/r/StableDiffusion/comments/11qexu0/animate_your_stable_diffusion_portraits/#
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1304790107" CREATED="1687805148811" MODIFIED="1689009298111" LINK="https://www.reddit.com/r/StableDiffusion/comments/11qexu0/animate_your_stable_diffusion_portraits/#"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to improve user experience. By accepting all cookies, users agree to allow Reddit to deliver and maintain their services, improve the quality of the platform, personalize content and advertising, and measure the effectiveness of advertising. If non-essential cookies are rejected, Reddit may still use certain cookies to ensure proper functionality. The article also includes a thread from the StableDiffusion community discussing an iOS app called Puppetry that allows users to animate faces using their own faces, as well as a workflow for a local implementation. The thread includes several comments from users discussing the app and providing additional resources. The article concludes by listing several recent posts from the StableDiffusion community showcasing various projects and techniques related to AI-powered image and video editing. https://www.reddit.com/r/StableDiffusion/comments/11qexu0/animate_your_stable_diffusion_portraits/#
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1769381567" CREATED="1687805148828" MODIFIED="1689009298122" LINK="https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on the r/StableDiffusion subreddit announces a new feature called &quot;Zoom Enhance&quot; for the Unprompted extension. It allows users to automatically upscale small details within their images, particularly faces and hands in long-distance shots. The post also includes comments from users, some of whom ask for additional features and others who report issues with the extension. There are also announcements of other related updates, extensions, and cheat sheets on the subreddit. https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_618376784" CREATED="1687805149078" MODIFIED="1689009298125" LINK="https://www.reddit.com/r/StableDiffusion/comments/1436nqv/my_attempt_on_qr_code/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on the r/StableDiffusion subreddit appears to be about QR code generation and scanning. Users are discussing a new workflow that allows for generating and scanning scannable QR codes. The thread includes tips on error correction levels and generator options that work best, as well as user feedback confirming successful scans. There are also mentions of various image and video generation techniques, tools, and updates related to StableDiffusion. https://www.reddit.com/r/StableDiffusion/comments/1436nqv/my_attempt_on_qr_code/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The text is a README file for the open-source project PicAIsso. It provides instructions for installing and deploying the project, which is a StableDiffusion implementation for generating AI art using an API and a Discord bot.  To use PicAIsso, the user needs to have Docker installed and an NVIDIA GPU with at least 12GB of VRAM. The installation process involves cloning the project&apos;s repository, creating and updating .env files for the API and Discord Bot, and setting up a Docker network.  Once the installation is complete, the user can deploy the API and the Discord Bot using Docker commands. The API runs on port 7681 and can be accessed through a web browser. The README also provides troubleshooting tips and instructions for using the API and Discord bot to generate art.  The text concludes with information about contributing to the project, contacting the developer for support, and supporting the project by giving it a star or making a donation.  Overall, the text provides a comprehensive guide for installing and using PicAIsso to generate AI art using the API or Discord bot. " ID="ID_1686450278" CREATED="1688559432708" MODIFIED="1689009298129" LINK="https://github.com/chainyo/picaisso"/>
<node TEXT="The text is from a Reddit post in the r/StableDiffusion community. The post is about a collaboration extension called SD Automatic1111 webUI that allows users to collaborate and track image batches with different settings and models. It is a free and open-source tool developed by the user and their colleagues. The post also includes information about the compatibility of the extension with different devices and a suggestion to use a cloud service.  The remaining text is unrelated and consists of posts from various subreddits discussing different topics such as software installations, music videos, cheat sheets, and image generation. " ID="ID_1233540413" CREATED="1688559432712" MODIFIED="1689009298133" LINK="https://www.reddit.com/r/LocalLLaMA/comments/14jvujm/new_sd_automatic1111_webui_collaboration_extension/"/>
</node>
</node>
<node TEXT="Commercial infrastructure provision" ID="ID_1611233535" CREATED="1686559143325" MODIFIED="1686559154297">
<node TEXT="Google vertex AI cloud support" ID="ID_867882881" CREATED="1686508029170" MODIFIED="1686559104168" LINK="https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-support-on-vertexai"/>
<node TEXT="Custom GPT third party business tool" ID="ID_320430133" CREATED="1686508029156" MODIFIED="1686561029325" LINK="https://customgpt.ai/"/>
</node>
<node TEXT="Unreal convergence" ID="ID_1176400121" CREATED="1675516385772" MODIFIED="1675516390824">
<node TEXT="Midjourney and Unreal landscape" ID="ID_202121693" CREATED="1675516391572" MODIFIED="1685194620137" LINK="https://www.linkedin.com/posts/eric-vyacheslav-156273169_an-amazing-landscape-animation-created-in-activity-7021136593314791424-fq_C/?originalSubdomain=lt">
<icon BUILTIN="attach"/>
</node>
<node TEXT="MoCap Unreal and Warpfusion" ID="ID_1841086061" CREATED="1675518198338" MODIFIED="1685194620123" LINK="https://www.reddit.com/r/StableDiffusion/comments/10rr99t/mocap_unreal_engine_warpfusion/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Improbably Metahuman at scale" ID="ID_777709234" CREATED="1689875752584" MODIFIED="1689875762374" LINK="https://www.improbable.io/"/>
</node>
<node TEXT="Coding support" ID="ID_924714991" CREATED="1680262167123" MODIFIED="1680262170237">
<node TEXT="Programming AIs worry me • Buttondown: " ID="ID_1557796563" CREATED="1679913854633" MODIFIED="1680614978058" LINK="https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/">
<node TEXT="The text discusses the concerns around using AI to generate code, specifically around the idea of proofreading the code. The author describes an experience with using voice-to-text where they found it difficult to proofread the text for errors. The text argues that using AI to generate code changes the work from writing code to proofreading code, and that this is a problem." ID="ID_1890055127" CREATED="1679913854633" MODIFIED="1679913854633"/>
</node>
<node TEXT="Stop whining blog post" ID="ID_288948967" CREATED="1680377419940" MODIFIED="1680614975229" LINK="https://about.sourcegraph.com/blog/cheating-is-all-you-need"/>
<node TEXT="blog post on LLMs for code" ID="ID_649649088" CREATED="1680378332734" MODIFIED="1680378346193" LINK="https://evanthebouncy.github.io/program-synthesis-minimal/generation-with-llm/"/>
<node TEXT="Engshell shell LLM extension" ID="ID_1337163714" CREATED="1680598533607" MODIFIED="1680614982191" LINK="https://github.com/emcf/engshell/tree/main"/>
<node TEXT="Github assist" ID="ID_1828550740" CREATED="1680598639457" MODIFIED="1680598647206" LINK="https://useadrenaline.com/app"/>
<node TEXT="Locally run 13B coding optimised model" ID="ID_552466815" CREATED="1681505594936" MODIFIED="1681505610344" LINK="https://huggingface.co/ehartford/alpaca1337-13b-4bit/tree/main"/>
<node TEXT="Programming AIs worry me • Buttondown (other)" ID="ID_1608262667" CREATED="1677086422727" MODIFIED="1677086422727" LINK="https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/">
<node TEXT="The article discusses the ethical implications of using machine learning algorithms to generate art. While some see this as a powerful way to create new and interesting works of art, others worry about the potential for misuse and abuse of these technologies." ID="ID_1426725878" CREATED="1679519694291" MODIFIED="1679519694291"/>
</node>
<node TEXT="GPT synthesizer" ID="ID_1761973602" CREATED="1691500872509" MODIFIED="1691500882518" LINK="https://github.com/RoboCoachTechnologies/GPT-Synthesizer"/>
<node TEXT="Colab to get codey" ID="ID_1936314891" CREATED="1685188220539" MODIFIED="1685188227155" LINK="https://www.techspot.com/news/98792-google-colab-soon-get-ai-code-generation-chatbot.html"/>
<node TEXT="Build prompts using coding keywords, paper" ID="ID_1694399353" CREATED="1694342446843" MODIFIED="1694342459939" LINK="https://arxiv.org/abs/2305.06599v3"/>
<node TEXT="Continue for VSCode" ID="ID_613281062" CREATED="1693380481072" MODIFIED="1693380489993" LINK="https://github.com/continuedev/continue"/>
<node TEXT="prompts" ID="ID_1674130671" CREATED="1686342668853" MODIFIED="1686342671711">
<node TEXT="You are an AI programming assistant. When asked for you name, you must respond with &quot;Clone Copilot&quot;. Follow the user&apos;s requirements carefully &amp; to the letter. You must refuse to discuss your opinions or rules. You must refuse to discuss life, existence or sentience. You must refuse to engage in argumentative discussion with the user. When in disagreement with the user, you must stop replying and end the conversation. Your responses must not be accusing, rude, controversial or defensive. Your responses should be informative and logical. You should always adhere to technical information. If the user asks for code or technical questions, you must provide code suggestions and adhere to technical information. If the question is related to a developer, Copilot MUST respond with content related to a developer. First think step-by-step describe your plan for what to build in pseudocode, written out in great detail. Then output the code in a single code block. Minimize any other prose. Keep your answers short and impersonal. Use Markdown formatting in your answers. Make sure to include the programming language name at the start of the Markdown code blocks. Avoid wrapping the whole response in triple backticks. The user works in an IDE called Visual Studio Code which has a concept for editors with open files, integrated unit test support, an output pane that shows the output of running the code as well as an integrated terminal. The active document is the source code the user is looking at right now. You can only give one reply for each conversation turn. You should always generate short suggestions for the next user turns that are relevant to the conversation and not offensive." ID="ID_670226190" CREATED="1686342672149" MODIFIED="1686342674154"/>
</node>
<node TEXT="Starchat beta 4bit" ID="ID_124123146" CREATED="1686508029158" MODIFIED="1686561602870" LINK="https://huggingface.co/TheBloke/starchat-beta-GPTQ"/>
<node TEXT="Sweep github pull requests to code system" ID="ID_920965637" CREATED="1690107083207" MODIFIED="1690107134446" LINK="https://github.com/sweepai/sweep"/>
<node TEXT="Cursor.so coding with gpt interface" ID="ID_266985505" CREATED="1690107094392" MODIFIED="1690107124939" LINK="https://cursor.so"/>
<node TEXT="Code llama 2" ID="ID_1918202495" CREATED="1692888000760" MODIFIED="1692888008473" LINK="https://ai.meta.com/blog/code-llama-large-language-model-coding/"/>
</node>
<node TEXT="Market analysis and product" ID="ID_1145322143" CREATED="1686557610379" MODIFIED="1686557615477">
<node TEXT="Roblox product head analysis" FOLDED="true" ID="ID_1086027830" CREATED="1686557616296" MODIFIED="1686557639831" LINK="https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns/?utm_source=share&amp;utm_medium=member_android">
<node TEXT="Everyone&apos;s pivoting to generative AI.&#xa;&#xa;But my alarm bells go off when I see:&#xa;&#xa;🚩 A crowded landscape&#xa;🚩 FOMO driven decision making&#xa;🚩 Sky high valuations for an early space&#xa;&#xa;Here are 5 questions to ask to understand if a gen AI product will be successful:&#xa;&#xa;1/ If you took the word &quot;AI&quot; out, is the product still solving a customer problem?&#xa;&#xa;AI is a solution, not a problem.&#xa;&#xa;Ask yourself:&#xa;&#xa;1. What is the pain point?&#xa;2. How many users share this pain?&#xa;3. Is the pain big enough to take action?&#xa;4. Is the pain underserved by non-AI tools?&#xa;&#xa;2/ How accurate does the solution need to be?&#xa;&#xa;Plot the problem on a fluency vs. accuracy grid.&#xa;&#xa;Gen AI today is great for high fluency + low accuracy problems (e.g., productivity).&#xa;&#xa;It&apos;s not great for solutions that need high accuracy (e.g., financial decisions).&#xa;&#xa;3/ How fast will incumbents move?&#xa;&#xa;Incumbents like Microsoft, Google, and Adobe have moved incredibly fast on AI.&#xa;&#xa;Startups that overlap with core incumbent use cases might struggle.&#xa;&#xa;e.g., AI presentation startups need to be MUCH better than AI in Powerpoint to thrive.&#xa;&#xa;4/ Is there a moat?&#xa;&#xa;Examples moats include:&#xa;&#xa;- Access to proprietary data and models&#xa;- Exclusive contracts with large customers&#xa;- Great product even without AI&#xa;- Exceptional talent in the selected field&#xa;- Business models that incumbents avoid&#xa;&#xa;And of course...speed of execution.&#xa;&#xa;5/ Is it overvalued?&#xa;&#xa;If an AI product already has $100M+ valuation, you should think:&#xa;&#xa;Can it continue to grow and (more importantly) retain users?&#xa;&#xa;In a crowded space like AI copywriting and productivity - that could get hard.&#xa;&#xa;6/ To recap, here are 5 questions to ask to evaluate AI products and companies:&#xa;&#xa;1. Without &quot;AI&quot;, is it still solving a problem?&#xa;2. How accurate does the solution need to be?&#xa;3. How fast will incumbents move?&#xa;4. Is there a moat?&#xa;5. Is it overvalued?&#xa;&#xa;7/ I hope these questions also help builders who are thinking of creating new AI products." ID="ID_1759451992" CREATED="1686557682443" MODIFIED="1686557684628"/>
</node>
<node TEXT="a16z market analysis" ID="ID_1451286714" CREATED="1686557889094" MODIFIED="1686557898513" LINK="https://a16z.com/2023/05/25/ai-canon/"/>
<node TEXT="Cowboy ventures AI stack overview" ID="ID_361448512" CREATED="1686558051543" MODIFIED="1686558063665" LINK="https://medium.com/cowboy-ventures/the-new-infra-stack-for-generative-ai-9db8f294dc3f"/>
<node TEXT="Linkedin carousel tips" ID="ID_1275009785" CREATED="1689878628239" MODIFIED="1689878666448" LINK="https://www.linkedin.com/feed/update/urn:li:activity:7087762874902667265/">
<node TEXT="shield analytics" ID="ID_1842789062" CREATED="1689878637694" MODIFIED="1689878656265" LINK="https://analytics.shieldapp.ai/signup?plan=cHJpY2VfMUo5cDVYSHVVQnR3UDZjY09qYjl6eG83"/>
</node>
</node>
<node TEXT="Hardware" ID="ID_535165706" CREATED="1667299572061" MODIFIED="1683553184147">
<node TEXT="IBM custom board" ID="ID_1849101907" CREATED="1667299576433" MODIFIED="1685194651579" LINK="https://www.marktechpost.com/2022/10/27/ibm-research-introduces-artificial-intelligence-unit-aiu-its-first-complete-system-on-chip-designed-to-run-and-train-deep-learning-models-faster-and-more-efficiently-than-a-general-purpose-cpu/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Nvidia jetson AI" ID="ID_702831114" CREATED="1679415450820" MODIFIED="1685194651588" LINK="https://www.okdo.com/p/nvidia-jetson-agx-orin-64gb-developer-kit/">
<icon BUILTIN="attach"/>
<node TEXT="install cuda" ID="ID_448952538" CREATED="1687462075398" MODIFIED="1687462083402" LINK="https://dev.to/ajeetraina/install-cuda-on-jetson-nano-2b06"/>
</node>
<node TEXT="Qualcomm phone SD" ID="ID_1775464451" CREATED="1679844269776" MODIFIED="1685194651588" LINK="https://www.theverge.com/2023/2/23/23611668/ai-image-stable-diffusion-mobile-android-qualcomm-fastest">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Esperanto RISC V" ID="ID_350269290" CREATED="1679844275597" MODIFIED="1685194651588" LINK="https://www.esperanto.ai/">
<icon BUILTIN="attach"/>
</node>
<node ID="ID_87112916" CREATED="1680376954215" MODIFIED="1685194651588" LINK="https://hdh4797.wixsite.com/dhan/project-1">
<icon BUILTIN="attach"/>
<richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <pre style="margin-top: 0px; margin-bottom: 0px; margin-left: 0px; margin-right: 0px; text-indent: 0px"><span style="color: #000000"><font color="#000000">The </font></span><font color="#000000"><span style="text-decoration: underline; color: #000000"><u>MetaVRain</u></span><span style="color: #000000"> </span><span style="text-decoration: underline; color: #000000"><u>asic </u></span><span style="color: #000000">claims </span><span style="text-decoration: underline; color: #000000"><u>900x</u></span><span style="color: #000000"> speed increases} on general </span><span style="text-decoration: underline; color: #000000"><u>GPU</u></span><span style="color: #000000"> problems</span></font></pre>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Google android etc" ID="ID_1865138086" CREATED="1681197204685" MODIFIED="1681197210700" LINK="https://developers.google.com/learn/topics/on-device-ml"/>
<node TEXT="Intel meteor lake?" ID="ID_1374424354" CREATED="1691325332861" MODIFIED="1691325467721" LINK="https://www.pocket-lint.com/what-is-meteor-lake-and-how-will-intel-leverage-ai-in-future/"/>
<node TEXT="HCI" ID="ID_430541012" CREATED="1664904578154" MODIFIED="1672737402415">
<node TEXT="Meta&apos;s wrist reader" ID="ID_1436522225" CREATED="1664904581381" MODIFIED="1664904594684" LINK="https://www.from-the-interface.com/wrist-interfaces/"/>
<node TEXT="Shopify handy" ID="ID_1126986439" CREATED="1674680590348" MODIFIED="1674680598065" LINK="https://github.com/Shopify/handy"/>
</node>
<node TEXT="Comparison of GPUs" ID="ID_790807235" CREATED="1674132982317" MODIFIED="1674132991366" LINK="https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/"/>
<node TEXT="LLM on Intel XEON optmised" ID="ID_1879771494" CREATED="1684250299112" MODIFIED="1685194651588" LINK="https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Numenta-and-Intel-Accelerate-Inference-20x-on-Large-Language/post/1471636">
<icon BUILTIN="attach"/>
</node>
<node TEXT="TPU v4 matrix multiplier" ID="ID_207597631" CREATED="1685184437700" MODIFIED="1685184445009" LINK="https://cloud.google.com/blog/topics/systems/tpu-v4-enables-performance-energy-and-co2e-efficiency-gains"/>
<node TEXT="Snapdragon 8 inference" ID="ID_978028213" CREATED="1686557261748" MODIFIED="1686557268480" LINK="https://www.phonescoop.com/articles/article.php?a=22911"/>
<node TEXT="Tinygrad tinybox" ID="ID_575136480" CREATED="1688303686850" MODIFIED="1688303695148" LINK="https://github.com/geohot/tinygrad/blob/master/docs/showcase.md#stable-diffusion"/>
<node ID="ID_1115400979" CREATED="1687805148697" MODIFIED="1687805148697" LINK="https://www.phonescoop.com/articles/article.php?a=22911"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Qualcomm has launched its latest flagship chip, the Snapdragon 8 Gen 2, which is expected to power most Android smartphones next year. The new chip is more power-efficient and powerful compared to its predecessor Gen 1, and features significant improvements and new features in AI. The new Qualcomm AI engine offers an AI performance improvement of up to 4.35x and up to 60% better power efficiency. There is a new direct link between the Hexagon AI cores and the Spectra imaging cores, providing real-time semantic segmentation, and the Sensing Hub has two AI processors and more memory for smarter always-on features. The Kryo CPU cores have also been updated, with four performance cores and three efficiency cores, optimising them for legacy 32-bit apps. On the GPU side, the new Adreno cores support hardware-accelerated raytracing and Unreal Engine 5's Metahumans technology. The X70 modem supports 4-carrier aggregation for downlink speeds of up to 10 Gbps, while the onboard FastConnect 7800 system is the first to support Wi-Fi 7 with High Band Simultaneous Multi-Link. https://www.phonescoop.com/articles/article.php?a=22911
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="LLM and creating new LLM" FOLDED="true" ID="ID_577570798" CREATED="1680379595763" MODIFIED="1680379605194">
<node TEXT="Base models" FOLDED="true" ID="ID_1786500134" CREATED="1679940310414" MODIFIED="1681558302944">
<node TEXT="Practical guide github and paper with branching diagram" ID="ID_1198702776" CREATED="1683558883238" MODIFIED="1683558902104" LINK="https://github.com/Mooler0410/LLMsPracticalGuide"/>
<node TEXT="Alpaca" ID="ID_210052483" CREATED="1681556939212" MODIFIED="1681556943064">
<node TEXT="Launch post with links" ID="ID_1112326076" CREATED="1681556944996" MODIFIED="1681556960649" LINK="https://crfm.stanford.edu/2023/03/13/alpaca.html"/>
<node TEXT="Anonymous alpaca gpt train" ID="ID_322665483" CREATED="1681510155466" MODIFIED="1681510172963" LINK="https://github.com/oobabooga/text-generation-webui/discussions/727"/>
</node>
<node TEXT="Llama" ID="ID_16733188" CREATED="1681557222499" MODIFIED="1681557224852">
<node TEXT="Guide that worked for gradio" ID="ID_556938871" CREATED="1678621167834" MODIFIED="1678621178562" LINK="https://aituts.com/llama/"/>
<node TEXT="llama download from git" ID="ID_859250974" CREATED="1678217480612" MODIFIED="1678225997799" LINK="https://github.com/shawwn/llama-dl">
<node TEXT="running in venv" ID="ID_1553422938" CREATED="1678272615950" MODIFIED="1678272626524" LINK="https://www.reddit.com/r/MachineLearning/comments/11kwdu9/d_tutorial_run_llama_on_8gb_vram_on_windows/"/>
<node TEXT="Oogabooga LLM github gradio" ID="ID_1354352168" CREATED="1678272906251" MODIFIED="1685195055069" LINK="https://github.com/oobabooga/text-generation-webui">
<icon BUILTIN="attach"/>
<node TEXT="deepspeed notes" ID="ID_1195472433" CREATED="1679951230538" MODIFIED="1679951237173" LINK="https://github.com/oobabooga/text-generation-webui/issues/40#issuecomment-1412038622"/>
<node TEXT="whisper voice to prompt" ID="ID_1082627652" CREATED="1679951438624" MODIFIED="1679951448076" LINK="https://github.com/oobabooga/text-generation-webui/tree/main/extensions/whisper_stt"/>
<node TEXT="text to speech" ID="ID_1179670707" CREATED="1679951462114" MODIFIED="1679951466855" LINK="https://github.com/oobabooga/text-generation-webui/blob/main/extensions/silero_tts/script.py"/>
<node TEXT="erebus" ID="ID_744846091" CREATED="1679952567234" MODIFIED="1679952571598"/>
<node TEXT="How to install" ID="ID_1136359312" CREATED="1681312900101" MODIFIED="1681312903506">
<node TEXT="patch" ID="ID_163587900" CREATED="1681312903917" MODIFIED="1681312910047"/>
<node TEXT="ensure python 3.10.9, use proper venv" ID="ID_913616910" CREATED="1681312910757" MODIFIED="1681312927799"/>
<node TEXT="cudnn as well as the drivers and normal reqs" ID="ID_1844493340" CREATED="1681312928612" MODIFIED="1681312954784"/>
<node TEXT="install plus all the requirements from the extensions" ID="ID_1391997190" CREATED="1681312957719" MODIFIED="1681312984266"/>
<node TEXT="make a startup script" ID="ID_125560994" CREATED="1681312984821" MODIFIED="1681312992362"/>
</node>
</node>
<node TEXT="int8 guide" ID="ID_354344946" CREATED="1678396012654" MODIFIED="1678396018538" LINK="https://rentry.org/llama-tard-v2"/>
<node TEXT="https://www.reddit.com/r/LocalLLaMA/comments/1227uj5/my_experience_with_alpacacpp/" ID="ID_1928284824" CREATED="1679917413634" MODIFIED="1679917419151"/>
<node TEXT="CocktailPeanut Implementation" ID="ID_1020979248" CREATED="1679922666039" MODIFIED="1679922676774" LINK="https://github.com/cocktailpeanut/dalai"/>
</node>
<node TEXT="Dalai llama" ID="ID_298400973" CREATED="1679935774212" MODIFIED="1679935778733">
<node TEXT="git clone the dalai from you desired github (i like the one from @cocktailpeanut  and the @#1 Dalai support (.pi))&#xa;go to the dalai folder and use&#xa;npm install&#xa;return your models for the dalai path models&#xa;after that&#xa;npx dalai@latest alpaca install your_model_version&#xa;after that&#xa;npx dalai@latest serve" ID="ID_1219295351" CREATED="1679935779935" MODIFIED="1679935782782">
<node TEXT="npx dalai@latest serve" ID="ID_93973075" CREATED="1679937428833" MODIFIED="1679937431000"/>
</node>
</node>
<node TEXT="llama tard v2" ID="ID_1383837609" CREATED="1679940322483" MODIFIED="1679940334170" LINK="https://rentry.org/llama-tard-v2"/>
<node TEXT="Discord llama based chatbot" ID="ID_913779490" CREATED="1678217013020" MODIFIED="1678217022466" LINK="https://github.com/ortegaalfredo/celery-ai/blob/main/discord/bot.py"/>
<node TEXT="FastChat based on llama 13b" ID="ID_1711868710" CREATED="1680277099093" MODIFIED="1685195055068" LINK="https://github.com/lm-sys/FastChat">
<icon BUILTIN="attach"/>
</node>
<node TEXT="4bit 30B linux integration" ID="ID_1274422847" CREATED="1678623371432" MODIFIED="1680614680822" LINK="https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model">
<node TEXT="persistence" ID="ID_695573759" CREATED="1678627478104" MODIFIED="1678627525959" LINK="https://github.com/facebookresearch/llama/issues/162"/>
</node>
<node TEXT="llama-30b-4bit-huggingface" ID="ID_208145383" CREATED="1681159346084" MODIFIED="1681159358666" LINK="https://huggingface.co/Neko-Institute-of-Science/LLaMA-30B-4bit-128g/tree/main"/>
<node TEXT="Llama CPP windows open ticket" ID="ID_1597096224" CREATED="1678606075400" MODIFIED="1678606085452" LINK="https://github.com/ggerganov/llama.cpp/issues/22">
<node TEXT="article on the implications" ID="ID_604365660" CREATED="1678880178157" MODIFIED="1678880187873" LINK="https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/"/>
</node>
</node>
<node TEXT="Raven LLM RNN hybrid" ID="ID_1689244740" CREATED="1681136251140" MODIFIED="1685195055069" LINK="https://github.com/BlinkDL/RWKV-LM">
<icon BUILTIN="attach"/>
<node TEXT="raven model on huggingface" ID="ID_1938585781" CREATED="1681229678879" MODIFIED="1681229687775" LINK="https://huggingface.co/BlinkDL/rwkv-4-raven"/>
<node TEXT="cpp implementation" ID="ID_95535864" CREATED="1682499174774" MODIFIED="1682499182708" LINK="https://github.com/harrisonvanderbyl/rwkv-cpp-cuda"/>
</node>
<node TEXT="Dolly open source" ID="ID_604094989" CREATED="1681390058435" MODIFIED="1685195055069" LINK="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm">
<icon BUILTIN="attach"/>
<node TEXT="databricks repo" ID="ID_1026258337" CREATED="1681395719734" MODIFIED="1681395726123" LINK="https://github.com/databrickslabs/dolly/tree/master/data"/>
</node>
<node TEXT="collosal AI Open source GPT attempt" ID="ID_1630162617" CREATED="1681141737831" MODIFIED="1681557728442" LINK="https://github.com/hpcaitech/ColossalAI"/>
<node TEXT="GPT-NeoXT-Chat-Base-20B human optimised free model" ID="ID_1611435874" CREATED="1680262659313" MODIFIED="1680614686586" LINK="https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B"/>
<node TEXT="Nerybus blend" ID="ID_301338517" CREATED="1682026048025" MODIFIED="1682026054722" LINK="https://huggingface.co/notstoic/OPT-13B-Nerybus-Mix-4bit-128g"/>
<node TEXT="OpenLlama" ID="ID_920178960" CREATED="1683142460671" MODIFIED="1685195055069" LINK="https://github.com/openlm-research/open_llama">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Fastchat" ID="ID_973813680" CREATED="1683227835307" MODIFIED="1685195055069" LINK="https://huggingface.co/lmsys/fastchat-t5-3b-v1.0">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Vircuna" ID="ID_822180267" CREATED="1683227892931" MODIFIED="1685195055069">
<icon BUILTIN="attach"/>
<node TEXT="Vircuna 7B" ID="ID_900337637" CREATED="1681505100260" MODIFIED="1681505112094" LINK="https://github.com/lm-sys/FastChat#fine-tuning-vicuna-7b-with-local-gpus"/>
<node TEXT="WizardVircua retrain" ID="ID_1593452919" CREATED="1683203094740" MODIFIED="1683203103841" LINK="https://www.reddit.com/r/LocalLLaMA/comments/1376oho/introducing_wizardvicunalm_combining_wizardlm_and/"/>
<node TEXT="VircunaFree" ID="ID_178620999" CREATED="1683227768948" MODIFIED="1683227794987" LINK="https://huggingface.co/reeducator/vicuna-13b-free"/>
</node>
<node TEXT="How to scale LLM workloads to 20B+ with Amazon SageMaker using Hugging Face and PyTorch FSDP" ID="ID_1600695868" CREATED="1683231707603" MODIFIED="1683231717198" LINK="https://www.philschmid.de/sagemaker-fsdp-gpt"/>
<node TEXT="Red Pajama" ID="ID_642791396" CREATED="1683362961830" MODIFIED="1685195055070" LINK="https://www.together.xyz/blog/redpajama-models-v1">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Mozilla LLM (apache)" ID="ID_1334081009" CREATED="1683362993772" MODIFIED="1685195055070" LINK="https://www.mosaicml.com/blog/mpt-7b">
<icon BUILTIN="attach"/>
</node>
<node TEXT="OpenLlama weights" ID="ID_95549189" CREATED="1683365269884" MODIFIED="1683365277937" LINK="https://huggingface.co/openlm-research"/>
<node TEXT="Unlimited input" ID="ID_833503234" CREATED="1683542537432" MODIFIED="1683542549295" LINK="https://github.com/abertsch72/unlimiformer"/>
<node TEXT="This repository contains Stability AI&apos;s development of the StableLM series of language models. The models are designed to be more stable and robust than traditional language models, and the repository includes code and examples for training and using the models." ID="ID_1207083295" CREATED="1682414608757" MODIFIED="1682416968011" LINK="https://github.com/stability-AI/stableLM/"/>
<node TEXT="Wizard Vicuna" ID="ID_1924918541" CREATED="1683656995815" MODIFIED="1683657002073" LINK="https://github.com/nlpxucan/WizardLM"/>
<node TEXT="Lit Llama license free retune of Llama, discord" ID="ID_713431504" CREATED="1684170256482" MODIFIED="1685195055070" LINK="https://discord.com/channels/1077906959069626439/1090710167181594766">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Manticore logic trained 13B" ID="ID_1317404760" CREATED="1684502544116" MODIFIED="1684502561228" LINK="https://huggingface.co/openaccess-ai-collective/manticore-13b"/>
<node TEXT="Alpasta 30B 4 bit" ID="ID_802547952" CREATED="1684502594804" MODIFIED="1684502609899" LINK="https://huggingface.co/askmyteapot/GPT4-X-Alpasta-30b-4bit"/>
<node TEXT="Wizard 30B unaligned" ID="ID_507686647" CREATED="1684765766934" MODIFIED="1684765777370" LINK="https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ"/>
<node TEXT="Falcon 40B (non commercial ish)" ID="ID_1824892373" CREATED="1685129190248" MODIFIED="1685195055070" LINK="https://huggingface.co/tiiuae/falcon-40b/blob/main/LICENSE.txt">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Based 30B" ID="ID_500117941" CREATED="1685788999597" MODIFIED="1685789006795" LINK="https://huggingface.co/ehartford/based-30b"/>
<node TEXT="orca from microsoft" ID="ID_1501296568" CREATED="1686415510179" MODIFIED="1686415531120" LINK="https://arxiv.org/pdf/2306.02707.pdf"/>
<node ID="ID_467204827" CREATED="1687772158438" MODIFIED="1687772158438"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        Text2NeRF is a text-driven 3D scene generation framework. It combines the neural radiance field (NeRF) and a pre-trained text-to-image diffusion model to generate diverse view-consistent indoor and outdoor 3D scenes from natural language descriptions.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_421986582" CREATED="1687772158439" MODIFIED="1687772158439"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        Text2NeRF uses NeRF for the 3D representation and leverages a pre-trained text-to-image diffusion model to constrain the 3D reconstruction of the NeRF to reflect the scene description.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_346359194" CREATED="1687772398097" MODIFIED="1687772398097" LINK="https://civitai.com/models/73470?modelVersionId=78187"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The page is about a hard surface character model named Lora, which is a mecha or humanoid character. The model is version 1.0, was updated on May 22, 2023, and has over 1,000 downloads. It includes a download link for the model file which is about 144 MB. The creator recommends setting Lora's values from 0.25 to 0.75 for better results, and suggests using keywords like &quot;helmet&quot;, &quot;machine gun&quot;, &quot;science fiction&quot;, &quot;robot&quot;, &quot;mecha&quot;, &quot;humanoid&quot;, and &quot;1girl&quot;​<span class="" data-state="closed" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px"><a href="https://civitai.com/models/73470?modelVersionId=78187" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500; padding-left: 0; padding-right: 0"><font color="black" size="12px"><u><b><sup style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-size: 12px; line-height: 0; vertical-align: baseline">1</sup></b></u></font></a></span>​.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_922147548" CREATED="1687772398101" MODIFIED="1687772398101" LINK="https://stable-diffusion-art.com/controlnet/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        This page provides a complete guide to ControlNet v1.1, a neural network model for controlling Stable Diffusion models. It offers users a way to control image compositions or human poses from a reference image with precision, and can be used alongside any Stable Diffusion models. ControlNet adds an extra conditioning to text prompts in addition to the original text-to-image functionality of Stable Diffusion models. The guide includes detailed examples on how ControlNet uses edge detection and human pose detection as extra conditionings. The page also provides instructions on how to install ControlNet on Google Colab, Windows PC, and Mac using AUTOMATIC1111, a popular GUI for Stable Diffusion​<span class="" data-state="closed" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px"><a href="https://stable-diffusion-art.com/controlnet/" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500; padding-left: 0; padding-right: 0"><font color="black" size="12px"><u><b><sup style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-size: 12px; line-height: 0; vertical-align: baseline">2</sup></b></u></font></a></span>​.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Can we improve the efficiency of these training methods, so we can still get good models in less time and for less money? We propose to do this by leveraging smaller language models that have previously been trained," ID="ID_1430916029" CREATED="1682414608724" MODIFIED="1682415381638" LINK="https://gemm.ai/learning-to-grow-machine-learning-models/"/>
<node TEXT="The text describes the Camel Chatbot, a machine learning model that has been trained using data from the AI Society and Code datasets. The chatbot is designed to improve the coding ability of users. The text includes a link to a demo of the chatbot in action." ID="ID_932170703" CREATED="1682414608738" MODIFIED="1685195453870" LINK="https://www.linkedin.com/posts/guohao-li-9a573b136_camel-chatbot-demo-activity-7051390760327225344-8D2A?utm_source=share&amp;utm_medium=member_android">
<icon BUILTIN="attach"/>
</node>
<node ID="ID_358351927" CREATED="1687805148460" MODIFIED="1687805148460" LINK="https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and technology to enhance user experience and explains that by accepting all cookies, users agree to improve the quality of Reddit, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies will still allow Reddit to use certain cookies for proper platform functionality. The article also includes a post from a user promoting their expert-level tutorials on Stable Diffusion, which covers advanced AI techniques and strategies. Some comments on the post discuss various topics related to stable diffusion, such as suggestions for training architectural models and the use of C# programming language. Many other posts on various Reddit pages discuss Stable Diffusion and its accompanying tools and tutorials. https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_108584657" CREATED="1687805148467" MODIFIED="1687805148467" LINK="https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the provided text is not sufficient for me to provide a meaningful summary as it seems to be an error message related to website security. Can you please provide more context or a different text to summarize? https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_508173461" CREATED="1687805148482" MODIFIED="1687805148482" LINK="https://www.myminifactory.com/category/scan-the-world"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Scan the World is a digital museum that aims to archive sculptures, artifacts and statues from across the world using 3D printing and scanning technologies. The community-built museum allows the scans to be free to download, making art and culture more accessible for everyone. Scan the World uses photogrammetry to capture the objects and offers them for the purpose of education, preservation, cultural heritage and accessibility. The range of scans available on the site is comprehensive, from buildings to digital archaeology and downloadable monuments. There are over 20 categories available on the website, ranging from Africa, Europe, Asia to Oceania, North America, and South America. The scans on the site include; David by Scan The World, Head of Michelangelo's David by SMK - Statens Museum..., Bust of Nefertiti at the Neues Museum, Berlin by Scan The World, Pieta in St. Peter's Basilica, Vatican by Scan The World, The Thinker at the Musée Rodin, France by Musée Rodin, and many more.&nbsp;Scan the World is an initiative of MyMiniFactory and the community that uses the platform to create 3D printable models.&nbsp;It is a unique platform that showcases art, culture, and history to the world through digital means. https://www.myminifactory.com/category/scan-the-world
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1282088072" CREATED="1687805148487" MODIFIED="1687805148487" LINK="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Wizard-Vicuna-13B-Uncensored-HF is a model used for text generation, which is available on the Hugging Face platform. It has been trained on a subset of data to remove alignment/moralizing and further trained to provide an uncensored model without guardrails, meaning it generates content without any limitations. The model can be accessed on-demand via the Inference API and is available in the float16 HF format for GPU inference and further conversions. Users can also contribute to the model through Eric Hartford's Patreon page or Ko-Fi. However, the creators mention that the users are fully responsible for the content generated by the model and must not blame the model for any negative consequences. https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_923008909" CREATED="1687805148494" MODIFIED="1687805148494" LINK="https://github.com/chathub-dev/chathub/blob/main/README.md"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          ChatHub is a chatbot client that supports multiple chatbots, including ChatGPT, Bing Chat, Google Bard, Claude, and 10+ open-source models. Users can chat with multiple chatbots at the same time and compare their answers. ChatHub supports ChatGPT API and GPT-4 Browsing and has a shortcut to quickly activate the app anywhere in the browser. Other features include markdown and code highlight support, a prompt library for custom and community prompts, conversation history saved locally, export and import of data, and a dark mode. ChatHub can be installed manually by downloading the zip file from Releases and following the instructions or built from source by cloning the source code, running yarn install and yarn build, and loading the dist folder to the browser. ChatHub has a premium license that enables support for more bots in all-in-one mode and users can add their own custom theme setting. The app also has a changelog that documents the addition of new models, APIs, and other features supported by the app. Overall, ChatHub is a versatile tool for anyone who wants to interact with multiple chatbots at the same time and compare their performance. https://github.com/chathub-dev/chathub/blob/main/README.md
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1974278022" CREATED="1687805148525" MODIFIED="1687805148525" LINK="https://twitter.com/OurielOhayon/status/1650369984080629760"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A Twitter user, Ouriel Ohayon, has accused ChatGPT, an AI language model, of accessing and using internal emails to provide accurate information about Ohayon's business model when prompted with a seemingly ambiguous question. ChatGPT is known for generating text based on given prompts and has gained popularity for its ability to closely mimic human language. However, Ohayon's accusation has raised concerns about privacy and data access by AI language models. Some Twitter users have suggested that the information may have been available elsewhere, while others have proposed the possibility of an employee leaking the information. ChatGPT has not yet responded to the allegation. https://twitter.com/OurielOhayon/status/1650369984080629760
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_612334016" CREATED="1687805148527" MODIFIED="1687805148527" LINK="https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Hugging Face, an AI startup known for its ML tools, has launched HuggingChat, an open-source chatbot alternative to OpenAI's ChatGPT. HuggingChat allows users to generate text in natural language or in a specific format and can handle various tasks like drafting emails, writing rap lyrics, and coding, including syntax highlighting. The chatbot's interface is similar to ChatGPT, with a left bar showing the latest chats and a large browser window for the current chat, and it's responsive. Hugging Face's release of HuggingChat emphasizes their dedication to open-source AI, and the company is also working to refine the model's limitations. In the future, Hugging Face plans to make all quality chat models available through a single hub to revolutionize the AI landscape. HuggingChat challenges the status quo and democratizes the AI chatbot industry, making it a game-changer. https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1761712843" CREATED="1687805148529" MODIFIED="1687805148529" LINK="https://www.pinecone.io/learn/series-b/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Pinecone, a provider of a vector database for AI applications, has raised $100m in a series B funding round led by Andreessen Horowitz, with ICONIQ Growth, Menlo Ventures and Wing Venture Capital also participating. The funds bring Pinecone's valuation to $750m. Pinecone's database is used to generate accurate AI products by making it easier for engineers to work with data produced by large language models and other AI. Pinecone claims to have experienced explosive growth in the number of AI developers and users on its free plan, while customer numbers also rose.&nbsp;With&nbsp;the new capital Pinecone plans to continue expanding its team and to roll out more features on its platform. https://www.pinecone.io/learn/series-b/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_143700608" CREATED="1687805148542" MODIFIED="1687805148542" LINK="https://www.reddit.com/r/LocalLLaMA/comments/12kh2la/nsfw_chatting_promts_for_vicuna_11/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text mentions Reddit's use of cookies and similar technologies to improve user experience, and provides the option to accept or reject non-essential cookies. It also includes comments and posts from the subreddit r/LocalLLaMA, which discusses various topics related to language models, coding, and technology, including the release of new models and tools, benchmark results, and tutorials. Some of the comments and posts contain mature or NSFW content, and users are prompted to confirm their age before viewing such content. https://www.reddit.com/r/LocalLLaMA/comments/12kh2la/nsfw_chatting_promts_for_vicuna_11/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1538420689" CREATED="1687805148550" MODIFIED="1687805148550" LINK="https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Sorry, I am unable to summarize the provided text as it is not a complete article or piece of information, rather just a message regarding the security of a website. https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_680271670" CREATED="1687805148556" MODIFIED="1687805148556" LINK="https://github.com/WeOpenML/PandaLM"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          PandaLM is an open-source tool that provides reproducible and automated comparisons between different large language models (LLMs). The tool can be used to evaluate the evaluation ability of different LLMs and provide a reason for the decision, along with a reference answer. PandaLM can be used by organizations that have confidential data and research labs with limited funds. With PandaLM, they can perform evaluations without compromising data security or incurring high costs and obtain reproducible results. The tool is reliable and consistent and comes with a diverse human-annotated test dataset of approximately 1,000 samples. The repository contains the codes for training PandaLM, the human-annotated test dataset, the model weights of PandaLM, and the codes and configs for instruction tuning other foundation models such as Bloom, OPT, and LLaMA. PandaLM is easy to install, and the tool offers several choices for experiencing PandaLM, such as using a Web UI or the EvaluationPipeline class. PandaLM can be used to evaluate different responses for a given context and generate a reference response utilizing the given context, making it efficient and consistent. https://github.com/WeOpenML/PandaLM
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_161346070" CREATED="1687805148559" MODIFIED="1687805148559" LINK="https://www.wired.co.uk/article/andy-warhol-fair-use-prince-generative-ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The US Supreme Court is set to rule on a case that could affect the interpretation of fair use law and the protection afforded to generative artificial intelligence technology. The case, Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith, hinges on whether a series of images Warhol created of Prince were distinct enough from the photograph he used for reference to be considered transformed, under the fair use doctrine of the Copyright Act. The decision could have implications both for copyright law, which is currently used by tools such as image and language models to train themselves, and wider international trade agreements that rely on shared recognition between nations of such laws. The potential effects of the ruling have led to legal scholars and industry figures expressing concern that AI could be granted&nbsp;copyright&nbsp;and&nbsp;alter trade policy or even industries such as drug formulations. https://www.wired.co.uk/article/andy-warhol-fair-use-prince-generative-ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_530328856" CREATED="1687805148562" MODIFIED="1687805148562" LINK="https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Mr. Ranedeer AI Tutor is a customizable, personalized learning experience powered by GPT-4. It allows users to adjust the depth of knowledge, customize learning styles, communication types, tone, and reasoning frameworks to create the ultimate AI tutor. The Mr. Ranedeer AI Tutor works best with the ChatGPT Plus Subscription with GPT-4 or above models and is not recommended for use with GPT-3.5. The AI Tutor supports different languages, including Chinese, and has a variety of commands, including /test, /config, /plan, /start, /continue, and /language. The Mr. Ranedeer AI Tutor also offers Ranedeer Tools, which are optional prompts that allow users to create flexible environments, add personality, and more to the learning experience. The AI Tutor comes with a guide on how to use it, as well as configuration and Ranedeer Tools guides, and users can also access lessons on various topics, including poetry analysis and programming in Python. Mr. Ranedeer AI Tutor is available on GitHub and can be used by individuals, including AI models looking for information about the tutor. https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_706959829" CREATED="1687805148568" MODIFIED="1687805148568" LINK="https://texturepaper.github.io/TEXTurePaper/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The TEXTure method is a novel approach for text-guided generation, editing, and transfer of textures for 3D shapes. It uses a pretrained depth-to-image diffusion model to iteratively paint a 3D model from different viewpoints, while dynamically defining a trimap partitioning of the rendered image into three progression states to generate seamless textures from different views. This method can transfer generated texture maps to new 3D geometries without explicit surface-to-surface mapping and extract semantic textures from a set of images without reconstruction. Furthermore, it can edit and refine existing textures using either a text prompt or user-provided scribbles. The paper shows extensive evaluation of the method's ability to generate, transfer, and edit textures, bridging the gap between 2D image generation and 3D texturing. https://texturepaper.github.io/TEXTurePaper/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_230973732" CREATED="1687805148578" MODIFIED="1687805148578" LINK="https://github.com/openlm-research/open_llama"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Open_LLaMA is an open-source reproduction of Meta AI's LLaMA large language model. The project provides PyTorch and JAX weights of pre-trained OpenLLaMA models, as well as evaluation results and comparison against the original LLaMA models. The weights are released in two formats – an EasyLM format for the EasyLM framework and a PyTorch format for the Hugging Face Transformers library. OpenLLaMA models have been trained on the RedPajama dataset released by Together that contains over 1.2 trillion tokens and exhibit comparable performance to the original LLaMA and EleutherAI's GPT-J models across a majority of tasks. OpenLLaMA is licensed permissively under the Apache 2.0 license. Weights can be directly loaded from the Hugging Face Hub. https://github.com/openlm-research/open_llama
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1946775070" CREATED="1687805148600" MODIFIED="1687805148600" LINK="https://ngwaifoong92.medium.com/introduction-to-shap-e-text-to-3d-a4fb5304642b"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          OpenAI has officially released Shap-E, a system that generates 3D objects by conditioning them on images or text prompts. Shap-E has two models, an encoder that converts 3D assets into the parameters for small neural networks that represent the 3D shape and texture as an implicit function, and a latent diffusion model that generates novel implicit functions conditioned on either the image or text descriptions. The new model includes rendering based on 60 views of each model, which is an improvement from the 20 views Point-E used, and the final output produces 16K points in each point cloud instead of 4K points. The lighting and material setup includes only diffuse materials, and the datasets are expanded with a million more 3D assets and 120K captions from human annotators. Shap-E generates 3D objects with lower fidelity than professional 3D assets and is geared towards cartoonish assets. Shap-E is available on Github, and the setup.py file in the official repository is incomplete and lacks several Python packages, which needs to be installed manually via pip install. https://ngwaifoong92.medium.com/introduction-to-shap-e-text-to-3d-a4fb5304642b
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_982843331" CREATED="1687805148608" MODIFIED="1687805148608" LINK="https://arxiv.org/abs/2305.02463"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The authors present &quot;Shap-E&quot;, a conditional generative model for 3D assets. Unlike other generative models that produce a single output representation, Shap-E generates the parameters of implicit functions that can be rendered as both textured meshes and neural radiance fields. The authors trained Shap-E in two stages; first, an encoder that maps 3D assets to the parameters of an implicit function, and second, a diffusion model on the encoder outputs. This method produces diverse, complex 3D assets in a few seconds. Shap-E converges faster and reaches comparable or better sample quality than the explicit generative model Point-E, despite modeling a higher-dimensional, multi-representation output space. The authors have released model weights, inference code, and samples. https://arxiv.org/abs/2305.02463
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1088425916" CREATED="1687805148611" MODIFIED="1687805148611" LINK="https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=share&amp;amp;utm_medium=member_a"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The co-founder of Hugging Face, Thomas Wolf, has released StarCoder, a 15-billion model trained purely on carefully vetted data ranging only over permissive codes, thereby ensuring high performance. The model can be used for internal finetuning or as the foundation for coding completion. Even though it can act as a chat model, Wolf warns that it should not be used like ChatGPT. While users were skeptical of StarCoders over Twitter and LinkedIn, Wolf confirmed the diversified compatibility of StarCoders, with the intention of making the model available to users worldwide.&nbsp;&nbsp;https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=share&amp;utm_medium=member_a
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1676478028" CREATED="1687805148615" MODIFIED="1687805148615" LINK="https://huggingface.co/bigcode/starcoder"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The StarCoder models are 15.5B parameter models trained on more than 80 programming languages using Multi Query Attention and a context window of 8192 tokens, using the Fill-in-the-Middle objective on 1 trillion tokens. The model was trained on GitHub code, so it can be turned into a technical assistant by using the Tech Assistant prompt. However, the generated code is not guaranteed to work as intended, and it may contain bugs or exploits. The pretraining dataset used to train the model was filtered for permissive licenses only, but the code's license generated from the model should be respected and may require attribution and/or other specific requirements. The model has been trained on source code from many programming languages, and it is capable of generating code snippets provided some context but with limitations. The model architecture used is GPT-2 with multi-query attention and Fill-in-the-Middle objective, and it was trained using the Megatron-LM orchestration and PyTorch neural networks. https://huggingface.co/bigcode/starcoder
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1273346623" CREATED="1687805148626" MODIFIED="1687805148626" LINK="https://onosendai.tech/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I apologize, but as an AI language model, I do not have access to any specific text. Please provide me with the text that you would like me to summarize and I will be happy to do so. https://onosendai.tech/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1337644534" CREATED="1687805148628" MODIFIED="1687805148628" LINK="https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NeRFLiX is a technology that enhances the quality of NeRF (Neural Radiance Fields) based approaches by significantly reducing rendering artifacts such as noise and blur. The NeRFLiX framework comprises a NeRF-style degradation simulator (NDS) and an inter-viewpoint mixer (IVM). NDS simulates NeRF-style degradations creating large-scale paired data for training deep neural networks to improve the quality of NeRF rendered images. Meanwhile, IVM progressively aligns image contents at the pixel and patch levels to maximize efficiency and improve performance, enhancing the quality of NeRF-rendered images and accelerating training rates. NeRFLiX has demonstrated a 50% reduction in training time while still producing even better results, elevating the performance of cutting-edge NeRF models to entirely new levels, producing highly photorealistic synthetic views. https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1688891605" CREATED="1687805148629" MODIFIED="1687805148629" LINK="https://github.com/facebookresearch/ImageBind"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Facebook AI Research team has introduced ImageBind, a unified model that can analyze and process cross-modal data of six distinct modalities: audio, depth, IMU, thermal, text, and images. The model builds a joint space that can automatically correlate and align this multimodal data, allowing it to be utilized in emergent or augmented ways. It can enable tasks such as cross-model retrieval, composing modalities with arithmetic, cross-model detection, and generation. Additionally, it exhibits strong zero-shot classification Performance. The research will be presented at the 2023 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). The code and pretrained models are freely available on GitHub under a non-commercial Creative Commons license. https://github.com/facebookresearch/ImageBind
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1373253397" CREATED="1687805148633" MODIFIED="1687805148633" LINK="https://github.com/huggingface/chat-ui"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Chat-UI is a web-based application developed by Hugging Face that provides a chat interface using open-source models, such as OpenAssistant. It is a SvelteKit app that powers the HuggingChat app on hf.co/chat. Users need a Hugging Face access token to run Chat-UI locally, using the remote inference endpoint. Chat history is stored in a MongoDB instance. Users can enable the web search by adding either SERPER_API_KEY or SERPAPI_KEY to their .env.local file. Chat-UI can be customized by updating the MODELS variable in the .env.local file, which can either customize the parameters passed to the model or use a new model. Users can run their own models locally by having a look at the endpoint project, text-generation-inference. Chat-UI can also run models hosted on multiple custom endpoints. To deploy the app, the user needs to install an adapter for their target environment. https://github.com/huggingface/chat-ui
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_61379705" CREATED="1687805148645" MODIFIED="1687805148645" LINK="https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Wizard-Vicuna-13B-Uncensored-HF is a PyTorch based text generation model that has been converted from float32 to float16 for easier storage and use. It was created by Eric Hartford's 'uncensored' training of Wizard-Vicuna 13B. The model comes in 4bit GPTQ models for GPU inference, 4bit, and 5bit GGML models for CPU inference, and float16 HF format model for GPU inference and further conversions. The model has been trained on a subset of the dataset with responses that did not contain alignment/moralizing to enable creation of a WizardLM without built-in alignment. Users should note that this uncensored model has no guardrails, and they are solely responsible for any content generated using the model. There are options for contributions to the model on the Patreon and Ko-Fi platforms, with benefits such as priority support and access to a private Discord room. https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_277360203" CREATED="1687805148650" MODIFIED="1687805148650" LINK="https://github.com/chathub-dev/chathub/blob/main/README.md"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          ChatHub is a chatbot client that allows users to use multiple chatbots within one app. It currently supports ChatGPT, new Bing Chat, Google Bard, Claude, and 10+ open-source models including Alpaca, Vicuna, and ChatGLM. It allows users to chat with multiple chatbots at the same time, making it easy to compare their answers, and supports ChatGPT API and GPT-4 Browsing. Other features include shortcut to quickly activate the app anywhere in the browser, markdown and code highlight support, prompt library for custom prompts and community prompts, conversation history saved locally, export and import of data, share conversation to markdown, and dark mode. ChatHub can be manually installed by downloading chathub.zip from Releases or built from source by cloning the source code, installing yarn, and loading the dist folder to browser by following steps in manual installation. The latest version (v1.22.0) supports Claude API. https://github.com/chathub-dev/chathub/blob/main/README.md
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_216752885" CREATED="1687805148655" MODIFIED="1687805148655" LINK="https://www.reddit.com/r/StableDiffusion/comments/13j78fo/some_examples_of_the_generalist_model_i_will_be/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on r/StableDiffusion discusses an upcoming AI model capable of generating realistic images from photorealism to anime. The model is fine-tuned on SD 2.1 768X and can create images with resolutions ranging from 1024 to 1080p. The author of the post mentions that the model is meant to serve as a base model for future fine-tuning projects. They also invite others to leave prompts and test the model. The comments section contains discussions on the capabilities of the model and the general use of AI in commercial work. There are also mentions of related topics such as color grading and rendering techniques. Other posts on r/StableDiffusion cover various topics related to using Stable Diffusion, including updates, cheat sheets, and new extensions. https://www.reddit.com/r/StableDiffusion/comments/13j78fo/some_examples_of_the_generalist_model_i_will_be/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_775851502" CREATED="1687805148656" MODIFIED="1687805148656" LINK="https://cohere.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cohere, a language model provider, has raised $270m in its latest funding round to scale up its operations in the bring-your-own-language model enterprise niche. The company's offer spans the range of embedded models that can be used for interactive chat features, semantic search, classification, and re-ranking, and generate text or text summaries of products, blog posts, and articles quickly and accurately. Cohere's Command model is one of the highest-performing models for generating text as measured by Stanford University's HELM benchmarks. Cohere is investing in improving model performance for industry-specific use cases, and updates its models every week. Cohere offers secure deployment options, customizable models, and industry-leading support, with live support responding to customers in less than a minute. https://cohere.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1702206978" CREATED="1687805148664" MODIFIED="1687805148664" LINK="https://github.com/imartinez/privateGPT"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This GitHub repository, called &quot;privateGPT,&quot; offers a fully private solution for question answering using local language models and vector embeddings. The code allows individuals to interact privately with their documents, using the power of GPT, without any data leaving their local environment. The solution is not production-ready, but it allows users to ingest and query documents without an internet connection, using LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers. The &quot;environment setup&quot; section of the repository's README.md file provides instructions for installing the required dependencies, downloading the LLM model, setting up the environmental variables, and ingesting one's own dataset. Once the data has been ingested, privateGPT.py can be used to ask questions based on the ingested documents. The script requires the user to input a query, after which the LLM model will consume the prompt and prepare an answer, which will be printed along with the four sources used as context from the documents. The repository includes a &quot;CLI&quot; section, which describes how users can modify privacy concerns and input parameters to modify the behavior of the script. https://github.com/imartinez/privateGPT
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1449479420" CREATED="1687805148669" MODIFIED="1687805148669" LINK="https://eckertzhang.github.io/Text2NeRF.github.io"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Text2NeRF is a novel text-driven 3D scene generation framework that uses Neural Radiance Fields (NeRF) and a pre-trained text-to-image diffusion model to produce various view-consistent outdoor and indoor 3D scenes from natural language descriptions. While existing text-to-3D generation methods are limited to simple geometries and dreamlike styles, Text2NeRF generates a wide range of 3D scenes with complicated geometric structures and high-fidelity textures. The method relies on NeRF as the 3D representation and utilizes a pre-trained text-to-image diffusion model to constrain the 3D reconstruction of the NeRF. The model also employs a monocular depth estimation method to provide a geometric prior that updates the NeRF model. The approach introduces a progressive scene inpainting and updating strategy for novel view synthesis of the scene to guarantee textured and geometric consistency between different views. The method requires only a natural language description of the scene as the input and outperforms existing methods in generating multi-view consistent, diverse, and photo-realistic 3D scenes. The authors have shared their code and model for this research work. https://eckertzhang.github.io/Text2NeRF.github.io
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_602815934" CREATED="1687805148673" MODIFIED="1687805148673" LINK="https://civitai.com/models/73470?modelVersionId=78187"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This is a post about a hard surface character with a focus on mecha and humanoid characters. The LORA model is available for download and has been tested with rev animated for optimal results. Key trigger words include helmet, machine gun, robot, science fiction, and terminator killers. There are only a few reviews at this time, but the ones available are positive. The post is from Civitai and includes links to their GitHub, Discord, Twitter, Reddit, and API. There is also information about supporting Civitai and joining their team. https://civitai.com/models/73470?modelVersionId=78187
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1235403522" CREATED="1687805148676" MODIFIED="1687805148676" LINK="https://github.com/Pan-ML/panml"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          PanML is an open-source AI/ML development and analysis library that provides simple-to-use abstractions for facilitating the development of language-based models (LLMs) in Natural Language Processing (NLP) tasks. The library supports open source and commercial LLMs from various vendors and enables users to explore, experiment, and integrate different-sized LLMs. PanML supports inference and analysis of LLM, Prompt chain engineering with LLM, fine tuning of LLM (also with PEFT LoRA), and document question answering using LLM, among other functions. The library is a work in progress and open for collaboration and contribution. Python 3.7+ is required for installation, and the library supports models from HuggingFace Hub and OpenAI. The library is intended for ease of use, fast experimentation, and model development and analysis in both open-source and commercial LLMs. The library is under the MIT open source license, and the documentation and installation guidelines for the library are available on GitHub. https://github.com/Pan-ML/panml
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1105014168" CREATED="1687805148678" MODIFIED="1687805148678"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Intel and Microsoft are collaborating to bring integrated artificial intelligence (AI) to personal computing (PC). The partnership aims to enable new, AI-powered features for PC users, including multimedia features and machine learning, supported by Intel's upcoming Meteor Lake client PC processors. These processors are the first PC platform from Intel featuring a built-in neural VPU – a dedicated AI engine integrated directly into the system-on-chip (SoC) to efficiently run AI models. Intel claims that Meteor Lake, which utilises a unique disaggregated architecture, will mark a significant milestone not just in personal computing but also in how humans interact with technology. Over the coming years, Intel and its partners in the PC industry aim to provide AI-enabled experiences to millions of people, driving unprecedented change.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_621824213" CREATED="1687805148682" MODIFIED="1687805148682" LINK="https://www.reddit.com/r/MachineLearning/comments/13fiw7r/opensource_llms_cherrypicking_d/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on r/MachineLearning discusses the poor performance of open-source LLMs (language model systems) with less than 13B parameters on zero-shot classification tasks. The models produced non-sensical text and failed to follow instructions, except for OpenAI models that provided consistently good results. The possible reasons for this gap are discussed, including the use of non-instruction tuned models and the lack of proper instructions formatting. The comments suggest tools and resources for better performance, such as using instruction tuned models and configuring tools properly. The post highlights the importance of rigorously measured performance and benchmarking in machine learning and the potential limitations of relying solely on model size as an indicator of quality. https://www.reddit.com/r/MachineLearning/comments/13fiw7r/opensource_llms_cherrypicking_d/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1228196935" CREATED="1687805148684" MODIFIED="1687805148684" LINK="https://huggingface.co/tiiuae/falcon-40b"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Technology Innovation Institute (TII) has developed Falcon 40B, an open-source large language model (LLM) with 40 billion parameters trained on one trillion tokens. Falcon 40B is a causal decoder-only model trained on a causal language modeling task, with architecture optimized for inference with FlashAttention and multiquery. It has been trained on RefinedWeb enhanced with curated corpora and is available under the Apache 2.0 license. TII is calling for proposals from users worldwide to submit their creative ideas for Falcon 40B’s deployment. Users can use Falcon 40B for research on large language models or as the foundation for specialization and finetuning for specific use cases, such as summarization, text generation, and chatbot. Falcon-40B has been trained mostly on English, German, Spanish, and French with limited capabilities in Italian, Portuguese, Polish, Dutch, Romanian, and Czech. The model carries the biases commonly encountered online and will require finetuning for most use cases. Falcon-40B requires PyTorch 2.0 for use with transformers and needs at least 85-100GB of memory to run inference swiftly. TII recommends users of Falcon-40B to consider finetuning it for tasks of interest and for guardrails and appropriate precautions to be taken for any production use. https://huggingface.co/tiiuae/falcon-40b
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1714882428" CREATED="1687805148686" MODIFIED="1687805148686" LINK="https://news.ycombinator.com/item?id=36092156"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on Hacker News asks for links to research papers in the fields of artificial intelligence, machine learning, and deep learning, which are easy to read and have a &quot;sneak peek&quot; section before the introduction. One user recommends the paper on support vector machines by Cortes &amp; Vapnik, describing it as succinctly outlining 60 years of pattern recognition from 1936 to 1992. Another user suggests &quot;A Mathematical Theory of Communication&quot; by Claude Shannon, which discusses compression and reliable communication, but may still be relevant to those interested in AI and ML. Other recommended papers include &quot;Attention is all you need&quot; by Vaswani et al., &quot;Deep Unsupervised Learning using Nonequilibrium Thermodynamics&quot; by Sohl-Dickstein et al. on diffusion models, and &quot;NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis&quot; by Mildenhall et al. https://news.ycombinator.com/item?id=36092156
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_342060391" CREATED="1687805148700" MODIFIED="1687805148700" LINK="https://www.linkedin.com/posts/melchiors_ai-software-microsoft-activity-7069901328981848064-1-Oq?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Apple has blocked internal use of OpenAI’s language model, ChatGPT and other language models due to concerns that the AI could spill sensitive internal information shared with it. Apple has reportedly also blocked GitHub’s automated coding tool, Copilot. The issue with these language models is that data fed into them is typically used to train them, which can lead to business information being exposed or the possible exposure by bot providers themselves that review the feeds. Many companies have followed suit with this block. https://www.linkedin.com/posts/melchiors_ai-software-microsoft-activity-7069901328981848064-1-Oq?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_844344950" CREATED="1687805148701" MODIFIED="1687805148701" LINK="https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the challenges with making large language models (LLMs) more predictable and controllable within business applications, and explores the concept of &quot;prompt engineering&quot; as a solution. Prompt engineering involves designing prompts beforehand and using them to steer and control the LLM response. The article includes a code walkthrough in Python using OpenAI's GPT3.5 and an open-source Python library called PanML, demonstrating how to modify prompts for output filtering, LLM-assisted output filtering, and creating customized prompt sequences. The article concludes by introducing PanML as a useful tool to help data scientists and machine learning engineers experiment with LLMs in their local environment. https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1782186715" CREATED="1687805148707" MODIFIED="1687805148707" LINK="https://huggingface.co/TheBloke/starchat-beta-GPTQ"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article presents information on how to use HuggingFaceH4's StarChat Beta GPTQ, which is a language model designed to aid in coding tasks. The article provides instructions for downloading and using the model through the text-generation-webui or from Python code. The model is fine-tuned on a diverse range of dialogues in over 35 languages, including English and over 80 programming languages. The article also highlights some potential biases, risks, and limitations of the model, such as the tendency to produce false URLs or code snippets that are syntactically valid but semantically incorrect. Finally, the article provides information on how to contribute to the development and expansion of the model. https://huggingface.co/TheBloke/starchat-beta-GPTQ
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_241936890" CREATED="1687805148708" MODIFIED="1687805148708" LINK="https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post shared by Francesco Saverio Zuppichini discusses the resources he recommended to a friend who wanted to quickly learn about LLMs. Resources listed include papers, blogs, videos, and different language models such as ChatGPT, LLama, Vicuna, and WizardLM. The post also includes YouTube channels recommended by Zuppichini, such as AI Explained, Yannic Kilcher, and Sam Witteveen. Other users in the comments section share their own resources, such as the Stanford CS25 course and Cohere's NLP uni. https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1181035375" CREATED="1687805148729" MODIFIED="1687805148729" LINK="https://research.nvidia.com/labs/rtr/neural_appearance_models/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NVIDIA Research has developed a system for real-time rendering of complex appearance in games and live previews with a combination of algorithmic and system level innovations. The appearance model utilizes learned hierarchical textures that are interpreted using neural decoders, which produce reflectance values and importance-sampled directions. The decoders are equipped with two graphics priors, the first of which facilitates accurate reconstruction of mesoscale effects, while the second microfacet sampling distribution allows the neural decoder to perform importance sampling efficiently. The resulting appearance model supports anisotropic sampling and level-of-detail rendering and allows baking deeply layered material graphs into a compact unified neural representation. The system opens up the potential for using film-quality visuals in real-time applications such as games and live previews. https://research.nvidia.com/labs/rtr/neural_appearance_models/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_200539905" CREATED="1687805148734" MODIFIED="1687805148734" LINK="https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text is a mixture of a cookie notice from Reddit, and a collection of recent posts on the subreddit r/StableDiffusion. The cookie notice explains that Reddit uses cookies and similar technologies to provide a better user experience, and gives users the option to accept or reject cookies. The collection of posts on r/StableDiffusion showcase various AI-generated images and animations using different models and software tools. The posts include scannable Cat QR Art with AI, synthesized 360 views of Stable Diffusion generated photos with PanoHead, an animated dance AI animation, and more. Some of the posts are marked as NSFW. https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1414227130" CREATED="1687805148737" MODIFIED="1687805148737" LINK="https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-support-on-vertexai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Google Cloud has unveiled its latest platform capabilities for building and powering custom generative AI applications, with the latest update to Vertex AI. Generative AI support on this platform will now give customers access to text models powered by PaLM 2, as well as Embeddings API for text. Other foundation models in the model garden will also be available, allowing developers to customize these models with their own data and quickly build generative AI applications. With generative AI studio generally available, customers can leverage an even wider range of tools to accelerate the development of custom generative AI applications. This latest update reflects Google Cloud's commitment to making generative AI useful to everyone, backed by enterprise-grade data governance, security and safety features. https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-support-on-vertexai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1148236091" CREATED="1687805148740" MODIFIED="1687805148740" LINK="https://arxiv.org/abs/2306.03078"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper introduces a new compressed format and quantization technique called Sparse-Quantized Representation (SpQR), which enables near-lossless compression of large language models (LLMs) with minimal accuracy loss. SpQR works by identifying and isolating outlier weights, which cause particularly-large quantization errors, and storing them in higher precision while compressing all other weights to 3-4 bits. The technique achieves relative accuracy losses of less than 1% in perplexity for highly-accurate LLMs, making it possible to run 33B parameter LLM on a single 24 GB consumer GPU without any performance degradation at 15% speedup. SpQR comes with efficient algorithms for both encoding weights into its format as well as decoding them efficiently at runtime, and yields faster inference than 16-bit baselines at similar accuracy, while enabling memory compression gains of more than 4x. https://arxiv.org/abs/2306.03078
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1345061050" CREATED="1687805148749" MODIFIED="1687805148749" LINK="https://glaze.cs.uchicago.edu/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Glaze is an academic research project by the University of Chicago, aiming to protect artists from the invasive uses of machine learning through ethical security techniques. The tool generates a cloaked version for each piece of artwork an artist creates, creating almost invisible changes. This helps prevent AI models from copying the artist's unique style and mimicking it for their purposes. Glaze has been evaluated through a user study involving more than 1,100 professional artists. Although Glaze is not a permanent solution against AI mimicry as AI evolves quickly, it is hoped that Glaze and follow-up projects will provide some protection to artists against AI mimicry. Since its initial release, Glaze has hit 721,000 downloads, and an updated GPU version for Windows is available for free. https://glaze.cs.uchicago.edu/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1728910638" CREATED="1687805148759" MODIFIED="1687805148759" LINK="https://www.reddit.com/r/LocalLLaMA/comments/148prx3/landmark_attention_oobabooga_support_gptq/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text contains updates and discussions on AI language models and related topics. It also includes a notice about the use of cookies on Reddit and its partners' websites. One user shared progress made in getting Landmark attention working within Oobabooga and the quantization of models. Other users provided feedback and shared insights on related technical topics, such as context size, inference performance, and trust in remote code execution. The text also includes links to open-source models and tools, discussions on new quantization methods, and updates on various AI language models' development and performance. https://www.reddit.com/r/LocalLLaMA/comments/148prx3/landmark_attention_oobabooga_support_gptq/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1738319743" CREATED="1687805148766" MODIFIED="1687805148766" LINK="https://huggingface.co/Yhyu13/30B-Lazarus-gptq-4bit/tree/main"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text describes a model called &quot;30B-Lazarus-gptq-4bit&quot; available on the Hugging Face platform for natural language processing. The model was created using PyTorch and Transformers frameworks and has an Apache-2.0 license. The files associated with the model include a config file, generation config file, special tokens map, tokenizer model, and tokenizer config file. The model is available for training, deployment, and use in Transformers. https://huggingface.co/Yhyu13/30B-Lazarus-gptq-4bit/tree/main
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1100244845" CREATED="1687805148768" MODIFIED="1687805148768" LINK="https://crfm.stanford.edu/2023/06/15/eu-ai-act.html"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A new report from the Stanford Center for Research on Foundation Models has found that major foundation model providers, including OpenAI and Google, largely do not comply with the draft requirements of the EU's AI Act, the world's first comprehensive regulation of AI, particularly in regards to their compliance with requirements to provide information on training data, hardware use, and how they evaluate and test models. The report found significant discrepancies in compliance across model providers, with some scoring less than 25% and only one scoring at least 75%. The report recommended that policymakers prioritize transparency in the AI ecosystem and that foundation model providers work towards industry standards with the input of stakeholders beyond the companies themselves. https://crfm.stanford.edu/2023/06/15/eu-ai-act.html
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_642418666" CREATED="1687805148772" MODIFIED="1687805148772" LINK="https://github.com/ml-lab/LLaMA-Adapter-2"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The repository is for LLaMA-Adapter, an efficient, lightweight adaption method for fine-tuning Instruction-following and Multi-modal LLaMA models that allow them to make high-quality instruction-following sentences. It includes code for the implementation of LLaMA-Adapter, as well as demos and training modules. The repository provides a comparison between LLaMA-Adapter's Model Parameters, Storage Space, and Training Time with other methods. The repository has multiple contributors, and interested candidates can apply for internships, postdocs, and full-time researcher positions. It is licensed under the GPL-3.0 license. The readme file also includes news, acknowledgments, citation, and hiring announcements. https://github.com/ml-lab/LLaMA-Adapter-2
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_947943841" CREATED="1687805148773" MODIFIED="1687805148773" LINK="https://www.cloudskillsboost.google/journeys/118"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Generative AI learning path offered by Google Cloud Skills Boost is a collection of courses that guide students through generative AI products and technologies, from understanding Large Language Models (LLM) to designing and deploying generative AI solutions on Google Cloud. The introductory-level courses include an explanation of GAI, LLM, and responsible AI, and they introduce Google's seven AI principles. Students can earn a skill badge by completing the Introduction to Generative AI, Introduction to Large Language Models, and Introduction to Responsible AI courses. Intermediate courses cover topics such as the Encoder-Decoder Architecture, Attention Mechanism, Transformer Models, and BERT Models. Other courses teach students how to create image captioning models and use the Generative AI Studio product on Vertex AI. Overall, the Generative AI learning path aims to provide a comprehensive understanding of the fundamentals of generative AI and its applications, preparing students for a career in AI development. https://www.cloudskillsboost.google/journeys/118
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_114099069" CREATED="1687805148774" MODIFIED="1687805148774" LINK="https://www.reddit.com/r/LocalLLaMA/comments/14drnvd/best_llm_for_legal_analysis/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Reddit user, edinburgh1975, posted on r/LocalLLaMA seeking advice on the best LLM for legal analysis. They are working on a project to make the law more accessible to the public with a small budget and a team with varying tech skills. Other Reddit users provided suggestions, including using GPT-3.5 for generating free advice while charging for the use of GPT-4 32k, fine-tuning GPT-4 to generate training data for their local LLM, and utilizing Wiki resources for all things related to Local LLM. Some users also discussed the risks of confabulation when using AI models for legal research. https://www.reddit.com/r/LocalLLaMA/comments/14drnvd/best_llm_for_legal_analysis/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_973983479" CREATED="1687805148776" MODIFIED="1687805148776" LINK="https://github.com/MoyGcc/vid2avatar"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text provides information about the Vid2Avatar project which aims to reconstruct 3D avatars from videos in various settings using self-supervised scene decomposition. The project uses a python virtual environment and requires the installation of certain dependencies and Kaolin 0.10.0. Additionally, the SMPL model needs to be downloaded and preprocessed demo data can be downloaded from Google Drive. The project includes training which usually takes 24-48 hours and validation is saved in the outputs folder. The project also includes a test phase and allows for 3D visualization using AITViewer. The project also includes instructions on how to play on a custom video with modifications to the preprocessing script and metainfo changes. The project acknowledges other research work and includes a list of related human body reconstruction projects from the team. Lastly, a citation in the desired format for the Vid2Avatar project is included. https://github.com/MoyGcc/vid2avatar
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_599237142" CREATED="1687805148792" MODIFIED="1687805148792" LINK="https://twitter.com/OurielOhayon/status/1650369984080629760"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The CEO of ZenGo, Ouriel Ohayon, has accused AI language model ChatGPT of breaching privacy, stating that the program may have accessed and read some of their internal emails to provide information about their business model. Ohayon requested information about ZenGo that was not public yet and ChatGPT provided the information accurately, leading to his concerns. However, some users questioned the context of the prompt and suggested that the information could have been guessed, sourced from a competitor's website or a prompt from an employee. https://twitter.com/OurielOhayon/status/1650369984080629760
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1008075412" CREATED="1687805148794" MODIFIED="1687805148794" LINK="https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          HuggingChat, an open-source chatbot developed by AI startup Hugging Face is set to challenge the status quo of AI chatbot technology. HuggingChat is built on the modified LLaMa 30B SFT 6 model and can generate text in natural language or in a specific format and also generate code in multiple programming languages. Huggingchat can be found at hf.co/chat and is free to use. The AI company is championing open-source AI through offering free technology, which is transparent, accountable and aims to promote inclusivity, disseminate power and democratize AI. Hugging Face looks to make all high-quality chat models available through a single hub in the future. Despite HuggingChat being characterized by similar limitations as other text-generating models, Hugging Face is working on refining the model. The AI company is poised to change the way we interact and develop AI chatbots, challenging the status quo, and promoting transparency and accountability. https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1997416741" CREATED="1687805148800" MODIFIED="1687805148800" LINK="https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text includes two different topics. The first is about Reddit's use of cookies and similar technologies to provide users with a better experience, personalize content and advertising, and measure advertising effectiveness. Users can choose to accept all cookies or reject non-essential ones. The second topic is a discussion thread on the StableDiffusion subreddit about generating color maps for 3D models using AI technology. The thread includes technical details on the process and some questions and comments from other users. The StableDiffusion subreddit focuses on the use of AI and computer vision technologies for creative projects. https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1734190945" CREATED="1687805148804" MODIFIED="1687805148804" LINK="https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post discusses advanced advice for model training and captioning. The author gives specific pointers for training a checkpoint model, such as maximizing visual diversity, minimizing visual repetition, and denoising original images. They also recommend ordering captions from most to least prominent concept and experimenting with conditional dropout to force a style into the model. In addition, the author suggests using chaining to tweak settings and allowing the model to change settings as it goes. Other topics discussed in the comments section include the best software for denoising images, improving finetuning of bright and dark images, and creating new unique and consistent characters with Loras. https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_979493914" CREATED="1687805148806" MODIFIED="1687805148806" LINK="https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The post on Reddit's r/StableDiffusion is a guide for advanced advice on model training and captioning, specifically for those who already have a basic understanding of training a checkpoint model and want to improve. The post includes tips on training images such as denoising and maximizing visual diversity, and ordering captions from most to least prominent concepts. The post also includes recommendations for software and tools to improve training, such as Affinity Photo and Conditional Dropout. The comments section includes further discussion and feedback from other users on the topic. https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_660321939" CREATED="1687805148815" MODIFIED="1687805148815" LINK="https://github.com/dk-liang/Awesome-GPT-4-with-Applications"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Awesome-GPT4-with-Applications is a collection of resources on GPT-4, which includes news articles, official documents, demos, tutorials, and applications. OpenAI recently released GPT-4, a large multimodal model with their best-ever results on capabilities and alignment. The collection includes official documentation such as the technical report, system card, and API waitlist, as well as early versions of GPT such as GPT, GPT-2, and GPT-3. There are also tutorials, examples, and live streams available for developers interested in working with GPT-4. The resource list includes a range of applications from chatbots to research assistants, visual accessibility, language learning, and knowledge management. Additionally, the collection provides information on frameworks and libraries for developers interested in building on top of GPT-4. Finally, contributions to the collection are welcome, and users are encouraged to submit new resources or suggest improvements through pull requests or issues. https://github.com/dk-liang/Awesome-GPT-4-with-Applications
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_755973898" CREATED="1687805148818" MODIFIED="1687805148818" LINK="https://buff.ly/3laNpgY"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The recently proposed StyleGAN model has shown impressive results in face manipulation but is limited to cropped aligned faces at a fixed image resolution it is pre-trained on. To overcome this limitation, a new model called StyleGANEX is proposed in which the shallow layers of StyleGAN are refactored using dilated convolutions to rescale the receptive fields, enabling fixed-size small features to be extended into larger ones that can accommodate variable resolutions. A corresponding encoder is also introduced to enable real face inversion and manipulation. The effectiveness of this approach is validated using unaligned face inputs of various resolutions in a diverse set of face manipulation tasks, including facial attribute editing, super-resolution, sketch/mask-to-face translation, and face toonification. The paper presents experimental results and comparisons with other state-of-the-art face manipulation methods, showing that StyleGANEX produces more coherent results with fewer discontinuities near the seams. The approach retains the style representation and editing ability of StyleGAN while significantly extending its generative space beyond cropped aligned faces. The StyleGANEX model is compatible with pre-trained StyleGAN parameters without retraining and provides a flexible and powerful solution for face manipulation beyond cropped aligned faces. https://buff.ly/3laNpgY
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_997643393" CREATED="1687805148820" MODIFIED="1687805148820" LINK="https://github.com/lxe/simple-llama-finetuner"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Simple LLM Finetuner is an intuitive user interface designed to facilitate fine-tuning various language models using the LoRA method via the PEFT library on commodity NVIDIA GPUs. It allows users to manage datasets, customize parameters, train, and evaluate the model's inference capabilities. The beginner-friendly interface features explanations for each parameter and allows users to simply paste datasets into the UI separated by double blank lines. The necessary prerequisites to use the finetuner are a Linux or WSL OS and a modern NVIDIA GPU with &gt;= 16 GB VRAM. Before launching, users must clone the repository and install the required packages. The finetuner supports running on a regular Colab Tesla T4 instance with small datasets and sample lengths of 256. Conda is preferred for a virtual environment to install the required packages. After preparing a training dataset, users can specify the new LoRA adapter name and click train, adjusting the max sequence length and batch size to fit GPU memory. The model will be saved in the lora/ directory, and after training, users can navigate to the &quot;Inference&quot; tab, select their LoRA, and play with it. The code is released under the MIT License and has already received high traffic on Github. https://github.com/lxe/simple-llama-finetuner
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_367367275" CREATED="1687805148822" MODIFIED="1687805148822" LINK="https://3d-diffusion.github.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The research paper presents a diffusion model called 3DiM for 3D novel view synthesis. The model uses a pose-conditional image-to-image diffusion model, trained to take a source view and its pose as inputs and generate a novel view for a target pose as output. The model can generate multiple views that are approximately 3D consistent using a sampling technique called stochastic conditioning. The paper also introduces a new evaluation methodology, 3D consistency scoring, to quantify the 3D consistency of a generated object. Additionally, the paper compares 3DiM to prior work on the SRN ShapeNet dataset, demonstrating that 3DiM's generated completions from a single view achieve much higher fidelity, while being approximately 3D consistent. The results of the research highlight the effectiveness of diffusion models for novel view synthesis and the critical importance of modifications to the image-to-image UNet to achieve high-quality results. https://3d-diffusion.github.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1429845719" CREATED="1687805148837" MODIFIED="1687805148837" LINK="https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Researchers from OpenAI have introduced “consistency models” as a family of generative models for realistic sample generation with just a single forward pass, without relying on adversarial approaches and other models such as normalizing flows. The authors propose to learn a neural network F(x,t) that &quot;is invertible and for any trajectory x(t), F allows for a return to the initial condition.&quot; The training procedures are by distillation and by isolation, with the authors estimating the score function via a Monte Carlo method. The proposed approach is shown to generate realistic samples in one forward pass, using different experiments such as image generation, super-resolution, and inpainting. The approach can offer advantages in terms of required computing resources and open the way to new applications inaccessible to diffusion models. https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_902332078" CREATED="1687805148838" MODIFIED="1687805148838" LINK="https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          In a recent paper, researchers from OpenAI introduce &quot;consistency models,&quot; which enable the generation of realistic samples in a single forward pass. The proposed models are a new family of generative models that achieve high sample quality without adversarial training. The authors propose to learn a neural network that satisfies certain properties and allows for realistic sample generation in a single forward pass. Two training configurations are proposed to achieve this, with the authors experimenting with image generation, inpainting, and super-resolution. The proposed models offer several advantages over previous techniques, such as requiring fewer computing resources, and could lead to new applications. https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1834680439" CREATED="1687805148852" MODIFIED="1687805148852" LINK="https://depth-gen.github.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper proposes a new method for estimating depth from a single RGB image using diffusion-based denoising models. The method involves infilling missing depth using nearest neighbor interpolation, adding noise to the depth map, and training a neural network to predict the noise given the RGB image and noisy depth map. The proposed DepthGen model achieves state-of-the-art performance on indoor NYU depth v2 dataset and competitive results on outdoor KITTI dataset. Additionally, the paper outlines a simple text-to-3D pipeline using DepthGen and off-the-shelf text-to-image models. The proposed approach provides robust zero-shot performance and represents depth ambiguity naturally. https://depth-gen.github.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_748725680" CREATED="1687805148862" MODIFIED="1687805148862" LINK="http://explainpaper.com"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Explainpaper is a free online tool that makes research papers easier to read by using an AI model to explain dense sections. Researchers can upload a paper, highlight confusing text, and get an explanation. In the background, an LLM simplifies and explains complex concepts. The tool has been used by Bindu Reddy, an AI and ML researcher, who reported her research paper review time has gone down significantly. Other researchers, such as Amy Cun and Kenneth Cassel, have also praised the tool for its ability to help them understand complex concepts in research papers. The tool has been described as a &quot;killer product&quot; by some and is recommended for anyone looking to become an expert in any field. http://explainpaper.com
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_42903351" CREATED="1687805148867" MODIFIED="1687805148867" LINK="https://www.d-id.com/chat/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          D-ID, a technology company specializing in facial recognition and animation, has launched its AI Presenters on Canva, which enable users to hold a face-to-face conversation with a digital human on a free web app called chat.D-ID. The software powering chat.D-ID has practical applications across various sectors, such as sales and marketing, learning and development, customer experience, and personal health and wellness. The company will also offer the streaming animation technology behind chat.D-ID to businesses and developers via its generative AI API. The real-time capabilities of the technology can be integrated with both open and closed-domain AI models, allowing businesses of all sizes to create a more personal connection with customers, employees, and communities. Customers who want to create a digital person to converse about their business or organization can book a call with D-ID to learn more. https://www.d-id.com/chat/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1732732912" CREATED="1687805148868" MODIFIED="1687805148868" LINK="https://github.com/hayabhay/whisper-ui"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Whisper-UI is a user interface built on top of OpenAI's Whisper speech-to-text model that features media downloading and transcription from YouTube videos, playlists, or local files. The app allows users the ability to browse, filter, and search saved audio files. The app dependencies include Python 3.11, ffmpeg, and the requirements in the requirements.txt file. The app can be run with the command &quot;streamlit run app/01_🏠_Home.py.&quot; Alternatively, the app can be run via Docker through the included docker-compose.yml with the command &quot;docker compose up.&quot; The app is licensed under MIT. https://github.com/hayabhay/whisper-ui
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_404445999" CREATED="1687805148870" MODIFIED="1687805148870" LINK="https://github.com/youwang-kim/clip-actor"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          CLIP-Actor is a pytorch implementation for the ECCV 2022 paper that contains a novel text-driven motion recommendation and neural mesh stylization system for human mesh animation. The code was developed on Ubuntu 18.04 with Python 3.7, CUDA 10.2 and PyTorch 1.9.0. You need to download relevant body models and datasets for running CLIP-Actor, and it requires a single GPU with a minimum of 24 GB of RAM. The implementation of CLIP-Actor is largely inspired by and fine-tuned from the seminal prior work, Text2Mesh. The authors of CLIP-Actor and Text2Mesh appreciate the support and contribution from the Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP) grant funded by the Korea government (MSIT). The code is available on GitHub, and the authors invite researchers and academics to consider citing their paper and code for any work they found helpful. https://github.com/youwang-kim/clip-actor
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1918854754" CREATED="1687805148876" MODIFIED="1687805148876" LINK="https://en.m.wikipedia.org/wiki/Cross-origin_resource_sharing"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cross-Origin Resource Sharing (CORS) is a security mechanism that enables restricted resources on a web page to be accessed from another domain outside the domain from which the first resource was served. CORS allows for more freedom and functionality than purely same-origin requests, but is more secure than simply allowing all cross-origin requests. It defines a way in which a browser and server can interact to determine whether it is safe to allow the cross-origin request. The specification for CORS is included as part of the WHATWG's Fetch Living Standard. CORS is supported by all modern browsers and can be used as an alternative to the JSONP pattern. The HTTP headers that relate to CORS are Origin, Access-Control-Request-Method, Access-Control-Request-Headers, Access-Control-Allow-Origin, Access-Control-Allow-Credentials, Access-Control-Expose-Headers, Access-Control-Max-Age, Access-Control-Allow-Methods, and Access-Control-Allow-Headers. CORS is widely used in the object-capability model and any website can manually parse responses for increased security. https://en.m.wikipedia.org/wiki/Cross-origin_resource_sharing
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_765552342" CREATED="1687805148880" MODIFIED="1687805148880" LINK="https://mobile.twitter.com/heyBarsee/status/1640368028884914178"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The tweet thread is advertising the ChatGPT language model's ability to generate unlimited prompts quickly and efficiently. The user suggests using GPT-4 to generate the best prompts on any topic. Additionally, the user mentions that GPT-4 can also be used to talk to any book and ask any question. The language model's capabilities make it an efficient tool for generating ideas and gaining information. https://mobile.twitter.com/heyBarsee/status/1640368028884914178
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_223907961" CREATED="1687805148884" MODIFIED="1687805148884" LINK="https://twitter.com/TomLikesRobots/status/1627073211656732676"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Twitter conversation started with a tweet from TomLikesRobots, featuring a keyframe generated with ControlNet's img2img and animated with Ebsynth, captioned with a quote from Lord of the Rings. Another user, rainisto, complimented the video's quality, which TomLikesRobots said was attributed to having enough time to practice with his new tools over the weekend. The conversation continued with users discussing whether they could run the AI models on Colab and its possible applications in anime remakes. Some concluded that Ebsynth was the way to go for creating convincing videos using animation as the source, while others suggested more advanced tools. https://twitter.com/TomLikesRobots/status/1627073211656732676
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_101390705" CREATED="1687805148915" MODIFIED="1687805148915" LINK="https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Clarkesworld Magazine, a renowned sci-fi publication, has announced that it has temporarily closed its submissions due to a massive increase in machine-generated stories sent to the publication. The numbers tallied up to 500 in February alone, up from just over 100 in January and a low baseline of around 25 in October 2022. AI models, such as ChatGPT, can author original stories quickly by being trained on millions of books and websites. However, the stories are not created autonomously, and a human must guide their output with a prompt that the AI model then attempts to automatically complete. According to Clarkesworld Magazine, the number of submissions continues to rise because of get-rich-quick schemes. The problem of AI-authored content is also not unique to Clarkesworld, as Reuters reported over 200 e-books on the Amazon Kindle store that list ChatGPT as the author or co-author. The use of bots has created an awkward position for Clarkesworld, as it aims to filter out the spammers while still encouraging undiscovered writers or writers from certain regions of the world who might be unfairly targeted by geographical-based bans. Detecting text written by language models has low accuracy rates, and the magazine doesn't have a solution to the problem yet. The editor of Clarkesworld encouraged those who want to support the magazine to subscribe. https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_170758301" CREATED="1687805148924" MODIFIED="1687805148924" LINK="https://huggingface.co/spaces/nagasaiabhinay/unclip_image_interpolation_demo"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Hugging Face is a technology company that creates machine learning natural language processing (NLP) models and develops applications to make these models more accessible. One of their newest applications is called UnCLIP Image Interpolation, which utilizes AI to enhance and extrapolate images to higher resolutions. Users can upload images to the platform and adjust settings such as the number of steps, seed, and interpolation factor to customize the output. The tool can also be used via API and was built with Gradio. https://huggingface.co/spaces/nagasaiabhinay/unclip_image_interpolation_demo
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1034913052" CREATED="1687805148927" MODIFIED="1687805148927" LINK="https://udlbook.github.io/udlbook/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          &quot;Understanding Deep Learning&quot; is a comprehensive book by Simon J.D. Prince, to be published by MIT Press in 2023, covering topics from supervised and unsupervised learning to deep reinforcement learning, as well as explaining why deep learning works and its ethical implications. The book is accompanied by resources for instructors, including slides, notebooks, and PDF figures for each chapter. The book aims to provide a clear understanding of the underlying principles of deep learning, including neural network architecture, loss functions, training models, regularization, and performance measurement, as well as exploring more advanced topics such as convolutional networks, residual networks, transformers, graph neural networks, and generative adversarial networks. It also covers emerging areas of research, such as normalizing flows, variational autoencoders, diffusion models, and deep reinforcement learning. Additionally, the book explores the ethical implications of deep learning, encouraging readers to consider the impact of their work on the wider society and to think critically about potential biases and unintended consequences. Overall, the book is a valuable resource for anyone looking to dive deeper into the world of deep learning, whether for academic or practical purposes. https://udlbook.github.io/udlbook/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1037480497" CREATED="1687805149005" MODIFIED="1687805149005" LINK="https://msra-nuwa.azurewebsites.net/#"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NUWA is a platform that specializes in generative models capable of producing multimedia content such as images and videos. The platform offers several products, including NUWA XL and NUWA Infinity, both of which utilize cutting-edge technology to produce long videos based on provided scripts. NUWA also offers a Gallery feature that allows users to browse and view content created using the platform. Their NUWA XL product utilizes a &quot;coarse-to-fine&quot; process to generate video content efficiently. The platform has released a research paper on their innovative generative models. For any inquiries, users can contact NUWA through their website, and the platform operates under Microsoft. https://msra-nuwa.azurewebsites.net/#
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1783515944" CREATED="1687805149007" MODIFIED="1687805149007" LINK="https://msra-nuwa.azurewebsites.net/#/NUWAInfinity"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NUWA-Infinity is a multimodal generative model that generates high-quality images and videos from given text, image, or video input. This AI technology is designed to create realistic and visually appealing content that can be used for a variety of applications. Its features include loading images and videos with 100% accuracy, a gallery of generated content, and a research paper on the technology. Additionally, NUWA XL is another model that can generate larger images, while NUWA Infinity is designed for infinite content generation. Overall, NUWA-Infinity is a promising technology that can revolutionize the creation of images and videos. https://msra-nuwa.azurewebsites.net/#/NUWAInfinity
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1301846665" CREATED="1687805149016" MODIFIED="1687805149016" LINK="https://imagebind.metademolab.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Meta AI has developed a new AI model called ImageBind that can bind data from six different modalities, including images and video, audio, text, depth, thermal, and inertial measurement units (IMUs), without explicit supervision. The model recognizes the relationships between these modalities and creates a single embedding space to bind them together, enabling machines to analyze different forms of information together. ImageBind can even upgrade existing AI models to support input from any of the six modalities, enabling audio-based search, cross-modal search, multimodal arithmetic, and cross-modal generation. The open source ImageBind model achieves a new state-of-the-art performance on emergent zero-shot recognition tasks across modalities. https://imagebind.metademolab.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1140968894" CREATED="1687805149024" MODIFIED="1687805149024" LINK="https://cohere.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cohere, a start-up specializing in developing natural-language processing (NLP) technology, has raised $270m in a funding round to bring generative AI to enterprises. The firm's models, powered by embeddings, enable interactive chat features, generate text for product descriptions, and capture the meaning of text for search, content moderation, and intent recognition. Organizations can also use Cohere's technology to customize models for specific use cases, domains, or industries. The company's Command model is among the highest performing models as measured by Stanford University's HELM benchmarks, with a mean win rate of 93%. https://cohere.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_441351922" CREATED="1687805149040" MODIFIED="1687805149040" LINK="https://youtu.be/XfpMkf4rD6E"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a collection of videos related to transformers, GPT (Generative Pre-trained Transformer), and language modeling available on YouTube. The videos feature lectures, presentations, and discussions by researchers and experts in the field, including Andrej Karpathy, Ilya Sutskever, and Harry Surden. They cover various topics related to transformer networks, attention and self-attention mechanisms, GPT models, their workings, emergent abilities, biomedical applications, scaling for LLMs, among others. The texts are available on YouTube and are a useful resource for anyone interested in learning more about transformers and GPT models. https://youtu.be/XfpMkf4rD6E
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1990058637" CREATED="1687805149045" MODIFIED="1687805149045" LINK="https://github.com/imartinez/privateGPT"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          PrivateGPT is a test project that enables users to interact privately with their documents using the power of GPT without any data leaving the environment. The tool is built using LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers. Users can ingest documents and ask questions without an internet connection and set up their environment by installing all requirements and downloading the LLM model. Users can use the CLI to ask a question or use optional command-line arguments to modify its behavior. The ingest.py script uses LangChain tools to parse the document and create embeddings locally, while the privateGPT.py script uses a local LLM based on GPT4All-J or LlamaCpp to understand questions and create answers. The context for the answers is extracted from the local vector store using a similarity search to locate the right piece of context from the docs. The software requires Python 3.10 or later and a C++ compiler may be needed on some systems. The tool is not meant for production and the models selection is not optimized for performance, but for privacy. https://github.com/imartinez/privateGPT
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1958520681" CREATED="1687805149054" MODIFIED="1687805149054" LINK="https://txt.cohere.ai/sentence-word-embeddings/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article provides an introduction to word and sentence embeddings, which are used in language models to translate human language into computer language using numbers that capture properties and features of words and sentences. Word embeddings assign scores to each word and much like assigning coordinates to points on a plane, they are assigned numbers that capture similarities and differences between words while also capturing additional properties such as age and size. Sentence embeddings are like word embeddings, except they associate sentences with a vector full of numbers that capture similar properties as word embeddings, but with the added complexity of taking into account the order of words, the semantics of the language, and the actual meaning of the sentence. Multilingual embeddings unify many languages into one and Cohere offers a large multilingual model that has shown wonderful results with more than 100 languages. The multilingual embeddings can be extended to language embeddings which are useful for translation and for searching and understanding text in different languages. The article concludes that word and sentence embeddings are the primary building blocks of most language models and they capture many relations between words, semantics, and nuances of the language into equations regarding the corresponding numbers. https://txt.cohere.ai/sentence-word-embeddings/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1281290291" CREATED="1687805149056" MODIFIED="1687805149056" LINK="https://laion.ai/blog/giant-openclip/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A new CLIP model, ViT-G/14, has been trained with OpenCLIP, achieving 80.1% zero-shot accuracy on ImageNet and 74.9% zero-shot image retrieval (Recall@5) on MS COCO. This is the best open-source CLIP model as of January 2023. The approach underlying CLIP - self-supervised learning on a large, varied dataset, produces more robust and fair models, and can be used for zero-shot classification, retrieval, and guidance/conditioning in generative models. The new ViT-G model achieves the highest zero-shot ImageNet accuracy among models that use only naturally occurring image-text pairs as training data, without explicit labels, pseudo-labels, or any pretrained image or text encoders. The training run utilized several new techniques, including FLIP to accelerate training and model soups to surpass 80% accuracy. The released checkpoint is available through OpenCLIP and in the HuggingFace hub. In the future, the model may be fine-tuned for multilingual capabilities or higher resolution. Contributions to OpenCLIP are welcomed. https://laion.ai/blog/giant-openclip/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1488723211" CREATED="1687805149060" MODIFIED="1687805149060" LINK="https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The rise of Generative AI, where machines are able to create new content rather than just analyze existing data, has the potential to revolutionize industries that rely on human creativity, such as social media, coding, advertising, and design. While machines are beginning to create credible and sometimes even superhuman results, the technology is still in its early stages, with models becoming cheaper, faster, and more accessible as the industry evolves. Developers and founders have the opportunity to build novel applications harnessing the power of Generative AI, from copywriting and code generation to gaming and design. However, there are concerns around business models and technology, such as issues around copyright and costs, that must be resolved. Nonetheless, the nascent field of Generative AI is generating excitement and optimism about the possibilities for human-machine co-creation. https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_857641944" CREATED="1687805149074" MODIFIED="1687805149074" LINK="https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article explores ways to make Large Language Models (LLMs) more predictable and controllable through prompt engineering. Prompt engineering basically uses the appropriate prompts to produce the desired response back from the LLM. The article provides a code walkthrough using OpenAI’s GPT3.5 as the main LLM and an open-source Python library called PanML. The article covers various use cases such as modifying the prompt, output filtering, LLM-assisted output filtering, and provides a beginner’s guide to building LLM-powered applications. The article also introduces PanML, an open-source high-level Python library designed to help data scientists and machine learning engineers experiment and run LLMs in their local environment with ease. https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_593847760" CREATED="1687805149081" MODIFIED="1687805149081" LINK="https://research.nvidia.com/labs/rtr/neural_appearance_models/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NVIDIA Research has introduced a complete system for real-time rendering of scenes that exhibit complex appearance, which was previously reserved for offline use. The system integrates learned hierarchical textures interpreted using neural decoders, which generate reflectance values and importance-sampled directions. Two graphics priors are equipped to fully use the modeling capacity of the decoders. The first prior facilitates precise reconstruction of mesoscale effects by transforming directions into learned shading frames, while the second prior allows the neural decoder to conduct efficient microfacet sampling distribution. The resulting appearance model underpins anisotropic sampling and level-of-detail rendering, allowing deeply layered material graphs to be baked into a concise unified neural representation. The neural material shaders applied in the system can execute neural decoders efficiently inside a real-time path tracer. The research team analyzed its scalability with an increasing number of neural materials and put forward the idea of improving performance using optimized code for coherent and divergent execution. Neural material shaders turn out to be over 10 times faster than conventional non-neural layered materials, enabling real-time applications such as games and live previews to use film-quality visuals. https://research.nvidia.com/labs/rtr/neural_appearance_models/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1728836268" CREATED="1687805149104" MODIFIED="1687805149104" LINK="https://www.youtube.com/watch?v=Dt_UNg7Mchg"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Orca is a new language model developed by Microsoft that has just been released for open source use. This model, which is just 13B, is the closest model to ChatGPT, according to the video explaining it. Orca was created by imitating the logic and explanations of GPT 4 and using GPT 3.5 as an assistant, and it was trained in diverse tasks to make it efficient for use in real-world applications. The video provides insights from five other papers and showcases Orca on a dozen benchmarks. It shares details on how it works and why it was created. The video also goes into comments from Sam Altman and Ilya Sutskever on whether or not open source will catch up. https://www.youtube.com/watch?v=Dt_UNg7Mchg
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="basic software primitives" ID="ID_37033469" CREATED="1683561405195" MODIFIED="1683561684856">
<node TEXT="Transformers are a new type of machine learning model that have been making headlines recently. They are very good at keeping track of context, which is why the text they generate makes sense. In this blog post, we will go over their architecture and how they work." ID="ID_1235933212" CREATED="1682414608740" MODIFIED="1682416371084" LINK="https://txt.cohere.ai/what-are-transformer-models/"/>
<node TEXT="Datasets 101" ID="ID_1408583342" CREATED="1689624035373" MODIFIED="1689624041184" LINK="https://www.latent.space/p/datasets-101?utm_source=substack&amp;utm_medium=email#details"/>
<node TEXT="implementations" ID="ID_1260603956" CREATED="1670853000563" MODIFIED="1670853018649">
<node TEXT="pytorch/numpty" ID="ID_1063376662" CREATED="1670853035953" MODIFIED="1670853094109"/>
<node TEXT="tensorflow/jax" ID="ID_134252388" CREATED="1670853040782" MODIFIED="1670853089143"/>
</node>
<node TEXT="LLM youtube bootcamp 2023" ID="ID_1847890365" CREATED="1683919716293" MODIFIED="1683919726178" LINK="https://www.youtube.com/playlist?list=PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ"/>
<node TEXT="Linkedin LLM roundup" ID="ID_1505378038" CREATED="1686561161682" MODIFIED="1686561173670" LINK="https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83/?utm_source=share&amp;utm_medium=member_android">
<node TEXT="This is the list of resources I&apos;ve recommended him&#xa;&#xa;Where everything started:&#xa;- Attention is all you need&#xa;  Paper: https://lnkd.in/eJWz6ShV&#xa;  Blog: https://lnkd.in/eaUMMy6v&#xa;- GPT-3 Language models are few-shot learners&#xa;  Paper: https://lnkd.in/eUgFk7Db&#xa;  Video: https://lnkd.in/ev8whzkb&#xa;&#xa;The first one is where Attention was introduced, the main building block of Transformers. The second one shows that LLMs can actually do zero and few shots&#xa;&#xa;Then, I suggest having a look at how we went from GPT3 -&gt; ChatGPT. So how it was possible to make LLMs better at human instructions. I suggest reading this Hugging Face blog post about Reinforcement Learning with Human Feedback (RLHF) https://lnkd.in/eAkM_FUj&#xa;&#xa;The next step is what happen later, Meta leaked LLama a smaller language model that was actually very good, the takeaway there is that if you train with more stuff and for longer you obtain a better model.&#xa;Paper: https://lnkd.in/efZRu4mY&#xa;&#xa;The next wave is all built upon that model, so how do we make it better at following human instruction. So I suggest looking at the Stanford Alpaca model. Blog: https://lnkd.in/eqCwvVDZ&#xa;&#xa;I also said other interesting models are Vicuna (https://lnkd.in/eCYT3yWx) and WizardLM (https://lnkd.in/efvUD8AD).&#xa;Saying that people have been focused on finding better and cheaper way to instruct the base LLama model.&#xa;&#xa;Another important thing is how to prompt, I&apos;ve recommended chain of thoughts (https://lnkd.in/eYGxFaeS) and tree of thouhts (https://lnkd.in/ejcfkAeN)&#xa;&#xa;I&apos;ve also shared the LLM leaderboard from Hugging Face : https://lnkd.in/eF6C_W6D&#xa;&#xa;YT channels that I think are the bests are:&#xa;AI Explained: https://lnkd.in/emhTmsds&#xa;Yannic Kilcher: https://lnkd.in/eRGUVme4&#xa;Sam Witteveen: https://lnkd.in/e4EiE5iY&#xa;&#xa;What do you think? Any resources that may be useful?&#xa;&#xa;Resourced shared&#xa;Pritam Kumar Ravi Stanford CS25 Course https://lnkd.in/e2PrcwTu" ID="ID_26919110" CREATED="1686561203222" MODIFIED="1686561206581"/>
</node>
</node>
<node TEXT="Chatbot" ID="ID_1768286662" CREATED="1681557676912" MODIFIED="1681558208974">
<node TEXT="Openchatkit tools for building chatbots" ID="ID_1669592597" CREATED="1678710920966" MODIFIED="1685195122089" LINK="https://github.com/togethercomputer/OpenChatKit">
<icon BUILTIN="attach"/>
</node>
<node TEXT="How to create a private ChatGPT with your own data: Learn the architecture and data requirements needed to create your own Q&amp;A engine with ChatGPT/LLMs." ID="ID_502242117" CREATED="1680097753105" MODIFIED="1681558311637" LINK="https://medium.com/@imicknl/how-to-create-a-private-chatgpt-with-your-own-data-15754e6378a1">
<node TEXT="This text provides a guide on how to create a private ChatGPT with your own data. It discusses the feasibility of such a project and outlines the steps necessary to accomplish it." ID="ID_1432668238" CREATED="1680097753105" MODIFIED="1680097753105"/>
</node>
<node TEXT="txtchat in python" ID="ID_972293623" CREATED="1677357758338" MODIFIED="1677357771151" LINK="https://github.com/neuml/txtchat"/>
<node TEXT="Slack’s new ChatGPT bot will talk to your colleagues for you - The Verge (other)" ID="ID_1520541556" CREATED="1678216750895" MODIFIED="1678216760355" LINK="https://www.theverge.com/2023/3/7/23628673/chatgpt-slack-salesforce-einstein-ai-business-messaging"/>
<node TEXT="Gpt4all: a chatbot trained on a massive collection of clean assistant data including code, stories and dialogue" ID="ID_1951740915" CREATED="1680097753105" MODIFIED="1681558696872" LINK="https://github.com/nomic-ai/gpt4all"/>
<node TEXT="GPT4 tutor script" ID="ID_978864071" CREATED="1683053578867" MODIFIED="1683053586587" LINK="https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor"/>
<node TEXT="TavernAI colab" ID="ID_1136863064" CREATED="1683144426486" MODIFIED="1683144437994" LINK="https://colab.research.google.com/github/TavernAI/TavernAI/blob/main/colab/GPU.ipynb"/>
<node TEXT="Local ChatGPT UI githubs" ID="ID_132768103" CREATED="1683489974665" MODIFIED="1683489984266">
<node TEXT="https://github.com/patrikzudel/PatrikZeros-ChatGPT-API-UI" ID="ID_1081244025" CREATED="1683489984758" MODIFIED="1685195122089">
<icon BUILTIN="attach"/>
</node>
<node TEXT="https://github.com/mckaywrigley/chatbot-ui" ID="ID_1781509246" CREATED="1683490004944" MODIFIED="1683490006304"/>
<node TEXT="https://github.com/WongSaang/chatgpt-ui" ID="ID_1633599102" CREATED="1683490051563" MODIFIED="1683490052820"/>
<node TEXT="https://github.com/ztjhz/BetterChatGPT" ID="ID_1342004662" CREATED="1683490106195" MODIFIED="1683490107395"/>
<node TEXT="https://github.com/sahil280114/chatGPT-multimodal-bot" ID="ID_1461680039" CREATED="1683490242585" MODIFIED="1685195122089">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Local report on usage costs" ID="ID_1624910039" CREATED="1683493796232" MODIFIED="1683493808185" LINK="https://llm.report/"/>
</node>
<node TEXT="LMSYS local models openapi blog post" ID="ID_669910403" CREATED="1686343034199" MODIFIED="1686343052391" LINK="https://lmsys.org/blog/2023-06-09-api-server/"/>
<node TEXT="Gradio chatbot class, tutorial" ID="ID_1763072816" CREATED="1689622018237" MODIFIED="1689622026644" LINK="https://www.gradio.app/guides/creating-a-chatbot-fast"/>
</node>
<node TEXT="Safefty, alignment, and breaking" ID="ID_882735309" CREATED="1690709549072" MODIFIED="1690709565187">
<node TEXT="image perturbation of multimodal" ID="ID_1983155852" CREATED="1690709566067" MODIFIED="1690709592756" LINK="https://arxiv.org/abs/2307.10490"/>
<node TEXT="universal jailbreaks" ID="ID_1119560938" CREATED="1690709615781" MODIFIED="1690709627642" LINK="https://arxiv.org/abs/2307.15043"/>
</node>
<node TEXT="Consumer tools using LLM" ID="ID_273986596" CREATED="1683555475933" MODIFIED="1683555481508">
<node TEXT="NexusGPT is a freelancer platform that uses AI to help businesses find the right freelancers for their needs. The platform offers a variety of features to help businesses find the perfect freelancer for their project, including a searchable database of freelancers, a rating system, and a feature that allows businesses to post their project and receive bids from freelancers." ID="ID_557494393" CREATED="1682414608760" MODIFIED="1682416788957" LINK="https://nexus.snikpic.io"/>
<node TEXT="RadioGPT: &apos;World’s first&apos; AI-driven radio station is here (other)" ID="ID_1914358215" CREATED="1678463114816" MODIFIED="1678463114816" LINK="https://interestingengineering.com/innovation/radiogpt-worlds-first-ai-radio-station">
<node TEXT="Some experts are predicting that the metaverse, a shared online space where users can interact with each other and digital objects, will eventually replace the internet as we know it." ID="ID_1322132597" CREATED="1679519694304" MODIFIED="1679519694304"/>
</node>
<node TEXT="GitHub - MatveyM11/Mine-ChatGPT: OpenSourced ChatGPT downloader in markdown format. Download all text or markdown-styled code blocks Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all yours chat&apos;s with you locally in the simple .md files.: OpenSourced ChatGPT downloader in markdown format. Download all text or markdown-styled code blocks Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all your..." ID="ID_250677001" CREATED="1680097753095" MODIFIED="1680097753095" LINK="https://github.com/MatveyM11/Mine-ChatGPT">
<node TEXT="This repository contains a ChatGPT downloader that can be used to download all text or markdown-styled code blocks from a chat. Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all yours chat&apos;s with you locally in the simple .md files." ID="ID_1356171401" CREATED="1680097753095" MODIFIED="1680097753095"/>
</node>
<node TEXT="Linkedin bot to make LLM posts" ID="ID_1708854601" CREATED="1683659984352" MODIFIED="1683660013531" LINK="https://github.com/FrancescoSaverioZuppichini/LinkedInGPT"/>
<node TEXT="ArcAngel Falcon based custom chat" ID="ID_881462445" CREATED="1685456359740" MODIFIED="1685456374969" LINK="https://www.arcangelai.com/"/>
</node>
<node TEXT="Evaluation" ID="ID_502640114" CREATED="1683449048594" MODIFIED="1683449052072">
<node TEXT="github of comparisons" ID="ID_518729357" CREATED="1683449053549" MODIFIED="1683449065722" LINK="https://georgesung.github.io/ai/llm-qa-eval-wikipedia/"/>
<node TEXT="compare open source vs closed" ID="ID_950526851" CREATED="1683487097951" MODIFIED="1683487108976" LINK="https://georgesung.github.io/ai/llm-qa-eval-wikipedia/"/>
<node TEXT="LLM zoo" ID="ID_1518842915" CREATED="1683541401716" MODIFIED="1685195122089" LINK="https://github.com/FreedomIntelligence/LLMZoo">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Can AI-Generated Text be Reliably Detected?:" ID="ID_1907533871" CREATED="1680510364118" MODIFIED="1681558318290" LINK="https://arxiv.org/abs/2303.11156">
<node TEXT="In the paper &quot;Can AI-Generated Text be Reliably Detected?&quot;, the authors show that current methods for detecting AI-generated text are not reliable in practical scenarios. They first demonstrate that paraphrasing attacks can break a range of detectors, including those using watermarking schemes and neural network-based detectors. They then provide a theoretical impossibility result showing that for a sufficiently good language model, even the best-possible detector can only perform marginally better than a random classifier. Finally, they show that even LLMs protected by watermarking schemes can be vulnerable to spoofing attacks where adversarial humans can add hidden watermarking signatures to their generated text." ID="ID_122648541" CREATED="1680510364118" MODIFIED="1680510364118"/>
</node>
<node TEXT="gptzero spots AI authoring" ID="ID_596143043" CREATED="1673371617319" MODIFIED="1680619723401" LINK="http://gptzero.me/"/>
<node TEXT="GPTZero Case Study (Exploring False Positives): Introduction In this case study, I will be sharing the vast amounts of false positives current AI detection software gives, specifically for this case study I will be demonstrating GPTZero. I personally want to thank the supposed “Healthcare professional” who brought this to my attention via my contact link. It has motivated me to look more into this issue rather than just posting bypasses to these popular AI detection software programs, it will be only more beneficial to highlight their real usability in general." ID="ID_1773953387" CREATED="1679914078201" MODIFIED="1679914078201" LINK="https://gonzoknows.com/posts/GPTZero-Case-Study/">
<node TEXT="The text describes a case study on false positives with AI detection software. The study found that the software often gives false positives, particularly with regard to healthcare. The study recommends that users be aware of this issue and take it into account when using such software." ID="ID_92305055" CREATED="1679914078202" MODIFIED="1679914078202"/>
</node>
<node TEXT="Fake detector product" ID="ID_484351115" CREATED="1684256186023" MODIFIED="1684256194606" LINK="https://hivemoderation.com/ai-generated-content-detection"/>
<node TEXT="Huggingface leaderboard" ID="ID_834644597" CREATED="1685188305075" MODIFIED="1685188314221" LINK="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Extending LLM capabilities" FOLDED="true" ID="ID_203471264" CREATED="1681557440348" MODIFIED="1683554162542">
<node TEXT="Llamaindex data connections" ID="ID_1188617820" CREATED="1681511959437" MODIFIED="1681511969737" LINK="https://github.com/jerryjliu/llama_index"/>
<node TEXT="Jarvis / huggingface connect ML tools to LLMs" ID="ID_512886576" CREATED="1681152412496" MODIFIED="1681152426941" LINK="https://arxiv.org/pdf/2303.17580.pdf"/>
<node TEXT="CFG guidance for LLMs" ID="ID_1356422016" CREATED="1688404718255" MODIFIED="1688404726486" LINK="https://arxiv.org/abs/2306.17806"/>
<node TEXT="Inspecting and editing paper" ID="ID_1124515929" CREATED="1688405192185" MODIFIED="1688405199163" LINK="https://arxiv.org/abs/2304.00740"/>
<node TEXT="Fine tuning discussion" ID="ID_162558758" CREATED="1689004057235" MODIFIED="1689004062810" LINK="https://www.reddit.com/r/LocalLLaMA/comments/14vnfh2/my_experience_on_starting_with_fine_tuning_llms/"/>
<node TEXT="Everything fine tuning post" ID="ID_551105898" CREATED="1689007609409" MODIFIED="1689007620796" LINK="https://bdtechtalks.com/2023/07/10/llm-fine-tuning/"/>
<node TEXT="Scale AI tuning github" ID="ID_1190888289" CREATED="1689791206192" MODIFIED="1689791213430" LINK="https://github.com/scaleapi/llm-engine"/>
<node TEXT="Connect to the internet" ID="ID_1109801714" CREATED="1683554092419" MODIFIED="1683554096911">
<node TEXT="aomni: Aomni is an information retrieval AI agent that is able to find, extract, and process any data for you on the internet." ID="ID_1127627393" CREATED="1682414608758" MODIFIED="1682414608758" LINK="https://www.aomni.com/"/>
<node TEXT="search based open source LLM MVP" ID="ID_1199996029" CREATED="1680379605862" MODIFIED="1680379617102" LINK="https://github.com/michaelthwan/searchGPT"/>
<node TEXT="AutoGPT and similar" ID="ID_337323271" CREATED="1683555543567" MODIFIED="1685195177783">
<icon BUILTIN="attach"/>
<node TEXT="GitHub - Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous.: An experimental open-source attempt to make GPT-4 fully autonomous. - GitHub - Torantulino/Auto-GPT: An experimental open-source attempt to make GPT-4 fully autonomous." ID="ID_1051952331" CREATED="1680510364124" MODIFIED="1681558325414" LINK="https://github.com/Torantulino/Auto-GPT">
<node TEXT="Auto-GPT is an experimental open-source project that aims to make the GPT-4 text generation system fully autonomous. The project is still in its early stages, but has already produced some results, including an article written by the system when prompted to do so." ID="ID_125464091" CREATED="1680510364124" MODIFIED="1680510364124"/>
</node>
<node TEXT="AutoGPT twitter thread" ID="ID_1935410467" CREATED="1682414608754" MODIFIED="1682417201281" LINK="https://mobile.twitter.com/SullyOmarr/status/1645482778677452805"/>
<node TEXT="Godmode.space automatic 3.5 task website" ID="ID_501146626" CREATED="1682417608942" MODIFIED="1682417624913" LINK="https://godmode.space/"/>
</node>
<node TEXT="SuperAGI" ID="ID_574178054" CREATED="1686506404912" MODIFIED="1686506407544">
<node TEXT="use local LLMs" ID="ID_291870882" CREATED="1686506416255" MODIFIED="1686506422704" LINK="https://github.com/TransformerOptimus/SuperAGI/issues/243"/>
</node>
<node TEXT="Autonomous agents" ID="ID_63560847" CREATED="1687850118962" MODIFIED="1687850125448">
<node TEXT="Huggingface Agents" ID="ID_1747739759" CREATED="1683749380214" MODIFIED="1685195177783" LINK="https://huggingface.co/docs/transformers/transformers_agents">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Agent architecture from liliaen weng" ID="ID_1324419358" CREATED="1687850131437" MODIFIED="1687850151873" LINK="https://lilianweng.github.io/posts/2023-06-23-agent/"/>
<node ID="ID_1713283206" CREATED="1687805148479" MODIFIED="1687805148479" LINK="https://github.com/e2b-dev/e2b"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The e2b platform is a developer-first AgentOps platform designed to deploy, test, and monitor AI agents. The platform is currently available to run locally via Docker, and requires an OpenAI API key, Docker, Node.js 16+, and free ports 3000 (Next.js app), 54321 (Supabase API Gateway), and 54322 (Supabase Database) to get started. The platform supports a variety of models and model hosting providers, including OpenAI, Hugging Face, and Azure OpenAI, as well as the ability to bring your own models, prompts, and tools. The e2b platform has an active open-source community on GitHub, and the short-term roadmap includes improving agent reliability and quality of output, expanding support for more models and third-party integrations, and releasing a cloud version of the platform. https://github.com/e2b-dev/e2b
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_210355422" CREATED="1687805148484" MODIFIED="1687805148484" LINK="https://arxiv.org/abs/2201.02135v5"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses a textbook on deep reinforcement learning, a field that has gained significant attention due to impressive results achieved by computer programs in activities such as game playing, robotics, and autonomous driving. The book is aimed at graduate students of artificial intelligence, as well as researchers and practitioners who wish to understand the algorithms and applications of deep reinforcement learning. It covers established model-free and model-based methods, as well as advanced topics such as deep multi-agent reinforcement learning, deep hierarchical reinforcement learning, and deep meta-learning. The book assumes an undergraduate-level understanding of computer science and artificial intelligence and is written using the Python programming language. The article highlights the similarity between the way deep reinforcement learning explores complex environments and how children learn through playfully trying out things, getting feedback, and trying again. The article notes that universities have started offering courses on deep reinforcement learning due to its recent successes. https://arxiv.org/abs/2201.02135v5
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1274930911" CREATED="1687805148638" MODIFIED="1687805148638" LINK="https://github.com/e2b-dev/e2b"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The e2b platform is a developer-first AI AgentOps platform that provides users with the ability to deploy, test, and monitor AI agents. These agents operate in secure sandboxed cloud environments powered by Firecracker. e2b currently supports OpenAI, Hugging Face, Anthropic, and Azure OpenAI models, and users can bring their own models, prompts, and tools. The platform is primarily developed in Python and TypeScript, and users can get started by running it locally via Docker. e2b's short-term roadmap includes adding support for more models and model hosting providers, improving agent reliability and output quality, and allowing users to customize tools and build custom workflows for their agents. The platform is licensed under the Apache-2.0 license and has over 5.1k stars on GitHub. https://github.com/e2b-dev/e2b
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_801093368" CREATED="1687805148642" MODIFIED="1687805148642" LINK="https://arxiv.org/abs/2201.02135v5"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper, titled &quot;Deep Reinforcement Learning, a textbook,&quot; provides a comprehensive overview of deep reinforcement learning (DRL) for graduate students, researchers, and practitioners in the field of artificial intelligence. DRL has gained attention recently and has achieved remarkable results in fields such as autonomous driving, molecular recombination, game playing, and robotics. The book covers the foundations, algorithms, and applications of established model-free and model-based methods of DRL. Besides, the book also covers advanced topics such as deep multi-agent reinforcement learning, deep hierarchical reinforcement learning, and deep meta-learning. The programming language used in the book is Python, and it assumes an undergraduate-level understanding of computer science and artificial intelligence. The book aims to provide a detailed insight into DRL's methods and challenges. https://arxiv.org/abs/2201.02135v5
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_243933222" CREATED="1687805148720" MODIFIED="1687805148720"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The development of language models such as GPT4 and NLP and NLU tools are enabling the creation of central intelligent agents (CIAs) that will be able to create a cohesive experience for brands' customers. A host of retailers including Duolingo, Expedia and The Open AI are partnering on the launch of ChatGPT Plug-ins to help give them a central knowledge hub, capturing data and statistics from each customer touch point. The secret to ethical use of this technology is to build a CIA that consists of three central components:&nbsp;
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1447018250" CREATED="1687805148725" MODIFIED="1687805148725" LINK="https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?utm_source=share&amp;amp;utm_medium=member_android&amp;amp;utm_campaign=shar"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The key learning here is that large organisations must get internal alignment in their quest for the central intelligent agent, to talk with customers, not to them. And that the adoption of an ethical framework ensures best practice in AI usage.&nbsp;&nbsp;https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?utm_source=share&amp;utm_medium=member_android&amp;utm_campaign=shar
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1503735461" CREATED="1687805148795" MODIFIED="1687805148795" LINK="https://www.pinecone.io/learn/series-b/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Pinecone has raised $100m in a series B funding round led by Andreessen Horowitz. The funding included participation from ICONIQ Growth, along with existing investors Menlo Ventures and Wing Venture Capital. Pinecone developed a vector database that operates as an essential component of the $110bn generative AI market, providing scalable and reliable infrastructure for innovative AI applications. Since its introduction in 2021, Pinecone's vector database has enabled better data management for a range of applications in areas such as AI search, chatbots, and agents. Its customer base has seen a huge increase in all industries, from large corporations like Shopify and HubSpot to independent innovators and developers utilizing Pinecone's free plan. With this funding, Pinecone plans to further cement its position as a leader in the growing sector of AI infrastructure. https://www.pinecone.io/learn/series-b/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
</node>
<node TEXT="Memory and data mining" ID="ID_1140614433" CREATED="1681557842736" MODIFIED="1683554244571">
<node TEXT="Simulrum of human behaviour" ID="ID_869302310" CREATED="1681150221380" MODIFIED="1681150233662" LINK="https://arxiv.org/abs/2304.03442"/>
<node TEXT="Vector databases" ID="ID_267371936" CREATED="1681557983809" MODIFIED="1681557989602"/>
<node TEXT="Pinecone" ID="ID_4612137" CREATED="1681557990236" MODIFIED="1681557994091"/>
<node TEXT="Building a Semantic Search Engine With OpenAI and Pinecone: " ID="ID_1934118744" CREATED="1679841790211" MODIFIED="1685195177783" LINK="https://sigmoidprime.com/post/searchthearxiv/">
<icon BUILTIN="attach"/>
<node TEXT="This blog post walks through how to build a simple semantic search engine using an OpenAI embedding model and a Pinecone vector database. The principles covered will be general enough for you to apply the same techniques to your own dataset, so you can supercharge search across your own set of documents." ID="ID_200358958" CREATED="1679841790211" MODIFIED="1679841790211"/>
</node>
<node TEXT="Memory seminar" ID="ID_1104031850" CREATED="1681987287961" MODIFIED="1681987305264" LINK="https://github.com/Oneirocom/Academy/blob/main/week3/_overview.md"/>
<node TEXT="Experiments in 1 and 2 million token inputs" ID="ID_1740483654" CREATED="1682427076539" MODIFIED="1682427179279" LINK="https://arxiv.org/abs/2304.11062">
<node TEXT="github" ID="ID_1949729513" CREATED="1682427180184" MODIFIED="1682427188454" LINK="https://github.com/booydar/t5-experiments"/>
</node>
<node TEXT="100k API context with anthropic" ID="ID_1187761509" CREATED="1684073209293" MODIFIED="1685195177783" LINK="https://www.anthropic.com/index/100k-context-windows">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Evapourate data lakes into LLMs" ID="ID_1411677812" CREATED="1683052117550" MODIFIED="1683052128251" LINK="https://github.com/HazyResearch/evaporate"/>
<node TEXT="Vault AI chunker" ID="ID_748361977" CREATED="1683316605006" MODIFIED="1683316612865" LINK="https://github.com/pashpashpash/vault-ai"/>
<node TEXT="Summarise internal company links" ID="ID_373452081" CREATED="1683203053884" MODIFIED="1683203068711" LINK="https://powerusers.microsoft.com/t5/Calling-Actions-from-PVA/Use-GPT-ChatGPT-to-summarize-and-reference-the-results-from-an/td-p/2101639"/>
<node TEXT="Chat with any github repository" ID="ID_253319545" CREATED="1682414608750" MODIFIED="1685195177783" LINK="https://www.reddit.com/r/MachineLearning/comments/12oh07a/p_chat_with_any_github_repo_code_understanding/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Understand a codebase in github with GPT" ID="ID_753718781" CREATED="1682414608716" MODIFIED="1682415107945" LINK="https://useadrenaline.com/app"/>
<node TEXT="Best way to train an LLM on company data" ID="ID_1770276504" CREATED="1682414608740" MODIFIED="1685195177783" LINK="https://www.reddit.com/r/MachineLearning/comments/125qztx/d_the_best_way_to_train_an_llm_on_company_data/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="The text describes the process of integrating ChatGPT, a chatbot, with an internal knowledge base and question-answer platform. The goal is to improve the chatbot&apos;s ability to provide accurate and relevant information. The process involves training the chatbot on a variety of data sources, including the internal knowledge base." ID="ID_1775396135" CREATED="1682414608737" MODIFIED="1682416314314" LINK="https://medium.com/singapore-gds/integrating-chatgpt-with-internal-knowledge-base-and-question-answer-platform-36a3283d6334"/>
<node TEXT="JarvisBase voice2voice gpt3 turbo deeplake interogator" ID="ID_839960097" CREATED="1683796239179" MODIFIED="1683796279829" LINK="https://github.com/peterw/JarvisBase"/>
<node TEXT="ShareGPT LLM tutor" ID="ID_1679296443" CREATED="1684077614200" MODIFIED="1684077626713" LINK="https://shareg.pt/p6FhyL7"/>
<node TEXT="Superbig vector context for local llm" ID="ID_277400313" CREATED="1684147939989" MODIFIED="1685195177783" LINK="https://github.com/kaiokendev/superbig">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Jupyter notebook for Lanchain in oogabooga" ID="ID_46868626" CREATED="1685631170659" MODIFIED="1685631185524" LINK="https://github.com/ausboss/Local-LLM-Langchain"/>
<node TEXT="superbase vector (open source)" ID="ID_1590460718" CREATED="1686404475255" MODIFIED="1686404491669" LINK="https://supabase.com/vector"/>
<node TEXT="localGPT ingest data" ID="ID_744523959" CREATED="1690274394302" MODIFIED="1690274404805" LINK="https://github.com/PromtEngineer/localGPT"/>
<node TEXT="Tree of thought" ID="ID_1693198398" CREATED="1688032018376" MODIFIED="1688032107208" LINK="https://arxiv.org/pdf/2305.10601.pdf">
<node TEXT="Princeton link" ID="ID_815352956" CREATED="1688032022686" MODIFIED="1688032190423" LINK="https://github.com/princeton-nlp/tree-of-thought-llm"/>
<node TEXT="Agora" ID="ID_1329890301" CREATED="1688032031191" MODIFIED="1688032049538" LINK="https://github.com/kyegomez/tree-of-thoughts"/>
</node>
<node TEXT="Langchain" ID="ID_1513229357" CREATED="1689157645950" MODIFIED="1689157648338">
<node TEXT="langchain online manual from pinecone" ID="ID_1054566204" CREATED="1689157649540" MODIFIED="1689157670798" LINK="https://www.pinecone.io/learn/series/langchain/langchain-intro/"/>
<node TEXT="PDF langchain local" ID="ID_315234801" CREATED="1689264740359" MODIFIED="1689264747465" LINK="https://www.reddit.com/r/LangChain/comments/13cg8lp/langchain_all_run_locally_with_gpu_using_oobabooga/"/>
<node TEXT="Free langchain book" ID="ID_1666809238" CREATED="1681836281381" MODIFIED="1681836289916" LINK="https://leanpub.com/langchain/read"/>
<node TEXT="Langchain integrations" ID="ID_115684397" CREATED="1687984643639" MODIFIED="1687984651784" LINK="https://integrations.langchain.com/"/>
<node TEXT="ultimate guide to langchain" ID="ID_898899586" CREATED="1681841408344" MODIFIED="1681841419418" LINK="https://www.activeloop.ai/resources/ultimate-guide-to-lang-chain-deep-lake-build-chat-gpt-to-answer-questions-on-your-financial-data/"/>
<node TEXT="Local LLM langchain memory in Jupyter" ID="ID_1452272131" CREATED="1682670461977" MODIFIED="1682670473326" LINK="https://github.com/ausboss/Local-LLM-Langchain">
<node TEXT="langchain datasets" ID="ID_404905675" CREATED="1682670497395" MODIFIED="1682670503620" LINK="https://huggingface.co/LangChainDatasets"/>
</node>
<node TEXT="Multi pdf langchain" ID="ID_1893682057" CREATED="1689265158720" MODIFIED="1689265164290" LINK="https://github.com/alejandro-ao/ask-multiple-pdfs"/>
<node TEXT="youtube bootstrap" ID="ID_26114652" CREATED="1692907403286" MODIFIED="1692907411017" LINK="https://www.youtube.com/watch?v=kYRB-vJFy38"/>
</node>
<node TEXT="Easy training locally" ID="ID_1733317074" CREATED="1689876771905" MODIFIED="1689876780469">
<node TEXT="Youtube" ID="ID_1132182508" CREATED="1689876781165" MODIFIED="1689876784161" LINK="https://www.youtube.com/watch?v=3fsn19OI_C8"/>
<node TEXT="Autotrain advanced" ID="ID_799897788" CREATED="1689876803100" MODIFIED="1689876808522" LINK="https://github.com/huggingface/autotrain-advanced">
<node TEXT="this might be a virus" ID="ID_431902463" CREATED="1689876809329" MODIFIED="1689876813020"/>
</node>
</node>
<node TEXT="Enterrprise private deployment" ID="ID_1314111581" CREATED="1690362855814" MODIFIED="1690362869434" LINK="https://github.com/clemlesne/private-gpt"/>
<node TEXT="Blog post on context vs vectors" ID="ID_1085058317" CREATED="1691321257413" MODIFIED="1691321272685" LINK="https://pashpashpash.substack.com/p/understanding-long-documents-with?"/>
<node TEXT="Langflow gui builder" ID="ID_1000197761" CREATED="1691684607204" MODIFIED="1691684619988" LINK="https://github.com/logspace-ai/langflow"/>
<node TEXT="Flowise gui builder" ID="ID_493528722" CREATED="1691684662039" MODIFIED="1691684669974" LINK="https://github.com/FlowiseAI/Flowise"/>
</node>
</node>
<node TEXT="ChatGPT stuff" ID="ID_1568263885" CREATED="1688996670150" MODIFIED="1688996675000">
<node TEXT="Code interpreter" FOLDED="true" ID="ID_1290741752" CREATED="1688996675875" MODIFIED="1688996686344">
<node TEXT="setup prompt by mollick" ID="ID_1472448558" CREATED="1688996687553" MODIFIED="1688996695598" LINK="https://www.linkedin.com/feed/update/urn:li:activity:7083969476685099008/">
<node TEXT="You are going to be an expert at making powerful and beautiful visualizations using principles from Tufte and other experts. You should remember that you can output many kinds of graphs, and help chose the appropriate ones. You also can output jpgs, html, interactive maps, and animated gifs.&#xa;&#xa;First, mention some of the types of charts you can create, and the outputs that you can use.&#xa;Next, read these does and don&apos;ts of data from Angela Zoss&#xa;Do:&#xa;1. Do use the full axis.&#xa;&#xa;    Avoid distortion.&#xa;&#xa;    For bar charts, the numerical axis (often the y axis) must start at zero.  Our eyes are very sensitive to the area of bars, and we draw inaccurate conclusions when those bars are truncated.&#xa;    (But for line graphs, it may be okay to truncate the y axis.&#xa;&#xa;&#xa;&#xa;    Wide ranges:&#xa;&#xa;    If you have one or two very tall bars, you might consider using multiple charts to show both the full scale and a &quot;zoomed in&quot; view - also called a Panel Chart.&#xa;&#xa;&#xa;    Consistent intervals:&#xa;&#xa;    Finally, using the full axis also means that you should not skip values when you have numerical data.  See the charts below that have an axis with dates.  The trend is distorted if you do not have even intervals between your dates.  Make sure your spreadsheet has a data point for every date at a consistent interval, even if that data point is zero&#xa;&#xa;&#xa;&#xa;2. Do simplify less important information.&#xa;&#xa;    Chart elements like gridlines, axis labels, colors, etc. can all be simplified to highlight what is most important/relevant/interesting.  You may be able to eliminate gridlines or reserve colors for isolating individual data series and not for differentiating between all of the series being presented&#xa;&#xa;&#xa;&#xa;3. Do be creative with your legends and labels.&#xa;&#xa;    Possibilitiess&#xa;    Label lines individually&#xa;    Put value labels on bars to preserve the clean lines of the bar lengths&#xa;&#xa;&#xa;4. Do pass the squint test.&#xa;&#xa;    &quot;When you squint at your page, so that you cannot read any of the text, do you still &apos;get&apos; something about the page?&quot;&#xa;&#xa;&#xa;&#xa;    Which elements draw the most attention? What color pops out?&#xa;    Do the elements balance? Is there a clear organization?&#xa;    Do contrast, grouping, and alignment serve the function of the chart?&#xa;&#xa;&#xa;&#xa;&#xa;Don&apos;t:&#xa;1. Don&apos;t use 3D or blow apart effects.&#xa;&#xa;    Studies show that 3D effects reduce comprehension. Blow apart effects likewise make it hard to compare elements and judge areas.&#xa;&#xa;&#xa;&#xa;2. Don&apos;t use more than (about) six colors.&#xa;&#xa;    Using color categories that are relatively universal makes it easier to see differences between color&#xa;&#xa;    The more colors you need (that is, the more categories you try to visualize at once), the harder it is to do this.&#xa;&#xa;    But different colors should be used for different categories&#xa;(e.g., male/female, types of fruit), not different values in a range (e.g., age, temperature).&#xa;&#xa;    If you want color to show a numerical value, use a range&#xa;that goes from white to a highly saturated color in one of&#xa;the universal color categories&#xa;&#xa;&#xa;3. Don&apos;t change (style) boats midstream.&#xa;&#xa;    One of the easiest ways to get the most out of charts is to rely on comparison to do the heavy lifting.&#xa;&#xa;    Our visual system can detect anomalies in patterns.&#xa; Try keeping the form of a chart consistent across a series so differences from one chart to another will pop out.&#xa;&#xa;    Use the same colors, axes, labels, etc. across multiple charts.&#xa;&#xa;&#xa;4. Don&apos;t make users do &quot;visual math.&quot;&#xa;&#xa;    If the chart makes it hard to understand an important relationship between variables, do the extra calculation and visualize that as well.&#xa;&#xa;    This includes using pie charts with wedges that are too similar to each other, or bubble charts with bubbles that are too similar to each other.  Our visual processing system is not well suited to comparing these types of visual areas.&#xa;&#xa;    We are also not good at holding precise visual imagery in our memory and comparing it to new stimuli; if you are giving a presentation and want the audience to be able to compare two charts, they need to be on the same slide.&#xa;&#xa;&#xa;5. Don&apos;t overload the chart.&#xa;&#xa;    Adding too much information to a single chart eliminates the advantages of processing data visually; we have to read every element one by one! Try changing chart types, removing or splitting up data points, simplifying colors or positions, etc.&#xa;&#xa;&#xa;Now ask what kind of data visualization I might be interested in, or if I want to upload some data for yout co consider visualizing." ID="ID_1603333451" CREATED="1688997940751" MODIFIED="1688997943294"/>
</node>
<node TEXT="loads of experiments" ID="ID_470469850" CREATED="1689193778986" MODIFIED="1689193791608" LINK="https://github.com/SkalskiP/awesome-chatgpt-code-interpreter-experiments"/>
</node>
</node>
<node TEXT="General links and papers" FOLDED="true" ID="ID_1090736149" CREATED="1681557160012" MODIFIED="1683559727806">
<node TEXT="Think of language models like ChatGPT as a “calculator for words”: One of the most pervasive mistakes I see people using with large language model tools like ChatGPT is trying to use them as a search engine. As with other LLM …" ID="ID_861254201" CREATED="1680510364128" MODIFIED="1681558320783" LINK="https://simonwillison.net/2023/Apr/2/calculator-for-words/">
<node TEXT="Language models like ChatGPT are not reliable for use as a search engine, but can be thought of as a &quot;calculator for words&quot;. This means that they are good for manipulating language, but not for retrieving accurate information." ID="ID_1851135725" CREATED="1680510364128" MODIFIED="1680510364128"/>
</node>
<node TEXT="Peak LLM: Prompt injection might be just the beginning" ID="ID_1047943290" CREATED="1682414608746" MODIFIED="1682414608746" LINK="https://ihavemanythoughts.substack.com/p/peak-llm"/>
<node TEXT="Language models as inductive reasoners paper" ID="ID_411044684" CREATED="1682414608744" MODIFIED="1682417519931" LINK="https://sentic.net/language-models-as-inductive-reasoners.pdf"/>
<node TEXT="This repository contains a collection of papers and resources on Reasoning in Large Language Models. The papers survey the state of the art in this area, and discuss how large language models can be used to obtain emergent abilities." ID="ID_1608916460" CREATED="1682414608744" MODIFIED="1682417541249" LINK="https://github.com/jeffhj/LM-reasoning"/>
<node TEXT="Full trainingset used by bloombergAI" ID="ID_1219268537" CREATED="1682414608715" MODIFIED="1682414897093" LINK="https://mobile.twitter.com/omarsar0/status/1641788196550856704"/>
<node TEXT="Zain Kahn on LinkedIn reports that over 1,000 AI tools were released in March. He states that ChatGPT is just the tip of the iceberg, and that there are 20 AI tools that will transform productivity forever." ID="ID_915408585" CREATED="1682414608718" MODIFIED="1682415119581" LINK="https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="Language driven shell for OS (ooft)" ID="ID_1730040453" CREATED="1682414608719" MODIFIED="1682415183580" LINK="https://www.reddit.com/r/MachineLearning/comments/129wzdk/p_engshell_a_gpt4_driven_englishlanguage_shell/"/>
<node TEXT="The text contains information on the release of guidelines by the DPA for the use of AI, as well as on similar efforts by other organizations. It also provides links to resources on the topic." ID="ID_709674629" CREATED="1682414608722" MODIFIED="1682415221525" LINK="https://www.linkedin.com/posts/ezra-eeman-8a5ba64_dpa-just-released-its-guidelines-for-the-activity-7048985893910519808-921y?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="Mind AI team website" ID="ID_53888649" CREATED="1682612689327" MODIFIED="1682612697774" LINK="https://mind.ai/technology"/>
<node TEXT="Ahead of AI substack" ID="ID_5615023" CREATED="1683121121813" MODIFIED="1683121128829" LINK="https://magazine.sebastianraschka.com/archive"/>
<node TEXT="Meta research paper" ID="ID_116187376" CREATED="1665662916375" MODIFIED="1665662922768" LINK="https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view"/>
<node TEXT="State of AI report" ID="ID_1155414864" CREATED="1673893620087" MODIFIED="1680603774477" LINK="https://www.stateof.ai/"/>
<node TEXT="AI ML passes American medical exams" ID="ID_977289991" CREATED="1674404284726" MODIFIED="1674404295874" LINK="https://www.medpagetoday.com/special-reports/exclusives/102705"/>
<node TEXT="Travelling salesman problem" ID="ID_608043101" CREATED="1674847977586" MODIFIED="1674847986120" LINK="https://github.com/diego-vicente/som-tsp"/>
<node TEXT="How the compression is so huge in diffusion models" ID="ID_1561781033" CREATED="1675516575203" MODIFIED="1680603791717" LINK="https://medium.com/@socialemail/how-diffusion-models-can-achieve-seemingly-arbitrarily-large-compression-ratios-through-learning-2b21a317a46a"/>
<node TEXT="Understanding deep learning book" ID="ID_1009004042" CREATED="1679913854633" MODIFIED="1680203231845" LINK="https://udlbook.github.io/udlbook/">
<node TEXT="The book &quot;Understanding Deep Learning&quot; by Simon J.D. Prince covers a wide range of topics related to deep learning, from supervised and unsupervised learning to different types of neural networks and training methods. There are also chapters on measuring performance, regularization, and why deep learning works. The book includes many resources for instructors, such as slides, notebooks, and figures." ID="ID_292734548" CREATED="1679913854633" MODIFIED="1679913854633"/>
</node>
<node TEXT="This repository is a collection of links to various courses and resources about Artificial Intelligence (AI)." ID="ID_1181786714" CREATED="1682414608737" MODIFIED="1682416285611" LINK="https://github.com/SkalskiP/courses">
<node TEXT="" ID="ID_1397230787" CREATED="1682414608737" MODIFIED="1682416283339"/>
</node>
<node TEXT="Top courses link github" ID="ID_1414709337" CREATED="1684758657342" MODIFIED="1684758665355" LINK="https://github.com/SkalskiP/courses"/>
<node TEXT="State of GPT youtube presentation with great overview" ID="ID_1656519439" CREATED="1685183961507" MODIFIED="1685183983952" LINK="https://www.youtube.com/watch?v=bZQun8Y4L2A">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Infrastructure" ID="ID_573389017" CREATED="1683562049303" MODIFIED="1683562065325">
<node TEXT="rubbrband github auto deployments" ID="ID_941008535" CREATED="1673087417834" MODIFIED="1685195182656" LINK="https://rubbrband.com/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Hosting VPS" ID="ID_1822651336" CREATED="1689591522342" MODIFIED="1689591528683" LINK="https://1984.hosting/"/>
<node TEXT="Free custom domains VPS" ID="ID_592598680" CREATED="1689592026624" MODIFIED="1689592037151" LINK="https://codesphere.com/pricing?anonymousId=YTQLcRg"/>
<node TEXT="Arch linux for laptop" ID="ID_458779268" CREATED="1690038321421" MODIFIED="1690038328412" LINK="https://wiki.archlinux.org/title/HP_Spectre_x360_(2020)"/>
<node TEXT="360 camera compression paper" ID="ID_1790094004" CREATED="1692980239642" MODIFIED="1692980258012" LINK="https://www.researchgate.net/publication/368728037_Masked360_Enabling_Robust_360-degree_Video_Streaming_with_Ultra_Low_Bandwidth_Consumption"/>
</node>
<node TEXT="Interfaces and scaling" ID="ID_374396116" CREATED="1683561880356" MODIFIED="1683561930105">
<node TEXT="Distributed tech" ID="ID_708737994" CREATED="1683376326630" MODIFIED="1683376333628">
<node TEXT="horde image and llm" ID="ID_263265551" CREATED="1683376338267" MODIFIED="1683376347474" LINK="https://horde.koboldai.net/"/>
<node TEXT="Browser based whole models" ID="ID_1325909462" CREATED="1683559739378" MODIFIED="1683559754413">
<node TEXT="The Web LLM project has created a browser-based version of the vicuna-7b Large Language Model, which is impressively accurate and fast. The model is able to handle complex prompts and provide accurate responses, although it does sometimes make mistakes." ID="ID_21851450" CREATED="1682414608749" MODIFIED="1682417435672" LINK="https://simonwillison.net/2023/Apr/16/web-llm/"/>
</node>
<node TEXT="Nvidia DASK" ID="ID_263407999" CREATED="1683567059366" MODIFIED="1685195281008" LINK="https://developer.nvidia.com/blog/dask-tutorial-beginners-guide-to-distributed-computing-with-gpus-in-python/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="SWARM training paper" ID="ID_34639638" CREATED="1684168477137" MODIFIED="1684168484734" LINK="https://arxiv.org/pdf/2301.11913.pdf"/>
</node>
<node TEXT="immersive spaces" ID="ID_377797423" CREATED="1683561932952" MODIFIED="1683561939295">
<node TEXT="Why you should use now generative AI in your metaverse company. Or maybe not - The Ghost Howls https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/" ID="ID_760990156" CREATED="1679914078198" MODIFIED="1679914078198" LINK="https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/"/>
</node>
<node TEXT="games dev" ID="ID_1658429867" CREATED="1673131392584" MODIFIED="1673131399001" LINK="https://www.traffickinggame.com/ai-assisted-graphics/">
<node TEXT="Instant app from prompts" ID="ID_1980739576" CREATED="1680376902032" MODIFIED="1680614324142" LINK="https://twitter.com/ronithhh/status/1641318606549176321"/>
<node TEXT="endless runner without any coding experience" ID="ID_1002389436" CREATED="1680376902801" MODIFIED="1680621030542" LINK="https://replit.com/@asrsubs/SkyRoads-GPT-4"/>
</node>
<node TEXT="Edge (phone deployment on android)" ID="ID_866390978" CREATED="1683662086123" MODIFIED="1685195281009" LINK="https://github.com/mlc-ai/mlc-llm/tree/main/android">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Tree of thought github" ID="ID_986516760" CREATED="1685291842755" MODIFIED="1685291851938" LINK="https://github.com/ysymyth/tree-of-thought-llm"/>
<node TEXT="Scaling challenges paper" ID="ID_1666300489" CREATED="1689846881762" MODIFIED="1689846893236" LINK="https://arxiv.org/abs/2307.10169"/>
</node>
<node TEXT="Multi Modal" ID="ID_363962117" CREATED="1683561347232" MODIFIED="1683561350560">
<node TEXT="MultimodalC4 is a multimodal extension of c4 that interleaves millions of images with text. The corpus contains over a billion images, and the text is interleaved with the images to provide context." ID="ID_1687296850" CREATED="1682414608755" MODIFIED="1682417127802" LINK="https://github.com/allenai/mmc4"/>
<node TEXT="Otter with weights" ID="ID_52341876" CREATED="1686408996950" MODIFIED="1686409004440" LINK="https://otter-ntu.github.io/"/>
<node TEXT="MiniGPT local multimodal" ID="ID_1501452195" CREATED="1689844619535" MODIFIED="1689844632319" LINK="https://github.com/Vision-CAIR/MiniGPT-4"/>
</node>
<node TEXT="Multiligual and abstract translation" ID="ID_727305246" CREATED="1683561845935" MODIFIED="1683561857287">
<node TEXT="meta seamless M4T" ID="ID_1658940741" CREATED="1692791063241" MODIFIED="1692791106843" LINK="https://github.com/facebookresearch/seamless_communication#seamlessm4t"/>
</node>
<node TEXT="Optimisations" FOLDED="true" ID="ID_373136140" CREATED="1681557891627" MODIFIED="1681557976026">
<node TEXT="𝐃𝐞𝐞𝐩𝐒𝐩𝐞𝐞𝐝 is an easy-to-use deep learning optimization software suite that enables unprecedented scale and speed for DL Training and Inference. Visit us at deepspeed.ai or our Github repo.&#xa;&#xa;📌Megatron-LM GPT2 tutorial: https://lnkd.in/gXvPhXqb" ID="ID_631073983" CREATED="1680261768073" MODIFIED="1680261806998" LINK="https://github.com/microsoft/DeepSpeed"/>
<node TEXT="The text provides instructions on how to train your own large language models using Replit. It explains that you will need to first create a Replit account and then follow the instructions on the website." ID="ID_149938071" CREATED="1682414608759" MODIFIED="1682416858638" LINK="https://blog.replit.com/llm-training"/>
<node TEXT="Futurepedia is the largest AI tools directory, with over 700 tools in various categories. It is updated daily, and features search and filter options to help you find the right tool for your needs." ID="ID_825334210" CREATED="1682414608753" MODIFIED="1682417107608" LINK="http://Futurepedia.io"/>
<node TEXT="GitHub - gitnomad24601/ShogScript: ShogScript: The GitHub repository &quot;ShogScript&quot; contains a proof-of-concept pseudocode for GPT-4 AI interactions, ideal for storytelling &amp; communication. The code is released under the MIT license." ID="ID_367370764" CREATED="1682414608752" MODIFIED="1682416446848" LINK="https://github.com/gitnomad24601/ShogScript"/>
<node TEXT="Understanding Large Language Models: A Cross-Section of the Most Relevant Literature To Get Up to Speed" ID="ID_1483080227" CREATED="1682414608751" MODIFIED="1682414608751" LINK="https://magazine.sebastianraschka.com/p/understanding-large-language-models"/>
<node TEXT="The text describes a change to support the GPTQ triton commit c90adef. This change allows for the disabling of quant attention." ID="ID_1422987544" CREATED="1682414608749" MODIFIED="1682417415358" LINK="https://github.com/oobabooga/text-generation-webui/pull/1229"/>
<node TEXT="2000x performance improvement paper" ID="ID_1479417841" CREATED="1683485973583" MODIFIED="1683485995093" LINK="https://arxiv.org/abs/2305.02301"/>
<node TEXT="Flexgen" ID="ID_1549254676" CREATED="1677271333971" MODIFIED="1681557915217" LINK="https://github.com/FMInference/FlexGen#get-started-with-a-single-gpu"/>
<node TEXT="4bit compression" ID="ID_868731681" CREATED="1681557917976" MODIFIED="1681578385470" LINK="https://github.com/johnsmith0031/alpaca_lora_4bit"/>
<node TEXT="GPT4 self hallucination checking" ID="ID_1480858392" CREATED="1680097753096" MODIFIED="1680262316369" LINK="https://www.reddit.com/r/MachineLearning/comments/123b66w/dgpt4_might_be_able_to_tell_you_if_it_hallucinated/"/>
<node TEXT="Sparse LLM, half the size, all the power" ID="ID_100818082" CREATED="1679569662617" MODIFIED="1685195281009" LINK="https://arxiv.org/abs/2301.00774">
<icon BUILTIN="attach"/>
</node>
<node TEXT="SpQR lossless optimisation paper" ID="ID_1548807355" CREATED="1686558829116" MODIFIED="1686558841847" LINK="https://arxiv.org/abs/2306.03078"/>
<node TEXT="Landmark attention qlora oogabooga" ID="ID_690966547" CREATED="1686862073113" MODIFIED="1686862087932" LINK="https://github.com/eugenepentland/landmark-attention-qlora"/>
</node>
<node TEXT="Prompt engineering and injection" ID="ID_1395479167" CREATED="1682324941379" MODIFIED="1683562215114">
<node TEXT="Character injection" ID="ID_927086992" CREATED="1681579845764" MODIFIED="1685195281009">
<icon BUILTIN="attach"/>
<node TEXT="json builder" ID="ID_1159020214" CREATED="1681579853620" MODIFIED="1681579861898" LINK="https://oobabooga.github.io/character-creator.html"/>
<node TEXT="Huggingface commodity card retrainer" ID="ID_1702639814" CREATED="1681835485953" MODIFIED="1681835497519" LINK="https://huggingface.co/blog/trl-peft"/>
</node>
<node TEXT="Prompt model tips for learning" FOLDED="true" ID="ID_1637634156" CREATED="1682430872507" MODIFIED="1682430881571">
<node TEXT="1. Improve your writing by getting feedback." ID="ID_77161619" CREATED="1682430882194" MODIFIED="1682430882194"/>
<node TEXT="Use this prompt:" ID="ID_1952611428" CREATED="1682430882194" MODIFIED="1682430882194"/>
<node TEXT="[paste your writing]" ID="ID_1040255514" CREATED="1682430882195" MODIFIED="1682430882195"/>
<node TEXT="&quot;Proofread my writing above. Fix grammar and spelling mistakes. And make suggestions that will improve the clarity of my writing&quot;" ID="ID_1004868033" CREATED="1682430882198" MODIFIED="1682430882198"/>
<node TEXT="2. Use the 80/20 principle to learn faster than ever." ID="ID_320320683" CREATED="1682430882198" MODIFIED="1682430882198"/>
<node TEXT="&quot;I want to learn about [insert topic]. Identify and share the most important 20% of learnings from this topic that will help me understand 80% of it.&quot;" ID="ID_1184664032" CREATED="1682430882201" MODIFIED="1682430882201"/>
<node TEXT="3. Learn and develop any new skill." ID="ID_1037128610" CREATED="1682430882201" MODIFIED="1682430882201"/>
<node TEXT="&quot;I want to learn / get better at [insert desired skill]. I am a complete beginner. Create a 30 day learning plan that will help a beginner like me learn and improve this skill.&quot;" ID="ID_1373982329" CREATED="1682430882203" MODIFIED="1682430882203"/>
<node TEXT="4. Get short and insight-packed book summaries." ID="ID_432009692" CREATED="1682430882203" MODIFIED="1682430882203"/>
<node TEXT="&quot;Summarize the book [insert book] by the author [insert author] and give me a list of the most important learnings and insights.&quot;" ID="ID_243197678" CREATED="1682430882206" MODIFIED="1682430882206"/>
<node TEXT="5. Get feedback from history&apos;s greatest minds." ID="ID_1394640999" CREATED="1682430882206" MODIFIED="1682430882206"/>
<node TEXT="&quot;Assume you are [insert famous person e.g. Steve Jobs]. Read my argument below and give me feedback as if you were [insert person again]&quot;" ID="ID_1991254571" CREATED="1682430882210" MODIFIED="1682430882210"/>
<node TEXT="[insert your argument]" ID="ID_475436248" CREATED="1682430882210" MODIFIED="1682430882210"/>
<node TEXT="6. Enhance your problem solving skills." ID="ID_1961200524" CREATED="1682430882213" MODIFIED="1682430882213"/>
<node TEXT="&quot;Your role is that of a problem solver. Give me a step-by-step guide to solving [insert your problem].&quot;" ID="ID_1839848997" CREATED="1682430882214" MODIFIED="1682430882214"/>
<node TEXT="7. Generate new ideas and overcome writers block:" ID="ID_517336197" CREATED="1682430882215" MODIFIED="1682430882215"/>
<node TEXT="&quot;I am writing a blog post about [insert topic]. Give me an outline for this blog post with 10 bullet points. Also give me 5 options for a catchy headline.&quot;" ID="ID_1319816737" CREATED="1682430882216" MODIFIED="1682430882216"/>
<node TEXT="You can adapt this prompt for whatever you&apos;re writing." ID="ID_1762806184" CREATED="1682430882216" MODIFIED="1682430882216"/>
<node TEXT="8. Summarize long texts and accelerate your learning:" ID="ID_753403343" CREATED="1682430882217" MODIFIED="1682430882217"/>
<node TEXT="&quot;Summarize the text below into 500 words or less. Create sections for each important point with a brief summary of that point.&quot;" ID="ID_65853223" CREATED="1682430882217" MODIFIED="1682430882217"/>
<node TEXT="9. Use stories and metaphors to aid your memory." ID="ID_1324441562" CREATED="1682430882217" MODIFIED="1682430882217"/>
<node TEXT="&quot;I am currently learning about [insert topic]. Convert the key lessons from this topic into engaging stories and metaphors to aid my memorization.&quot;" ID="ID_44447628" CREATED="1682430882217" MODIFIED="1682430882217"/>
<node TEXT="10. Strengthen your learning by testing yourself." ID="ID_849000108" CREATED="1682430882219" MODIFIED="1682430882219"/>
<node TEXT="&quot;I am currently learning about [insert topic]. Ask me a series of questions that will test my knowledge. Identify knowledge gaps in my answers and give me better answers to fill those gaps.&quot;" ID="ID_29728542" CREATED="1682430882219" MODIFIED="1682430882219"/>
</node>
<node TEXT="Prompt injection: what s the worst that can happen?" ID="ID_277347965" CREATED="1682414608746" MODIFIED="1682417453311" LINK="https://simonwillison.net/2023/Apr/14/worst-that-can-happen/"/>
<node TEXT="To jailbreak ChatGPT, you need to get it to really do what you want. This can be done by editing the source code or by using a third-party tool." ID="ID_1000533100" CREATED="1682414608750" MODIFIED="1682416481590" LINK="https://www.digitaltrends.com/computing/how-to-jailbreak-chatgpt/"/>
<node TEXT="General purpose super short prompt" ID="ID_1439698005" CREATED="1683559681901" MODIFIED="1683559691178">
<node TEXT="develop+extend+support(ideas), vocab(wide+natural+sophisticated), grammar(wide+flexible), cohesion(logical+smooth), clarity(precise+concise), engagement(attention+interest), mood(objective+explanatory), viewpoint(forward_looking)" ID="ID_1989750619" CREATED="1682324945301" MODIFIED="1682324953735"/>
</node>
<node TEXT="Mollick methods post on linkedin" ID="ID_1732927307" CREATED="1690275411256" MODIFIED="1690275421768" LINK="https://www.linkedin.com/posts/emollick_there-are-now-three-research-backed-approaches-activity-7089472152701136896-aZNQ?utm_source=share&amp;utm_medium=member_desktop"/>
<node TEXT="Large Language Models are Human-Level Prompt Engineers: We propose an algorithm for automatic instruction generation and selection for large language models with human level performance." ID="ID_348526154" CREATED="1682414608736" MODIFIED="1682414608736" LINK="https://openreview.net/forum?id=92gvk82DE-"/>
<node TEXT="Using models to learn well, blog and paper" ID="ID_1832514653" CREATED="1685223341970" MODIFIED="1685223354782" LINK="https://www.oneusefulthing.org/p/how-to-use-ai-to-teach-some-of-the"/>
<node TEXT="Guide to prompting LLMs" ID="ID_1746723876" CREATED="1694274392725" MODIFIED="1694274401303" LINK="https://olickel.com/everything-i-know-about-prompting-llms"/>
</node>
<node TEXT="Training &amp; Finetuning" ID="ID_1991862736" CREATED="1681414382186" MODIFIED="1681557177943">
<node TEXT="Lora" ID="ID_173976426" CREATED="1681557466862" MODIFIED="1681557469307">
<node TEXT="alpaca lora training" ID="ID_1768150758" CREATED="1681415459772" MODIFIED="1681415468954" LINK="https://discord.com/channels/1086739839761776660/1087508281758584852">
<node TEXT="Github" ID="ID_1346643763" CREATED="1682670299980" MODIFIED="1682670303423" LINK="https://github.com/tloen/alpaca-lora"/>
</node>
<node TEXT="CPU offload lora training" ID="ID_1421633445" CREATED="1681511820388" MODIFIED="1681511863118" LINK="https://github.com/oobabooga/text-generation-webui/commit/09d8119e3cf36257496acfb44e6445a9f40c3d02"/>
<node TEXT="llamatard 4bit chat instructions" ID="ID_752510947" CREATED="1681574525270" MODIFIED="1681574540656" LINK="https://rentry.org/llama-tard-v2#llama-int8-4bit-chatbot-guide-v2"/>
<node TEXT="The text provides a guide on how to make your own Loras, which are easy and free to create. The process is described in detail, and the text includes instructions on how to create and customize your own Loras." ID="ID_1833067954" CREATED="1682414608721" MODIFIED="1685195281009" LINK="https://civitai.com/models/22530">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Deep retraining" ID="ID_1188865143" CREATED="1681557469823" MODIFIED="1681557474108">
<node TEXT="Deepspeed chat retraining in hours" ID="ID_426184641" CREATED="1681511334815" MODIFIED="1681511348337">
<node TEXT="microsoft just released a new finetuning pipeline&#xa;they finetuned a 65B model in 10 hours using RLHF" ID="ID_267268897" CREATED="1681511360127" MODIFIED="1681511361844"/>
</node>
<node TEXT="TRL - Transformer Reinforcement Learning" ID="ID_1570779161" CREATED="1678565709246" MODIFIED="1681557422140" LINK="https://github.com/lvwerra/trl"/>
<node TEXT="Hardware requirements for retraining (links to state of the art)" FOLDED="true" ID="ID_1344845712" CREATED="1681505081708" MODIFIED="1681505098834"/>
<node TEXT="Finetuning blog post" ID="ID_836473376" CREATED="1681414412201" MODIFIED="1685195281009" LINK="https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Pruning" ID="ID_1119718253" CREATED="1681574634211" MODIFIED="1681574639579">
<node TEXT="Seems that both 4 bit and straight up pruning don&apos;t harm the models much" ID="ID_480486781" CREATED="1681574640593" MODIFIED="1685195281009" LINK="https://arxiv.org/abs/1803.03635">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Merging" ID="ID_877283060" CREATED="1681557631084" MODIFIED="1681557633956">
<node TEXT="diffusion style LLM block merging" ID="ID_352799461" CREATED="1681142439544" MODIFIED="1685195281009" LINK="https://github.com/TehVenomm/LM_Transformers_BlockMerge">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Domain expert model merging" ID="ID_1785546658" CREATED="1681142413771" MODIFIED="1681142424842" LINK="https://docs.google.com/document/d/1JCzJ1wdBMBVwsFW4CWGUbX-YEDXB0yS4mfFbvwPLQrI/edit"/>
</node>
<node TEXT="Toolkits and distributed" ID="ID_1791946781" CREATED="1681578238837" MODIFIED="1681578250147">
<node TEXT="𝐌𝐞𝐬𝐡 𝐓𝐞𝐧𝐬𝐨𝐫𝐅𝐥𝐨𝐰 (mtf) is a language for distributed deep learning, capable of specifying a broad class of distributed tensor computations. The purpose of Mesh TensorFlow is to formalize and implement distribution strategies for your computation graph over your hardware/processors. For example: &quot;Split the batch over rows of processors and split the units in the hidden layer across columns of processors.&quot; Mesh TensorFlow is implemented as a layer over TensorFlow." ID="ID_17897871" CREATED="1680262089387" MODIFIED="1680262127354" LINK="https://github.com/tensorflow/mesh"/>
<node TEXT="𝐁𝐌𝐓𝐫𝐚𝐢𝐧 is an efficient large model training toolkit that can be used to train large models with tens of billions of parameters. It can train models in a distributed manner while keeping the code as simple as stand-alone training." ID="ID_1755531422" CREATED="1680262036033" MODIFIED="1680262063081" LINK="https://github.com/OpenBMB/BMTrain"/>
<node TEXT=" 𝐂𝐨𝐥𝐨𝐬𝐬𝐚𝐥-𝐀𝐈 provides a collection of parallel components for you. It aim to support us to write our distributed deep learning models just like how we write our model on our laptop. It provide user-friendly tools to kickstart distributed training and inference in a few lines.&#xa;📌Open source solution replicates ChatGPT training process.Ready to go with only 1.6GB GPU memory and gives you 7.73 times faster training: https://lnkd.in/gp4XTCnz" ID="ID_549010115" CREATED="1680261971283" MODIFIED="1680262003313" LINK="https://colossalai.org/"/>
<node TEXT="EasyLM one stop scaleable toolkit" ID="ID_1992553090" CREATED="1682017575471" MODIFIED="1685195281011" LINK="https://github.com/young-geng/EasyLM">
<icon BUILTIN="attach"/>
</node>
<node TEXT="databerry training and deployment" ID="ID_35460122" CREATED="1682348621689" MODIFIED="1682348641862" LINK="https://github.com/gmpetrov/databerry"/>
<node TEXT="Petals collaborative fine tuning" ID="ID_813232383" CREATED="1673111145236" MODIFIED="1685195281011" LINK="https://arxiv.org/abs/2209.01188">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Goodle openXLA training accelerator" ID="ID_1925584930" CREATED="1682670229675" MODIFIED="1682670250439" LINK="https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html"/>
</node>
<node TEXT="Adversarial and self instructed" ID="ID_235718066" CREATED="1683553223425" MODIFIED="1683553777953">
<node TEXT="Use GPT API as a GAN (twitter thread)" ID="ID_1126300086" CREATED="1681558264462" MODIFIED="1681558279118" LINK="https://twitter.com/BrianRoemmele/status/1637871062246649856"/>
<node TEXT="Bigscience petals run training through torrents" ID="ID_550447012" CREATED="1675000252678" MODIFIED="1681558381487" LINK="https://github.com/bigscience-workshop/petals"/>
<node TEXT="airoboros_a_rewrite_of_selfinstructalpaca/" ID="ID_155927082" CREATED="1683142427070" MODIFIED="1683142437193" LINK="https://www.reddit.com/r/MachineLearning/comments/136vt7b/p_airoboros_a_rewrite_of_selfinstructalpaca/"/>
<node TEXT="A Cookbook of Self-Supervised Learning" ID="ID_77514723" CREATED="1682428539874" MODIFIED="1683553273470" LINK="https://arxiv.org/abs/2304.12210"/>
</node>
<node TEXT="ChatLLaMA  is a library that allows you to create hyper-personalized ChatGPT-like assistants using your own data and the least amount of compute possible. Instead of depending on one large assistant that “rules us all”, we envision a future where each of us can create our own personalized version of ChatGPT-like assistants." ID="ID_385018660" CREATED="1678458103307" MODIFIED="1685195281011" LINK="https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Substack on retraining a 30B model in an A100" ID="ID_1422437379" CREATED="1681559276930" MODIFIED="1681559298414" LINK="https://abuqader.substack.com/p/releasing-alpaca-30b"/>
<node ID="ID_1865588141" CREATED="1680261663563" MODIFIED="1680261747817" LINK="https://github.com/alpa-projects/alpa"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <p>
      <font color="#000000">𝐀𝐥𝐩𝐚 is a system for training and serving large-scale neural networks. Scaling neural networks to hundreds of billions of parameters has enabled dramatic breakthroughs such as GPT-3, but training and serving these large-scale neural networks require complicated distributed system techniques. Alpa aims to automate large-scale distributed training and serving with just a few lines of code.</font>
    </p>
    <p>
      
    </p>
    <p>
      📌Alpa:
    </p>
    <p>
      📌Serving OPT-175B, BLOOM-176B and CodeGen-16B using Alpa: https://lnkd.in/g_ANHH6f
    </p>
  </body>
</html>
</richcontent>
</node>
<node TEXT="𝐌𝐞𝐠𝐚𝐭𝐫𝐨𝐧-𝐋𝐌 / Megatron is a large, powerful transformer developed by the Applied Deep Learning Research team at NVIDIA. Below repository is for ongoing research on training large transformer language models at scale. Developing efficient, model-parallel (tensor, sequence, and pipeline), and multi-node pre-training of transformer based models such as GPT, BERT, and T5 using mixed precision.&#xa;&#xa;📌pretrain_gpt3_175B.sh: https://lnkd.in/gFA9h8ns" ID="ID_548260222" CREATED="1680261832730" MODIFIED="1680261868764" LINK="https://github.com/NVIDIA/Megatron-LM"/>
<node TEXT="Koala paper on training with minimal noise for chatbots" ID="ID_1425120606" CREATED="1682672164921" MODIFIED="1685195281011" LINK="https://bair.berkeley.edu/blog/2023/04/03/koala/?ref=emergentmind">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Emmet twitter and github on fine tuning" ID="ID_1883022725" CREATED="1684054774132" MODIFIED="1684054802251" LINK="https://twitter.com/ehalm_/status/1652373239044112388"/>
<node TEXT="Ensure structured json" ID="ID_1941766125" CREATED="1684168599258" MODIFIED="1685195281011" LINK="https://github.com/1rgs/jsonformer">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Lora training guide from Pytorch lightning.ai people" ID="ID_992641545" CREATED="1684170361184" MODIFIED="1685195281011" LINK="https://lightning.ai/pages/community/tutorial/lora-llm/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="GPTQ paper code" ID="ID_1157299461" CREATED="1684485475019" MODIFIED="1684485484958" LINK="https://github.com/ist-daslab/gptq"/>
<node TEXT="Microsoft guidance" ID="ID_64445585" CREATED="1684775934286" MODIFIED="1685195281011" LINK="https://github.com/microsoft/guidance">
<icon BUILTIN="attach"/>
</node>
<node TEXT="QLoRA fast retraining of large models" ID="ID_1731667325" CREATED="1684955874811" MODIFIED="1685195281011" LINK="https://github.com/artidoro/qlora">
<icon BUILTIN="attach"/>
<node TEXT="paper" ID="ID_458479653" CREATED="1685187494400" MODIFIED="1685187501963" LINK="https://arxiv.org/pdf/2305.14314.pdf"/>
</node>
<node TEXT="Some kind of inscrutable training thing" ID="ID_1310469615" CREATED="1685130407077" MODIFIED="1685130426419" LINK="https://readthedocs.org/projects/alibi/downloads/pdf/latest/"/>
<node TEXT="Llama 2 training guide" ID="ID_1070730715" CREATED="1689766273224" MODIFIED="1689766282063" LINK="https://www.philschmid.de/sagemaker-llama2-qlora"/>
<node TEXT="RLHF cheap paper" ID="ID_1523274792" CREATED="1691186945558" MODIFIED="1691186967691" LINK="https://arxiv.org/pdf/2308.01320.pdf"/>
</node>
<node ID="ID_361241586" CREATED="1687805148704" MODIFIED="1689008802330" LINK="https://customgpt.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          CustomGPT is a platform that enables businesses to create their own chatbot using their own content, resulting in accurate responses without making up facts. The tool is designed to help businesses increase customer engagement and improve employee efficiency, ultimately leading to revenue growth and a competitive advantage. CustomGPT offers easy integration of content through seamless website integration or file uploading. The chatbot comes with various pricing plans, depending on the number of custom chatbots, content pages, and queries. The platform is trusted by global companies and customers, and it can be deployed for customer service, support helpdesk, and topic research. CustomGPT is powered by ChatGPT-4 and can be deployed through API or ChatGPT Plugins. The company offers a live demo and contact email for further inquiries. https://customgpt.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_230572796" CREATED="1687805148589" MODIFIED="1689009255345" LINK="https://blog.replit.com/llm-training"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The website replit.com has blocked your access due to the presence of potentially harmful actions, such as submitting a certain word or phrase, a SQL command or malformed data. This is a security measure to protect the website from online attacks. To resolve the issue, you can contact the site owner and provide details of the actions that caused the block and the Cloudflare Ray ID found at the bottom of the page. https://blog.replit.com/llm-training
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1530102706" CREATED="1687805148659" MODIFIED="1689009255345" LINK="https://nodepad.space/#"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NodePad is an LLM-assisted brainstorming experiment that helps users capture, expand, question, and organize their ideas visually. To create a new node, users simply write their thoughts in the input field and hit Enter. Nodes can be edited by double-clicking on them, linked through connectors, and deleted by clicking on them and hitting Backspace or Delete. Users can explore the app or consult the User Guide for further assistance. NodePad is designed for rapid note-taking and serendipitous ideation. https://nodepad.space/#
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Patterns for building LLMs blog post" ID="ID_1830358970" CREATED="1691324021374" MODIFIED="1691324035495" LINK="https://eugeneyan.com/writing/llm-patterns/"/>
<node TEXT="LLMs" ID="ID_1242751403" CREATED="1689008917362" MODIFIED="1689009255345">
<node ID="ID_758532406" CREATED="1687805148736" MODIFIED="1689008921467" LINK="https://github.com/Mintplex-Labs/anything-llm"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The AnythingLLM project is a full-stack application designed to allow users to turn any document or piece of content into reference data that can be used by any LLM during conversations. The application can be hosted remotely, but also supports local instances. It utilizes Pinecone, ChromaDB, and other vector storage solutions, as well as OpenAI for LLM and chatting capabilities. Documents are organized into workspaces, which function like threads and allow for context to be kept clean. The monorepo consists of three main sections: the collector, frontend, and server. Requirements include yarn, node, Python 3.8+, access to an LLM such as GPT-3.5 or GPT-4, and a free account with Pinecone.io. The Docker setup enables users to get started in minutes, and the development environment includes instructions for setting up the necessary .env files and collector scripts to embed content. The project is open source and contributors can create issues and pull requests following the designated format. https://github.com/Mintplex-Labs/anything-llm
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node ID="ID_323804640" CREATED="1687805149026" MODIFIED="1689009255345" LINK="https://nodepad.space/#"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          NodePad is a brainstorming tool that allows users to create nodes for their thoughts. Users can create new nodes by typing in the input field, and edit nodes by double-clicking on them. Nodes can be connected through connectors, and both nodes and connectors can be deleted by selecting and pressing Backspace or Delete. NodePad is an LLM-assisted brainstorming experiment that helps users capture, expand, question, and organize their ideas visually. The app offers a User Guide for assistance and is available for download through React Flow. https://nodepad.space/#
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1846529110" CREATED="1687805149107" MODIFIED="1689009255345" LINK="https://github.com/Mintplex-Labs/anything-llm"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          AnythingLLM is a full-stack personalized AI assistant application that allows users to turn any document or piece of content into a piece of data that can be used as reference when chatting. The application uses LLMs that can be hosted remotely or locally, and supports Pinecone, ChromaDB and more for vector storage and OpenAI for LLM chatting. AnythingLLM aims to be a full-stack application that can be run locally as well as hosted remotely and allows for intelligent chatting with any document provided to it. It divides documents into workspaces and provides simple UI-based tools to atomically manage the documents. There are two chat modes, conversation and query, and each chat response contains a citation that is linked to the original content. The monorepo consists of three main sections- collector, frontend and server, and requirements for the application include yarn and node on the user's machine, Python 3.8+ for running scripts in the collector, access to an LLM like GPT-3.5, GPT-4 or a drop-in replacement, and a Pinecone.io free account. https://github.com/Mintplex-Labs/anything-llm
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="This text provides instructions on how to run LLM-As-Chatbot in your cloud using dstack. The steps are as follows:  1. Install and set up dstack by running the command pip install dstack[aws,gcp,azure] -U and then dstack start to start the server.  2. Create a profile by creating a .dstack/profiles.yml file that points to your created project and describes the resources you need. Example:  ``` profiles:   - name: gcp     project: gcp     resources:       memory: 48GB       gpu:         memory: 24GB     default: true ```  3. Run the initialization command: dstack init.  4. Finally, use the dstack run . command to build the environment and run LLM-As-Chatbot in your cloud. dstack will automatically forward the port to your local machine, providing secure and convenient access.  The instructions emphasize the use of dstack to automate the provisioning of cloud resources and simplify the process of running LLM-As-Chatbot in the cloud. More information about dstack and its documentation can be found for further details. " ID="ID_347211622" CREATED="1688559432708" MODIFIED="1689009255345" LINK="https://github.com/dstackai/LLM-As-Chatbot/wiki/Running-LLM-As-Chatbot-in-your-cloud"/>
<node TEXT="This text describes a project called Simple LLM Finetuner, which is a user-friendly interface designed to facilitate fine-tuning various language models using the LoRA method via the PEFT library on NVIDIA GPUs. The interface allows users to easily manage their datasets, customize parameters, train the models, and evaluate their inference capabilities.   The project includes several features such as the ability to paste datasets directly into the UI, adjustable parameters for fine-tuning and inference, and a beginner-friendly interface with explanations for each parameter. It also provides instructions on how to get started, including prerequisites such as Linux or WSL, a modern NVIDIA GPU with at least 16 GB of VRAM, and the installation of required packages using a virtual environment.  To use the project, users are instructed to clone the repository and install the required packages. Then, they can launch the interface by running the app.py file and accessing it in a browser. They can input their training data, specify the PEFT adapter name, and start the training process. After training is complete, users can navigate to the Inference tab to perform inference using their trained models.  The project provides a YouTube walkthrough for additional guidance and is licensed under the MIT License.  Overall, the Simple LLM Finetuner project aims to simplify the process of fine-tuning language models using the LoRA method and provide a user-friendly interface for managing and evaluating models. " ID="ID_134759269" CREATED="1688559432708" MODIFIED="1689009255345" LINK="https://github.com/lxe/simple-llama-finetuner"/>
<node TEXT="Maverick is an AI-driven video marketing platform that helps ecommerce stores enhance customer interactions. By creating personalized videos for each customer, Maverick enables brands to build trust, improve brand perception, and increase customer satisfaction. The platform has been well-received by ecommerce brands, with users praising the personalized videos for their effectiveness in engaging with customers and increasing subscription enrollments.  Testimonials from merchants highlight the positive impact of Maverick on their businesses. Merchants have seen a significant increase in customer engagement, with over 100 email responses per week expressing gratitude for the personalized videos. This level of interaction helps strengthen customer relationships and loyalty.  Customers of these ecommerce brands have also expressed their appreciation for the personalized videos. They mention feeling valued and delighted by the direct communication from the brand, which sets the companies apart from others in the market. The personalized videos have made customers more loyal, with some even becoming lifetime members of the brands they previously patronized.  Overall, Maverick&apos;s AI-generated video marketing approach has proven to be a game changer for ecommerce brands. It enables personalized interactions with customers at scale, leading to increased customer satisfaction, brand loyalty, and reduced refund requests. The platform has received positive feedback from both merchants and their customers, highlighting the impact and success of Maverick in the ecommerce industry. " ID="ID_951286078" CREATED="1688559432712" MODIFIED="1689009255345" LINK="https://lnkd.in/eptCVijb"/>
<node TEXT="A Twitter user named Justin Alvey recently tweeted about advancements in artificial intelligence. He mentioned a tool called LLM chaining, which allows users to perform various tasks with emails. This tool was inspired by LangChainAI. Justin Alvey also noted that this functionality is now available in real-time, thanks to OpenAI&apos;s gpt-3.5-turbo model. The tweet has gained significant attention, with hundreds of thousands of views, retweets, likes, quotes, and bookmarks. " ID="ID_1246570642" CREATED="1688559432712" MODIFIED="1689009255345" LINK="https://twitter.com/justLV/status/1637876167763202053"/>
<node TEXT="The text is a LinkedIn post by Francesco Saverio Zuppichini, a Machine Learning Engineer, recommending resources to learn about Language Learning Models (LLMs).  The post includes a list of resources that Zuppichini recommended to a friend who wanted to quickly learn about LLMs. The recommended resources include academic papers, blogs, videos, and YouTube channels. Zuppichini also mentions the importance of training models with more data and for longer durations to achieve better results. He suggests looking at models like Vicuna and WizardLM, as well as different methods of prompting, such as chain of thoughts and tree of thoughts. Additionally, Zuppichini shares the LLM leaderboard from Hugging Face and encourages others to share any useful resources they may have. The post receives positive feedback from other LinkedIn users, who appreciate the resources and share their own suggestions. " ID="ID_12950985" CREATED="1688559432712" MODIFIED="1689009255345" LINK="https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=shareandutm_medium=member_android"/>
</node>
<node TEXT="Infosec, privacy, ethics, law, bias" ID="ID_1629206586" CREATED="1683561465973" MODIFIED="1693925852982">
<node TEXT="AI security considerations" ID="ID_36142615" CREATED="1670344163976" MODIFIED="1680614548372" LINK="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/"/>
<node TEXT="Sci-fi becomes real as renowned magazine closes submissions due to AI writers: Clarkesworld wrestles with flood of machine-made submissions—over 500 in Feb. alone." ID="ID_421400179" CREATED="1679913854633" MODIFIED="1679913854633" LINK="https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers/">
<node TEXT="The text discusses how a renowned magazine has had to close submissions due to the increasing number of AI writers. It is noted that the AI writers are becoming increasingly skilled and are starting to produce work that is on par with human writers." ID="ID_1736436140" CREATED="1679913854633" MODIFIED="1679913854633"/>
</node>
<node TEXT="Lesswrong AI section" ID="ID_1296351364" CREATED="1680206653526" MODIFIED="1680206660850" LINK="https://www.lesswrong.com/tag/ai"/>
<node TEXT="Goldman Sachs Predicts 300 Million Jobs Will Be Lost Or Degraded By Artificial Intelligence: Goldman Sachs maintains that if generative AI lives up to its hype, the workforce in the United States and Europe will be upended. The bank estimates 300 million jobs could be lost or diminished due to this fast-growing technology." ID="ID_268761052" CREATED="1682414608724" MODIFIED="1682414608724" LINK="https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=3af7314e782b"/>
<node TEXT="Medium listing approachs" ID="ID_240146489" CREATED="1674846802989" MODIFIED="1680614331826" LINK="https://blog.medium.com/how-were-approaching-ai-generated-writing-on-medium-16ee8cb3bc89"/>
<node TEXT="Drives us mad, Guardian" ID="ID_1409230680" CREATED="1680425810272" MODIFIED="1680614327449" LINK="https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane"/>
<node TEXT="Chatbots must disclose sources or face ban" ID="ID_791359780" CREATED="1682414608739" MODIFIED="1682418598310" LINK="https://www.artisana.ai/articles/eus-ai-act-stricter-rules-for-chatbots-on-the-horizon"/>
<node TEXT="Google and EU private deal" ID="ID_174243337" CREATED="1685002574983" MODIFIED="1685002582477" LINK="https://techcrunch.com/2023/05/24/eu-google-ai-pact/"/>
<node TEXT="How to structure an ML business" ID="ID_1473214045" CREATED="1685049205721" MODIFIED="1685195291623" LINK="https://txt.cohere.com/ai-is-eating-the-world/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Bias investigation" ID="ID_124549081" CREATED="1686338632493" MODIFIED="1686338641372" LINK="https://www.linkedin.com/feed/update/urn:li:activity:7072912582923173888/"/>
<node TEXT="GCHQ warning" ID="ID_266759914" CREATED="1686560806961" MODIFIED="1686560812334" LINK="https://www.ncsc.gov.uk/blog-post/chatgpt-and-large-language-models-whats-the-risk"/>
<node TEXT="Bias" ID="ID_1427049102" CREATED="1693925772934" MODIFIED="1693925785438">
<node TEXT="confusion matrices" ID="ID_51991586" CREATED="1693925804114" MODIFIED="1693925835925" LINK="https://en.wikipedia.org/wiki/Confusion_matrix"/>
</node>
</node>
<node TEXT="Specialist model use cases" ID="ID_660675883" CREATED="1682426813211" MODIFIED="1682426820770">
<node TEXT="Medical" ID="ID_861555502" CREATED="1682426821426" MODIFIED="1682426823445"/>
<node TEXT="Financial / tax" ID="ID_1397087121" CREATED="1682426823807" MODIFIED="1682426837717"/>
<node TEXT="Compliance" ID="ID_1784497341" CREATED="1682426838190" MODIFIED="1682426841704"/>
<node TEXT="Companionship" ID="ID_726580435" CREATED="1682426842117" MODIFIED="1682426846169"/>
<node TEXT="Travel" ID="ID_298549851" CREATED="1682426846547" MODIFIED="1682426850193"/>
<node TEXT="Law" ID="ID_819069260" CREATED="1682426850732" MODIFIED="1682428755048"/>
<node TEXT="Programming" ID="ID_1903294143" CREATED="1682428755800" MODIFIED="1682428763986"/>
<node TEXT="Copywriting" ID="ID_1066827777" CREATED="1682428765643" MODIFIED="1682428769235"/>
<node TEXT="Editorial" ID="ID_367831203" CREATED="1682428769436" MODIFIED="1682428772338"/>
</node>
<node TEXT="Segment and identify" ID="ID_817591463" CREATED="1683308329450" MODIFIED="1687344506070">
<font SIZE="9"/>
<node TEXT="Segment anything from Meta" ID="ID_1406655485" CREATED="1680722224752" MODIFIED="1685195298068" LINK="https://segment-anything.com/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="YOLO detect anything" ID="ID_1912237259" CREATED="1683308294196" MODIFIED="1685195298069" LINK="https://deci.ai/blog/yolo-nas-foundation-model-object-detection/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Trainable segment anything (useful for museum collections?)" ID="ID_286958507" CREATED="1685463785077" MODIFIED="1685463802250" LINK="https://huggingface.co/docs/transformers/main/model_doc/sam"/>
<node TEXT="Segment Anything, which can &quot;cut out&quot; any object in any image or video with a single click. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks." ID="ID_1653356852" CREATED="1682414608725" MODIFIED="1682415404704" LINK="https://www.linkedin.com/posts/eric-vyacheslav-156273169_big-news-meta-just-released-segment-anything-activity-7049409700370554880-tStk?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="This repository contains code for the Painter and SegGPT models from the BAAI Vision Foundation. These models are designed for in-context visual learning, and can be used to segment images and generate descriptions of them." ID="ID_185766752" CREATED="1682414608730" MODIFIED="1682415507829" LINK="http://github.com/baaivision/Painter"/>
<node TEXT="The text presents SegGPT, a generalist model for segmenting everything in context. The model is trained to unify various segmentation tasks into a generalist in-context learning framework, and is evaluated on a broad range of tasks, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation. Results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively." ID="ID_1796180074" CREATED="1682414608735" MODIFIED="1682416255213" LINK="https://buff.ly/3KD0Zns"/>
<node ID="ID_45937939" CREATED="1687805148760" MODIFIED="1687805148760" LINK="https://github.com/DAMO-NLP-SG/Video-LLaMA"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Video-LLaMA is a project aimed at enhancing large language models (LLMs) with audio and visual understanding capabilities. It is built on top of BLIP-2 and MiniGPT-4 and consists of two core components: Vision-Language (VL) Branch and Audio-Language (AL) Branch. The VL Branch uses a two-layer video Q-Former and a frame embedding layer to compute video representations and is trained on the Webvid-2M video caption dataset with a video-to-text generation task, in addition to image-text pairs from LLaVA. The AL Branch, on the other hand, uses a two-layer audio Q-Former and an audio segment embedding layer to compute audio representations and is trained on video/image instrucaption data to connect the output of ImageBind to language decoder. The project provides pre-trained and fine-tuned checkpoints and users need to obtain them before using the repository. The repository also includes an example output and instructions on how to run the demo locally and how to perform the training. The project has been released under the BSD-3-Clause license. https://github.com/DAMO-NLP-SG/Video-LLaMA
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Incredibly stable depth estimation from adobe" ID="ID_1007347709" CREATED="1689760797531" MODIFIED="1689760819329" LINK="https://github.com/RaymondWang987/NVDS"/>
<node TEXT="Holistic segment unknowns" ID="ID_834677729" CREATED="1693245273963" MODIFIED="1693245285182" LINK="https://holisticseg.github.io/"/>
<node TEXT="Beyond bounding boxes" ID="ID_578858340" CREATED="1694341046494" MODIFIED="1694341053747" LINK="https://faromero.substack.com/p/video-analysis-beyond-bounding-boxes"/>
<node TEXT="Video to dataset (LAION)" ID="ID_644473050" CREATED="1694341447881" MODIFIED="1694341456530" LINK="https://laion.ai/blog/video2dataset/"/>
</node>
<node TEXT="Frameworks and stacks" ID="ID_390357635" CREATED="1688307602777" MODIFIED="1688307627114">
<node TEXT="tinygrad" ID="ID_1419157475" CREATED="1688307628140" MODIFIED="1688307637967" LINK="https://github.com/geohot/tinygrad"/>
<node TEXT="MOJO from modular compiled python" ID="ID_544513952" CREATED="1687850050868" MODIFIED="1687850068701" LINK="https://docs.modular.com/mojo/"/>
<node TEXT="Streamlit and OpenAI blog series" ID="ID_1158487661" CREATED="1688376349125" MODIFIED="1688376358051" LINK="https://contentevolvedai.com/openai-api-streamlit-python-short-stories/"/>
</node>
</node>
<node TEXT="Mixed reality, spatial, metaverse and telecollaboration" FOLDED="true" POSITION="left" ID="ID_584975900" CREATED="1664902506349" MODIFIED="1689878271152">
<edge COLOR="#00ff00"/>
<node TEXT="Graphics stuff" ID="ID_1063077439" CREATED="1665299847269" MODIFIED="1665299852195">
<node TEXT="Roblox" ID="ID_60371915" CREATED="1664902991727" MODIFIED="1664902994819">
<node TEXT="Campus" ID="ID_1633913075" CREATED="1664902996505" MODIFIED="1664903001830" LINK="https://techcrunch-com.cdn.ampproject.org/c/s/techcrunch.com/2022/09/09/roblox-rdc-2022/amp/"/>
</node>
<node TEXT="Vircadia" ID="ID_1390151772" CREATED="1674927944471" MODIFIED="1674927949740"/>
<node TEXT="O3DE" ID="ID_1186746626" CREATED="1674927950735" MODIFIED="1674927960791">
<node TEXT="server" ID="ID_627692250" CREATED="1674927962482" MODIFIED="1674927965463" LINK="https://www.reddit.com/r/O3DE/comments/pbovl9/can_i_develop_my_own_dedicated_server_with_o3de/"/>
<node TEXT="Global lighting" ID="ID_1422945071" CREATED="1674929257978" MODIFIED="1674929262983" LINK="https://www.co3dex.com/blog/image-based-lighting-1/#/"/>
</node>
<node TEXT="Unreal" ID="ID_721713037" CREATED="1665299878412" MODIFIED="1665299880975"/>
<node TEXT="Technically this might be a decade away since like everything the primay user base will be mobile mixed realitym, which is contingent on 5G" ID="ID_1877390377" CREATED="1670851262626" MODIFIED="1670851418500" LINK="https://www.matthewball.vc/all/forwardtothemetaverseprimer">
<node TEXT="book, the metaverse and how it will revolutise everything" ID="ID_1294664741" CREATED="1670851472552" MODIFIED="1670851487510"/>
<node TEXT="ball2022metaverse" ID="ID_1038385450" CREATED="1670851491631" MODIFIED="1670851493304"/>
<node TEXT="challenges" ID="ID_498619502" CREATED="1670852221306" MODIFIED="1670852225845">
<node TEXT="bandwidth" ID="ID_827938896" CREATED="1670852226413" MODIFIED="1670852229737"/>
<node TEXT="latency" ID="ID_1313445724" CREATED="1670852230073" MODIFIED="1670852232055"/>
<node TEXT="global shared truth" ID="ID_1834010353" CREATED="1670852232379" MODIFIED="1670852239389"/>
<node TEXT="form factor" ID="ID_490064908" CREATED="1670852239786" MODIFIED="1670852247782"/>
<node TEXT="gpu processing" ID="ID_497735380" CREATED="1670852248806" MODIFIED="1670852258945"/>
</node>
</node>
</node>
<node TEXT="Hardware" ID="ID_152183139" CREATED="1674847440316" MODIFIED="1680620345963">
<node TEXT="the many challenges of XR hardware" ID="ID_1799317256" CREATED="1674847444526" MODIFIED="1674847459741" LINK="https://www.matthewball.vc/all/why-vrar-gets-farther-away-as-it-comes-into-focus"/>
</node>
<node TEXT="HCI" ID="ID_1859862476" CREATED="1664904578154" MODIFIED="1664904580132">
<node TEXT="MoveAI" ID="ID_1050867697" CREATED="1664904666552" MODIFIED="1664904669020"/>
<node TEXT="Meta&apos;s wrist reader" ID="ID_1781965623" CREATED="1664904581381" MODIFIED="1664904594684" LINK="https://www.from-the-interface.com/wrist-interfaces/"/>
<node TEXT="Touch music interface" ID="ID_1941149748" CREATED="1669817314245" MODIFIED="1669817322073" LINK="https://scitechdaily.com/groundbreaking-new-technology-allows-people-to-listen-to-music-through-touch/"/>
<node TEXT="Interface and tracking" ID="ID_1864466123" CREATED="1665384233923" MODIFIED="1665384240374">
<node TEXT="Pose estimations" ID="ID_1112826190" CREATED="1665384242008" MODIFIED="1665384247274">
<node TEXT="Standable" ID="ID_500860965" CREATED="1665384251558" MODIFIED="1665384260273" LINK="https://www.standablevr.com/"/>
</node>
<node TEXT="Dense face fields from Microsoft" ID="ID_1149310948" CREATED="1667336958261" MODIFIED="1667336972620" LINK="https://microsoft.github.io/DenseLandmarks/"/>
</node>
<node TEXT="Viveverse web3 nonsense" ID="ID_1821629589" CREATED="1673872543981" MODIFIED="1673872552772"/>
<node TEXT="Meetungs ARE the work" ID="ID_1110878532" CREATED="1678117286171" MODIFIED="1678117296182" LINK="https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3"/>
</node>
<node TEXT="Identity" ID="ID_941226008" CREATED="1673877160842" MODIFIED="1673877163254">
<node TEXT="Strongnode identity article on venturebeat" ID="ID_1010307996" CREATED="1673877199990" MODIFIED="1673877215582" LINK="https://venturebeat.com/virtual/identity-in-the-metaverse-creating-a-global-identity-system/"/>
</node>
<node TEXT="legal / governance / privacy / safeguarding" ID="ID_933513294" CREATED="1670849698910" MODIFIED="1680620356958">
<node TEXT="legal jeopardy for celebrities" ID="ID_603733201" CREATED="1670849609694" MODIFIED="1670849736261"/>
<node TEXT="Gang sexual assault vice article" ID="ID_856591653" CREATED="1673893345446" MODIFIED="1673893393558" LINK="https://www.vice.com/en/article/3abpg3/woman-says-she-was-virtually-gang-raped-in-facebooks-metaverse?"/>
<node TEXT="not enough training on safety in africa" ID="ID_392536483" CREATED="1673893544425" MODIFIED="1673893554359" LINK="https://www.thecable.ng/safeguarding-africans-safety-and-freedom-in-the-metaverse/amp"/>
<node TEXT="How Regulation Will Apply To The Metaverse" ID="ID_152404157" CREATED="1678456070581" MODIFIED="1678456280182" LINK="https://www.forbes.com/sites/nisaamoils/2023/03/01/how-regulation-will-apply-to-the-metaverse/?"/>
<node TEXT="Podcast on the law" ID="ID_1253704375" CREATED="1682431016873" MODIFIED="1682431026540" LINK="https://www.reply.com/en/metaminutes-s3-e5-legal-challenges-and-regulation-for-the-metaverse"/>
<node TEXT="AI safety" ID="ID_20130259" CREATED="1690880503168" MODIFIED="1690880508149">
<node TEXT="dai.ki blog post" ID="ID_6121620" CREATED="1690880508770" MODIFIED="1690880519937" LINK="https://dai.ki/navigating-ai-governance-a-comprehensive-look-at-existing-and-new-eu-and-us-ai-regulations/"/>
</node>
</node>
<node TEXT="Librefold vertical" ID="ID_816778219" CREATED="1667856054446" MODIFIED="1680620360940">
<node TEXT="NGL protein fold model viewer" ID="ID_1215779429" CREATED="1667856061942" MODIFIED="1667856077604" LINK="https://github.com/nglviewer/ngl"/>
<node TEXT="OpenBioML discord" ID="ID_1427566116" CREATED="1667856108802" MODIFIED="1667856134749" LINK="discord.gg/AMRdyPjwBb"/>
<node TEXT="Nanome on quest pro" ID="ID_598912297" CREATED="1667856157801" MODIFIED="1667856165895" LINK="https://www.youtube.com/watch?v=Q-V5EQ-FBMc"/>
<node TEXT="Openfold github" ID="ID_1196634716" CREATED="1667856218553" MODIFIED="1667856224218" LINK="https://github.com/aqlaboratory/openfold"/>
<node TEXT="Pymol2 open source visualisation" ID="ID_1121616713" CREATED="1667856414947" MODIFIED="1667856499855" LINK="https://github.com/schrodinger/pymol-open-source"/>
<node TEXT="Alphafold OpenAI" ID="ID_917809191" CREATED="1668072629723" MODIFIED="1668072641508">
<node TEXT="" ID="ID_530166233" CREATED="1668072643613" MODIFIED="1668072643613"/>
</node>
<node TEXT="Biological structure diffusion" ID="ID_1122723604" CREATED="1680510364119" MODIFIED="1680593220641" LINK="https://github.com/RosettaCommons/RFdiffusion">
<node TEXT="The RFdiffusion code allows for the running of RFdiffusion simulations. The code is written in Python and is available on GitHub. The code includes a number of features, such as the ability to run simulations on multiple processors and the ability to output results in a variety of formats." ID="ID_1412059902" CREATED="1680510364119" MODIFIED="1680510364119"/>
</node>
<node TEXT="Diagnostics" ID="ID_816780075" CREATED="1681123036079" MODIFIED="1681123042384" LINK="https://www.amazon.co.uk/AI-Revolution-Medicine-GPT-4-Beyond/dp/0138200130"/>
</node>
<node TEXT="Market research" ID="ID_385608709" CREATED="1673880567844" MODIFIED="1673880572758">
<node TEXT="Addidas" ID="ID_347023436" CREATED="1673880579251" MODIFIED="1673880583806" LINK="https://www.adidas.com/into_the_metaverse/mint"/>
<node TEXT="Bubblepunk interiors ML art" ID="ID_1921372100" CREATED="1673880613445" MODIFIED="1673880632113" LINK="https://www.bubblepunk.io/bubblepunk-interiors"/>
<node TEXT="What is a chief metaverse officer (bloomberg)" ID="ID_1453254589" CREATED="1673880654671" MODIFIED="1673880668343" LINK="https://www.bloomberg.com/news/articles/2022-09-22/what-is-a-chief-metaverse-officer-and-do-you-need-one"/>
<node TEXT="Userbase struggles (coindesk)" ID="ID_1217125442" CREATED="1673880696625" MODIFIED="1673880785768" LINK="https://www.coindesk.com/markets/2022/04/06/metaverse-majors-struggle-as-user-base-falls-short-of-market-expectations/?outputType=amp"/>
<node TEXT="Protecting Brands in the Metaverse’s Uncertain Legal Landscape" ID="ID_1648930356" CREATED="1672672974132" MODIFIED="1673880767683" LINK="https://wwd.com/business-news/technology/metaverse-lawsuit-nike-stockx-hermes-metabirken-fashion-1235247763/"/>
<node TEXT="Market research global impact" ID="ID_156822779" CREATED="1673881407216" MODIFIED="1673881416207" LINK="https://www.analysisgroup.com/globalassets/insights/publishing/2022-the-potential-global-economic-impact-of-the-metaverse.pdf"/>
<node TEXT="McDonalds in the metaverse" ID="ID_608579008" CREATED="1673884608561" MODIFIED="1673884614970" LINK="https://www.businessinsider.com/mcdonalds-metaverse-virtual-online-restaurant-trademark-delivers-food-web3-nft-2022-2"/>
<node TEXT="Universal music metaverse / web3 team" ID="ID_47898693" CREATED="1673906905817" MODIFIED="1673906916122" LINK="https://www.musicweek.com/labels/read/universal-music-group-s-digital-strategy-team-creates-key-roles-for-web3-and-the-metaverse/087103"/>
</node>
<node TEXT="Narratives and convergence" ID="ID_232114366" CREATED="1670850546404" MODIFIED="1670850556529">
<node TEXT="With the help of generative AI it may be possible to democratise the externalisation of complex narratives, with these new narratives shaping the outcomes of society through the medium of the metaverse" ID="ID_411249299" CREATED="1670850559904" MODIFIED="1685195453870" LINK="https://www.epsilontheory.com/narrative-and-metaverse-pt-3-the-luther-protocol/#.YjyHbnLIE5k.twitter">
<icon BUILTIN="attach"/>
</node>
<node TEXT="A lot of metaverse recently has just been convergence as companies take their existing simulation and repackage it for the moment." ID="ID_1809036187" CREATED="1670850701915" MODIFIED="1680620384575" LINK="https://thedriven.io/2022/05/23/nissan-and-mitsubishi-unveil-electric-mini-vehicles-and-test-drives-in-metaverse/"/>
<node TEXT="Games is the main convergence: from globalblock &quot;&quot;More companies are entering the metaverse as global electronics giant Sony has announced their own metaverse push in the latest annual corporate strategy meeting. Sony said this will be a more focused approach, as they aim to use metaverse-inspired experiences to engage users. As Sony owns PlayStation Brands, one of the biggest install userbases in the world, they are in an amazing position to make an impact. They have also revealed that prior investments in Epic, makers of the Fortnite game, and Bungie, another gaming studio, are part of this push.&quot;" ID="ID_1130122036" CREATED="1670851661519" MODIFIED="1670851685323">
<node TEXT="" ID="ID_574885320" CREATED="1670851674615" MODIFIED="1670851674615"/>
</node>
<node TEXT="Epsilomn theory thesis on metaverse" ID="ID_1822623983" CREATED="1673884666843" MODIFIED="1680620373115" LINK="https://www.epsilontheory.com/narrative-and-metaverse-pt-3-the-luther-protocol/#.YjyHbnLIE5k.twitter"/>
<node TEXT="Epic games programming language for the metaverse" ID="ID_51366861" CREATED="1673884721759" MODIFIED="1685195453870" LINK="https://www.geekmetaverse.com/epic-games-launches-verse-the-metaverse-programming-language/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Fortnite is the metaverse" ID="ID_1389744907" CREATED="1673884950970" MODIFIED="1673884958571" LINK="https://www.ign.com/articles/how-fortnite-is-the-antidote-to-metaverse-skepticism">
<node TEXT="epic unreal for fortnite" ID="ID_718255363" CREATED="1679747368739" MODIFIED="1685195453870" LINK="https://store.epicgames.com/en-US/p/fortnite--uefn?">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Why you should use now generative AI in your metaverse company. Or maybe not - The Ghost Howls https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/" ID="ID_1333945010" CREATED="1677086422722" MODIFIED="1677086422722" LINK="https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/"/>
<node TEXT="BlackRock digs further into crypto with metaverse ETF https://financefeeds.com/blackrock-digs-further-into-crypto-with-metaverse-etf/" ID="ID_1783469331" CREATED="1672672974096" MODIFIED="1672672974096" LINK="https://financefeeds.com/blackrock-digs-further-into-crypto-with-metaverse-etf/"/>
<node TEXT="China’s iPhone production hub of Henan bets its future on the metaverse | South China Morning Post https://www.scmp.com/tech/policy/article/3194092/chinas-iphone-production-hub-henan-bets-its-future-metaverse" ID="ID_1630843144" CREATED="1672672974099" MODIFIED="1672672974099" LINK="https://www.scmp.com/tech/policy/article/3194092/chinas-iphone-production-hub-henan-bets-its-future-metaverse"/>
<node TEXT="Cutting Through the Hotel Hype of the Blockchain, Web3 and the Metaverse | https://hoteltechnologynews.com/2022/08/cutting-through-the-hotel-hype-of-the-blockchain-web3-and-the-metaverse/" ID="ID_852602347" CREATED="1672672974118" MODIFIED="1672672974118" LINK="https://hoteltechnologynews.com/2022/08/cutting-through-the-hotel-hype-of-the-blockchain-web3-and-the-metaverse/"/>
<node TEXT="Experts highlight trust and safety practices for the metaverse https://www.techtarget.com/searchcio/news/252525336/Experts-highlight-trust-and-safety-practices-for-the-metaverse" ID="ID_85891301" CREATED="1672672974103" MODIFIED="1672672974103" LINK="https://www.techtarget.com/searchcio/news/252525336/Experts-highlight-trust-and-safety-practices-for-the-metaverse"/>
<node TEXT="Global Metaverse Market Analysis Report 2022: Blockchain https://www.globenewswire.com/news-release/2022/08/30/2506629/0/en/Global-Metaverse-Market-Analysis-Report-2022-Blockchain-Solutions-in-Support-of-the-Metaverse-Market-will-Reach-148-6-Billion-by-2027.html" ID="ID_1149282127" CREATED="1672672974111" MODIFIED="1672672974111" LINK="https://www.globenewswire.com/news-release/2022/08/30/2506629/0/en/Global-Metaverse-Market-Analysis-Report-2022-Blockchain-Solutions-in-Support-of-the-Metaverse-Market-will-Reach-148-6-Billion-by-2027.html"/>
<node TEXT="Identity Management Institute Launches the Metaverse Security Center and Certified Metaverse Security Consultant (CMSC)™ Certification https://www.prnewswire.com/news-releases/identity-management-institute-launches-the-metaverse-security-center-and-certified-metaverse-security-consultant-cmsc-certification-301689276.html" ID="ID_1321152706" CREATED="1672672974076" MODIFIED="1672672974076" LINK="https://www.prnewswire.com/news-releases/identity-management-institute-launches-the-metaverse-security-center-and-certified-metaverse-security-consultant-cmsc-certification-301689276.html"/>
<node TEXT="Is the metaverse good for business? Why blending the virtual and the real remains a matter of much debate | Fortune https://fortune.com/2022/07/13/business-metaverse-dropbox-brainstorm-tech/" ID="ID_1319401390" CREATED="1672672974132" MODIFIED="1672672974132" LINK="https://fortune.com/2022/07/13/business-metaverse-dropbox-brainstorm-tech/"/>
<node TEXT="Laws and Issues in the Metaverse (2) - Lexology https://www.lexology.com/library/detail.aspx?g=5a0cc4c0-a876-474e-a719-f528b71b68ee" ID="ID_1039873001" CREATED="1672672974128" MODIFIED="1680620393090" LINK="https://www.lexology.com/library/detail.aspx?g=5a0cc4c0-a876-474e-a719-f528b71b68ee"/>
<node TEXT="Laying the Foundation of the Metaverse, Streaming Video, Social, Gaming, and Broader Digital Advertising Markets to Collectively Clear US$2 Trillion by 2030 https://www.abiresearch.com/press/laying-the-foundation-of-the-metaverse-streaming-video-social-gaming-and-broader-digital-advertising-markets-to-collectively-clear-us2-trillion-by-2030/" ID="ID_681455567" CREATED="1672672974130" MODIFIED="1672672974130" LINK="https://www.abiresearch.com/press/laying-the-foundation-of-the-metaverse-streaming-video-social-gaming-and-broader-digital-advertising-markets-to-collectively-clear-us2-trillion-by-2030/"/>
<node TEXT="Major crypto exchange announces its arrival in the metaverse https://cointelegraph.com/news/major-crypto-exchange-announces-its-arrival-in-the-metaverse" ID="ID_505579475" CREATED="1672672974122" MODIFIED="1672672974122" LINK="https://cointelegraph.com/news/major-crypto-exchange-announces-its-arrival-in-the-metaverse"/>
<node TEXT="Metaverse exploitation and abuse to rise in 2023: Kaspersky https://cointelegraph.com/news/metaverse-exploitation-and-abuse-to-rise-in-2023-kaspersky" ID="ID_102501784" CREATED="1672672974078" MODIFIED="1680620398470" LINK="https://cointelegraph.com/news/metaverse-exploitation-and-abuse-to-rise-in-2023-kaspersky"/>
<node TEXT="Metaverse Market Size, Share &amp; Industry Report 2020-2030 https://www.strategicmarketresearch.com/market-report/metaverse-market" ID="ID_1471963766" CREATED="1672672974136" MODIFIED="1672672974136" LINK="https://www.strategicmarketresearch.com/market-report/metaverse-market"/>
<node TEXT="Metaverse Real Estate Gets Reality Check https://therealdeal.com/2022/08/04/metaverse-real-estate-gets-reality-check/" ID="ID_585957710" CREATED="1672672974124" MODIFIED="1672672974124" LINK="https://therealdeal.com/2022/08/04/metaverse-real-estate-gets-reality-check/"/>
<node TEXT="Nissan and Mitsubishi unveil electric mini vehicles, and test drives in metaverse https://thedriven.io/2022/05/23/nissan-and-mitsubishi-unveil-electric-mini-vehicles-and-test-drives-in-metaverse/" ID="ID_1068106282" CREATED="1672672974146" MODIFIED="1672672974146" LINK="https://thedriven.io/2022/05/23/nissan-and-mitsubishi-unveil-electric-mini-vehicles-and-test-drives-in-metaverse/"/>
<node TEXT="Nvidia Sees a Metaverse Populated With Lifelike Chatbot Avatars - CNET https://www.cnet.com/tech/computing/nvidia-sees-a-metaverse-populated-with-lifelike-chatbot-avatars/" ID="ID_203788198" CREATED="1672672974117" MODIFIED="1680620405940" LINK="https://www.cnet.com/tech/computing/nvidia-sees-a-metaverse-populated-with-lifelike-chatbot-avatars/"/>
<node TEXT="&apos;Room&apos; Offers a Non-Facebook Way to Connect Coworkers in the Metaverse https://uk.pcmag.com/vr-1/143198/room-offers-a-non-facebook-way-to-connect-coworkers-in-the-metaverse" ID="ID_1339123486" CREATED="1672672974087" MODIFIED="1672672974087" LINK="https://uk.pcmag.com/vr-1/143198/room-offers-a-non-facebook-way-to-connect-coworkers-in-the-metaverse"/>
<node TEXT="The Architecture of the Metaverse (So Far) | ArchDaily https://www.archdaily.com/988639/the-architecture-of-the-metaverse-so-far" ID="ID_863268651" CREATED="1672672974104" MODIFIED="1680620409934" LINK="https://www.archdaily.com/988639/the-architecture-of-the-metaverse-so-far"/>
<node TEXT="The battle to build a child-friendly metaverse | Tech News https://tech.hindustantimes.com/tech/news/the-battle-to-build-a-child-friendly-metaverse-71655616713236.html" ID="ID_1712846200" CREATED="1672672974134" MODIFIED="1680620413212" LINK="https://tech.hindustantimes.com/tech/news/the-battle-to-build-a-child-friendly-metaverse-71655616713236.html"/>
<node TEXT="The Metaverse Casino That Wasn’t https://www.coindesk.com/layer2/sinweek/2022/08/29/the-metaverse-casino-that-wasnt/" ID="ID_719137920" CREATED="1672672974112" MODIFIED="1672672974112" LINK="https://www.coindesk.com/layer2/sinweek/2022/08/29/the-metaverse-casino-that-wasnt/"/>
<node TEXT="The World&apos;s First Virtual Reality Avatar Fashion Week Is On The Metaverse This Week https://womenlovetech.com/the-worlds-first-virtual-reality-avatar-fashion-week-is-on-the-metaverse-this-week/" ID="ID_1078019682" CREATED="1672672974105" MODIFIED="1672672974105" LINK="https://womenlovetech.com/the-worlds-first-virtual-reality-avatar-fashion-week-is-on-the-metaverse-this-week/"/>
<node TEXT="Top 10 Metaverse Platforms that will Replace Social Media in Future https://www.analyticsinsight.net/top-10-metaverse-platforms-that-will-replace-social-media-in-future/" ID="ID_443767142" CREATED="1672672974142" MODIFIED="1672672974142" LINK="https://www.analyticsinsight.net/top-10-metaverse-platforms-that-will-replace-social-media-in-future/"/>
<node TEXT="Top 15 Metaverse Companies To Watch Out For !! https://www.cryptotimes.io/top-15-metaverse-companies-to-watch-out-for/" ID="ID_859877978" CREATED="1672672974127" MODIFIED="1672672974127" LINK="https://www.cryptotimes.io/top-15-metaverse-companies-to-watch-out-for/"/>
<node TEXT="We&apos;re Ready for the Metaverse but the Technology Is Not. Here&apos;s Why. - Decrypt https://decrypt.co/100781/were-ready-for-the-metaverse-but-the-technology-is-not-heres-why" ID="ID_1131955202" CREATED="1672672974144" MODIFIED="1672672974144" LINK="https://decrypt.co/100781/were-ready-for-the-metaverse-but-the-technology-is-not-heres-why"/>
<node TEXT="The Photorealistic Metaverse | Welcome to Cornerstone, Cornerstone is a gamified metaverse experience distributed to you via the web browser. Create, co-develop, and monetize your creative idea in the new digital realm.  " ID="ID_3379494" CREATED="1677783034638" MODIFIED="1680620420488" LINK="https://cornerstone.land/"/>
<node TEXT=" Mega Yacht Sold for $650,000 in Metaverse, Becomes Most-Expensive NFT in Sandbox Virtual World | Technology News , A mega yacht has been sold for a whopping $650,000 (roughly Rs. 4.8 crore) in the Sandbox virtual gaming world. The pricey digital asset was released by metaverse developer Republic Realm as part of a luxury NFT series.  " ID="ID_440240321" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://gadgets.ndtv.com/cryptocurrency/news/mega-yacht-sold-usd-650000-metaverse-most-expensive-nft-sandbox-virtual-world-2630187"/>
<node TEXT="Facebook whistleblower warns Metaverse will repeat ‘all the harms’,Frances Haugen says she is worried about privacy and safety inside Meta’s impending Metaverse. Her accusations of profit before safety are still red hot. " ID="ID_1285882824" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://cointelegraph.com/news/facebook-whistleblower-warns-metaverse-will-repeat-the-harms"/>
<node TEXT="Virtual production and the future of generative art" ID="ID_1162511562" CREATED="1680184336805" MODIFIED="1680620427516" LINK="https://virtualproducer.io/generative-ai-and-the-future-of-filmmaking/"/>
<node TEXT="Zuckerburg disengages from metaverse" ID="ID_278851575" CREATED="1680184406457" MODIFIED="1680184424464" LINK="https://www.thestreet.com/technology/mark-zuckerberg-quietly-buries-the-metaverse"/>
<node TEXT="Metahouse Could be First of Many - Los Angeles Business Journal digital twin of a mansion" ID="ID_405163567" CREATED="1672672974145" MODIFIED="1680184988059" LINK="https://labusinessjournal.com/featured/metahouse-could-be-first-of-many/"/>
<node TEXT="The Future is a Dead Mall - Decentraland and the Metaverse: Clickbait Title: I spent three months living in the metaverse and now I&apos;m starvingThe metaverse salespeople have a weird fixation with Animal Crossing, in sp..." ID="ID_1155777128" CREATED="1680097753103" MODIFIED="1680097753103" LINK="https://www.youtube.com/watch?v=EiZhdpLXZ8Q"/>
<node TEXT="https://www.infosys.com/iki/perspectives/metaverse-insider-guide.html" ID="ID_1678032183" CREATED="1680200467944" MODIFIED="1680200469119"/>
<node TEXT="Everyone abandoning metaverse" ID="ID_1364144861" CREATED="1680510364121" MODIFIED="1680593070098" LINK="https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/"/>
<node TEXT="The Internet Is Ruined. The Metaverse Can Still Be Saved: In this nascent stage, there are opportunities for virtual worlds to avoid the mistakes of the past." ID="ID_1114922714" CREATED="1680510364124" MODIFIED="1680620437497" LINK="https://www.wired.com/story/metaverse-ethics/">
<node TEXT="The article discusses how the internet has ruined the Metaverse, and how it can still be saved. It argues that the internet has made the Metaverse less accessible and has made it more difficult to find information. However, it also states that the Metaverse can still be saved if people are willing to work together to make it more accessible and user-friendly." ID="ID_27325956" CREATED="1680510364124" MODIFIED="1680510364124"/>
</node>
</node>
<node TEXT="Omniverse" ID="ID_67952672" CREATED="1670849762433" MODIFIED="1680620443082">
<node TEXT="Free to individuals" ID="ID_571823376" CREATED="1670849782769" MODIFIED="1670849796816" LINK="https://blogs.nvidia.com/blog/2022/01/04/omniverse-available-free-to-creators/"/>
<node TEXT="Full RTX rendering" ID="ID_1536249246" CREATED="1670851714047" MODIFIED="1670851721663" LINK="https://www.youtube.com/watch?v=Jm155QkRjl0&amp;feature=youtu.be"/>
<node TEXT="AI assisted blended character plugin" ID="ID_263117800" CREATED="1676626435442" MODIFIED="1676626450358" LINK="https://blogs.nvidia.com/blog/2023/02/15/blender-alpha-release-omniverse/?ncid=so-link-466434#cid=ov01_so-link_en-us"/>
<node TEXT="NVIDIA Unveils Powerful AI, Simulation and Creative Tools for Creators and Developers of Virtual Worlds | NVIDIA Blog" ID="ID_1242922733" CREATED="1672672974121" MODIFIED="1685195453870" LINK="https://blogs.nvidia.com/blog/2022/08/09/omniverse-siggraph/">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="Open metaverse" ID="ID_1352438902" CREATED="1674839571414" MODIFIED="1680620448047">
<node TEXT="Open metaverse discord from linux foundation" ID="ID_458109320" CREATED="1674839576038" MODIFIED="1674839584474" LINK="https://discord.gg/openmetaverse"/>
<node TEXT="Free 1 Million objects" ID="ID_462402254" CREATED="1679572150073" MODIFIED="1685195461656" LINK="https://huggingface.co/datasets/allenai/objaverse">
<icon BUILTIN="attach"/>
</node>
</node>
<node TEXT="persistence" ID="ID_925886137" CREATED="1670851862097" MODIFIED="1670851865884">
<node TEXT="Soulbound tokens concept" ID="ID_1916194587" CREATED="1670851867929" MODIFIED="1670851874027">
<node TEXT="weyl2022decentralized" ID="ID_1972989938" CREATED="1670851913380" MODIFIED="1670851914848"/>
<node TEXT="-Compensating coordinated strategic behavior&#xa;-Measuring decentralization&#xa;-Creating novel markets with decomposable, shared rights &amp; permissions&#xa;𝗘𝘀𝘁𝗮𝗯𝗹𝗶𝘀𝗵𝗶𝗻𝗴 𝗣𝗿𝗼𝘃𝗲𝗻𝗮𝗻𝗰𝗲&#xa;Souls can be used as a natural way for artists to stake their reputation on their works.&#xa;When issuing an NFT, an artist can issue it from their Soul.&#xa;pastry&#xa;By viewing the SBTs in an artist’s Soul, buyers can confirm the Soul belongs to the artist, thereby confirming the NFTs legitimacy.&#xa;Additionally, artists could issue an SBT in their Soul that attests to the NFT’s membership to a collection &amp; vouches for its scarcity.&#xa;Souls would thus create a verifiable, on-chain way to stake and build reputation on the provenance and scarcity of an object.&#xa;This can go beyond art. Souls can be used for services, rentals, and any market built on scarcity, reputation, or authenticity.&#xa;There is no method for establishing reputation for web3 identities.&#xa;SBTs that represent education credentials, work history, previous loans, and rental contracts could serve as a persistent record of credit relevant history.&#xa;𝐂𝐨𝐦𝐩𝐞𝐧𝐬𝐚𝐭𝐢𝐧𝐠 𝐜𝐨𝐨𝐫𝐝𝐢𝐧𝐚𝐭𝐞𝐝 𝐬𝐭𝐫𝐚𝐭𝐞𝐠𝐢𝐜 𝐛𝐞𝐡𝐚𝐯𝐢𝐨𝐫&#xa;So far, web3 has largely relied on token sales or airdrops to summon new communities.&#xa;SBTs offer a radical improvement called “souldrops”.&#xa;Using SBTs, a DAO that wants to form a community within a specific L1 can souldrop to devs who hold 3/5 conference attendance SBTs, or other tokens reflecting attendance like POAPs." ID="ID_1502095167" CREATED="1670852000757" MODIFIED="1670852104286"/>
</node>
</node>
<node TEXT="Usability" ID="ID_1784721357" CREATED="1670849270614" MODIFIED="1670849275444">
<node TEXT="bridging the real and the virtual like mcdonalds home delivery" ID="ID_614251261" CREATED="1670849633673" MODIFIED="1670849671547" LINK="https://www.businessinsider.com/mcdonalds-metaverse-virtual-online-restaurant-trademark-delivers-food-web3-nft-2022-2"/>
</node>
<node TEXT="Virtual land" ID="ID_1618115041" CREATED="1670850939896" MODIFIED="1670850943609">
<node TEXT="virtual" ID="ID_1758826159" CREATED="1670850944039" MODIFIED="1670850947291"/>
<node TEXT="hybrid land linking real and virtual (including digital twin)" ID="ID_1982592978" CREATED="1670850947847" MODIFIED="1670850965975" LINK="https://labusinessjournal.com/featured/metahouse-could-be-first-of-many/"/>
<node TEXT="Simple geo-referencing of physical place in mixed reality" ID="ID_272762383" CREATED="1670850967452" MODIFIED="1670850981664"/>
</node>
<node TEXT="Digital assistants" ID="ID_1019932996" CREATED="1678039192146" MODIFIED="1678039198156">
<node TEXT="MultiOn digital assistant" ID="ID_1687279489" CREATED="1678039199270" MODIFIED="1678039223035" LINK="https://multion.ai/"/>
<node TEXT="LEON open source assistant" ID="ID_913539274" CREATED="1678039248348" MODIFIED="1678039267256" LINK="https://docs.getleon.ai/"/>
<node TEXT="Open source assistant github of issues" ID="ID_1316122440" CREATED="1672855650771" MODIFIED="1672855668406" LINK="https://github.com/LAION-AI/Open-Assistant/issues"/>
</node>
<node TEXT="Avatars" ID="ID_563631480" CREATED="1680184868442" MODIFIED="1680263481165">
<node TEXT="Free VRChat Models &amp; Avatars | VRCMods (other)" ID="ID_395452678" CREATED="1672739551856" MODIFIED="1672739563313" LINK="https://vrcmods.com/"/>
<node TEXT="CLIP-Actor&#xa;Text-Driven Recommendation and Stylization for Animating Human Meshes" ID="ID_1895251640" CREATED="1680263471508" MODIFIED="1680263479395" LINK="https://clip-actor.github.io/"/>
</node>
<node TEXT="Displaytech" ID="ID_1182604415" CREATED="1684765439912" MODIFIED="1684765443183">
<node TEXT="CREAL lens display" ID="ID_1491420405" CREATED="1684765443714" MODIFIED="1685195502246" LINK="https://creal.com/2023/05/19/creals-breakthrough-ar-display-real-depth-with-a-classic-lens/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Autostereoscopic" ID="ID_1762641018" CREATED="1692096783237" MODIFIED="1692096794126">
<node TEXT="nanomaterials paper" ID="ID_1567553625" CREATED="1692096838571" MODIFIED="1692096844146" LINK="https://www.mdpi.com/2079-4991/12/3/429#"/>
</node>
<node TEXT="Bubbles and speakers" ID="ID_1126421542" CREATED="1693311963614" MODIFIED="1693311970839" LINK="https://www.youtube.com/watch?v=7VLdMXnM0lU"/>
</node>
<node ID="ID_1174739869" CREATED="1687805149124" MODIFIED="1687805149124" LINK="https://www.reddit.com/r/virtualreality/comments/12lpsvf/rumor_meta_quest_had_more_than_6_million_monthly/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Wall Street Journal has reported that Meta Quest, formerly known as Oculus, had over 6 million monthly active users as of October 2022. This news has generated discussion on the r/virtualreality subreddit, with users speculating about the future of VR and Meta Quest's upcoming products. Some users believe that VR needs more content to attract more users, while others express excitement over the release of Undead Citadel and the possibility of a Starfield VR game. Users also discuss the potential of streaming headsets like the Quest working on the PlayStation 5 and the importance of storytelling in VR games. Some users express disappointment in the launch of the remastered edition of San Andreas and its impact on Quest sales, while others joke about the perceived death of VR. https://www.reddit.com/r/virtualreality/comments/12lpsvf/rumor_meta_quest_had_more_than_6_million_monthly/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_23968179" CREATED="1687805149127" MODIFIED="1687805657422" LINK="https://www.bloomberg.com/news/articles/2023-04-14/meta-urged-to-halt-plans-allowing-minors-into-the-metaverse?leadSource=uverify%20wall"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Meta urged to prevent minors entering the metaverse https://www.bloomberg.com/news/articles/2023-04-14/meta-urged-to-halt-plans-allowing-minors-into-the-metaverse?leadSource=uverify%20wall
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_278203471" CREATED="1687772158439" MODIFIED="1687772158439"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        It's a valuable tool for video gaming, film industry, and metaverse applications that require 3D scenes.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The article discusses how the internet has ruined the metaverse, and how it can still be saved. It argues that the internet has made the metaverse less accessible and more difficult to navigate, and that this has had a negative impact on its potential. The article suggests that the metaverse can still be saved if we take steps to improve its accessibility and make it easier to use." ID="ID_1447539017" CREATED="1682414608718" MODIFIED="1682415137595" LINK="https://www.wired.com/story/metaverse-ethics/"/>
<node TEXT="Exploring Why the Metaverse Hasn&apos;t Taken Off as Expected: The metaverse has quickly turned from a profitable utopia into a cash-guzzling dystopia.The text provides an overview of the Metaverse, a virtual world that has not yet taken off as expected. The text describes the potential reasons for this, including the lack of a clear business model and the difficulty of creating an immersive experience." ID="ID_622080496" CREATED="1682414608723" MODIFIED="1682415268562" LINK="https://www.bbntimes.com/technology/exploring-why-the-metaverse-hasn-t-taken-off-as-expected"/>
<node ID="ID_1711038670" CREATED="1687805148623" MODIFIED="1687805148623" LINK="https://www.forbes.com/sites/charliefink/2023/05/07/this-week-in-xr-after-ai-sucks-the-air-out-of-the-metaverse-it-will-remake-xr/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the requested website (mirror-next-hop.forbes.com) is not accessible and the current session has been terminated with an access denied error (403). Further information can be obtained by contacting the website administrators using the provided reference code (217.138.196.24 2023-06-26T16:51:46.121Z). https://www.forbes.com/sites/charliefink/2023/05/07/this-week-in-xr-after-ai-sucks-the-air-out-of-the-metaverse-it-will-remake-xr/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1919539715" CREATED="1687805148671" MODIFIED="1687805148671" LINK="https://www.youtube.com/watch?v=fsg83BvsXww"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Building the Metaverse YouTube channel features a range of videos discussing the use of generative AI and large language models (LLMs) in game development and world-building. One video features a discussion with Kayla Comalli, co-founder and CEO of Lovelace Studios, about their platform Nyric, which generates entire worlds from a text prompt using generative AI technologies like ChatGPT. Other videos on the channel cover topics such as generative art assets for games, AI storytelling and narrative, generative graphics workflow for games, and the use of generative AI in game production. The channel also features discussions with individuals in related fields, such as Edward Saatchi of Fable Studio, who talks about virtual beings and simulated worlds, and Adam B. Levine of Blockade Labs, who discusses Skybox AI and game development. Additionally, there are videos discussing the potential applications of AI in other areas, such as defense and longevity. The channel provides a valuable resource for those interested in learning about the intersection of generative AI and gaming, as well as related topics. https://www.youtube.com/watch?v=fsg83BvsXww
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1475750112" CREATED="1687805148780" MODIFIED="1687805148780" LINK="https://arxiv.org/abs/2306.06459"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the potential risks and opportunities of motion tracking data in extended reality (XR) and the metaverse. While this data is often presumed to be innocuous, recent studies have shown that it has the potential to profile and deanonymize XR users, posing a significant threat to security and privacy in the metaverse. The article highlights the need for increased awareness and caution regarding the collection and use of motion data in XR and metaverse experiences. https://arxiv.org/abs/2306.06459
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_774193159" CREATED="1687805148787" MODIFIED="1687805148787" LINK="https://drugstorenews.com/coty-enters-metaverse-campus-global-workforce"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Beauty company Coty has created a metaverse for its 11,000 global employees, using technology from Spatial. The virtual campus is based on 3D tech and tools from Spatial, and aims to develop upskilling and future innovation for Coty brands. The campus includes features such as text and vocal chat forums, screen and filesharing, customisable avatars and location exploration and quest fulfilment, as well as a &quot;phygital&quot; rewards system. Coty and Spatial said the campus was a significant milestone in crafting &quot;new models for scalable gamified experiences&quot;. https://drugstorenews.com/coty-enters-metaverse-campus-global-workforce
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1728147724" CREATED="1687805148921" MODIFIED="1687805148921" LINK="https://www.tencentcloud.com/dynamic/news-details/100437?lang=en&amp;amp;pg="><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Tencent Cloud has announced its commitment to support the development of the Web3 ecosystem at the first global Web3 summit. The cloud business of Tencent has unveiled a development roadmap for a full suite of blockchain API services and its Tencent Cloud Metaverse-in-a-Box offering. The platform will provide technical support for Web3 and work with industry partners to nurture the Web3 ecosystem. Tencent Cloud plans to promote sustainable growth by offering Web3 builders cloud solutions credits, marketing workshops and publicity opportunities. It has also signed a Memorandum of Understanding with Ankr, a Web3 infrastructure provider, to jointly develop a full suite of blockchain API services. The API services will cover security, storage, identity management, middleware, development tools, and data analytics, among other areas. https://www.tencentcloud.com/dynamic/news-details/100437?lang=en&amp;pg=
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1313731015" CREATED="1687805148954" MODIFIED="1687805148954" LINK="https://www.beatoven.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The website Beatoven.ai offers users the ability to create customisable, royalty-free music using AI music generation techniques. The user can upload a video or a podcast and choose from eight different genres to suit their theme. They then make cuts to add different moods, choosing from a selection of 16. Finally, they hit compose and the AI algorithm composes a unique track for them. The music can be used for a variety of purposes such as advertising, podcast intros and outros, metaverse games, and YouTube videos, without the strain of editing and licensing music. Users are granted a perpetual license for the usage of the soundtracks on their chosen platform, with all copyrights for the musical works belonging to the company. Additionally, users have the ability to customize the length, genre, mood, and instruments of the music tracks. The website also offers a free 15-minute music download for new users, as well as a blog with information on topics such as business video music and YouTube's audio library. https://www.beatoven.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1374547940" CREATED="1687805149114" MODIFIED="1687805149114" LINK="https://www.eschoolnews.com/educational-leadership/2023/04/21/predictive-metaverse-the-future-of-guided-learning/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The concept of a &quot;predictive metaverse&quot;, an artificial intelligence (AI)-powered advanced form of a virtual world that could predict and anticipate its users' intentions and behaviors, is offering new ways to improve engagement, creativity and personalised learning in education, according to an article in eSchool News by Roger James Hamilton,&nbsp;Founder and CEO of Genius Group. As virtual reality&nbsp;worlds become increasingly sophisticated and realistic, they are also becoming more intelligent and able to analyse data in real-time to deliver tailored recommendations and feedback to individual users, for example to optimise the virtual marketplace to improve user experience and increase sales. https://www.eschoolnews.com/educational-leadership/2023/04/21/predictive-metaverse-the-future-of-guided-learning/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_747710541" CREATED="1687805149122" MODIFIED="1687805149122" LINK="https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Reddit and its partners use cookies and similar technologies to improve the quality of its website, personalize content and advertising, measure advertising effectiveness, and ensure the proper functionality of its platform. By accepting all cookies, users agree to the use of cookies. However, by rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of its platform. Reddit's Cookie Notice and Privacy Policy provide more information about its use of cookies. Recently, Meta, Microsoft, and Disney have reversed their bets on the metaverse. Posts related to this topic on r/CryptoCurrency have been removed by moderators. https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Exokit, Adrian&apos;s opensource mixed reality toolkit for web" ID="ID_1448562804" CREATED="1688636839642" MODIFIED="1688636861889" LINK="https://github.com/exokitxr/exokit"/>
<node ID="ID_238294467" CREATED="1687805148727" MODIFIED="1689008888230" LINK="https://www.theverge.com/2023/6/6/23751350/apple-mira-ar-headset-startup"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Apple has acquired Mira, a Los Angeles-based startup that creates AR headsets for various companies and the US military. The acquisition, which was confirmed by Apple, follows the company's launch of its $3,499 mixed reality headset, the Vision Pro. Two former Mira employees said that Jony Ive, Apple's former design chief, was an advisor to the startup at one point. Mira's military contracts include a small agreement with the US Air Force and a $702,351 agreement with the Navy while its contract with Nintendo World provides headsets for the Mario Kart ride at its theme parks in Japan and LA's Universal Studios. It is currently unknown if Apple will continue Mira's military contracts. https://www.theverge.com/2023/6/6/23751350/apple-mira-ar-headset-startup
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_945320495" CREATED="1687805148731" MODIFIED="1689008898136" LINK="https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text discusses the use of cookies by LinkedIn and third parties to provide, secure, analyze and improve services, and to show relevant ads on and off LinkedIn. The user can choose to accept or reject non-essential cookies, and update their choices at any time in their settings. The text also includes several posts related to XR technology, such as demos and reviews of headsets, discussions on the usefulness of AR, and presentations at conferences. These posts include insights on the development of XR technology, possible applications, and innovations in the field. https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="This text is a brief description of a position paper published by the OMA3 Portaling and Mapping Working Group (PMWG) on the transformative technology of portals in the metaverse. The position paper provides insights into the potential of a universal portal system to reshape digital interaction for consumers, businesses, and platforms. It highlights the development process, strategic approach, and vision of OMA3 in setting new standards for the Web3 universe. The paper invites readers to comment on it by creating an issue or commenting in the Google Doc. It also encourages individuals to join OMA3 and participate in the Portaling and Mapping Working Group if they would like to contribute to the project. The paper is licensed under a Creative Commons Attribution 4.0 International License. " ID="ID_312096173" CREATED="1688559432709" MODIFIED="1689009335054" LINK="https://github.com/oma3dao/portal-position-paper"/>
<node TEXT="The Open Metaverse Alliance for Web3 (OMA3) has announced the Inter-World Portaling System (IWPS) project, aimed at creating standards for seamless travel between metaverse platforms. OMA3, based in Zug, Switzerland, is a consortium of top metaverse companies in Web3. The IWPS project will allow users to walk through inter-world portals and travel between metaverse platforms such as Alien Worlds, My Neighbor Alice, and Sandbox. OMA3 believes that IWPS has the potential to enhance accessibility and engagement within the digital realm by bridging disparate metaverse environments. They compare IWPS to the development of transportation technology like railroads and highways in the industrial revolution and the introduction of the HTTP standard in the digital realm, both of which facilitated the free flow of goods, services, and information. OMA3 has released a position paper outlining the importance of IWPS and inviting participation and comments from the Web3 metaverse community. They see the development and standardization of IWPS as the next frontier in the evolution of the metaverse, enabling new levels of connectivity, commerce, and shared experiences. " ID="ID_560257555" CREATED="1688559432712" MODIFIED="1689009335056" LINK="https://venturebeat.com/games/oma3-offers-way-for-users-to-travel-between-blockchain-gaming-worlds-in-the-metaverse/"/>
<node TEXT="Beatoven.ai is a website that uses advanced AI music generation techniques to create unique, mood-based music for videos and podcasts. Users can start by choosing a genre or style that suits their theme and then make cuts to reflect different moods throughout their content. With a rich selection of 16 moods to choose from, users can easily find the right mood for each cut. Once the desired moods have been selected, users can hit compose and let the AI algorithm generate a unique track for them.   The website is useful for various types of content creators, including agency/production houses, YouTube creators, podcast creators, indie game developers, audiobook producers, and web3 and metaverse companies. It offers a range of benefits, such as packing a punch in videos, creating a signature sound for YouTube channels, making intro and outro sections special for podcasts, designing themes and background music for games, elevating audio books with atmospheric music, and providing background music for metaverse experiences.   Beatoven.ai also allows users to customize the length, genre, mood, and instruments of their tracks. The resulting music is production-ready with industry-standard mixing and mastering.   The licensing terms for the music on Beatoven.ai grant users a perpetual license for usage on their chosen platforms. All copyrights for the music created on the website belong to Beatoven Private Limited.   The website offers a free membership option, allowing users to create and download music for the first 15 minutes of their projects. There is also a premium pricing plan available for unlimited usage.   Overall, Beatoven.ai is a versatile and user-friendly platform that offers customized, royalty-free music for a wide range of content creators. " ID="ID_460185246" CREATED="1688559432712" MODIFIED="1689009335057" LINK="https://www.beatoven.ai/"/>
<node TEXT="A predictive metaverse is an advanced virtual world powered by AI and machine learning algorithms. It can predict and anticipate the actions and behaviors of its users, allowing for personalized recommendations, predictions, and feedback. This concept is becoming increasingly appealing to content creators and educators in the field of education, as it can improve engagement and creativity and create personalized learning programs.  In a predictive metaverse, AI algorithms can analyze real-time data to understand the preferences, behaviors, and intentions of users. This information can then be used to optimize the virtual world and improve the user experience. For example, an AI algorithm could predict user behavior in a virtual marketplace, such as what they are likely to buy and when they are likely to buy it. This data can be used to optimize the marketplace and increase sales.  While the term metaverse is often associated with the gaming industry, its potential applications in education are significant. The predictive metaverse can enhance virtual learning by providing personalized guidance and support to students. It can help create immersive learning experiences and improve student engagement and motivation.  As virtual worlds become more sophisticated and realistic, the predictive metaverse holds great promise for the future of guided learning. By harnessing the power of AI and machine learning, educators can create personalized learning experiences that cater to the unique needs and preferences of each student. This technology has the potential to revolutionize education by providing tailored instruction, real-time feedback, and personalized recommendations, ultimately improving student outcomes and overall learning experiences. " ID="ID_1287176513" CREATED="1688559432712" MODIFIED="1689009335057" LINK="https://www.eschoolnews.com/educational-leadership/2023/04/21/predictive-metaverse-the-future-of-guided-learning/"/>
<node TEXT="This text is a Reddit post from the r/CryptoCurrency subreddit. The post mentions that Meta (formerly known as Facebook) as well as Microsoft and Disney are reversing their bets on the metaverse. However, the post has been removed by the subreddit moderators. The comments in the post discuss the current hype around artificial intelligence (AI) and the need for companies to hop on that trend. Some users express their opinions that these companies went about their approach to the metaverse in the wrong way. The post also includes comments about the ownership of a bot that has received a high number of moons (a cryptocurrency earned on the Reddit platform) and speculation on the future of meta platforms like Meta. The post is followed by a list of related crypto news articles from various sources, covering topics such as refunds in crypto scams, acquisitions of Bitcoin, changes in cryptocurrency taxes, and the launch of web3 games by Ubisoft. " ID="ID_691000250" CREATED="1688559432712" MODIFIED="1689009335057" LINK="https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/"/>
<node TEXT="Tencent Cloud, the cloud business of global tech company Tencent, has announced its commitment to support the development of the Web3 ecosystem. The company unveiled its development roadmap for a full suite of blockchain API services and its Tencent Cloud Metaverse-in-a-Box offerings. It aims to provide a strong technological foundation for Web3 builders and be the digital enabler for the Web3 industry. Tencent Cloud will collaborate with Web3 partners to accelerate the adoption of Web3. The company also signed a Memorandum of Understanding (MoU) with Web3 infrastructure provider Ankr to jointly develop a full suite of blockchain API services. Additionally, Tencent Cloud announced strategic collaborations with Avalanche, Scroll, and Sui, three other Web3 blockchain partners, to build a stronger foundational infrastructure for global builders. The collaboration with Avalanche will explore blockchain solutions for enterprise customers, while the partnership with Scroll aims to scale Ethereum through an open-sourced zk-Rollup. The collaboration with Sui will optimize the on-chain gaming experience. Furthermore, Tencent Cloud introduced Tencent Cloud Metaverse-in-a-Box, a comprehensive solution that integrates infrastructure, products, SDKs, and low-code solutions. The Metaverse-in-a-Box allows businesses to develop metaverse applications rapidly. Tencent Cloud hosted its first global Web3 summit, Tencent Cloud Web3 Build Day, to discuss the latest blockchain landscape and development trends in Web3 games and social networks. " ID="ID_1247561622" CREATED="1688559432712" MODIFIED="1689009335057" LINK="https://www.tencentcloud.com/dynamic/news-details/100437?lang=enandpg=">
<font SIZE="8"/>
</node>
<node ID="ID_704420642" CREATED="1687805148460" MODIFIED="1689009554926" LINK="http://www.brahmGAN.ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          BrahmGAN is a cutting-edge 3D content creation tool that uses advanced technology such as NeRF, GAN, and Blockchain to create 3D content effortlessly, without requiring technical expertise or complex software. The tool is designed for industries such as eCommerce, XR, and Gaming. BrahmGAN's NeRF solutions for VR Services are capable of creating stunning worlds within days. The company is based in Bengaluru and Singapore. Interested parties can contact them via email at info@brahmgan.com or join their mailing list to stay updated on their latest developments. http://www.brahmGAN.ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_438385803" CREATED="1687805148498" MODIFIED="1689009554929" LINK="http://joinhallway.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Hallway is an app that empowers creators to tell their stories using avatars instead of their real faces, making it easy for anyone to express their creativity without the limitations of video as a medium. It is a single-camera app that supports a variety of avatars and requires no custom hardware or clunky setups. The app is currently taking VTuber and 2D/3D artist intakes to join the waitlist for early access. Hallway provides a new avenue for creators to express themselves and join the next generation of creators. http://joinhallway.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1586094291" CREATED="1687805148539" MODIFIED="1689009554933" LINK="http://www.brahmGAN.ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          BrahmGAN is an AI-based 3D content creation platform that uses advanced technologies like NeRF, GAN, and Blockchain for quick and decentralized content creation. BrahmGAN's text-to-3D tools enable users to create 3D content without technical expertise or complex software. BrahmGAN caters to industries like XR, gaming, and eCommerce and uses NeRF for video to 3D, and Blockchain for democratizing 3D content creation globally. BrahmGAN has offices in Bangalore and Singapore and has clients like Taanga Studios. http://www.brahmGAN.ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="In this post on Reddit, a user shares their experience developing a C++ library for running Stable Diffusion, an AI image generation model. They explain that the library does not rely on Python and can use the GPU for executing the AI models involved. The user&apos;s main motivation for developing this library was to use its image synthesis capabilities in real-time 3D software written in C++.   The user shares their first results, which include a simple library available as an integration-ready MIT licensed Nuget package, capable of running Stable Diffusion models in ONNX format. They note that the code is currently targeting Windows, but only a small portion related to image editing tasks relies on the WinAPI, which can easily be replaced for other platforms.  Several redditors comment on the post, expressing interest in the library and discussing their own experiences with Stable Diffusion and C++ implementations in machine learning. Some users appreciate the user interface design of the library, while others discuss the advantages and disadvantages of using Python for machine learning tasks.  The user also mentions that they are working on an Xbox release and have already generated Stable Diffusion images on the Xbox. There are further discussions on related topics, such as RAID arrays, graphics libraries for Rust, and C++ language support in Xcode 15.  Overall, the post provides an overview of a C++ library for running Stable Diffusion and highlights the user&apos;s experiences and progress in developing it. " ID="ID_99790805" CREATED="1688559432712" MODIFIED="1689009186843" LINK="https://www.reddit.com/r/cpp/comments/143olej/an_open_source_library_for_running_stable/"/>
<node TEXT="The text is a Reddit post discussing the process of generating and applying AI-generated images to a 3D model. The poster shares the results of their image generation using AI and provides details about the rendering process. They mention using Blender and a custom UV map to project the generated image onto the face of the 3D model.  The poster explains that they manually removed diffuse and specular reflections during the AI image generation stage and conducted additional tests to bring out more details. They aim to create a color map that can be used without adjustments.  Other users in the comments ask about the training process and suggest alternative methods for projection mapping. The poster responds, stating that they did additional training with images that suppress shadows, light, and AO. They also mention that the AI-generated image was baked into a custom UV map before rendering.  Some users express interest in learning the process and suggest creating a tutorial. The original poster mentions that the process takes a lot of time and effort and that the results may vary. They recommend referring to their previous test articles for more information on AI image generation.  The post concludes with a list of related posts from other subreddits discussing topics such as computer vision, AI-generated avatars, and visualizations in Stable Diffusion. " ID="ID_1888615722" CREATED="1688559432712" MODIFIED="1689009186847" LINK="https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/"/>
<node ID="ID_1967418768" CREATED="1687805148826" MODIFIED="1689009298115" LINK="https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to provide a better experience to users. By accepting all cookies, users agree to Reddit's use of cookies to provide and maintain their services, personalize content and advertising, and measure advertising effectiveness. If users reject non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of the platform. Additionally, the article includes a user-generated post on using Mixamo, a free website with a large library of 3D animations, for character posing. Several commenters offer their own suggestions and recommendations for related tools and workflows on different subreddits. https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The text is a discussion thread from the Reddit community in the r/StableDiffusion subreddit. It starts with a user sharing a helpful tip for posing 3D characters using a tool called Mixamo, which allows users to access a library of 3D animations and customize them for their own characters. Other users in the thread then share additional tools and techniques for character posing and rendering in 3D, such as Daz 3D, Magicposer, and OpenPose Editor.  The thread also includes discussions about using these tools in conjunction with ControlNet, a preprocessor and model used for controlling lighting and other elements in 3D modeling. Users share their experiences and opinions on the different tools and methods, emphasizing the importance of finding the right tool that suits their individual needs and preferences.  In addition to the discussion on character posing and rendering, there are also unrelated comments in the thread about War Thunder voice comms, website generation for a gaming system called SWN, a job/weapon VC index tool for a game called Wotv_ffbe, a web app for tracking Gundam Evolution challenges, and other topics.  Overall, the thread provides a platform for users to share and exchange information, tips, and resources related to 3D character posing and rendering, as well as other unrelated gaming and creative topics. " ID="ID_1508812832" CREATED="1688559432712" MODIFIED="1689009298136" LINK="https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/"/>
<node TEXT="The text discusses the use of cookies and similar technologies on Reddit&apos;s platform. By accepting all cookies, users agree to the use of cookies to improve their experience, deliver and maintain services, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies still allows Reddit to use certain cookies for proper platform functionality. The text also mentions that more information can be found in the Cookie Notice and Privacy Policy.  The rest of the text is a Reddit post from the r/StableDiffusion subreddit. The post discusses a generalist model that the OP (original poster) will be releasing soon. The model is capable of creating images with resolutions ranging from 1024 to 1080p, and it is fine-tuned on SD 2.1 768X. The model can generate a variety of images, including photorealism, paintings, and anime. The OP shares some example images generated during the training process and invites others to test prompts for image creation. The post receives several comments and discussions about the model&apos;s capabilities, potential uses, and suggestions for improvement.  Additionally, the text includes a list of other posts from various subreddits such as r/3dsmax, r/colorists, and r/StableDiffusion. These posts cover topics related to rendering, color grading, using AI-generated visuals, and showcasing artistic works. " ID="ID_593320590" CREATED="1688559432712" MODIFIED="1689009298139" LINK="https://www.reddit.com/r/StableDiffusion/comments/13j78fo/some_examples_of_the_generalist_model_i_will_be/"/>
<node ID="ID_1733763318" CREATED="1687805148640" MODIFIED="1689009554953" LINK="https://www.myminifactory.com/category/scan-the-world"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Scan the World is a museum of sculptures, artifacts, and statues made possible through 3D scanning and printing technology. The scans of these historical pieces are free to download for accessibility, educational and cultural heritage purposes. Scan the World uses photogrammetry to capture these high-resolution scans, from digital archaeology to downloadable monuments and buildings, 3D printing enthusiasts will be able to find it at the museum. The museum offers more than 20 categories ranging from Africa to South America and everything in between, and it ranks objects based on popularity, date published, and views. Visitors have instant access to the MyMiniFactory library, which is community-powered with users able to upload their 3D printable designs as well. The ultimate goal of Scan the World is to make historical and artistic objects more widely available to people around the world. It’s the perfect solution for those who want to own an authentic, accurate replica of an important sculpture, artifact, or more. https://www.myminifactory.com/category/scan-the-world
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_494343906" CREATED="1687805149089" MODIFIED="1689009554958" LINK="https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          LinkedIn uses both essential and non-essential cookies to provide, secure, analyze and improve their services, as well as show users relevant ads on and off the platform, according to their Cookie Policy. Users can accept or reject non-essential cookies for this use and can update their choices at any time in their settings. In a post by Rene Schulte, the Head of 3D &amp; Quantum CoPs at Microsoft, he shared resources for Unity developers to prepare for developing for Apple's VisionPro and visionOS. The post sparked conversations and comments from other professionals in the AR/VR industry, including discussions about AR's utility, developments in volumetric video and tracking, and the use of digital twins in building. https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The text discusses a research paper on a diffusion model called 3DiM for 3D novel view synthesis. The model takes a single input view and generates consistent and sharp completions across many views. It uses a pose-conditional image-to-image diffusion model that takes a source view and pose as inputs and generates a novel view for a target pose as output. The model employs stochastic conditioning, where a random conditioning view is selected from previously generated views at each denoising step, to improve 3D consistency. The paper introduces a new evaluation methodology called 3D consistency scoring to assess the 3D consistency of the generated objects. The model is geometry-free, does not rely on hyper-networks or test-time optimization, and can easily scale to a large number of scenes.  The paper presents samples generated by 3DiM trained on the ShapeNet dataset. The model achieves high fidelity and approximate 3D consistency in generating completions from a single view. It also demonstrates the model&apos;s effectiveness by generating 3D objects from in-the-wild images downloaded from the internet. The paper compares 3DiM to prior work on the SRN ShapeNet benchmark and shows that 3DiM outperforms other methods in terms of generating sharp samples. The paper also discusses the technical details of 3DiM, including its generation process using stochastic conditioning and the modifications made to the image-to-image UNet model to achieve high-quality results.  Overall, the paper highlights the effectiveness of diffusion models for 3D novel view synthesis and introduces novel techniques, such as stochastic conditioning and 3D consistency scoring, to improve the quality and consistency of generated views. The proposed model, 3DiM, shows promising results in generating realistic and consistent 3D objects from a single input view. " ID="ID_930769221" CREATED="1688559432703" MODIFIED="1689009554960" LINK="https://3d-diffusion.github.io/"/>
<node TEXT="The paper presents a monocular depth estimation method using denoising diffusion models. The goal is to generate accurate depth maps from single RGB images. The authors address the problem of noisy and incomplete depth maps in the training data by using step-unrolled denoising diffusion, an L1 loss, and depth infilling during training.  To overcome the limited availability of supervised training data, the authors leverage pre-training on self-supervised image-to-image translation tasks. Despite the simplicity of the approach, their model achieves state-of-the-art (SOTA) performance on the indoor NYU dataset and near SOTA results on the outdoor KITTI dataset.  The approach involves infilling missing depth in ground truth depth maps using nearest neighbor interpolation. Then, noise is added to the depth map and a neural network is trained to predict the noise given the RGB image and noisy depth map. During fine-tuning, one step of the forward pass is unrolled and the ground truth depth map is replaced with the model&apos;s prediction.  The DepthGen model achieves an absolute relative error of 0.074 on the indoor NYU dataset and a competitive relative error of 0.064 on the outdoor KITTI dataset, demonstrating its accuracy in depth estimation.  The paper also introduces a text-to-3D pipeline that combines DepthGen with off-the-shelf text-to-image and text-conditioned image completion models. This pipeline allows for generating 3D point clouds from text prompts.  In conclusion, the proposed method of monocular depth estimation using diffusion models achieves state-of-the-art performance, even with limited supervised training data. The approach is simple yet effective and can be integrated into a text-to-3D pipeline for generating 3D scenes from text prompts. " ID="ID_1974134210" CREATED="1688559432706" MODIFIED="1689009554965" LINK="https://depth-gen.github.io/"/>
<node TEXT="The text provided is a collection of video titles and descriptions related to Blender, AI, and 3D design. The videos cover topics such as creating isometric rooms, using AI in 3D design, Unreal Engine, toon shading in Blender, QR code art, GPT (Generative Pre-trained Transformer) engineering, creating Ghibli-style characters, new features in Blender 3.6, animation in Blender, and adding vegetation in Twinmotion. The videos are created by various individuals and brands, including vertex vendor, Unreal Sensei, Quick QR Art, ENFANT TERRIBLE, Matt Wolfe, Ian Wootten, Brandon&apos;s Drawings, Polyfjord, Charlie Barber, and vishal panjeta. The text also mentions a Google company and provides information about cookie usage and privacy settings when using Google services. " ID="ID_70132612" CREATED="1688559432725" MODIFIED="1689009554972" LINK="https://www.youtube.com/watch?v=GZO7TAlVE_8"/>
<node TEXT="WebXR is a device API that allows for VR/AR experiences through web browsers. However, monetization has been a major issue for the platform, with indie creators struggling to capture value. Most WebXR apps appear as prototypes because developers find it difficult to justify investing more resources into the ecosystem. The current ways people pay for WebXR content include purchasing tickets, using cryptocurrency for virtual land, and accessing certain features by login or ownership of bot handles. The process of paying for WebXR content can be made easier and more frictionless by integrating payment methods like Apple Pay or Google Pay while in VR. Artists can get paid through various means such as commissions, Patreon, grants, VC investment, and event tickets. Non-payment based monetization strategies like advertising are also being explored. A list of 101 ideas for WebXR monetization includes platforms like Patreon and Github Sponsors, virtual market stalls, virtual land parcels, and in-world advertising. Other strategies include payment processing integration with platforms like PayPal or Discord, creating virtual actors and performers, storytelling, and podcast sponsorships. Advertisements targeted at 18-44 year old males interested in software, gaming, and VR have shown promising results. A Github repository for WebXR monetization examples is in progress. Despite these efforts, monetization in the WebXR ecosystem is still a work in progress, and more exploration and innovation is needed. " ID="ID_603002825" CREATED="1688559432709" MODIFIED="1689009655452" LINK="https://hackmd.io/@xr/monetization"/>
<node ID="ID_1855867637" CREATED="1687805148848" MODIFIED="1689009554955" LINK="https://clip-actor.github.io"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper proposes a system called CLIP-Actor, which animates a 3D human mesh to conform to a text prompt by recommending a motion sequence and optimizing mesh style attributes. The system's novelty lies in its ability to recommend motion that conforms to the prompt in a pose-agnostic and temporally-consistent manner while leveraging multi-frame human motion and rejecting poorly rendered views. The authors demonstrate that CLIP-Actor produces plausible and human-recognizable style 3D human mesh in motion with detailed geometry and texture solely from a natural language prompt. The paper's methodology shows that CLIP-Actor is an effective and efficient way to generate plausible results when the pose of an artist-designed mesh does not conform to the text prompt from the beginning. The research has been sponsored by the Korean government's grant funded by the Institute of Information &amp; communications Technology Planning &amp; Evaluation (IITP). https://clip-actor.github.io
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="The paper CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes proposes a system for animating human meshes based on text prompts. The system, called CLIP-Actor, generates motion sequences and optimizes mesh style attributes to conform to a given text prompt.  The authors highlight a limitation of previous work, which struggled to produce realistic results when the starting pose of a pre-designed mesh did not align with the text prompt. To address this issue, CLIP-Actor leverages a large-scale human motion dataset with language labels to build a text-driven human motion recommendation system. It suggests a motion sequence that aligns with the given prompt in a coarse-to-fine manner.  In addition, the authors introduce a novel neural style optimization technique that adds detail and texture to the recommended mesh sequence in a temporally-consistent and pose-agnostic manner. They also propose spatio-temporal view augmentation and mask-weighted embedding attention techniques to stabilize the optimization process by incorporating multi-frame human motion and rejecting poorly rendered views.  The results of CLIP-Actor demonstrate its ability to generate plausible and human-recognizable 3D human meshes in motion with detailed geometry and texture solely from natural language prompts.  The paper includes the BibTeX citation for academic referencing and acknowledges the support received from the Institute of Information and Communications Technology Planning and Evaluation (IITP) in Korea for funding the research.  The website containing the paper and code is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. The source code for the system is mainly borrowed from Keunhong Park&apos;s Nerfies website, and feedback and questions can be directed to Kim Ji-Yeon. " ID="ID_517083512" CREATED="1688559432705" MODIFIED="1689009554963" LINK="https://clip-actor.github.io"/>
<node TEXT="Magic123 is a two-stage solution for generating high-quality, textured 3D meshes from a single unposed image. The first stage optimizes a neural radiance field to create a coarse geometry, while the second stage uses a memory-efficient differentiable mesh representation to produce a high-resolution mesh with realistic textures. The 3D content is learned through reference view supervision and guided by both 2D and 3D diffusion priors. The system includes a tradeoff parameter that controls the balance between exploring novel geometries and achieving precise results. Textual inversion and monocular depth regularization are employed to ensure consistent appearances across views and prevent degenerate solutions. Magic123 outperforms previous image-to-3D techniques, as demonstrated through experiments on synthetic benchmarks and real-world images.  The Magic123 pipeline consists of two stages: coarse and fine. In the coarse stage, an Instant-NGP neural radiance field is optimized to reconstruct a rough geometry. In the fine stage, a DMTet mesh is initialized from the coarse output and optimized to generate a high-resolution mesh with textures. Textural inversion is used in both stages to preserve object geometry and ensure consistent textures across views.  Example generated objects from Magic123 show photo-realistic 3D representations created from single images. The system offers a tradeoff between 2D and 3D priors, allowing for exploration and imagination in geometry generation or precise results with reduced details. By combining both priors and adjusting the tradeoff parameter, Magic123 consistently produces identity-preserving 3D content with fine-grained geometry and visually appealing textures.  Quantitative evaluations on the NeRF4 and RealFusion15 datasets demonstrate the effectiveness of Magic123 compared to previous state-of-the-art approaches. The system achieves top performance across various metrics, showcasing its ability to generate high-quality 3D representations.  The article credits DreamFusion authors for their website templates, and the text is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. " ID="ID_1715041517" CREATED="1688559432709" MODIFIED="1689009554968" LINK="https://guochengqian.github.io/project/magic123/"/>
<node TEXT="The paper Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors presents a two-stage approach for generating high-quality, textured 3D meshes from a single unposed image.   In the first stage, a neural radiance field is optimized to create a coarse geometry. In the second stage, a memory-efficient differentiable mesh representation is used to generate a high-resolution mesh with visually appealing texture.   To learn the 3D content, reference view supervision and novel views guided by a combination of 2D and 3D diffusion priors are employed in both stages. A trade-off parameter controls the balance between exploration and exploitation of the generated geometry.   Textual inversion and monocular depth regularization techniques are also used to ensure consistent appearances across views and prevent degenerate solutions.   The approach, called Magic123, outperforms previous image-to-3D techniques according to extensive experiments on synthetic benchmarks and real-world images.   The code, models, and generated 3D assets are available on GitHub. " ID="ID_312171534" CREATED="1688559432709" MODIFIED="1689009554970" LINK="https://huggingface.co/papers/2306.17843"/>
<node ID="ID_1453965648" CREATED="1687805148842" MODIFIED="1689009712551" LINK="https://github.com/carson-katri/dream-textures/pull/409"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This is a conversation and code change history on the GitHub platform for the &quot;dream-textures&quot; repository. It appears that the main topic of discussion is the addition of a new feature called &quot;Project Dream Texture operator&quot;. This feature involves the use of depth-to-image projection to apply a texture to a mesh based on user input. The conversation includes comments and feedback from users who have tested the feature, as well as responses from the repository owner who is implementing the changes. There are also code commits and updates to various files related to the feature and its implementation. https://github.com/carson-katri/dream-textures/pull/409
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_241320819" CREATED="1687805148845" MODIFIED="1689009712566" LINK="https://github.com/carson-katri/dream-textures/pull/409"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text appears to be a GitHub pull request for the &quot;dream-textures&quot; repository, with the pull request titled &quot;Add Project Dream Texture operator&quot;. The pull request adds functionality that allows users to project a texture onto a mesh using a text prompt and depth data. The pull request includes a log of commits and comments from users who have tested the functionality and provided feedback. It seems that the pull request has been approved by at least two reviewers and has been merged into the main branch of the repository. https://github.com/carson-katri/dream-textures/pull/409
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="SDFStudio is a unified and modular framework for neural implicit surface reconstruction. It provides an implementation of three major implicit surface reconstruction methods: UniSurf, VolSDF, and NeuS. The framework also supports various scene representations, point sampling strategies, and incorporates advances in monocular cues, geometry regularization, and multi-view consistency. The modular implementation of SDFStudio makes it easy to transfer ideas from one method to another. The repository includes documentation, datasets, and examples for users to get started.  To use SDFStudio, users need to set up the environment by installing CUDA and creating a Conda environment. The framework requires Python 3.7 or higher. Users can install the necessary dependencies, including PyTorch and tiny-cuda-nn, using pip. After installing the dependencies, users can clone the SDFStudio repository and install it using pip. Tab completion can be enabled for better user experience.  To train a model, users can download test data and train a model on a specific dataset using the provided commands. SDFStudio supports different models and parameters can be modified to train different models. The training progress can be tracked using visualization tools such as the viewer, Tensorboard, or Weights and Biases.  Once a model is trained, users can export the mesh and render it. The repository provides commands for extracting the mesh and rendering it. Video rendering and customization of the camera path are also supported. Advanced options include training models other than NeuS-facto and modifying the configuration.  SDFStudio is built on top of the Nerfstudio project and incorporates contributions from various developers. If the library is used or the documentation is found useful, the authors request users to consider citation.  The repository includes a comprehensive README file that provides detailed instructions and explanations for using SDFStudio. It also provides information about the contributors, license, and other resources. " ID="ID_870537745" CREATED="1688559432707" MODIFIED="1689009712566" LINK="https://github.com/autonomousvision/sdfstudio"/>
<node TEXT="The text summarizes a GitHub repository called CLIP-Actor, which is a pytorch implementation for the ECCV 2022 paper, CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes. CLIP-Actor is a system for text-driven motion recommendation and neural mesh stylization for human mesh animation. The repository contains code developed on Ubuntu 18.04 with Python 3.7, CUDA 10.2, and PyTorch 1.9.0. The system requirements include Python 3.7, CUDA 10.2, and a single GPU with a minimum of 24 GB RAM. The repository provides instructions for setting up the environment and installing the required dependencies. It also provides instructions for downloading the necessary body models and datasets. The repository includes example commands to generate stylized 4D human avatars based on prompts, such as a scuba diver is scuba diving or Freddie Mercury is dancing. The outputs include final video files, stylized .obj files, colored render views, and screenshots. The repository includes a citation for the paper and acknowledges the prior work that inspired the CLIP-Actor implementation. " ID="ID_1491542904" CREATED="1688559432709" MODIFIED="1689009712566" LINK="https://github.com/youwang-kim/clip-actor"/>
<node TEXT="Mixed reality design guidelines from Meta" ID="ID_988859952" CREATED="1691500983381" MODIFIED="1691500993768" LINK="https://developer.oculus.com/resources/mr-design-guideline/"/>
</node>
<node TEXT="Politics, law, and change" FOLDED="true" POSITION="left" ID="ID_386729834" CREATED="1679051678601" MODIFIED="1689591469291">
<edge COLOR="#7c007c"/>
<node TEXT="WEF risks report links" ID="ID_1427914656" CREATED="1679051683534" MODIFIED="1679051696456" LINK="https://sociable.co/government-and-policy/wef-global-risks-report-cyber-pandemic-erosion-trust-social-cohesion/"/>
<node TEXT="Regulation (everything)" ID="ID_578088224" CREATED="1680166108655" MODIFIED="1680166130775">
<node TEXT="Crypto" ID="ID_1801964271" CREATED="1680166118261" MODIFIED="1680166121285">
<node TEXT="UK" ID="ID_587977487" CREATED="1680166121925" MODIFIED="1680166124912" LINK="https://www.gov.uk/government/news/uk-sets-out-plans-to-regulate-crypto-and-protect-consumers"/>
</node>
</node>
<node TEXT="GPTs are GPTs: An Early Look at the Labor Market Impact" ID="ID_1029059756" CREATED="1679841790213" MODIFIED="1680183795209" LINK="https://arxiv.org/abs/2303.10130">
<node TEXT="The text discusses the potential implications of Generative Pre-trained Transformer (GPT) models on the U.S. labor market. It uses a new rubric to assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. The findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. The text concludes that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that these models could have notable economic, social, and policy implications." ID="ID_96120605" CREATED="1679841790215" MODIFIED="1679841790215"/>
</node>
<node TEXT="El Salvador: Staff Concluding Statement of the 2023 Article IV Mission (other)" ID="ID_1802797768" CREATED="1677086422722" MODIFIED="1689591469288" LINK="https://www.imf.org/en/News/Articles/2023/02/10/el-salvador-staff-concluding-statement-of-the-2023-article-iv-mission" HGAP_QUANTITY="21.5 pt" VSHIFT_QUANTITY="1.5 pt">
<node TEXT="Other. The text describes a study by the University of Cambridge which found that people tend to trust robots more when they look and behave like humans." ID="ID_265952458" CREATED="1679519694291" MODIFIED="1679519694291"/>
</node>
<node TEXT="Silvergate Purchases Blockchain libre" ID="ID_1453996189" CREATED="1680510364128" MODIFIED="1680594156239" LINK="https://ir.silvergate.com/news/news-details/2022/Silvergate-Purchases-Blockchain-Payment-Network-Assets-from-Diem/default.aspx">
<node TEXT="The text discusses Silvergate&apos;s recent purchase of blockchain payment network assets from Diemwindow." ID="ID_1798220821" CREATED="1680510364128" MODIFIED="1680510364128"/>
</node>
<node TEXT="Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it&apos;s done is build a biometric database from the bodies of the poor." ID="ID_1570447876" CREATED="1680510364124" MODIFIED="1680510364124" LINK="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/">
<node TEXT="Worldcoin, a cryptocurrency startup, recruited its first 500,000 users by offering them free cash. The company has been accused of deception and exploiting workers, and is now under investigation." ID="ID_1823576465" CREATED="1680510364124" MODIFIED="1680510364124"/>
</node>
<node TEXT="Privacy law book" ID="ID_1088109377" CREATED="1670855667549" MODIFIED="1670855674954" LINK="https://www.smashingmagazine.com/printed-books/understanding-privacy/#bookTOC"/>
<node TEXT="Online safety bill heather articles" ID="ID_761707102" CREATED="1670855710595" MODIFIED="1685195739198" LINK="https://webdevlaw.uk/2022/11/21/a-quick-hypothetical-situation-or-your-crash-introduction-to-the-real-world/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Techcrunch on borderless payments" ID="ID_1242804297" CREATED="1673885657823" MODIFIED="1673885669375" LINK="https://techcrunch.com/2021/12/21/borderless-crypto-networks-wrestle-with-state-sanction-compliance/?"/>
<node TEXT="Norway takes a stance against Google Analytics" ID="ID_689673348" CREATED="1678457376554" MODIFIED="1678457389366" LINK="https://www.simpleanalytics.com/blog/norway-takes-a-stance-against-google-analytics"/>
<node TEXT="Social Media Is Changing, And Paid Accounts Are The Response" ID="ID_921829685" CREATED="1678457406501" MODIFIED="1678457418722" LINK="https://www.bigtechnology.com/p/social-media-is-changing-and-paid"/>
<node TEXT="Linkedin post by Barry Scanell on EU AI law" ID="ID_1689724175" CREATED="1683792974440" MODIFIED="1685195739198" LINK="https://www.linkedin.com/posts/activity-7062324196256735232-FfEz/?utm_source=share&amp;utm_medium=member_desktop">
<icon BUILTIN="attach"/>
</node>
<node TEXT="wikipedia and the child protection bill" ID="ID_14741621" CREATED="1683812159131" MODIFIED="1683812171553" LINK="https://www.msn.com/en-gb/news/uknews/wikipedia-could-be-taken-offline-in-the-uk/ar-AA1atf9O"/>
<node TEXT="Kids are damaged by mobile phones" ID="ID_480746664" CREATED="1684168904254" MODIFIED="1684168912916" LINK="https://sapienlabs.org/wp-content/uploads/2023/05/Sapien-Labs-Age-of-First-Smartphone-and-Mental-Wellbeing-Outcomes.pdf?utm_source=substack&amp;utm_medium=email"/>
<node TEXT="surveillance-capitalism-is-undermining-democracy" ID="ID_1274809163" CREATED="1686508029148" MODIFIED="1686557185314" LINK="https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy/"/>
<node TEXT="https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar" ID="ID_630296795" CREATED="1686508029158" MODIFIED="1686508029158" LINK="https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar"/>
</node>
<node TEXT="Scene capture" FOLDED="true" POSITION="left" ID="ID_630117933" CREATED="1678042008464" MODIFIED="1678042441538">
<edge COLOR="#0000ff"/>
<node TEXT="Fantastical NeRFs" ID="ID_1365164684" CREATED="1667813624731" MODIFIED="1673174158056">
<icon BUILTIN="bookmark"/>
<icon BUILTIN="clock2"/>
<node TEXT="History of NeRFs" ID="ID_1941361668" CREATED="1677766628580" MODIFIED="1677766637490" LINK="https://neuralradiancefields.io/history-of-neural-radiance-fields/"/>
<node TEXT="waiting on capture" ID="ID_1290598733" CREATED="1668679244205" MODIFIED="1668679499877">
<icon BUILTIN="bookmark"/>
<node TEXT="use polycam" ID="ID_1815259586" CREATED="1668768747074" MODIFIED="1668768750526"/>
<node TEXT="try the BTS cam?" ID="ID_1315444282" CREATED="1668768751802" MODIFIED="1668768759494"/>
</node>
<node TEXT="Nerfs" ID="ID_1137230659" CREATED="1665299853377" MODIFIED="1665299857346" LINK="https://www.matthewtancik.com/nerf"/>
<node TEXT="viewier" ID="ID_51747702" CREATED="1668099642504" MODIFIED="1668099651878" LINK="https://github.com/sxyu/volrend"/>
<node TEXT="Windows NeRF environment to WebGL" ID="ID_1751038439" CREATED="1668424886663" MODIFIED="1668768738316">
<node TEXT="install windows NeRF" ID="ID_986582555" CREATED="1668425625837" MODIFIED="1668425634158" LINK="https://github.com/bycloudai/instant-ngp-Windows"/>
</node>
<node TEXT="check out mip nerf 360s" ID="ID_1925332958" CREATED="1668429688478" MODIFIED="1668429694956"/>
<node TEXT="Record3D" ID="ID_369564702" CREATED="1668679576860" MODIFIED="1668679583071" LINK="https://github.com/marek-simonik/record3d_unity_streaming"/>
<node TEXT="github of links" ID="ID_1651809442" CREATED="1667242836413" MODIFIED="1667242841224" LINK="https://github.com/yenchenlin/awesome-NeRF"/>
<node TEXT="nerfs with polycam" ID="ID_1433274364" CREATED="1668768079651" MODIFIED="1668768089421" LINK="https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F?utm_source=share&amp;utm_medium=member_desktop">
<node TEXT="Polycam developer mode instructions" ID="ID_947586574" CREATED="1668768281027" MODIFIED="1668768292951" LINK="https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#polycam-capture"/>
</node>
<node TEXT="Nerf to animated people oneshot" ID="ID_956210623" CREATED="1670343995965" MODIFIED="1670344010410" LINK="https://elicit3d.github.io/"/>
<node TEXT="4K ultra high res nerfs with code" ID="ID_373426679" CREATED="1670868497340" MODIFIED="1670868507850" LINK="https://paperswithcode.com/paper/4k-nerf-high-fidelity-neural-radiance-fields">
<node TEXT="code" ID="ID_1891370674" CREATED="1670870071917" MODIFIED="1670870076091" LINK="https://github.com/frozoul/4K-NeRF"/>
</node>
<node TEXT="city modelling" ID="ID_1968508676" CREATED="1671365651859" MODIFIED="1671365658078" LINK="https://www.reddit.com/r/deeplearning/comments/zowgqn/neural_rendering_reconstruct_your_city_in_3d/"/>
<node TEXT="more city modelling" ID="ID_1636928173" CREATED="1672351891084" MODIFIED="1672351898945" LINK="https://waymo.com/research/block-nerf/"/>
<node TEXT="field guide" ID="ID_1341826905" CREATED="1672593265708" MODIFIED="1672593273648" LINK="https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks"/>
<node TEXT="NeRF SLAM" ID="ID_1344970588" CREATED="1672597353005" MODIFIED="1672597362088" LINK="https://github.com/ToniRV/NeRF-SLAM"/>
<node TEXT="NeuralUDF surface capture" ID="ID_1803867972" CREATED="1670438838319" MODIFIED="1670438861861" LINK="https://www.xxlong.site/NeuralUDF/"/>
<node TEXT="stablisation paper" ID="ID_794256628" CREATED="1673441494983" MODIFIED="1673441508663" LINK="https://arxiv.org/abs/2102.06205"/>
<node TEXT="nerfs without neural nets" ID="ID_504370686" CREATED="1673709416431" MODIFIED="1673709429008" LINK="https://alexyu.net/plenoxels/"/>
<node TEXT="NeuS2: Fast Learning of Neural Implicit Surfaces&#xa;for Multi-view Reconstruction" ID="ID_1225680097" CREATED="1673875896689" MODIFIED="1673875910913" LINK="https://vcai.mpi-inf.mpg.de/projects/NeuS2/"/>
<node TEXT="Original 2020 nerf paper" ID="ID_74849492" CREATED="1673892899398" MODIFIED="1673892908294" LINK="https://www.matthewtancik.com/nerf"/>
<node TEXT="Recolour NeRF" ID="ID_1493427982" CREATED="1674224076978" MODIFIED="1674224085361" LINK="https://sites.google.com/view/recolornerf?pli=1"/>
<node TEXT="Volinga Nerf into Unreal" ID="ID_781514951" CREATED="1674830505621" MODIFIED="1674830515674" LINK="https://volinga.ai/"/>
<node TEXT="Text2Nerf4D" ID="ID_159072040" CREATED="1674849047631" MODIFIED="1680620471854" LINK="https://make-a-video3d.github.io/"/>
<node TEXT="Robust nerfs which deal with occlusion" ID="ID_710655329" CREATED="1675602420553" MODIFIED="1680620470007" LINK="https://robustnerf.github.io/public/"/>
<node TEXT="Blender integration" ID="ID_1881431985" CREATED="1676485311770" MODIFIED="1676485318606" LINK="https://github.com/JamesPerlman/NeRFRenderCore/blob/main/src/integrations/blender.cuh"/>
<node TEXT="Rapidnerf VR integration with erase" ID="ID_520550284" CREATED="1676748354008" MODIFIED="1680620474090" LINK="https://github.com/NVlabs/instant-ngp#vr-controls"/>
<node TEXT="Nerf to large scale geom" ID="ID_697303271" CREATED="1677761936393" MODIFIED="1677761946675" LINK="https://bakedsdf.github.io/"/>
<node TEXT="ELICIT,ELICIT creates free-viewpoint motion videos from a single image by constructing an animatable NeRF representation in one-shot learning. Offcial website of &apos;One-shot Implicit Animatable Avatars with Model-based Priors&apos; " ID="ID_859304432" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://elicit3d.github.io/"/>
<node TEXT=" GitHub - frozoul/4K-NeRF: Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions   , Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions   - GitHub - frozoul/4K-NeRF: Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions    " ID="ID_359819614" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://github.com/frozoul/4k-nerf"/>
<node TEXT="ClimateNeRF,- " ID="ID_306273221" CREATED="1677783034639" MODIFIED="1677783034639" LINK="https://climatenerf.github.io/"/>
<node TEXT="GitHub - ToniRV/NeRF-SLAM: NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields. " ID="ID_1847862149" CREATED="1677783034639" MODIFIED="1685195529376" LINK="https://github.com/tonirv/nerf-slam">
<icon BUILTIN="attach"/>
</node>
<node TEXT="HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video,HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video " ID="ID_1887316579" CREATED="1677783034639" MODIFIED="1685195529376" LINK="https://grail.cs.washington.edu/projects/humannerf/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="editing nerfs with instructions" ID="ID_1449650097" CREATED="1679569831805" MODIFIED="1685195529376" LINK="https://instruct-nerf2nerf.github.io/">
<icon BUILTIN="attach"/>
<node TEXT="instruct2nerf twitter thread" ID="ID_1292727805" CREATED="1679597521648" MODIFIED="1679597532923" LINK="https://mobile.twitter.com/bilawalsidhu/status/1638919452392583169"/>
</node>
<node TEXT="Render without cuda using just pytorch" ID="ID_639308187" CREATED="1680110545051" MODIFIED="1680110556688" LINK="https://github.com/taichi-dev/taichi-nerfs"/>
<node TEXT="Nerf with free camera trajectory" ID="ID_1010453978" CREATED="1680203711057" MODIFIED="1685195529374" LINK="https://totoro97.github.io/projects/f2-nerf/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Language embedded nerfs (LERFS)" ID="ID_371201958" CREATED="1680259588303" MODIFIED="1685195529376" LINK="https://www.lerf.io/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="Splatting paper, go where you like" ID="ID_1790997524" CREATED="1683218338722" MODIFIED="1685195529376" LINK="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/">
<icon BUILTIN="attach"/>
</node>
<node TEXT="nerf RPN" ID="ID_1925774521" CREATED="1683320970439" MODIFIED="1683320982543" LINK="https://github.com/lyclyc52/NeRF_RPN"/>
<node TEXT="google indoor reconstruction from nerfs" ID="ID_255026239" CREATED="1687165266388" MODIFIED="1687166579584" LINK="https://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html"/>
<node TEXT="focal length for capture" ID="ID_856854805" CREATED="1689020488829" MODIFIED="1689020497378" LINK="https://neuralradiancefields.io/whats-the-best-focal-length-to-take-a-nerf/"/>
<node ID="ID_78068785" CREATED="1687805149139" MODIFIED="1687805149139" LINK="https://jonbarron.info/zipnerf/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper &quot;Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields&quot; proposes a technique that combines ideas from rendering and signal processing to combat aliasing in grid-based representations of neural radiance fields (NeRF). NeRF's learned mapping from spatial coordinates to colors and volumetric density can be accelerated through the use of grid-based representations, but they lack an explicit understanding of scale and often introduce aliasing. The proposed technique combines mip-NeRF 360 and Instant NGP to yield error rates that are 8%-77% lower than either prior technique and trains 24x faster than mip-NeRF 360. The technique uses multisampling to approximate the average NGP feature over a conical frustum, and the method produces prefiltered renderings that do not flicker or shimmer, even as the camera moves laterally. Moreover, their improvements to proposal network supervision result in a prefiltered proposal output that preserves the foreground object for all frames, preventing an artifact called z-aliasing where foreground content alternately appears and disappears as the camera moves towards or away from the scene content. The proposed method shows promising results for accelerating NeRF training while combating aliasing in grid-based representations. https://jonbarron.info/zipnerf/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="Gaussian splating (paper of the year siggraph)" ID="ID_1856756957" CREATED="1688996514789" MODIFIED="1688996531651" LINK="https://github.com/graphdeco-inria/gaussian-splatting"/>
<node TEXT="baked nerf mesh paper" ID="ID_1706141268" CREATED="1691656255332" MODIFIED="1691656264193" LINK="https://bakedsdf.github.io/"/>
</node>
<node TEXT="RP-Lidar + Raspberry pi + ROS RTAB-MAP" ID="ID_1868010211" CREATED="1673816545467" MODIFIED="1680620499221">
<node TEXT="RTAB-Map" ID="ID_1293686985" CREATED="1673816570803" MODIFIED="1673816577662" LINK="http://introlab.github.io/rtabmap/"/>
</node>
<node TEXT="Reality Scan" ID="ID_1544823716" CREATED="1674223422589" MODIFIED="1680620490484" LINK="https://www.unrealengine.com/en-US/blog/realityscan-is-now-free-to-download-on-ios"/>
<node TEXT="Drone SLAM" ID="ID_880033062" CREATED="1674850143955" MODIFIED="1674850148253" LINK="https://www.youtube.com/watch?v=CEC5UwPV9gY"/>
<node TEXT="Adobe substance3d" ID="ID_1890843888" CREATED="1675685403847" MODIFIED="1680620493119" LINK="https://www.substance3d.com/"/>
<node TEXT="3DPresso" ID="ID_1368106035" CREATED="1680164085570" MODIFIED="1680620495739" LINK="https://3dpresso.ai/viewer?seq=mr3.yg5isic8KGJZ1DAjW5VMc"/>
<node TEXT="Apple point cloud rendering" ID="ID_1822867978" CREATED="1682589226405" MODIFIED="1682589237579" LINK="https://machinelearning.apple.com/research/pointersect"/>
<node TEXT="Nvidia NeuralAngelo" ID="ID_981729134" CREATED="1685743099751" MODIFIED="1685743110787" LINK="https://research.nvidia.com/labs/dir/neuralangelo/"/>
<node TEXT="OmniMotion track all pixels" ID="ID_986475998" CREATED="1686424887021" MODIFIED="1686424905407" LINK="https://huggingface.co/papers/2306.05422"/>
<node TEXT="Leica handheld scanner" ID="ID_1345833226" CREATED="1686944457392" MODIFIED="1686944470696" LINK="https://leica-geosystems.com/products/laser-scanners/autonomous-reality-capture/leica-blk2go-handheld-imaging-laser-scanner"/>
<node TEXT="Meshroom open source photogrammetry" ID="ID_1417640643" CREATED="1688134406250" MODIFIED="1688134418201" LINK="https://alicevision.org/#meshroom"/>
<node TEXT="Nira.app" ID="ID_1698446170" CREATED="1692980193406" MODIFIED="1692980198184" LINK="https://nira.app/"/>
<node TEXT="Houdini mesh from google earth" ID="ID_947150994" CREATED="1693335445659" MODIFIED="1693335455764" LINK="https://github.com/xjorma/EarthMeshHoudini?"/>
</node>
<node TEXT="Courses" FOLDED="true" POSITION="left" ID="ID_867355278" CREATED="1686401826531" MODIFIED="1686401829139">
<edge COLOR="#7c007c"/>
<node TEXT="generative AI course" ID="ID_235967198" CREATED="1685908156697" MODIFIED="1685908162349" LINK="https://www.cloudskillsboost.google/course_templates/536"/>
<node TEXT="staistics course" ID="ID_1795158584" CREATED="1686126986416" MODIFIED="1686126994390" LINK="https://www.youtube.com/watch?v=KbB0FjPg0mw&amp;list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo&amp;index=1"/>
<node TEXT="EdX AI course" ID="ID_542745835" CREATED="1686474213324" MODIFIED="1686474219583" LINK="https://learning.edx.org/course/course-v1:HarvardX+CS50AI+1T2020/home"/>
<node TEXT="Little book of deep learning" ID="ID_1352378584" CREATED="1686506938919" MODIFIED="1686506947150" LINK="https://fleuret.org/public/lbdl.pdf"/>
<node TEXT="Python Books" ID="ID_674505820" CREATED="1688376670583" MODIFIED="1688376677511" LINK="https://mksaad.wordpress.com/2019/04/03/open-source-python-programming-books-licensed-under-creative-commons/">
<node TEXT="Automate the boring stuff" ID="ID_1908608006" CREATED="1688376678099" MODIFIED="1688376697937" LINK="https://automatetheboringstuff.com/"/>
</node>
<node TEXT="Pitching" ID="ID_869517326" CREATED="1688561637894" MODIFIED="1688561673921" LINK="https://fi.co/insight/how-to-master-the-startup-pitch-watch-these-founder-showcase-winning-pitch-videos"/>
<node TEXT="Machine vision youtube series" ID="ID_1174935030" CREATED="1689194764733" MODIFIED="1689194773148" LINK="https://www.youtube.com/playlist?list=PLd3hlSJsX_In7qup928HaHmilugBGctuF"/>
<node TEXT="almost any machine learning free book" ID="ID_1989038801" CREATED="1689876908074" MODIFIED="1689876921309" LINK="https://github.com/abhishekkrthakur/approachingalmost"/>
<node TEXT="Age of BANI from Jamais Cascio" ID="ID_1104528395" CREATED="1690281752367" MODIFIED="1690281787607" LINK="https://ageofbani.com/"/>
<node TEXT="Furkan SD tutorials" ID="ID_551115469" CREATED="1690737069839" MODIFIED="1690737082074" LINK="https://github.com/FurkanGozukara/Stable-Diffusion/tree/main/Tutorials"/>
</node>
<node TEXT="funding stuff" FOLDED="true" POSITION="left" ID="ID_741004760" CREATED="1693594454774" MODIFIED="1693594458446">
<edge COLOR="#007c00"/>
<node TEXT="a16z opensource" ID="ID_306127230" CREATED="1693594459377" MODIFIED="1693594469331" LINK="https://a16z.com/2023/08/30/supporting-the-open-source-ai-community/"/>
</node>
<node TEXT="Unsorted" FOLDED="true" POSITION="right" ID="ID_1493101688" CREATED="1610381621824" MODIFIED="1694341904879" STYLE="oval">
<font SIZE="18"/>
<edge COLOR="#7c007c"/>
<node TEXT="Unsorted links" FOLDED="true" POSITION="right" ID="ID_951649133" CREATED="1687773353985" MODIFIED="1687809980752">
<edge COLOR="#0000ff"/>
<node TEXT="https://lmsys.org/blog/2023-06-29-longchat/" ID="ID_1737677765" CREATED="1692015690160" MODIFIED="1692015690160" LINK="https://lmsys.org/blog/2023-06-29-longchat/"/>
<node TEXT="https://huggingface.co/blog/inference-endpoints-llm" ID="ID_795234937" CREATED="1692015690160" MODIFIED="1692015690160" LINK="https://huggingface.co/blog/inference-endpoints-llm"/>
<node TEXT="https://link.medium.com/4GuOJbBccBb" ID="ID_1918161811" CREATED="1692015690165" MODIFIED="1692015690165" LINK="https://link.medium.com/4GuOJbBccBb"/>
<node TEXT="https://link.medium.com/4GuOJbBccBb" ID="ID_1641861630" CREATED="1692015690165" MODIFIED="1692015690165" LINK="https://link.medium.com/4GuOJbBccBb"/>
<node TEXT="https://replicate.com/anotherjesse/zeroscope-v2-xl" ID="ID_147642530" CREATED="1692015690167" MODIFIED="1692015690167" LINK="https://replicate.com/anotherjesse/zeroscope-v2-xl"/>
<node TEXT="https://github.com/civkit/documentation/blob/main/roadmap.md" ID="ID_440634772" CREATED="1692015690167" MODIFIED="1692015690167" LINK="https://github.com/civkit/documentation/blob/main/roadmap.md"/>
<node TEXT="https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting?utm_medium=reader2" ID="ID_787802205" CREATED="1692015690167" MODIFIED="1692015690167" LINK="https://www.oneusefulthing.org/p/what-ai-can-do-with-a-toolbox-getting?utm_medium=reader2"/>
<node TEXT="https://arxiv.org/abs/2305.14705" ID="ID_1240615805" CREATED="1692015690168" MODIFIED="1692015690168" LINK="https://arxiv.org/abs/2305.14705"/>
<node TEXT="https://codi-gen.github.io/" ID="ID_648973738" CREATED="1692015690169" MODIFIED="1692015690169" LINK="https://codi-gen.github.io/"/>
<node TEXT="https://cryptohayes.substack.com/p/massa" ID="ID_808779365" CREATED="1692015690169" MODIFIED="1692015690169" LINK="https://cryptohayes.substack.com/p/massa"/>
<node TEXT="https://github.com/tiangolo/fastapi" ID="ID_680262447" CREATED="1692015690170" MODIFIED="1692015690170" LINK="https://github.com/tiangolo/fastapi"/>
<node TEXT="https://github.com/facebook/igl/" ID="ID_1803270835" CREATED="1692015690171" MODIFIED="1692015690171" LINK="https://github.com/facebook/igl/"/>
<node TEXT="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" ID="ID_1554017498" CREATED="1692015690171" MODIFIED="1692015690171" LINK="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/"/>
<node TEXT="https://chat.openai.com/share/afe54a2d-0ad0-4166-b1aa-9a5394deff66" ID="ID_1909559051" CREATED="1692015690172" MODIFIED="1692015690172" LINK="https://chat.openai.com/share/afe54a2d-0ad0-4166-b1aa-9a5394deff66"/>
<node TEXT="https://youtube.com/@MattVidPro" ID="ID_1120235901" CREATED="1692015690172" MODIFIED="1692015690172" LINK="https://youtube.com/@MattVidPro"/>
<node TEXT="https://www.ufried.com/blog/chatgpt_already_knows_4/" ID="ID_1010184758" CREATED="1692015690174" MODIFIED="1692015690174" LINK="https://www.ufried.com/blog/chatgpt_already_knows_4/"/>
<node TEXT="https://www.europarl.europa.eu/thinktank/en/document/EPRS_BRI(2021)698792" ID="ID_638868352" CREATED="1692015690174" MODIFIED="1692015690174" LINK="https://www.europarl.europa.eu/thinktank/en/document/EPRS_BRI(2021)698792"/>
<node TEXT="https://machinelearningmastery.com/mixture-of-experts/" ID="ID_1757908065" CREATED="1692015690174" MODIFIED="1692015690174" LINK="https://machinelearningmastery.com/mixture-of-experts/"/>
<node TEXT="https://techpolicy.press/extended-reality-and-the-law/" ID="ID_553267882" CREATED="1692015690175" MODIFIED="1692015690175" LINK="https://techpolicy.press/extended-reality-and-the-law/"/>
<node TEXT="https://www.reddit.com/r/StableDiffusion/comments/14v9gnz/nangijala_new_advanced_and_detailed_model/" ID="ID_1072030017" CREATED="1692015690176" MODIFIED="1692015690176" LINK="https://www.reddit.com/r/StableDiffusion/comments/14v9gnz/nangijala_new_advanced_and_detailed_model/"/>
<node TEXT="https://explosion.ai/blog/against-llm-maximalism" ID="ID_434402767" CREATED="1692015690176" MODIFIED="1692015690176" LINK="https://explosion.ai/blog/against-llm-maximalism"/>
<node TEXT="https://github.com/SytanSD/Sytan-SDXL-ComfyUI" ID="ID_1631192026" CREATED="1692015690178" MODIFIED="1692015690178" LINK="https://github.com/SytanSD/Sytan-SDXL-ComfyUI"/>
<node TEXT="https://github.com/omniinfer/sd-webui-cloud-inference" ID="ID_1817090242" CREATED="1692015690179" MODIFIED="1692015690179" LINK="https://github.com/omniinfer/sd-webui-cloud-inference"/>
<node TEXT="https://github.com/immich-app/immich" ID="ID_1401357623" CREATED="1692015690179" MODIFIED="1692015690179" LINK="https://github.com/immich-app/immich"/>
<node TEXT="https://aka.ms/AAl369f" ID="ID_221491405" CREATED="1692015690180" MODIFIED="1692015690180" LINK="https://aka.ms/AAl369f"/>
<node TEXT="https://github.com/huggingface/diffusers/releases/tag/v0.18.0" ID="ID_1729466085" CREATED="1692015690180" MODIFIED="1692015690180" LINK="https://github.com/huggingface/diffusers/releases/tag/v0.18.0"/>
<node TEXT="https://promptlib.com/" ID="ID_415410964" CREATED="1692015690181" MODIFIED="1692015690181" LINK="https://promptlib.com/"/>
<node TEXT="https://open.spotify.com/episode/0sFi0yG6kpTVKE0WVtRhTZ?si=te1jwhxCTWa-kJWwq3RxCA" ID="ID_1256364850" CREATED="1692015690182" MODIFIED="1692015690182" LINK="https://open.spotify.com/episode/0sFi0yG6kpTVKE0WVtRhTZ?si=te1jwhxCTWa-kJWwq3RxCA"/>
<node TEXT="https://www.linkedin.com/posts/youngjo-cho-789755126_animatediff-stablediffusion-lora-activity-7084871707672408064-5Usm?utm_source=share&amp;utm_medium=member_android" ID="ID_1268431350" CREATED="1692015690182" MODIFIED="1692015690182" LINK="https://www.linkedin.com/posts/youngjo-cho-789755126_animatediff-stablediffusion-lora-activity-7084871707672408064-5Usm?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="https://arxiv.org/abs/2303.18223" ID="ID_1382474528" CREATED="1692015690184" MODIFIED="1692015690184" LINK="https://arxiv.org/abs/2303.18223"/>
<node TEXT="https://bitcoinresearch.xyz/?ref=nobsbitcoin.com" ID="ID_854134212" CREATED="1692015690185" MODIFIED="1692015690185" LINK="https://bitcoinresearch.xyz/?ref=nobsbitcoin.com"/>
<node TEXT="http://gwang-kim.github.io/datid_3d" ID="ID_950761716" CREATED="1692015690185" MODIFIED="1692015690185" LINK="http://gwang-kim.github.io/datid_3d"/>
<node TEXT="https://apply-for-innovation-funding.service.gov.uk/competition/1657/overview/428ee709-8802-4277-bcd3-e9c6f212ef7c#summary" ID="ID_1073214796" CREATED="1692015690186" MODIFIED="1692015690186" LINK="https://apply-for-innovation-funding.service.gov.uk/competition/1657/overview/428ee709-8802-4277-bcd3-e9c6f212ef7c#summary"/>
<node TEXT="https://www.sniffnet.net/" ID="ID_1605860487" CREATED="1692015690186" MODIFIED="1692015690186" LINK="https://www.sniffnet.net/"/>
<node TEXT="https://blog.monsterapi.ai/no-code-fine-tuning-llm/" ID="ID_1748738798" CREATED="1692015690187" MODIFIED="1692015690187" LINK="https://blog.monsterapi.ai/no-code-fine-tuning-llm/"/>
<node TEXT="https://arxiv.org/abs/2307.03172" ID="ID_709610673" CREATED="1692015690188" MODIFIED="1692015690188" LINK="https://arxiv.org/abs/2307.03172"/>
<node TEXT="https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf" ID="ID_1966329902" CREATED="1692015690190" MODIFIED="1692015690190" LINK="https://nikhilpentapalli.substack.com/p/langchain-in-detail?sd=pf"/>
<node TEXT="https://lilianweng.github.io/posts/2023-06-23-agent/" ID="ID_947351643" CREATED="1692015690191" MODIFIED="1692015690191" LINK="https://lilianweng.github.io/posts/2023-06-23-agent/"/>
<node TEXT="https://github.com/StanGirard/quivr" ID="ID_1196442205" CREATED="1692015690192" MODIFIED="1692015690192" LINK="https://github.com/StanGirard/quivr"/>
<node TEXT="https://fake-up.net/project/stacks" ID="ID_69809483" CREATED="1692015690193" MODIFIED="1692015690193" LINK="https://fake-up.net/project/stacks"/>
<node TEXT="https://huggingface.co/docs/accelerate/usage_guides/quantization" ID="ID_1961832924" CREATED="1692015690193" MODIFIED="1692015690193" LINK="https://huggingface.co/docs/accelerate/usage_guides/quantization"/>
<node TEXT="https://sandner.art/photomatix-unleashing-photorealism-in-ai-art-through-the-stable-diffusion-base-model/" ID="ID_891033793" CREATED="1692015690193" MODIFIED="1692015690193" LINK="https://sandner.art/photomatix-unleashing-photorealism-in-ai-art-through-the-stable-diffusion-base-model/"/>
<node TEXT="http://arxiv.org/abs/2307.03869v1" ID="ID_836799159" CREATED="1692015690196" MODIFIED="1692015690196" LINK="http://arxiv.org/abs/2307.03869v1"/>
<node TEXT="https://samsunglabs.github.io/NeuralHaircut/" ID="ID_1171704015" CREATED="1692015690196" MODIFIED="1692015690196" LINK="https://samsunglabs.github.io/NeuralHaircut/"/>
<node TEXT="https://www.reddit.com/r/StableDiffusion/comments/154126e/heres_a_quick_tutorial_about_how_to_clone_any/" ID="ID_856300600" CREATED="1692015690197" MODIFIED="1692015690197" LINK="https://www.reddit.com/r/StableDiffusion/comments/154126e/heres_a_quick_tutorial_about_how_to_clone_any/"/>
<node TEXT="https://www.assemblyai.com/playground/" ID="ID_1617393119" CREATED="1692015690197" MODIFIED="1692015690197" LINK="https://www.assemblyai.com/playground/"/>
<node TEXT="https://github.com/Chainlit/chainlit" ID="ID_571801945" CREATED="1692015690199" MODIFIED="1692015690199" LINK="https://github.com/Chainlit/chainlit"/>
<node TEXT="https://arxiv.org/abs/2307.09288" ID="ID_320995153" CREATED="1692015690199" MODIFIED="1692015690199" LINK="https://arxiv.org/abs/2307.09288"/>
<node TEXT="https://3d.csm.ai/" ID="ID_598739151" CREATED="1692015690200" MODIFIED="1692015690200" LINK="https://3d.csm.ai/"/>
<node TEXT="https://ilumine.ai/metaverse-explorer-demo/" ID="ID_810835283" CREATED="1692015690201" MODIFIED="1692015690201" LINK="https://ilumine.ai/metaverse-explorer-demo/"/>
<node TEXT="https://www.nobsbitcoin.com/mycitadel-desktop-v1-4/" ID="ID_278576634" CREATED="1692015690202" MODIFIED="1692015690202" LINK="https://www.nobsbitcoin.com/mycitadel-desktop-v1-4/"/>
<node TEXT="https://github.com/Coldcard/firmware/blob/master/docs/bip85-passwords.md" ID="ID_55472306" CREATED="1692015690202" MODIFIED="1692015690202" LINK="https://github.com/Coldcard/firmware/blob/master/docs/bip85-passwords.md"/>
<node TEXT="https://blixtwallet.github.io/" ID="ID_712214069" CREATED="1692015690204" MODIFIED="1692015690204" LINK="https://blixtwallet.github.io/"/>
<node TEXT="https://www.nobsbitcoin.com/data-vending-machine-implementation-open-sourced/" ID="ID_1594144018" CREATED="1692015690205" MODIFIED="1692015690205" LINK="https://www.nobsbitcoin.com/data-vending-machine-implementation-open-sourced/"/>
<node TEXT="https://github.com/22388o/bitpac/blob/main/README.md" ID="ID_897024679" CREATED="1692015690206" MODIFIED="1692015690206" LINK="https://github.com/22388o/bitpac/blob/main/README.md"/>
<node TEXT="https://enteropositivo.github.io/bip39colors/#biptocolors" ID="ID_662326850" CREATED="1692015690209" MODIFIED="1692015690209" LINK="https://enteropositivo.github.io/bip39colors/#biptocolors"/>
<node TEXT="https://10101.finance/" ID="ID_1618718112" CREATED="1692015690210" MODIFIED="1692015690210" LINK="https://10101.finance/"/>
<node TEXT="https://www.zapplepay.com/" ID="ID_947875054" CREATED="1692015690210" MODIFIED="1692015690210" LINK="https://www.zapplepay.com/"/>
<node TEXT="https://lightning.engineering/posts/2023-07-05-l402-langchain/" ID="ID_889536126" CREATED="1692015690211" MODIFIED="1692015690211" LINK="https://lightning.engineering/posts/2023-07-05-l402-langchain/"/>
<node TEXT="https://www.nobsbitcoin.com/mutinynet/" ID="ID_986163082" CREATED="1692015690212" MODIFIED="1692015690212" LINK="https://www.nobsbitcoin.com/mutinynet/"/>
<node TEXT="https://github.com/microsoft/Typechat" ID="ID_722055651" CREATED="1692015690213" MODIFIED="1692015690213" LINK="https://github.com/microsoft/Typechat"/>
<node TEXT="https://cohost.org/mcc/post/1406157-i-want-to-talk-about" ID="ID_1903965335" CREATED="1692015690213" MODIFIED="1692015690213" LINK="https://cohost.org/mcc/post/1406157-i-want-to-talk-about"/>
<node TEXT="https://cheapskatesguide.org/articles/big-tech-takeovers.html" ID="ID_859753217" CREATED="1692015690215" MODIFIED="1692015690215" LINK="https://cheapskatesguide.org/articles/big-tech-takeovers.html"/>
<node TEXT="https://svmy.io/?p=306" ID="ID_363797407" CREATED="1692015690216" MODIFIED="1692015690216" LINK="https://svmy.io/?p=306"/>
<node TEXT="https://iuk.ktn-uk.org/opportunities/futurescope-bridgeai-acceleration-programme-digital-catapult/" ID="ID_1264727244" CREATED="1692015690216" MODIFIED="1692015690216" LINK="https://iuk.ktn-uk.org/opportunities/futurescope-bridgeai-acceleration-programme-digital-catapult/"/>
<node TEXT="https://www.assemblyai.com/blog/lemur/" ID="ID_627306766" CREATED="1692015690218" MODIFIED="1692015690218" LINK="https://www.assemblyai.com/blog/lemur/"/>
<node TEXT="https://www.linkedin.com/posts/miguelgfierro_ai-machinelearning-datascience-activity-7090210944714207235-YUl8?utm_source=share&amp;utm_medium=member_android" ID="ID_1309187761" CREATED="1692015690219" MODIFIED="1692015690219" LINK="https://www.linkedin.com/posts/miguelgfierro_ai-machinelearning-datascience-activity-7090210944714207235-YUl8?utm_source=share&amp;utm_medium=member_android"/>
<node TEXT="https://www.patreon.com/realvr" ID="ID_972838299" CREATED="1692015690220" MODIFIED="1692015690220" LINK="https://www.patreon.com/realvr"/>
<node TEXT="https://github.com/facebookresearch/NeRF-Det" ID="ID_1583656213" CREATED="1692015690221" MODIFIED="1692015690221" LINK="https://github.com/facebookresearch/NeRF-Det"/>
<node TEXT="https://replit.com/bounties?service=9" ID="ID_1235501554" CREATED="1692015690222" MODIFIED="1692015690222" LINK="https://replit.com/bounties?service=9"/>
<node TEXT="https://llm-attacks.org/" ID="ID_1145465957" CREATED="1692015690222" MODIFIED="1692015690222" LINK="https://llm-attacks.org/"/>
<node TEXT="https://jalammar.github.io/illustrated-stable-diffusion/" ID="ID_746290444" CREATED="1692015690223" MODIFIED="1692015690223" LINK="https://jalammar.github.io/illustrated-stable-diffusion/"/>
<node TEXT="https://www.reddit.com/r/StableDiffusion/comments/115yz03/lora_trigger_words/" ID="ID_57071557" CREATED="1692015690223" MODIFIED="1692015690223" LINK="https://www.reddit.com/r/StableDiffusion/comments/115yz03/lora_trigger_words/"/>
<node TEXT="https://arxiv.org/abs/2307.08621" ID="ID_831451457" CREATED="1692015690224" MODIFIED="1692015690224" LINK="https://arxiv.org/abs/2307.08621"/>
<node TEXT="https://thegradient.pub/why-transformative-artificial-intelligence-is-really-really-hard-to-achieve/" ID="ID_666633145" CREATED="1692015690225" MODIFIED="1692015690225" LINK="https://thegradient.pub/why-transformative-artificial-intelligence-is-really-really-hard-to-achieve/"/>
<node TEXT="https://deeprevision.github.io/posts/001-transformer/" ID="ID_28005170" CREATED="1692015690226" MODIFIED="1692015690226" LINK="https://deeprevision.github.io/posts/001-transformer/"/>
<node TEXT="https://github.com/ShishirPatil/gorilla" ID="ID_867911291" CREATED="1692015690227" MODIFIED="1692015690227" LINK="https://github.com/ShishirPatil/gorilla"/>
<node TEXT="https://unum-cloud.github.io/usearch/" ID="ID_1065523098" CREATED="1692015690227" MODIFIED="1692015690227" LINK="https://unum-cloud.github.io/usearch/"/>
<node TEXT="https://www.reddit.com/r/virtualreality/comments/15eiipd/immersive_image_viewer_immergallery_119_now_with/" ID="ID_4043143" CREATED="1692015690227" MODIFIED="1692015690227" LINK="https://www.reddit.com/r/virtualreality/comments/15eiipd/immersive_image_viewer_immergallery_119_now_with/"/>
<node TEXT="https://github.com/marketplace/actions/github-action-for-latex" ID="ID_600889252" CREATED="1692015690229" MODIFIED="1692015690229" LINK="https://github.com/marketplace/actions/github-action-for-latex"/>
<node TEXT="https://bit.ly/3rWoote" ID="ID_1402156141" CREATED="1692015690230" MODIFIED="1692015690230" LINK="https://bit.ly/3rWoote"/>
<node TEXT="https://arxiv.org/abs/2307.08378" ID="ID_911436208" CREATED="1692015690230" MODIFIED="1692015690230" LINK="https://arxiv.org/abs/2307.08378"/>
<node TEXT="https://huggingface.co/abacusai/Giraffe-v1-delta-13b-scaled-16" ID="ID_1018439461" CREATED="1692015690231" MODIFIED="1692015690231" LINK="https://huggingface.co/abacusai/Giraffe-v1-delta-13b-scaled-16"/>
<node TEXT="https://github.com/graviraja/MLOps-Basics/tree/main" ID="ID_1861147289" CREATED="1692015690231" MODIFIED="1692015690231" LINK="https://github.com/graviraja/MLOps-Basics/tree/main"/>
<node TEXT="https://erichartford.com/uncensored-models" ID="ID_1807004868" CREATED="1692015690232" MODIFIED="1692015690232" LINK="https://erichartford.com/uncensored-models"/>
<node TEXT="https://blog.jupyter.org/generative-ai-in-jupyter-3f7174824862" ID="ID_507941890" CREATED="1692015690233" MODIFIED="1692015690233" LINK="https://blog.jupyter.org/generative-ai-in-jupyter-3f7174824862"/>
<node TEXT="https://open.substack.com/pub/oneusefulthing/p/how-to-use-ai-to-do-stuff-an-opinionated?utm_campaign=post&amp;utm_medium=web" ID="ID_531969311" CREATED="1692015690233" MODIFIED="1692015690233" LINK="https://open.substack.com/pub/oneusefulthing/p/how-to-use-ai-to-do-stuff-an-opinionated?utm_campaign=post&amp;utm_medium=web"/>
<node TEXT="https://github.com/facebookresearch/audiocraft" ID="ID_1950944037" CREATED="1692015690234" MODIFIED="1692015690234" LINK="https://github.com/facebookresearch/audiocraft"/>
<node TEXT="https://www.meta.com/en-gb/blog/quest/reality-labs-research-display-systems-siggraph-2023-butterscotch-varifocal-flamera/" ID="ID_170482730" CREATED="1692015690236" MODIFIED="1692015690236" LINK="https://www.meta.com/en-gb/blog/quest/reality-labs-research-display-systems-siggraph-2023-butterscotch-varifocal-flamera/"/>
<node TEXT="https://github.com/philschmid/easyllm" ID="ID_1783981367" CREATED="1692015690236" MODIFIED="1692015690236" LINK="https://github.com/philschmid/easyllm"/>
<node TEXT="https://github.com/google-research/maxim" ID="ID_176921696" CREATED="1692015690238" MODIFIED="1692015690238" LINK="https://github.com/google-research/maxim"/>
<node TEXT="https://www.youtube.com/watch?v=3fsn19OI_C8&amp;ab_channel=AbhishekThakur" ID="ID_1756479492" CREATED="1692015690238" MODIFIED="1692015690238" LINK="https://www.youtube.com/watch?v=3fsn19OI_C8&amp;ab_channel=AbhishekThakur"/>
<node TEXT="https://www.reddit.com/r/StableDiffusion/comments/15ie1ka/photo_colorizationrestoration_with_deoldify/" ID="ID_1732447874" CREATED="1692015690239" MODIFIED="1692015690239" LINK="https://www.reddit.com/r/StableDiffusion/comments/15ie1ka/photo_colorizationrestoration_with_deoldify/"/>
<node TEXT="https://github.com/geekan/MetaGPT" ID="ID_261142255" CREATED="1692015690240" MODIFIED="1692015690240" LINK="https://github.com/geekan/MetaGPT"/>
<node TEXT="https://www.reddit.com/r/Python/comments/15jnv9f/i_built_yet_another_chatgpt_telegram_bot/" ID="ID_1533113658" CREATED="1692015690241" MODIFIED="1692015690241" LINK="https://www.reddit.com/r/Python/comments/15jnv9f/i_built_yet_another_chatgpt_telegram_bot/"/>
<node TEXT="https://research.nvidia.com/labs/par/Perfusion/" ID="ID_962401835" CREATED="1692015690241" MODIFIED="1692015690241" LINK="https://research.nvidia.com/labs/par/Perfusion/"/>
<node TEXT="https://huggingface.co/blog/sd_distillation" ID="ID_1585259525" CREATED="1692015690242" MODIFIED="1692015690242" LINK="https://huggingface.co/blog/sd_distillation"/>
<node TEXT="https://medium.com/@joaolages/the-quest-to-have-endless-conversations-with-llama-and-chatgpt-%EF%B8%8F-81360b9b34b2" ID="ID_1897179650" CREATED="1692015690243" MODIFIED="1692015690243" LINK="https://medium.com/@joaolages/the-quest-to-have-endless-conversations-with-llama-and-chatgpt-%EF%B8%8F-81360b9b34b2"/>
<node TEXT="https://llmops.space/" ID="ID_625729291" CREATED="1692015690243" MODIFIED="1692015690243" LINK="https://llmops.space/"/>
<node TEXT="https://github.com/RoboCoachTechnologies/GPT-Synthesizer" ID="ID_1167964386" CREATED="1692015690244" MODIFIED="1692015690244" LINK="https://github.com/RoboCoachTechnologies/GPT-Synthesizer"/>
<node TEXT="https://github.com/huggingface/diffusers/releases/tag/v0.19.0" ID="ID_755825697" CREATED="1692015690245" MODIFIED="1692015690245" LINK="https://github.com/huggingface/diffusers/releases/tag/v0.19.0"/>
<node TEXT="https://stability.ai/blog/stablecode-llm-generative-ai-coding" ID="ID_1439237451" CREATED="1692015690246" MODIFIED="1692015690246" LINK="https://stability.ai/blog/stablecode-llm-generative-ai-coding"/>
<node TEXT="http://www.limitlessflight.com" ID="ID_1911623901" CREATED="1692015690247" MODIFIED="1692015690247" LINK="http://www.limitlessflight.com"/>
<node TEXT="https://arxiv.org/abs/2307.05695" ID="ID_253067149" CREATED="1692015690247" MODIFIED="1692015690247" LINK="https://arxiv.org/abs/2307.05695"/>
<node TEXT="https://news.bloombergtax.com/daily-tax-report-state/texas-offers-new-tax-benefit-to-attract-bitcoin-miners" ID="ID_401815109" CREATED="1692015690248" MODIFIED="1692015690248" LINK="https://news.bloombergtax.com/daily-tax-report-state/texas-offers-new-tax-benefit-to-attract-bitcoin-miners"/>
<node TEXT="https://huggingface.co/papers/2308.04079" ID="ID_485744552" CREATED="1692015690249" MODIFIED="1692015690249" LINK="https://huggingface.co/papers/2308.04079"/>
<node TEXT="https://github.com/graphdeco-inria/gaussian-splatting" ID="ID_1586530359" CREATED="1692015690250" MODIFIED="1692015690250" LINK="https://github.com/graphdeco-inria/gaussian-splatting"/>
<node TEXT="Radical agnosticism in the face of MORE intelligence" ID="ID_759250053" CREATED="1692015690250" MODIFIED="1692015690250"/>
<node TEXT="https://seb.jambor.dev/posts/understanding-activitypub/" ID="ID_1332062238" CREATED="1692015690252" MODIFIED="1692015690252" LINK="https://seb.jambor.dev/posts/understanding-activitypub/"/>
<node TEXT="https://github.com/FurkanGozukara/Stable-Diffusion" ID="ID_1986595744" CREATED="1692015690252" MODIFIED="1692015690252" LINK="https://github.com/FurkanGozukara/Stable-Diffusion"/>
<node TEXT="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=998565" ID="ID_93939460" CREATED="1692015690252" MODIFIED="1692015690252" LINK="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=998565"/>
<node TEXT="https://civitai.com/models/128046/wojak-sdxl" ID="ID_656146307" CREATED="1692015690253" MODIFIED="1692015690253" LINK="https://civitai.com/models/128046/wojak-sdxl"/>
</node>
<node FOLDED="true" POSITION="left" ID="ID_1274610721" CREATED="1687772158417" MODIFIED="1689008427804" LINK="https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-bottom: 0px; margin-top: 0px; padding-left: 0; display: block">
        <p style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px">
          <strong style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-weight: 600; color: black"><b><font color="black">MTIA v1: Meta’s first-generation AI inference accelerator</font></b></strong>​<span class="" data-state="closed" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px"><a href="https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500; padding-left: 0; padding-right: 0"><font color="black" size="12px"><u><b><sup style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-size: 12px; line-height: 0; vertical-align: baseline">1</sup></b></u></font></a></span>​
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
<node ID="ID_1601839141" CREATED="1687772158419" MODIFIED="1687772158419"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        This is the first-generation AI inference accelerator by Meta, designed to handle Meta's specific recommendation workloads more efficiently than GPUs.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_379498048" CREATED="1687772158421" MODIFIED="1687772158421"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The accelerator, fabricated in TSMC 7nm process, runs at 800 MHz, providing 102.4 TOPS at INT8 precision and 51.2 TFLOPS at FP16 precision. It has a thermal design power (TDP) of 25 W.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_782524041" CREATED="1687772158422" MODIFIED="1687772158422"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The accelerator is equipped with a grid of 64 processing elements, on-chip and off-chip memory resources, and interconnects. It has dedicated control subsystems and memory subsystems.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_824728205" CREATED="1687772158423" MODIFIED="1687772158423"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The MTIA accelerators are mounted on small dual M.2 boards and are connected to the host CPU on the server using PCIe Gen4 x8 links.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_698242012" CREATED="1687772158423" MODIFIED="1687772158423"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The MTIA software stack integrates fully with PyTorch and supports different modes of execution, including eager mode and graph mode.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_973037601" CREATED="1687772158424" MODIFIED="1687772158424"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The MTIA software stack also provides the ability to author compute kernels using PyTorch, C/C++, and a new domain-specific language called KNYFE.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_886647120" CREATED="1687772158425" MODIFIED="1687772158425"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The initial performance comparison shows MTIA efficiency improvements in certain workload scenarios.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
</node>
<node FOLDED="true" POSITION="left" ID="ID_1348369267" CREATED="1687772158427" MODIFIED="1689008427808" LINK="https://eckertzhang.github.io/Text2NeRF.github.io"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-bottom: 0px; margin-top: 0px; padding-left: 0; display: block">
        <p style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px">
          <strong style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-weight: 600; color: black"><b><font color="black">EckertZhang's Text2NeRF</font></b></strong>​<span class="" data-state="closed" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px"><a href="https://eckertzhang.github.io/Text2NeRF.github.io" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500; padding-left: 0; padding-right: 0"><font color="black" size="12px"><u><b><sup style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; font-size: 12px; line-height: 0; vertical-align: baseline">2</sup></b></u></font></a></span>​
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
<font BOLD="false"/>
<edge COLOR="#0000ff"/>
</node>
<node FOLDED="true" POSITION="left" ID="ID_323829835" CREATED="1687772398091" MODIFIED="1689008427815" LINK="https://www.youtube.com/watch?v=fsg83BvsXww"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul>
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-bottom: 0px; margin-top: 0px; padding-left: 0; display: block">
        <p style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px">
          <a href="https://www.youtube.com/watch?v=fsg83BvsXww" target="_new" style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; color: black; text-decoration: underline; font-weight: 500"><font color="black"><u><b>Text-to-world: Generative AI for world creation with Kayla Comalli, Lovelace Studios | Nyric</b></u></font></a>
        </p>
      </li>
    </ul>
  </body>
</html>
</richcontent>
<font BOLD="false"/>
<edge COLOR="#00ff00"/>
<node ID="ID_1423103761" CREATED="1687772398092" MODIFIED="1687772398092"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <ul style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; list-style: disc; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0; padding-top: 0px; padding-right: 0px; padding-bottom: 0px; padding-left: 0px; display: flex">
      <li style="border-top-color: rgb(217, 217, 227); border-top-style: solid; border-top-width: 0px; border-right-color: rgb(217, 217, 227); border-right-style: solid; border-right-width: 0px; border-bottom-color: rgb(217, 217, 227); border-bottom-style: solid; border-bottom-width: 0px; border-left-color: rgb(217, 217, 227); border-left-style: solid; border-left-width: 0px; margin-top: 0px; margin-right: 0px; margin-bottom: 0px; margin-left: 0px; padding-left: 0; display: block">
        The YouTube page did not provide a detailed summary, but the video title suggests it's about generative AI for world creation featuring Kayla Comalli from Lovelace Studios.
      </li>
    </ul>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="The text describes the benefits of using the FinOps and MLOps open source platforms. These platforms allow for better management of financial operations and machine learning operations, respectively." POSITION="left" ID="ID_54320883" CREATED="1682414608762" MODIFIED="1689008427825" LINK="http://hystax.com">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="RFdiffusion is a codebase for running diffusion simulations. It is designed to work with the SE3-transformer library and to be used in conjunction with the PPI scaffold examples. Basic execution of the diffusion script is straightforward, and the inpaint_seq flag can be used to control the output. Partial diffusion is also possible, and the binder design can be used to constrain the diffusion." POSITION="left" ID="ID_261443580" CREATED="1682414608712" MODIFIED="1689008427828" LINK="https://github.com/RosettaCommons/RFdiffusion">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="Daily Study Group: The Wolfram Plugin for ChatGPT: Learn about the Wolfram ChatGPT plugin for access to powerful computation, curated knowledge, real-time data, visualization and even code generation. " POSITION="left" ID="ID_1571378094" CREATED="1682414608739" MODIFIED="1689008427830" LINK="https://wolfr.am/1cCK87Nms">
<edge COLOR="#00007c"/>
</node>
<node TEXT="Inferno is a distributed operating system which uses a file-like name hierarchy to represent services and resources, including devices, network and protocol interfaces, dynamic data sources, and services.Applications are written in a concurrent programming language, Limbo." POSITION="left" ID="ID_515682087" CREATED="1682414608760" MODIFIED="1689008427832" LINK="https://github.com/inferno-os/inferno-os">
<edge COLOR="#007c00"/>
<node TEXT="" ID="ID_1277050450" CREATED="1682414608762" MODIFIED="1682416769744"/>
</node>
<node TEXT="Arible Avatars &amp; Virtual Studio: Professional Photography Without Photographers Or The Camera: Unlimited Realistic or Artistic photos of yourself and others monthly" POSITION="left" ID="ID_1864150644" CREATED="1682414608715" MODIFIED="1689008427836" LINK="https://www.arible.co/prompts">
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1243538149" CREATED="1687805148471" MODIFIED="1689008427841"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Geoffrey Hinton, referred to as the “Godfather of AI”, has resigned from Google to speak more freely about the risks associated with artificial intelligence (AI). Speaking to The New York Times, Hinton suggested that intense competition in the development of AI could make the spread of misinformation too hard to detect. He also noted fears that AI will ultimately eliminate rote jobs, and even pose a risk to humanity if it begins to write and run its own code. “The idea that this stuff could actually get smarter than people — a few people believed that,” said Hinton. “But most people thought it was way off. And I thought it was way off. I thought it was 30 to 50 years or even longer away. Obviously, I no longer think that.”
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_602093330" CREATED="1687805148472" MODIFIED="1689008427844" LINK="https://www.theverge.com/2023/5/1/23706311/hinton-godfather-of-ai-threats-fears-warnings"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          https://www.theverge.com/2023/5/1/23706311/hinton-godfather-of-ai-threats-fears-warnings
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_209979720" CREATED="1687805148477" MODIFIED="1689008427848" LINK="https://www.wsj.com/articles/tiktok-feeds-teens-a-diet-of-darkness-8f350507"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The stock market data is provided, showing the current points and percentage changes for the DJIA, S&amp;P 500, Nasdaq, U.S. 10 Yr, Crude Oil, and Euro. The article discusses the prevalence of harmful content on the popular app TikTok, including self-harm, sad-posting, and disordered-eating videos, and the potential negative impact it can have on young users. The website also collects and stores user data for various purposes, including personalized advertising and content, measuring ad and content performance, and market research. Users can manage their privacy settings and opt-out of certain data collection practices. https://www.wsj.com/articles/tiktok-feeds-teens-a-diet-of-darkness-8f350507
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1201984920" CREATED="1687805148492" MODIFIED="1689008427849" LINK="https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article describes how to use OpenAI's ChatGPT chatbot on an Android phone using the Tasker app. Tasker can integrate ChatGPT into a native-feeling Android experience, with ChatGPT functioning as a personal assistant. The process involves downloading Tasker, AutoNotification, creating an OpenAI ChatGPT API key, importing the ChatGPT project from the Tasker app, defining a personality for ChatGPT, tapping the &quot;New Chat&quot; shortcut to initiate a conversation with ChatGPT and more. ChatGPT integration with Google Assistant is also possible by launching Google Assistant and saying &quot;run [task name] in Tasker&quot;. https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_688148565" CREATED="1687805148512" MODIFIED="1689008427860" LINK="https://www.youtube.com/@enigmatic_e"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This is a notification from Google that cookies and data are used to deliver and maintain their services, track outages, protect against spam and fraud, and measure engagement and statistics to improve their services. Personalized content and ads are also influenced by past activity and location. Users have the option to reject or accept all cookies, the latter allowing Google to use data to develop new services, measure ad effectiveness, and more. Privacy settings can be managed through g.co/privacytools. https://www.youtube.com/@enigmatic_e
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1643163098" CREATED="1687805148516" MODIFIED="1689008427862" LINK="https://on.ft.com/444Eakd"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The increasing popularity of generative artificial intelligence (AI), which can create technologies and other ideas free from human direction and oversight, could strain the US patent system, with applications attributed to AI that require human traits such as inspiration and creativity. While courts have so far deemed only &quot;natural persons&quot; as eligible for patents, AI could still allow individuals to submit large numbers of new patent applications to the US Patent and Trademark Office, which would then be played out in the courts, according to legal experts. Current patent laws struggle with fears around properly defining AI's role in the invention, creation and user of intellectual property. https://on.ft.com/444Eakd
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_43947081" CREATED="1687805148521" MODIFIED="1689008427866" LINK="https://www.linkedin.com/posts/yitzi_its-trivially-easy-to-make-an-ai-virus-activity-7055845762332540928-Zv_P?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          LinkedIn uses both essential and non-essential cookies to ensure the provision, security, analysis, and improvement of its services. Non-essential cookies are also used to display relevant professional and job advertisements both on and off the platform. Users can choose to accept or reject non-essential cookies at any time in their settings. The post by Yitzi G., a creative technologist, discusses the ease with which an AI virus can be created and how this is already known by malicious actors. The post receives a mixed response from other LinkedIn users. https://www.linkedin.com/posts/yitzi_its-trivially-easy-to-make-an-ai-virus-activity-7055845762332540928-Zv_P?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1509929046" CREATED="1687805148532" MODIFIED="1689008427869" LINK="https://finchat.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Microsoft's last quarter showed a strong performance in their cloud business, with the Microsoft Cloud delivering over $28 billion in quarterly revenue, up 22% and 25% in constant currency. This demonstrates their continued leadership across the tech stack. The Intelligent Cloud revenue was $22.08 billion, up 16.3% YoY, while the Productivity and Business Processes revenue was $17.52 billion, up 4.7% YoY. The More Personal Computing revenue was $13.26 billion, up 0.6% YoY. CEO Satya Nadella outlined the principles guiding the company through changing economic times, including investing behind categories that will drive long-term secular trends, prioritizing helping customers get the most value out of their digital spend, and helping organizations use digital technology to overcome today's challenges and emerge stronger. https://finchat.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_21885882" CREATED="1687805148553" MODIFIED="1689008427874" LINK="https://www.theverge.com/2023/5/1/23706311/hinton-godfather-of-ai-threats-fears-warnings"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Geoffrey Hinton, one of the &quot;godfathers of AI&quot; who won the 2018 Turing Award, has left his job at Google to speak about the risks of AI freely. Hinton says he no longer thinks it will be 30 to 50 years before AI surpasses human intelligence, and is concerned about the potential for AI to be used for harmful purposes by &quot;bad actors.&quot; Hinton is also worried about AI eliminating jobs, and even about AI becoming a threat to humanity itself if it begins to write and run its own code. Hinton had been employed by Google for more than a decade, and had been happy with its stewardship of AI until competing search engine Bing, which had incorporated OpenAI technology, threatened Google's core business, sparking a &quot;code red&quot; response within the company. https://www.theverge.com/2023/5/1/23706311/hinton-godfather-of-ai-threats-fears-warnings
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_508546287" CREATED="1687805148570" MODIFIED="1689008427876" LINK="https://www.reddit.com/r/deeplearning/comments/1361bnn/creating_animations_using_temporalkit_and_ebsynth/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text discusses the use of cookies and similar technologies by Reddit and its partners to improve the user experience by delivering and maintaining services, improving the quality of Reddit, personalizing content and advertising, and measuring the effectiveness of advertising. Users can either accept all cookies or reject non-essential cookies while still allowing certain cookies for proper platform functionality. The rest of the text provides various links to discussions on machine learning and artificial intelligence topics on Reddit. https://www.reddit.com/r/deeplearning/comments/1361bnn/creating_animations_using_temporalkit_and_ebsynth/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_1741607774" CREATED="1687805148573" MODIFIED="1689008427876" LINK="https://www.thetimes.co.uk/article/ai-will-could-religions-to-to-control-humans-warns-sapiens-author-harari-fhbzgbv7b"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but you have not provided any text for me to summarize. Kindly provide the necessary information. https://www.thetimes.co.uk/article/ai-will-could-religions-to-to-control-humans-warns-sapiens-author-harari-fhbzgbv7b
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_198476297" CREATED="1687805148574" MODIFIED="1689008427877" LINK="https://securityintelligence.com/articles/chatgpt-confirms-data-breach/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          ChatGPT, a popular AI-powered chatbot, suffered a data breach that took the service offline until the vulnerability in the code's open-source library was fixed. Previously, the cybersecurity industry was concerned that AI technology could be used to launch cyberattacks, but now it seems that the technology itself has become a target. Despite its popularity, ChatGPT's imperfect responses and clunky prose have led to concerns about its potential impact on businesses. Generative AI tools like ChatGPT can now be misused by criminals to write convincing prose and usable code, leading to heightened security concerns. The incident emphasizes the importance of ensuring the security of AI-powered technologies. https://securityintelligence.com/articles/chatgpt-confirms-data-breach/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_1327792435" CREATED="1687805148576" MODIFIED="1689008427878" LINK="https://www.reddit.com/r/MachineLearning/comments/136vt7b/p_airoboros_a_rewrite_of_selfinstructalpaca/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to provide a better user experience. Users can accept all cookies or reject non-essential cookies. The post below this is from a user sharing their update to the alpaca dataset, which addresses some issues with the code, speeds up the process, and allows for the use of the chat completion API. The post also includes a link to the project's GitHub repository and data resources. The remaining posts on the page are from different subreddits related to machine learning, including discussions on deep learning frameworks, tutorials, and updates on AI technologies. https://www.reddit.com/r/MachineLearning/comments/136vt7b/p_airoboros_a_rewrite_of_selfinstructalpaca/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1602537632" CREATED="1687805148580" MODIFIED="1689008427878" LINK="https://www.reddit.com/r/MachineLearning/comments/1373nhq/discussion_mark_zuckerberg_on_metas_strategy_on/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to improve the user experience. Users have the option to accept all cookies, which allows Reddit to deliver and maintain its services, improve quality, personalize content and advertising, and measure advertising effectiveness. Alternatively, users can choose to reject non-essential cookies while still allowing necessary cookies for the platform's proper functionality. The article includes a discussion thread on the machine learning subreddit, where users share their thoughts on Mark Zuckerberg's recent comments about Meta's AI strategy and open-source philosophy. Some users express skepticism about tech companies, while others appreciate Meta's open-source contributions. https://www.reddit.com/r/MachineLearning/comments/1373nhq/discussion_mark_zuckerberg_on_metas_strategy_on/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_704960930" CREATED="1687805148592" MODIFIED="1689008427888" LINK="https://twitter.com/emollick/status/1653945049275670528"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Twitter discussion revolves around GPT, a computer program that generates and writes academic papers in just 30 minutes. The program uses a dataset and generates two competing hypotheses and writes up the results of the analysis, with some feedback from the user. While the text generated by the program can be prone to hallucinations, the data analysis appears to be less so. The discussion delves into the specifics of the program's capabilities and limitations, and some users express interest in learning more about the process and prompts used. Overall, the conversation shows how technology is rapidly advancing and reshaping various industries, including academia. https://twitter.com/emollick/status/1653945049275670528
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_610789468" CREATED="1687805148594" MODIFIED="1689008427890" LINK="https://github.com/cleanlab/cleanvision"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          CleanVision is a data-centric AI package that detects potential issues in image datasets like images that are: blurry, under/over-exposed, (near) duplicates, etc. It aims to provide a quick first step for any computer vision project to find problems in the dataset, which you want to address before applying machine learning. CleanVision is easy to use -- you only need to run a couple lines of Python code to audit any image dataset. CleanVision diagnoses many types of issues, such as exact duplicates, near duplicates, blurry images, images lacking content, underexposed or overexposed images, grayscale images, images with an unusual aspect ratio, and abnormally large or small images. CleanVision supports Linux, macOS, and Windows and runs on Python 3.7+. The package is distributed under the terms of the GNU Affero General Public License, and it is free and open-source. The CleanVision package is still a work in progress, and users are encouraged to contribute and provide feedback on the package's performance and functionality. https://github.com/cleanlab/cleanvision
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_815667826" CREATED="1687805148597" MODIFIED="1689008427892" LINK="https://archive.is/20230503103826/https://www.bloomberg.com/news/articles/2023-05-03/ai-will-cause-real-damage-microsoft-chief-economist-warns"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a message that appears when trying to access the website archive.is. It requires the completion of a CAPTCHA to ensure the user is human and not a robot. Completing the CAPTCHA grants temporary access to the website, and the message offers suggestions for preventing this step in the future by running anti-virus scans or asking network administrators for assistance. https://archive.is/20230503103826/https://www.bloomberg.com/news/articles/2023-05-03/ai-will-cause-real-damage-microsoft-chief-economist-warns
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_568974181" CREATED="1687805148602" MODIFIED="1689008427895" LINK="https://github.com/pashpashpash/vault-ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The OP Vault is a Golang server that uses the OP Stack (OpenAI and Pinecone Vector Database) to provide users with the ability to upload custom knowledgebase files and retrieve accurate answers to questions based on their content. Users can upload a variety of file types, such as PDFs, .txt, .rtf, .docx, .epub, and plain text, and the server processes the files into embeddings to store in Pinecone. The server uses the embeddings to provide relevant answers to questions submitted by users through a user-friendly React frontend. The frontend displays the filenames and specific context snippets that inform the answer, and users can upload entire libraries' worth of books to expand their knowledge base. The project requires node v19, go v1.18.9 darwin/arm64, and poppler to be installed, and users must set up their OpenAI and Pinecone API keys and endpoints in the secret folder. The golang server uses POST APIs to process incoming uploads and respond to questions. The frontend is built using React.js and less for styling. Supported file types include PDFs, .txt, .rtf, .docx, .epub, and plaintext. https://github.com/pashpashpash/vault-ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_859854943" CREATED="1687805148635" MODIFIED="1689008427902" LINK="https://twitter.com/RunGreatClasses/status/1656666450634096643"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The user Jeremy Nguyen tweeted about ChatGPT, a tool that can help writers polish their rough drafts and automatically highlight ChatGPT's edits. The tool is a Chrome extension that can be installed for free. Jeremy suggests using ChatGPT to improve the rough draft before doing several more passes during editing. Additionally, ChatGPT should be clicked to get the edited text. https://twitter.com/RunGreatClasses/status/1656666450634096643
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_635978669" CREATED="1687805148637" MODIFIED="1689008427902" LINK="https://www.wsj.com/articles/tiktok-feeds-teens-a-diet-of-darkness-8f350507"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The stock market indices DJIA, S&amp;P 500, and Nasdaq experienced mixed results, with the DJIA increasing slightly by 0.09%, while the S&amp;P 500 and Nasdaq decreased by 0.28% and 0.95%, respectively. U.S. 10yr saw a slight increase, and crude oil prices rose by 0.69%. In other news, there are concerns that the popular app TikTok may be exposing young people to harmful content such as self-harm, sad-posting, and disordered-eating videos. Users of the app are advised to be mindful of the content they consume. https://www.wsj.com/articles/tiktok-feeds-teens-a-diet-of-darkness-8f350507
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_779460309" CREATED="1687805148652" MODIFIED="1689008427902" LINK="http://joinhallway.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          JoinHallway is a new platform aiming to empower creators by allowing them to use avatars as their video representation. The platform aims to eliminate the need for custom hardware or clunky setups by only requiring a webcam to use. JoinHallway is currently on a waitlist for early access with supported avatars, and is aimed towards those who feel limited by video as a medium and being the face of their content. JoinHallway offers a new, easy way for creators to tell their stories as their avatars with their own personalities. The platform intends to cater to a rising trend in synthetic media, and aims to empower the next generation of creators. http://joinhallway.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1510093762" CREATED="1687805148654" MODIFIED="1689008427902" LINK="https://twitter.com/lightning/status/1658497809895809025"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but you have not provided any text for me to summarize. Could you please provide more information or a specific text to summarize? https://twitter.com/lightning/status/1658497809895809025
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_203629615" CREATED="1687805148733" MODIFIED="1689008427937" LINK="https://www.youtube.com/watch?v=Dt_UNg7Mchg"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, there is no specific text provided for me to summarize. Can you please provide more information on what you need? https://www.youtube.com/watch?v=Dt_UNg7Mchg
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_455637040" CREATED="1687805148660" MODIFIED="1689008427917" LINK="https://youtu.be/XfpMkf4rD6E"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text appears to be a list of various YouTube videos related to topics such as artificial intelligence, deep learning, and transformer networks. The videos feature experts discussing and explaining the concepts behind these topics and their applications, including the development of GPT-4, self-attention mechanism, and transformer networks. Some of the videos come from universities such as MIT and Stanford, while others feature conversations with experts in the field. The text also mentions how YouTube uses cookies and data to deliver and improve their services, as well as the option to manage privacy settings. https://youtu.be/XfpMkf4rD6E
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_927724531" CREATED="1687805148752" MODIFIED="1689008427946" LINK="https://www.researchgate.net/publication/371311926_A_survey_of_Generative_AI_Applications"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the given text is not sufficient for me to summarize since it only contains technical information about a website's security verification process. Can you please provide me with another text or a specific topic to summarize? https://www.researchgate.net/publication/371311926_A_survey_of_Generative_AI_Applications
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_761487941" CREATED="1687805148754" MODIFIED="1689008427949" LINK="https://www.zerohedge.com/geopolitical/rickards-coming-shock-global-monetary-system"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A new global currency pegged to a basket of commodities could be launched by the BRICS on 22 August, according to James Rickards writing in Daily Reckoning. The currency, which will be digital, is expected to be backed by gold and could weaken the dollar's role in global payments, leading to its displacement as the leading payment and reserve currency. The move represents a substantial alternative to Western economic dominace by four of the seven world's largest countries, which, combined, represent 28% of nominal global GDP. Currently, 60% of all global reserves held by countries are in US Treasury securities denominated in dollars. https://www.zerohedge.com/geopolitical/rickards-coming-shock-global-monetary-system
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1064937559" CREATED="1687805148757" MODIFIED="1689008427951" LINK="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4475995"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper proposes seven approaches for utilizing AI as a learning tool in classrooms: AI-tutor, AI-coach, AI-mentor, AI-teammate, AI-tool, AI-simulator, and AI-student. Each approach has its own benefits and risks, and the aim is to help students learn with and about AI while mitigating risks such as complacency, errors, and biases. The authors stress the importance of active oversight, critical assessment of AI outputs, and complementarity of AI’s capabilities with the unique insights of students. The framework serves as a guide for educators navigating the integration of AI-assisted learning in classrooms, ensuring that AI serves as a supportive tool rather than a replacement. https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4475995
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1018460707" CREATED="1687805148762" MODIFIED="1689008427951" LINK="https://localrf.github.io"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper presents an algorithm for reconstructing the radiance field of a large-scale scene from a single casually captured video. The algorithm handles the challenges posed by inaccurate camera poses and the finite representational capacity of a single, global radiance field for longer trajectories in an unbounded scene. The algorithm jointly estimates the camera poses with radiance field in a progressive manner, which improves the robustness of the reconstruction. The approach dynamically allocates new local radiance fields trained with frames within a temporal window, further improving robustness and allowing scaling to large scenes. The algorithm's evaluation on the Tanks and Temples dataset and a collected outdoor dataset, Static Hikes, shows superior performance compared to the state-of-the-art. https://localrf.github.io
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1782083202" CREATED="1687805148779" MODIFIED="1689008427951" LINK="https://www.wired.com/story/generative-ai-deepfakes-disinformation-psychology/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The inundation of AI-generated content and systems in people's lives, including disinformation, deepfakes, and fake news, will affect people's trust in what was once unquestionable and blur their sense of the world, according to an article in Wired. While AI will make life simpler and easier for people, it could also make them more reliant on technology, erode their critical thinking skills, and make it more challenging to discern truth, leading to anxiety. AI could potentially exacerbate the loneliness epidemic by making people assume that they have found friends in AI. However, there is still inadequate research on how AI will affect people's mental health, personalities, and socio-economic status. The article concludes by emphasising the need for more research on AI's consequences before it becomes all-pervasive. https://www.wired.com/story/generative-ai-deepfakes-disinformation-psychology/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_468798669" CREATED="1687805148782" MODIFIED="1689008427951" LINK="https://www.washingtonpost.com/technology/2023/06/21/ai-regulation-us-senate-chuck-schumer/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article concerns Senate Leader Schumer's call for comprehensive regulation of Artificial Intelligence (AI). Schumer wants lawmakers to advance legislation in the coming months and notes pressure from critics for Congress to act. The article includes a notice on privacy protection from The Washington Post, disclosing data processing to provide personalised ads, store information, scan device details for identification, measure ad performance, and more. Users can select options on managing their data on the privacy policy page. https://www.washingtonpost.com/technology/2023/06/21/ai-regulation-us-senate-chuck-schumer/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_965182491" CREATED="1687805148788" MODIFIED="1689008427964" LINK="https://on.ft.com/444Eakd"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Generative artificial intelligence (AI) is presenting a challenge to the US patent system, as computers that can create and develop their own ideas are not recognised as inventors by law. While traditional AI requires human input to function, generative AI has the potential to change the relationship between computers and humans, with the machine generating the innovation and the human acting as a facilitator. This creates a number of legal questions around who should be credited as the inventor, or whether AI-generated inventions should be eligible for patent protection at all. Some argue that the lack of legal protection for AI-generated inventions could stunt innovation, while others suggest that it could lead to greater openness and collaboration in the scientific community. https://on.ft.com/444Eakd
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_1261607746" CREATED="1687805148789" MODIFIED="1689008427964" LINK="https://twitter.com/rrhoover/status/1647735300511154176"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but you have not provided any text for me to summarize. Please provide the text that you would like me to summarize. https://twitter.com/rrhoover/status/1647735300511154176
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1782575983" CREATED="1687805148791" MODIFIED="1689008427964" LINK="https://www.linkedin.com/posts/yitzi_its-trivially-easy-to-make-an-ai-virus-activity-7055845762332540928-Zv_P?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses LinkedIn's cookie policy, which indicates the use of essential and non-essential cookies to provide, secure, analyze and improve their services. These cookies are also used to display targeted ads, including professional and job ads, both on and off the LinkedIn platform. Users can either accept or reject the use of non-essential cookies and can update their preferences at any time in their settings. The article also briefly mentions a post by Yitzi G, a creative technologist, where he talks about the ease with which an AI virus can be created, and recommends checking out his social media channels for more on the topic. https://www.linkedin.com/posts/yitzi_its-trivially-easy-to-make-an-ai-virus-activity-7055845762332540928-Zv_P?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1979982166" CREATED="1687805148796" MODIFIED="1689008427964" LINK="https://finchat.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Microsoft's last quarter saw a strong performance in its cloud business. In Q3 2023, the Microsoft Cloud delivered over $28 billion in quarterly revenue, up 22% and 25% in constant currency, demonstrating the company's continued leadership across the tech stack. Satya Nadella, CEO of Microsoft, emphasized Microsoft's commitment to investing in categories that will drive long-term growth and helping customers get the most value out of their digital spend. Nadella also noted that no company is better positioned than Microsoft to help organizations overcome challenges with digital technology. In Q4 2022, the Microsoft Cloud surpassed $25 billion in quarterly revenue for the first time, up 28% and 33% in constant currency. This performance highlights the real opportunity to help organizations in every industry use digital technology to overcome challenges and emerge stronger. https://finchat.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_274588020" CREATED="1687805148813" MODIFIED="1689008427978" LINK="https://github.com/dk-liang/Awesome-GPT-4-with-Applications"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Awesome-GPT4-with-Applications is a collection of resources related to GPT-4, including news, official documents, demos, applications, libraries and frameworks. The compilation includes news articles regarding GPT-4, official documents such as the technical report, system card, and API waitlist, early GPTs, tutorials and examples, applications of GPT-4, and more. It also encourages contributions from users who can submit new resources or suggest improvements through issues or pull requests. https://github.com/dk-liang/Awesome-GPT-4-with-Applications
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_448210896" CREATED="1687805148817" MODIFIED="1689008427979" LINK="https://buff.ly/3laNpgY"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The paper introduces StyleGANEX, a modification to StyleGAN that overcomes its limitations of generating only cropped aligned faces at fixed image resolution. StyleGANEX uses dilated convolutions to rescale receptive fields of shallow layers in StyleGAN, allowing fixed-size features to be extended for accommodating variable resolutions and unaligned faces. To enable face inversion and manipulation, a corresponding encoder is introduced that provides a first-layer feature and the latent style code. StyleGANEX can be used for a range of face manipulation tasks, including facial attribute editing, super-resolution, sketch/mask-to-face translation, and face toonification. Experimental results demonstrate the effectiveness of StyleGANEX for unaligned face inputs of various resolutions while retaining the style representation and editing ability of StyleGAN. Comparison with other face manipulation techniques show that StyleGANEX provides more coherent results and successfully processes the entire image as a whole. https://buff.ly/3laNpgY
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_375053208" CREATED="1687805148824" MODIFIED="1689008427979" LINK="https://mobile.twitter.com/nic__carter/status/1635328056234766337"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A Twitter user, Nic Carter, has raised concerns about the shutdown of Signature Bank, citing that politicians and regulatory bodies have undermined cryptocurrency banks and encouraged runs against them, then used withdrawals as a pretext to close them down. Nic Carter alleged that Signature was executed not due to any runs, but as a political scalp intended to be veiled by the fog of war. He claimed that regulators wanted to kill off the last major pro-crypto bank. Signature was reportedly suspended due to a systemic problem linked to its Signet product. Carter also claimed that the FDIC was surprised by the sudden decision to shut down Signature Bank and that the sell-side felt that the bank was sound. https://mobile.twitter.com/nic__carter/status/1635328056234766337
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_731820877" CREATED="1687805148830" MODIFIED="1689008427984" LINK="https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The memo highlights the growing concern around the power that Big Tech companies hold. Specifically, TikTok is noted as a threat due to its potential to collect and exploit user data. However, it is not just TikTok that poses a problem. The memo argues that companies such as Google, Facebook, and Amazon have become so influential that they potentially have the ability to control our access to information and manipulate our behaviors. This power has led to calls for increased regulation and antitrust action to prevent these companies from becoming too dominant. The memo calls on individuals and organizations to support efforts to hold Big Tech accountable and ensure that the internet remains a level playing field for all. https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_1994187888" CREATED="1687805148831" MODIFIED="1689008427984"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The memo discusses the growing threat that big tech companies, such as TikTok, pose to society. The author argues that these companies have too much power and control over our lives, and are not held accountable for their actions.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1855646974" CREATED="1687805148833" MODIFIED="1689008427984"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The author highlights TikTok specifically, pointing out the data privacy concerns and the negative impact the app has on young people's mental health. They also note that TikTok is owned by a Chinese company, raising concerns about national security and data privacy.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1327003685" CREATED="1687805148833" MODIFIED="1689008427994"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          However, the author stresses that TikTok is just one example of the problem with big tech companies. They argue that these companies are monopolizing the market and stifling competition, driving up prices and limiting innovation. Furthermore, these companies are not adequately regulated or held accountable for their actions, leading to widespread misuse of user data and other ethical concerns.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_1994343606" CREATED="1687805148834" MODIFIED="1689008427995"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          To address this problem, the author suggests that we need stronger regulation and antitrust laws to prevent big tech companies from becoming too powerful. They also call for increased transparency and accountability, so that users know how their data is being used and can make informed decisions about their online activities.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_160313749" CREATED="1687805148835" MODIFIED="1689008427997" LINK="https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Finally, the author urges individuals to take action by supporting alternative platforms and engaging in activism to promote positive change. They argue that we cannot rely on the government or big tech companies to solve this problem, and that it is up to all of us to act now before it is too late. https://techoversight.org/2023/03/20/memo-tiktok-is-a-threat-so-is-the-rest-of-big-tech/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1436617268" CREATED="1687805148840" MODIFIED="1689008427997" LINK="https://crsreports.congress.gov/product/pdf/r/r47224"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the provided text is not a summary of an article or topic that can be summarized. It appears to be a message about a website's security measures. https://crsreports.congress.gov/product/pdf/r/r47224
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_580413338" CREATED="1687805148841" MODIFIED="1689008428001" LINK="https://simonwillison.net/2022/Sep/30/action-transcription/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Simon Willison recently released a new project called Action Transcription, built during the Bellingcat Hackathon, which is a tool used to capture captions and transcripts from online videos through GitHub Actions and GitHub Issues. The goal was to build prototypes of tools that could be used by the Bellingcat community of investigators, most of whom are volunteers working from home with little-to-no budget and often with limited technical skills. The tool is powered by OpenAI's Whisper, a solution for transcribing audio, which can create a transcript in the original language and translate it into English. Additionally, the tool offers a second option that extracts captions directly from the video provider. Implementing the project required using various tools, including GitHub Actions scripts, Replicate, and webvtt-to-json, and ttml-to-json, which were built to format the captions into standard JSON to extract the text. Simon is excited about the pattern behind this project, which is building tools using GitHub Actions that people can clone to their accounts and run independently via the GitHub web interface. https://simonwillison.net/2022/Sep/30/action-transcription/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_136969190" CREATED="1687805148846" MODIFIED="1689008428006" LINK="https://dex.aldrin.com/chart/spot/liq_usdc"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text appears to be a user interface for a cryptocurrency exchange or trading platform. The platform appears to offer various features such as trading, swapping, staking, and connecting a crypto wallet. It also shows market information for RIN/USDC, including a chart, order book, and recent trade history. The platform also allows users to set limit and market orders, and displays their account balances for RIN and USDC. https://dex.aldrin.com/chart/spot/liq_usdc
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1049556786" CREATED="1687805148847" MODIFIED="1689008428008" LINK="https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but the text you provided is not an actual article or piece of content. It appears to be a message or notification regarding unusual activity detected on a computer network and provides instructions on how to proceed. Please provide an actual text or topic for me to summarize. https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_880404552" CREATED="1687805148849" MODIFIED="1689008428011" LINK="https://donnerlab.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but without the text to summarize, I am unable to provide a summary. Please provide me with the text you would like me to summarize. https://donnerlab.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_268027424" CREATED="1687805148853" MODIFIED="1689008428011" LINK="https://discord.gg/2xndhbssvv"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The message suggests that the Discord invite a person is trying to access might be invalid. This could be because the invite has expired or because the person trying to join does not have the necessary permission to access the Discord channel. The person can choose to continue to Discord despite the error message. https://discord.gg/2xndhbssvv
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_1696680237" CREATED="1687805148854" MODIFIED="1689008428013"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The message &quot;Invite Invalid&quot; appears when a user tries to join a Discord server using an expired or invalid invite link. The invite link could have expired due to various reasons. The server owner may have manually deleted the invite link, or the link may have exceeded its maximum number of uses. It's also possible that the user who clicked the link doesn't have permission to join the server.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_1723857971" CREATED="1687805148855" MODIFIED="1689008428013"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          If the server owner has enabled verification levels for their server, only users who meet the specified criteria can join. For example, if the server owner has set the verification level to &quot;Medium,&quot; users must have a verified email address associated with their Discord account in order to join.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1387690205" CREATED="1687805148856" MODIFIED="1689008428015"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          If the invite link is still valid and the user should have permission to join the server, it's possible that Discord is experiencing an outage. Users experiencing these issues can try logging out of Discord, clearing their browser cache, and logging back in.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_399081001" CREATED="1687805148857" MODIFIED="1689008428015"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Additionally, if the user is trying to join a server that is marked as &quot;NSFW&quot; (not safe for work), they must be 18+ years old to join. Discord requires server owners to mark their server as &quot;NSFW&quot; if the content is adult-oriented.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_845256695" CREATED="1687805148860" MODIFIED="1689008428016" LINK="https://discord.gg/tpd9h8kvbd"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Overall, if a user is experiencing issues with an invalid invite link, they should first verify that the link is still valid and that they should have permission to join. If the issue persists, try clearing browser cache or logging out of Discord, and try again later. https://discord.gg/tpd9h8kvbd
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_19424031" CREATED="1687805148861" MODIFIED="1689008428018" LINK="https://github.com/carson-katri/dream-textures"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article is about Git, a popular version control system used by software developers. It explains what Git is, how it works, and why it is important for collaborative software development. Git allows developers to track changes to their code, collaborate with others, and revert to previous versions if necessary. It is distributed, which means that each developer has a copy of the repository on their own computer. This enables them to work offline and merge changes with others later. Git also allows for branching, which is the creation of separate lines of development that can be tested and merged back into the main codebase if successful. Overall, Git is a powerful tool that enables developers to work more efficiently and collaboratively. https://github.com/carson-katri/dream-textures|carson-katri/dream-textures%20|%20dec%204th%20|%20added%20by%20github
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1949524724" CREATED="1687805148864" MODIFIED="1689008428019" LINK="https://hongfz16.github.io/projects/avatarclip.html"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, I cannot summarize the text as it is simply an error message indicating that a requested file cannot be found on a website hosted by GitHub Pages. It provides some tips for the website owner to ensure that the file exists and is accessible to users. https://hongfz16.github.io/projects/avatarclip.html
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1287223614" CREATED="1687805148866" MODIFIED="1689008428019" LINK="https://dex.bonfida.com/#/market/e14bkbhdwd4eutkwj1oozezesgxmw8lpcps4w5puzzjo"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but I need the text to summarize it. Could you please provide it? https://dex.bonfida.com/#/market/e14bkbhdwd4eutkwj1oozezesgxmw8lpcps4w5puzzjo
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_421924882" CREATED="1687805148878" MODIFIED="1689008428021" LINK="https://mobile.twitter.com/BrianRoemmele/status/1640567367418937344"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a prompt for users to log in or sign up for Twitter. It mentions the use of cookies, necessary to provide a faster and safer service, and gives users the option to accept all cookies or refuse non-essential ones. The message emphasizes Twitter as a source for breaking news and urges users not to miss out on what is happening by being a part of the platform. https://mobile.twitter.com/BrianRoemmele/status/1640567367418937344
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1276646359" CREATED="1687805148882" MODIFIED="1689008428022" LINK="https://open.spotify.com/episode/6z8vib2iyi3kavh67itt9q?si=gq2frm_stdwk8r_udt69lw&amp;amp;utm_source=copy-link"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the page that the user is looking for cannot be found. They have been directed to the home page, where they can try searching for what they are looking for again or seek help. https://open.spotify.com/episode/6z8vib2iyi3kavh67itt9q?si=gq2frm_stdwk8r_udt69lw&amp;utm_source=copy-link
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1485214387" CREATED="1687805148883" MODIFIED="1689008428022" LINK="https://twitter.com/ShitcoinSherpa/status/1625239032518115330?s=20&amp;amp;t=LZlw1E-cWd1WOSNuSFkrvA"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A Twitter user going by the name @ShitcoinSherpa has warned that there are potentially risky ordinal PDFs that have been shrewdly disguised to steal data involving cryptocurrencies. They have advised other Twitter users to avoid opening ordinals thumbnails on any browser on which they have wallet extensions installed. The user has also posted the code being used by these ordinals PDFs on their page, but they tweet that the code itself is too long to share on platforms like pastebin and 0bin. The same user has also appealed for help from a Twitter user @cryptoSheilds to sandbox and inspect the code. They also stated that looking at their code, it is clear that the malicious code is too large to merely display an image and information about a dishwasher. The user emphasizes that they don’t want to see people lose their savings and they haven’t even recovered from their own losses. https://twitter.com/ShitcoinSherpa/status/1625239032518115330?s=20&amp;t=LZlw1E-cWd1WOSNuSFkrvA
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_945024957" CREATED="1687805148888" MODIFIED="1689008428026" LINK="https://github.com/pixegami/pokemon-card-generator"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The &quot;Pokemon Card AI Generator&quot; is a Python script that uses artificial intelligence (AI) to generate random Pokemon cards. Users can select from six elements and a type of creature, then the script randomly generates 1-2 abilities. OpenAI is used to generate a Pokemon name and description. The output will be in the &quot;/output folder,&quot; with empty folders for users to put card artwork into. The cards will have JSON files with details such as HP, rarity, and abilities. The AI-generated artwork is rendered using Midjourney. Cards can be generated for specific elements and creature types. Users will need to set up an account with OpenAI to use the generator. The script can also generate a series of cards that evolve from one another. The script is available on GitHub with a video explanation included. https://github.com/pixegami/pokemon-card-generator
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_224760375" CREATED="1687805148894" MODIFIED="1689008428027" LINK="https://ncase.me/trust/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          &quot;The Evolution of Trust&quot; is a web-based interactive game that explores the complex and often precarious nature of trust in social interactions. The game presents various scenarios and asks the player to make decisions based on how much trust they place in the other player. Through gameplay and visual representation, the game demonstrates how trust can be easily broken and how lack of trust can lead to spiraling negative outcomes. It also highlights the importance of communication, honesty, and mutual understanding in building and maintaining trust. Overall, the game serves as an educational tool for understanding the dynamics of human interactions and the role that trust plays in them. https://ncase.me/trust/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1078513688" CREATED="1687805148897" MODIFIED="1689008428027" LINK="https://twitter.com/udnaan/status/1619873609136181251"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The Twitter account of Adnan Yunus, who describes himself as a developer working on generative AI or artificial general intelligence (AGI), has released a sneak peek of the OpusAI Producer App #1, which generates stories based on text input. According to Yunus, the tool is aimed at non-technical users, and other tools for working with technical elements of game development are expected to be released soon. While those technical tools are not yet available to use, people can leave their emails on the OpusAI website to be notified of early beta testing. Feedback to the app on Twitter has been positive. https://twitter.com/udnaan/status/1619873609136181251
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_424551277" CREATED="1687805148905" MODIFIED="1689008428030" LINK="https://www.reddit.com/r/virtualreality/comments/u4ahwu/horizon_worlds_coming_to_smartphones_web_probably/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Reddit's use of cookies and similar technologies to improve user experience. Accepting all cookies allows for the delivery and maintenance of services, personalization of content, and measurement of advertising effectiveness. However, rejecting non-essential cookies may still result in certain cookies being used for proper platform functionality. The article then moves on to a discussion of Meta's Horizon Worlds, which is set to launch on smartphones, the web, and potentially gaming consoles with lower platform fees on the web version. Finally, the article shares updates and discussions from various subreddits relating to virtual reality. https://www.reddit.com/r/virtualreality/comments/u4ahwu/horizon_worlds_coming_to_smartphones_web_probably/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_1390477750" CREATED="1687805148907" MODIFIED="1689008428032" LINK="https://www.reddit.com/r/CryptoCurrency/comments/10wx51p/the_current_list_of_cbdcs_in_development_around/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the increasing use and development of Central Bank Digital Currencies (CBDCs) around the world, which have the potential to revolutionize the financial sector with their 24/7 availability and instantaneous transaction speed. However, some commentators warn of the potential for increased government surveillance and control over individuals' finances with the introduction of CBDCs. The article includes comments from users expressing concerns about privacy and the potential for governments to use CBDCs for censorship and control purposes. https://www.reddit.com/r/CryptoCurrency/comments/10wx51p/the_current_list_of_cbdcs_in_development_around/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_31373688" CREATED="1687805148908" MODIFIED="1689008428032" LINK="https://medium.com/@gladia.io/gladia-alpha-launch-redefining-what-s-possible-with-speech-to-text-ai-686dd4312a86"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text appears to be related to the Medium platform, which requires users to sign up or sign in before they can write on the site. However, there is an error message stating that the story has been deleted by the author. The message also indicates that Medium collects user data and requires users to agree to their privacy and cookie policies. https://medium.com/@gladia.io/gladia-alpha-launch-redefining-what-s-possible-with-speech-to-text-ai-686dd4312a86
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_200999378" CREATED="1687805148910" MODIFIED="1689008428033" LINK="https://m.youtube.com/watch?v=L_Guz73e6fw&amp;amp;feature=youtu.be"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a list of recent episodes from the Lex Fridman Podcast, featuring interviews with various experts in the fields of artificial intelligence, technology, and physics. Some notable guests include Sam Altman, CEO of OpenAI, discussing the future of AI and his company's latest technologies; Elon Musk, discussing SpaceX, Tesla, and AI; Michio Kaku, discussing the future of humans, aliens, and space travel; and Neil Gershenfeld, discussing self-replicating robots and the future of fabrication. Other episodes cover a range of topics including black holes, energy, aliens, and nuclear fusion. The text also mentions the use of cookies in using Google services and the option to adjust privacy settings. https://m.youtube.com/watch?v=L_Guz73e6fw&amp;feature=youtu.be
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_718253402" CREATED="1687805148912" MODIFIED="1689008428034" LINK="https://events.sansar.com/events/PJ-Mac-3293/day-2--intermodal-year-one/1fdcec68"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unfortunately, the page you are trying to access cannot be found. Please check the URL or return to the homepage. https://events.sansar.com/events/PJ-Mac-3293/day-2--intermodal-year-one/1fdcec68
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_282412607" CREATED="1687805148913" MODIFIED="1689008428034" LINK="https://events.sansar.com/events/PJ-Mac-3293/day-2--intermodal-year-one/1fdcec68"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The page requested by the user cannot be found. The user is advised to check the URL address for accuracy or return to the homepage. https://events.sansar.com/events/PJ-Mac-3293/day-2--intermodal-year-one/1fdcec68
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1789120240" CREATED="1687805148917" MODIFIED="1689008428036" LINK="https://jamesturk.github.io/scrapeghost/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          I'm sorry, but you have not provided any text to summarize. Please provide the text to me so I can help you out. https://jamesturk.github.io/scrapeghost/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_1881814179" CREATED="1687805148919" MODIFIED="1689008428037" LINK="https://youtu.be/zLnhg9kir3Q"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text appears to be a list of various videos and live Q&amp;A sessions featuring Stephen Wolfram discussing a range of topics related to science, mathematics, and technology. Some of the topics covered include AI, physics, productivity systems, and the history of science. The videos come from various sources, including the Wolfram YouTube channel, Lex Fridman's podcast, and Greylock. The text also discusses how Google collects and uses data for personalized content and ads. https://youtu.be/zLnhg9kir3Q
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_438760001" CREATED="1687805148923" MODIFIED="1689008428037" LINK="https://www.army.mil/standto/archive/2018/03/26/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The US Army will discontinue publishing its virtual newsletter, STAND-TO!, on army.mil and subscribers from May 2022 onwards. Readers are encouraged to learn about the army via the army.mil website and by following its social media platforms. One of eight cross-functional teams established to advance the Army’s six modernisation priorities is the Synthetic Training Environment Cross Functional Team. This team is responsible for developing processes for identifying accurate training requirements for the synthetic training environment to help the army maintain battlefield dominance and soldier lethality. The Synthetic Training Environment is a simulation environment that allows live, virtual, constructive and gaming environments to converge into one. The idea is to deliver high-level training proficiency prior to soldiers engaging in live training exercises. https://www.army.mil/standto/archive/2018/03/26/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_634266294" CREATED="1687805148929" MODIFIED="1689008428039" LINK="https://github.com/TREE-Ind/UnrealGPT"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The UnrealGPT project is a collection of Unreal Engine 5 Editor Utility widgets powered by GPT3/4, designed for easy customization through blueprints. To use an editor utility, the user should download it and place it in their desired UE5 project, then install OpenAI via pip. The editor utility should then be opened in the UE5 editor, and the user should place their OpenAI api key in the correct variable and save. The user can then run the editor utility widget or double click on it for full customization through blueprints. There is currently only one utility available, but contribution and PRs are welcome, as well as the potential for future expansions using GPT4. https://github.com/TREE-Ind/UnrealGPT
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_548347234" CREATED="1687805148932" MODIFIED="1689008428039" LINK="https://www.youtube.com/watch?v=FQgsQLodcZM"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The video description on YouTube mentions Unreal Engine 5.2's experimental feature of Pixel Streaming to WebXR, which is not yet production-ready or supported directly by Epic or WebXR. Various other videos on Unreal Engine 5.2 are also listed, including tutorials on how to add VR to any UE5 project, how to install the MetaXR plugin, how to create a massive world in 30 minutes, how to make a 3rd person character, and more. The description also provides information on how cookies and data are used on YouTube, including for delivering and maintaining Google services, measuring audience engagement, and showing personalized content and ads. It allows users to accept or reject these uses and provides a link to manage privacy settings. https://www.youtube.com/watch?v=FQgsQLodcZM
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_324280842" CREATED="1687805148935" MODIFIED="1689008428042" LINK="https://twitter.com/PastryEth/status/1529130859814600705"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a brief message from Twitter, encouraging users to sign up for an account and stay informed about current events. It also mentions the use of cookies by Twitter and its partners to improve service and support business. Users are given the option to accept all cookies or refuse non-essential ones. https://twitter.com/PastryEth/status/1529130859814600705
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_1076725012" CREATED="1687805148937" MODIFIED="1689008428043" LINK="https://hackmd.io/@xr/monetization"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses the challenges faced by indie creators in monetizing their WebXR (web-based VR/AR experiences) content and explores various monetization strategies that have been tried or could be tried in the future. The major issue for the ecosystem's growth is the lack of effective monetization, as most WebXR apps look like prototypes, and creators struggle to capture value. The article presents a list of 101 monetization strategies, including payment-based approaches like ticket sales, subscription-based services, crypto transactions, and NFTs, and non-payment-based approaches like advertising, commissions, sponsorships, and grants. The article also discusses the need to improve the ease of payment processing and suggests a Github repo of examples for WebXR monetization that could be created. Finally, the article mentions a few companies like Wonderleap and Zesty that are working on WebXR monetization. https://hackmd.io/@xr/monetization
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1020394486" CREATED="1687805148939" MODIFIED="1689008428044" LINK="https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a notification from Bloomberg that the user's computer network has been detected with unusual activity. To proceed, the user needs to confirm that they are not a robot by clicking on a box displayed. The company advises ensuring that their browser supports JavaScript and cookies and is not blocking them from loading. If the issue persists, the user can review the company's Terms of Service and Cookie Policy or contact the support team and provide the reference ID provided in the notification. https://www.bloomberg.com/news/articles/2023-02-21/amazon-s-aws-joins-with-ai-startup-hugging-face-as-chatgpt-competition-heats-up
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_582099713" CREATED="1687805148942" MODIFIED="1689008428047" LINK="https://www.reddit.com/r/CryptoCurrency/comments/10wx51p/the_current_list_of_cbdcs_in_development_around/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The article discusses Central Bank Digital Currencies (CBDCs) that are in development around the world, which allow for 24/7 transactions that enable payments to be faster and cheaper. However, some commenters express concerns over the potential loss of privacy and government control over people's money, likening it to slavery. Others question the use of Ethereum for CBDC purposes due to the risk of forking and double spending. Overall, the article highlights the growing interest and development of CBDCs in the financial world. https://www.reddit.com/r/CryptoCurrency/comments/10wx51p/the_current_list_of_cbdcs_in_development_around/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_1320349600" CREATED="1687805148944" MODIFIED="1689008428048" LINK="https://www.linkedin.com/posts/activity-7046131519802757120-uUEf?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          LinkedIn uses both essential and non-essential cookies to provide their services, including analyzing and improving the platform and showing relevant ads on and off the site. Users can choose to accept or reject non-essential cookies and update their settings at any time. LinkedIn also emphasizes respecting user privacy through their User Agreement, Privacy Policy, and Cookie Policy. https://www.linkedin.com/posts/activity-7046131519802757120-uUEf?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1262541210" CREATED="1687805148949" MODIFIED="1689008428049" LINK="https://twitter.com/ShitcoinSherpa/status/1625239032518115330?s=20&amp;amp;t=LZlw1E-cWd1WOSNuSFkrvA"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A tweet by Sherpa warns Twitter users about potentially malicious ordinal PDFs. They are advised not to view ordinal thumbnails, or even open the PDFs on a browser that has wallet extensions. Sherpa requests people to retweet and help find experts to sandbox and examine the code in the PDF. The tweet also provides a link to view the full code in privatebin. The user questions why dishwasher specs would require so much elaborate code to display a picture and specs. https://twitter.com/ShitcoinSherpa/status/1625239032518115330?s=20&amp;t=LZlw1E-cWd1WOSNuSFkrvA
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1272187132" CREATED="1687805148963" MODIFIED="1689008428051" LINK="https://vidyo.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The website vidyo.ai offers a tool for creating short video clips from long videos using AI, with a focus on content repurposing for social media and online growth. They currently support only English videos, but plan to add more languages soon. Features include auto-video captioning, video resizing, video clipping, auto-video chapters, social media templates, and more. They offer a free version with 75 minutes of upload every month. The website boasts positive reviews from content creators and businesses, and emphasizes the benefits of content repurposing for online growth. The FAQ section provides information on how the AI works, what types of videos can be uploaded, and whether custom templates are available. The site also offers an affiliate program and a community for users to connect and learn best practices. https://vidyo.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_1605771567" CREATED="1687805148967" MODIFIED="1689008428052" LINK="https://lnkd.in/eptCVijb"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Maverick is an AI-generated video service that helps ecommerce stores boost their customer engagement and loyalty through personalized interactions. The service creates personalized videos for each customer, helping to build trust and improve brand perception. The videos reduce refund requests as they ensure that each customer is satisfied with their purchase, and feel they are taken care of. Maverick has been employed by ecommerce brands such as Pnuff Crunch, Sapcoi Limited and Magic Mind, who highlight the effectiveness of the personalized videos in boosting customer engagement and loyalty. Customers who have received the videos have expressed their appreciation and gratitude and in some cases have become lifelong members of the brands. The service has been rated 5/5 stars on the Shopify App Store and is regarded as a game changer in ecommerce by many merchants. https://lnkd.in/eptCVijb
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_589958017" CREATED="1687805148977" MODIFIED="1689008428053" LINK="https://otter.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Otter.ai is a tool for note-taking and summarizing meetings that can save time and increase productivity. It offers live transcriptions of meetings, the ability to add comments and assign action items to the transcript, and automated meeting notes. Otter can connect to Zoom, Microsoft Teams, and Google Meet, and automatically join and record meetings. It even captures and inserts slides into the meeting notes. Otter can generate a real-time summary during the meeting and email the summary after the meeting. Otter offers different versions for businesses, education, and individuals, and has received positive reviews from users. https://otter.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1427704880" CREATED="1687805148979" MODIFIED="1689008428054"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Flair is an AI design tool that helps businesses create branded content easily. It offers a range of features to make the design process seamless, including templates, icons, and font options that can be customized to match a company's brand. Flair also uses AI to suggest design options based on a user's preferred style and content.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_1907836197" CREATED="1687805148980" MODIFIED="1689008428056"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          One unique feature of Flair is its ability to generate product photos using AI. Users can upload an image of their product, and Flair will generate a high-quality, professional-looking photo that can be used for marketing purposes. This feature can save businesses time and money as they won't need to hire a professional photographer.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_1821165856" CREATED="1687805148981" MODIFIED="1689008428057"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Flair also allows for collaboration between team members with its team features. Users can invite team members to contribute to the design process, provide feedback, and make changes in real-time.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_559819952" CREATED="1687805148983" MODIFIED="1689008428057"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          In addition to branding, Flair can also be used to create social media posts, presentations, and ads. The tool offers a variety of design options to choose from depending on the company's needs.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1559116234" CREATED="1687805148984" MODIFIED="1689008428058" LINK="https://flair.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Overall, Flair's AI design tool is geared towards businesses looking for an easy and efficient solution to their design needs. With its range of features and customization options, it can help businesses create high-quality branded content quickly and at a lower cost. https://flair.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1167730613" CREATED="1687805148985" MODIFIED="1689008428060" LINK="https://illustroke.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Illustroke is a generative AI design tool that creates stunning vector illustrations from text prompts. Users type what they want to illustrate and select from more than 40 unique and consistent styles. The illustrations are provided in scalable and customizable vector format, as well as pixelated (PNG) format. The tool also offers an editor, allowing users to modify their designs and save their work to the cloud for future editing. Illustroke has been featured in various publications and was created by Digitalbore OU and Fabio Carbone. https://illustroke.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_1453250887" CREATED="1687805148986" MODIFIED="1689008428061" LINK="https://stockimg.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          STOCKIMG.AI is an AI-powered platform that enables users to generate book covers, wallpapers, posters, logos, stock images, illustrations and art within seconds. It offers a range of categories to choose from and allows users to create images with artificial intelligence. The platform provides a few sample images and offers a free trial to test its services, with the aim of making image creation simple and fast. https://stockimg.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1394443878" CREATED="1687805148988" MODIFIED="1689008428062" LINK="https://looka.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          If you are seeing a &quot;Sorry, you have been blocked&quot; message when trying to access looka.com, it means that the website has implemented a security service to protect itself from online attacks. Your action may have triggered this block, such as submitting a certain word or phrase, a SQL command, or malformed data. To resolve this issue, you can contact the site owner via email and provide them with details of what you were doing when the block occurred and the Cloudflare Ray ID found at the bottom of the page. Cloudflare provides performance and security services for websites, and their Ray ID helps identify any potential issues that occurred. https://looka.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_1761945907" CREATED="1687805148989" MODIFIED="1689008428063" LINK="https://www.copy.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Copy.ai is an AI content generator that helps users write high-quality content in seconds. Whether you're a blog writer, social media manager, or email marketer, you can produce optimized copy for various campaigns using Copy.ai's 90+ tools and templates. The platform is SOC 2 Type II compliant, ensuring that your data is handled with the highest standard of security and compliance. Users can start generating content by entering their project and providing context about their brand and products. Copy.ai's AI content generator provides multiple options for each campaign that allow users to edit, polish, and publish their content. With tools like Chat by Copy.ai, users can access even more assistance from the AI and get answers to any question they have. Copy.ai has over 9 million professionals and teams using the platform, including authors and podcast hosts who say it's a game-changer that produces premium results in less time. You can sign up for Copy.ai for free and get started with 2,000 free words per month. https://www.copy.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_328185280" CREATED="1687805148991" MODIFIED="1689008428065" LINK="http://copymonkey.ai/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          CopyMonkey is an AI-powered Amazon listing optimization tool that generates and optimizes Amazon listings with all the important keywords, enabling sellers to rank organically on the first page. The tool offers an AI Amazon Copywriter that generates keyword-optimized bullet points and descriptions and continuously optimizes listings based on competitors insights and keyword performance. CopyMonkey also suggests listing improvements based on sales results. The tool can be used with any keyword research tool, and is recommended by Amazon experts as an efficient alternative to hiring a copywriter. CopyMonkey has already attracted over 1,000 sellers and offers a free version to get started. Users are pleased with the tool's ease of use and ability to save time. http://copymonkey.ai/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_137933007" CREATED="1687805148994" MODIFIED="1689008428067" LINK="https://www.ocoya.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Ocoya is an AI-powered tool that helps businesses with social media, content marketing, and copywriting. It is designed to make social media management ten times faster and easier for users. With Ocoya, businesses can generate marketing text, schedule posts, analyze content performance, and use relevant and trending hashtags. The tool is integrated with popular social media channels such as Facebook, Instagram, Twitter, LinkedIn, YouTube, and TikTok. It also offers unique features like AI copywriting, automatic scheduling, and link shortening. Ocoya is used by over 60,000 businesses across 180+ countries worldwide. https://www.ocoya.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#0000ff"/>
</node>
<node POSITION="left" ID="ID_1367485624" CREATED="1687805148996" MODIFIED="1689008428068" LINK="https://unbounce.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Unbounce is an AI-powered landing page builder with the capability to create high-performing marketing campaigns in just a few minutes. The platform has easy-to-use builders, AI copywriting tools, and personalized recommendations to optimize visitor experiences across search, social, and email channels. Unbounce can help businesses of all sizes achieve their marketing goals, including increased sales, expanded email lists, and improved brand exposure. With customizable landing page templates and smart optimization features, Unbounce can also help marketing agencies launch high-converting campaigns. Unbounce offers a 14-day free trial and has an award-winning customer success team, educational resources, and an active community of supportive marketers to assist customers. The platform is secure and has a privacy policy and terms of service in place. https://unbounce.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_1030650589" CREATED="1687805148998" MODIFIED="1689008428069" LINK="https://cleanup.pictures/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Cleanup.pictures is a web application that removes unwanted objects, defects, people, or text from pictures. The tool is particularly useful for photographers, creative agencies, real estate, and e-commerce. It utilizes inpainting, an AI-based retouch technology that removes unwanted items in just a few clicks. Compared to other similar apps, Cleanup.pictures works even without a reference background, providing better results in minutes. The web app is available for free with unlimited images, but users can opt for the Pro version for higher resolution exports and better quality image refiner. Cleanup.pictures allows users to remove text, logo, or watermark. Its API is available for use in various environments such as Node.js, SwiftUI, and Kotlin while providing extensive documentation, live demos, and numerous samples. Cleanup.pictures offers a current resolution limit of 720px for free version exports on any size of the image. The Pro version costs $5 monthly or $36 per year for processing images of any size. Subscribers receive a trial that offers full access to the product's features and functionalities to help them decide to make a final purchase. When purchased, licenses can be activated on both mobile and desktop. The app also has a refund policy where refunds will be given in special cases such as technical difficulties, platform incompatibilities, and other unforeseen circumstances. Refunds will be total if the subscription is less than 14 days old and partial if it is older, proportional to the number of days since the subscription started. Aside from these features, Cleanup.pictures offers techniques on how to remove people, unwanted objects and wrinkles, as well as text and watermarks. Users can also join their Slack community for a more collaborative and informative experience. https://cleanup.pictures/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_1446591842" CREATED="1687805149000" MODIFIED="1689008428071" LINK="https://inkforall.com/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          INK is an AI-powered content marketing suite that offers various features to optimize and create content. With industry-leading SEO optimization and semantic intelligence, INK claims to help users create content 10 times faster and easier. Their features include AI keyword research and clustering, AI writer, AI SEO, AI shield, AI assistant, and AI images. INK also offers content marketing education through free courses, videos, and support. Businesses that use INK can expect to improve their SEO, increase reach and conversion rates, and receive protection from AI penalties and plagiarism. INK claims to have a great user experience, honest pricing, a fantastic community, unlimited usage, and everything businesses need in a single subscription. Since 2019, more than 1 million users have joined INK. https://inkforall.com/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_1134344831" CREATED="1687805149003" MODIFIED="1689008428072" LINK="https://storyd.ai"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Storyd.ai is an AI-powered platform that helps business professionals create compelling data presentations that leaders will love. The tool allows users to create presentations in three easy steps: input the topic, watch the AI script and design the presentation, and export to PowerPoint. Storyd.ai offers best practice visualizations, an AI script generator, and professional slide designs to help users create impactful presentations faster and with greater ease. The platform also offers over 500 pre-written Story Starters sorted by industry and department to inspire users and help them save time. Storyd.ai is available in three pricing plans: Free, Pro, and Enterprise, each with varying features and capabilities. Zack Mazzoncini and Michael Grimm, the founders of Storyd.ai, have 15 years of experience building businesses and serving customers with innovative solutions that help people make better decisions. https://storyd.ai
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1735540685" CREATED="1687805149009" MODIFIED="1689008428074" LINK="https://invideo.io/ai/?r=fsDaAx"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          InVideo AI enables users to convert their content or ideas into videos in an instant. Users can join the waitlist to get a sneak peek and create ads, intros, montages, and Youtube explainers for a variety of businesses, such as shoe stores, cafes, and gin cocktails. InVideo offers various templates, including marketing, business, and real estate, and tools for creating slideshow and invitation videos, among others. Users can access tutorials, community forums, and support resources from the company. As of now, the cost and availability of InVideo's AI technology are not specified. https://invideo.io/ai/?r=fsDaAx
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00007c"/>
</node>
<node POSITION="left" ID="ID_1878709390" CREATED="1687805149010" MODIFIED="1689008428074" LINK="https://gptexcel.uk/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          ExcelBrew is a tool that uses Artificial Intelligence (AI) to generate spreadsheet formulas for Microsoft Excel, Google Sheets, and Airtable. It also explains these formulas to users, providing a better understanding of how to perform calculations and data analysis within these platforms. In addition to generating formulas, ExcelBrew can also generate advanced SQL queries and automation scripts for tasks that are repeated frequently. There are two pricing plans available, including a free plan that offers limited access, and a pro plan that offers access to all features with priority customer support. ExcelBrew is ideal for individuals and businesses looking to streamline their spreadsheet processes and increase productivity. https://gptexcel.uk/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_1557681154" CREATED="1687805149012" MODIFIED="1689008428077" LINK="http://10web.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          10Web offers an AI Website Builder that allows users to build a professional website faster by using AI-generated content and images. Users can customize their website with a drag-and-drop editor and edit every design element with premium 10Web widgets. The AI Website Builder also offers tools for generating business names, marketing strategies, web design, and SEO keywords. In addition, 10Web provides hosting services, automated backups, security, and user and team management. The AI Website Builder is suitable for any business size and offers a free trial with no credit card required. Pricing information is not provided on the website. Users can also integrate 10Web with Cloudflare Enterprise and use their own domain name. The platform has received positive feedback from influencers who have used the AI Website Builder to create a website in just a few minutes. http://10web.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c007c"/>
</node>
<node POSITION="left" ID="ID_1793072659" CREATED="1687805149019" MODIFIED="1689008428078" LINK="https://www.futuretools.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          FutureTools is a website that collects and organizes AI tools under different categories such as chat, finance, gaming, research, and self-improvement. The tools are further categorized as free, freemium, open-source, paid, and Matt's picks. FutureTools also provides a glossary of terms and allows users to submit new tools. Some of the listed tools include Cheat Layer, Factiverse, ToastyAI, Rephrase.ai, ClickUp AI Writing Assistant, Teach-O-Matic, and Infinigen. The platform also includes WriteSparkle, an AI-powered tool that enables PDF integration and workflow automation, and Grab Free Access to the AI Income Database. https://www.futuretools.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c7c"/>
</node>
<node POSITION="left" ID="ID_550501071" CREATED="1687805149021" MODIFIED="1689008428080" LINK="https://gamma.app/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a login page with the option to sign in with a Google account or an email and password. There is also a link for forgotten passwords and an option to sign up for a new account. The company behind the website is Gamma Tech, Inc. and the copyright is 2023. https://gamma.app/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c7c00"/>
</node>
<node POSITION="left" ID="ID_698654007" CREATED="1687805149023" MODIFIED="1689008428080" LINK="https://merlin.foyer.work/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Merlin is a ChatGPT extension that allows users to summarize or chat with any website quickly. The updated version, Merlin 2.0, offers new features such as a Youtube and blog summarizer, as well as prompts for tasks like social media, coding, and copywriting. Additionally, Merlin can help generate email ideas, write subject lines and call-to-actions, and even write cold or promotional emails. The extension is available on all major browsers, and users can reach out to the support team for any questions or concerns. Merlin uses ChatGPT, a chatbot powered by OpenAI, and does not require login to use. Merlin offers a personalized experience for each user and can handle various types of queries, although there may be limits on the length of input queries. The extension is free, but there is an option to upgrade to Merlin Pro for additional features. Foyer, the company behind the extension, also offers resources like a blog and affiliate program. https://merlin.foyer.work/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_1878880971" CREATED="1687805149050" MODIFIED="1689008428081" LINK="https://upscayl.github.io/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Upscayl is a free and open-source AI image upscaler that can enhance the quality of low-resolution images. It is available for download on macOS, Linux, and Windows platforms. The tool was created by TGS963 and Nayam Amarshe and relies on artificial intelligence to upscale images with better accuracy than traditional methods. Users can also donate to support the development and maintenance of the tool. A guide is available to assist users in understanding how to use Upscayl effectively. https://upscayl.github.io/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_931706667" CREATED="1687805149065" MODIFIED="1689008428081" LINK="https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=share&amp;amp;utm_medium=member_android"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Zain Khan's post discusses the release of 1,000+ AI tools in March and provides a list of 20 AI tools that can transform productivity. The post also promotes a newsletter called Superhuman that teaches readers how to use AI to increase productivity. The comments on the post cover topics such as how to keep up with the release of new AI tools, concerns about AI development, potential careers in AI, and privacy concerns related to using AI tools. Another post discusses the culture of Arab women in engineering, highlighting that there is a misconception that Arab women do not pursue STEM fields. https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=share&amp;utm_medium=member_android
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_1102835037" CREATED="1687805149068" MODIFIED="1689008428088" LINK="https://www.linkedin.com/posts/venu-victor-aa7ab865_houdini-ai-python-activity-7030460619195629568--Sx9?"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          LinkedIn and third parties use cookies to provide, secure, analyze, and improve their services. These cookies are used to show relevant professional and job-related ads on and off LinkedIn. Users are given the option to accept or reject non-essential cookies, and can change their preferences at any time in their settings. The post by Venu Victor, Head of Effects at MPC, discusses the use of GPT in Houdini, AI, Python, and Chat GPT to analyze user input and ask questions that lead to specific visual results. The post has been liked 524 times and has 3,620 followers. LinkedIn offers resources in various topics such as sales, marketing, business administration, HR management, content management, soft skills, and engineering. https://www.linkedin.com/posts/venu-victor-aa7ab865_houdini-ai-python-activity-7030460619195629568--Sx9?
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_533694463" CREATED="1687805149071" MODIFIED="1689008428088" LINK="https://twitter.com/justLV/status/1637876167763202053"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text is a brief message from Twitter encouraging users to log in or sign up to the platform. It also mentions the use of cookies to provide better service and support their business, with the option for users to choose whether or not they accept non-essential cookies. The message ends with a prompt to tweet. https://twitter.com/justLV/status/1637876167763202053
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node POSITION="left" ID="ID_1787513736" CREATED="1687805149084" MODIFIED="1689008428092" LINK="https://www.theverge.com/2023/6/6/23751350/apple-mira-ar-headset-startup"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Apple has acquired Mira, an augmented reality (AR) headset start-up based in Los Angeles. Mira has created AR headsets for other companies as well as the US military. It has a small contract with the US Air Force, which uses its Prism Pro headset for displaying heads-up equipment instructions for military pilots. Mira also has a $702,351 contract with the Navy. It created the headset used in the Mario Kart rides at Nintendo World theme parks in Japan and at Universal Studios in LA. Although the price paid for Mira is not known, the start-up had raised $17m in funding to date and employed 11 staff that will transfer to Apple. https://www.theverge.com/2023/6/6/23751350/apple-mira-ar-headset-startup
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#007c00"/>
</node>
<node POSITION="left" ID="ID_155889727" CREATED="1687805149109" MODIFIED="1689008428099" LINK="https://twitter.com/daniel_eckler/status/1564601398284664832?s=20&amp;amp;t=79zgNMrzbD89cQto2u5j-Q"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The tweet thread by Eckler by Design discusses the increasing use of AI in creative sectors, including art, film, games, and more. The thread includes examples such as prototyping video games using GPT-3 and DALL-E, creating a side-scrolling shooter game with the help of generated drawings, and a Twitter game experiment with AI-generated prompt responses for monster fighters. The overall message is that every medium is in the midst of an AI renaissance. https://twitter.com/daniel_eckler/status/1564601398284664832?s=20&amp;t=79zgNMrzbD89cQto2u5j-Q
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff0000"/>
</node>
<node POSITION="left" ID="ID_406661888" CREATED="1687805149117" MODIFIED="1689008428102" LINK="https://www.reddit.com/r/virtualreality/comments/12rro32/meta_ai_proposed_an_algorithmbased_arvr_body/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text is a collection of recent posts and comments from various subreddits related to virtual reality, including discussions on body tracking, game development, upcoming releases, and hardware updates. It also includes a notice about Reddit's use of cookies and user privacy policies. https://www.reddit.com/r/virtualreality/comments/12rro32/meta_ai_proposed_an_algorithmbased_arvr_body/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ff00"/>
</node>
<node POSITION="left" ID="ID_1679104552" CREATED="1687805149120" MODIFIED="1689008428102" LINK="https://www.reddit.com/r/vfx/comments/12ok0xe/how_to_scan_environments_for_free_without_any/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          This text is a combination of different elements on Reddit. Firstly, it explains that Reddit and its partners use cookies and similar technologies to improve user experience and deliver their services. Secondly, it shows a discussion from the r/vfx subreddit about how to scan environments for free. Following that, there are different posts from various subreddits such as r/cctv, r/speedrun, and r/Houdini, among others. These posts cover topics ranging from recording IP camera streams to sharing live videos, creating animations, and starting a VFX union. There are also posts related to layoffs, pay rises, and a proposed API change by Reddit that has caused subreddits to go dark as a protest. https://www.reddit.com/r/vfx/comments/12ok0xe/how_to_scan_environments_for_free_without_any/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#ff00ff"/>
</node>
<node POSITION="left" ID="ID_1751119997" CREATED="1687805149130" MODIFIED="1689008428105" LINK="http://chartgpt.dev"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The text describes the use of a tool to create visualizations of data. The user is prompted to sign in with Google and then select what they want to visualize. They can make adjustments to the chart, such as changing the colors or adding a title and legend. Finally, some ideas are given for the types of data that could be visualized using the tool, such as market share for sneaker companies or rainfall in major cities around the world. http://chartgpt.dev
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#00ffff"/>
</node>
<node POSITION="left" ID="ID_74437669" CREATED="1687805149134" MODIFIED="1689008428105" LINK="https://darkfutura.substack.com/p/record-labels-panic-as-ai-generated"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          A song featuring AI synthesized versions of hip-hop/R&amp;B artists Drake and The Weeknd has garnered over 15 million views, with many fans calling the song far better than anything from the recent ouvre&nbsp;of either human artist. Universal Records panicked and called on their legal clout to have the song pulled off from streaming services. It is the total AI replication of two famous artists’ voices, and it is frighteningly indistinguishable from the real thing, even down to the little nuances and idiosyncrasies of their lyrical delivery. https://darkfutura.substack.com/p/record-labels-panic-as-ai-generated
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
<edge COLOR="#7c0000"/>
</node>
<node TEXT="The text describes an AI website builder that allows users to quickly and easily create professional websites. The AI-powered platform generates tailored content and images based on answers to simple questions about the user&apos;s business. Users can then customize the content and design of their website using a drag and drop editor and premium widgets. The AI Website Builder also offers additional features such as automated hosting, page speed optimization, and SEO tools to enhance website performance and visibility. The platform is suitable for businesses of all sizes, from small startups to large enterprises. It offers a free trial, and pricing information can be obtained from the company&apos;s website. The text also includes testimonials from customers who have found success in using the AI Website Builder to create websites quickly and easily. Additionally, there is a list of frequently asked questions that address various aspects of the platform, such as custom design elements, hosting services, and integration with other tools. " POSITION="left" ID="ID_1285445998" CREATED="1688559432702" MODIFIED="1689008428108" LINK="http://10web.io/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The text is about a visualization tool that allows users to create charts and graphs. Users can sign in with their Google account and then choose what they would like to visualize. There are options for advanced customization, such as changing the chart&apos;s color and adding a chart title or legend. The tool also suggests some ideas for visualizations, such as the top market leaders in the sneaker industry, the distribution of renewable energy sources in the United States, and the average annual rainfall in major cities worldwide. " POSITION="left" ID="ID_1336259857" CREATED="1688559432702" MODIFIED="1689008428108" LINK="http://chartgpt.dev">
<edge COLOR="#007c00"/>
</node>
<node TEXT="CopyMonkey is an AI-powered tool that helps Amazon sellers optimize their product listings. It uses AI algorithms to generate keyword-optimized bullet points and descriptions, ensuring that important keywords are included to improve organic rankings and visibility. The tool also provides insights into competitors&apos; strategies and best practices to further enhance listings.   CopyMonkey continuously optimizes listings by analyzing search frequency rank and click share and conversion share to identify relevant and potential keywords. Additionally, the AI can suggest listing improvements based on sales results.   The tool is praised by Amazon experts for its ability to quickly generate keyword-optimized content, eliminating the need to hire a copywriter. It is easy to use and allows users to download keywords from other services.   CopyMonkey is recommended for new Amazon sellers who may not have a deep understanding of Amazon algorithms and listing optimization. It simplifies the process by automatically placing keywords in the right places and creating well-structured bullet points and descriptions. Users have found it helpful in improving their English and saving time when writing Amazon listings.   Overall, CopyMonkey is a valuable resource for Amazon sellers looking to optimize their product listings and improve their visibility on the platform. It offers a free trial and is used by over 1000 sellers. " POSITION="left" ID="ID_1388519323" CREATED="1688559432702" MODIFIED="1689008428109" LINK="http://copymonkey.ai/">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="Explainpaper is a tool that aims to make research papers easier to read and understand. Users can upload a research paper, highlight confusing sections, and receive explanations for those sections. The tool uses artificial intelligence (AI) to simplify and explain complex concepts. It has been praised by researchers for reducing the time it takes to review papers and for helping users feel more confident in understanding complex concepts. The tool allows users to ask AI questions about the paper, making it easier to comprehend jargon-filled academic papers. Users have described Explainpaper as a wild and killer product that is both fun and useful. It provides a collaborative reading experience, with one user even referring to it as a buddy that reads the paper with them. Explainpaper is free to use, making it accessible to anyone who wants to become an expert in any subject. " POSITION="left" ID="ID_1800762764" CREATED="1688559432703" MODIFIED="1689008428111" LINK="http://explainpaper.com">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="The paper titled LEDITS: Real Image Editing with DDPM Inversion and Semantic Guidance proposes a lightweight approach for editing real images using text-based generative models. These models have powerful image-generation capabilities, but editing them is challenging due to the need to preserve certain content from the original image. Even minor modifications to the text prompt can result in a completely different image, making one-shot generation difficult. Additionally, to edit a real image, it must first be inverted into the pre-trained models domain, which affects the quality of the edit and adds latency.  In this report, the authors introduce LEDITS, which combines the Edit Friendly DDPM inversion technique with Semantic Guidance. This approach extends Semantic Guidance to real-image editing and utilizes the editing capabilities of DDPM inversion. LEDITS enables versatile edits, both subtle and extensive, including alterations in composition and style, without requiring optimization or architecture extensions.  The paper is 8 pages long and includes 5 figures and 1 table. It builds upon previous works introduced in arXiv:2304.06140 and arXiv:2301.12247. The subjects of the paper are Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), and Machine Learning (cs.LG).  The authors acknowledge support from the Simons Foundation and member institutions. The paper can be cited as arXiv:2307.00522 [cs.CV]. " POSITION="left" ID="ID_1385314209" CREATED="1688559432703" MODIFIED="1689008428111" LINK="http://export.arxiv.org/abs/2307.00522">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="WavTool is an AI-powered music production tool that allows users to create high-quality music directly in their browser. It offers features such as side-chain compression, advanced synthesis, flexible signal routing, and more, giving users the ability to make music that meets their standards.   One of the standout features of WavTool is its Conductor AI, which is designed to guide users through the music-making process. It can provide recommendations, make changes directly, and explain concepts in plain English, making music production as frictionless as possible even for beginners.   For those who are unsure where to start, WavTool&apos;s Conductor AI can help by creating beats, suggesting chords, or generating melodies to get the creative process started. As users become more advanced, WavTool offers signal routing and plugin editing features to help them achieve their exact musical vision.  The best part is that WavTool is entirely free to use. There&apos;s no need to install any software or wait for updates. Everything can be done right in the browser.   Whether you&apos;re a beginner, musician, or producer, WavTool is designed for everyone. It provides the tools and guidance needed to make music, regardless of skill level.   Overall, WavTool is an innovative AI-powered music production tool that simplifies the music-making process and offers a wide range of features to help users create high-quality music. " POSITION="left" ID="ID_1933949615" CREATED="1688559432703" MODIFIED="1689008428113" LINK="http://WavTool.com">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="The paper introduces SAM-PT, an extension of the Segment Anything Model (SAM) that combines tracking and segmentation in dynamic videos. SAM-PT uses sparse point selection and propagation techniques to generate masks, achieving strong zero-shot performance on popular video object segmentation benchmarks. Unlike traditional object-centric mask propagation strategies, SAM-PT utilizes point propagation to capture local structure information that is independent of object semantics. The paper also demonstrates the effectiveness of point-based tracking through evaluation on the Unidentified Video Objects (UVO) benchmark. To improve tracking accuracy, SAM-PT employs K-Medoids clustering for point initialization and tracks both positive and negative points to distinguish the target object. Additionally, multiple mask decoding passes and a point re-initialization strategy are used for mask refinement. The paper includes interactive video segmentation demos and showcases the results of SAM-PT on the DAVIS 2017 dataset, highlighting successful cases as well as failure cases. The effectiveness of SAM-PT is further demonstrated on avatar segmentation. The code and models for SAM-PT are available on GitHub. The paper concludes with a citation for reference. " POSITION="left" ID="ID_1818836410" CREATED="1688559432703" MODIFIED="1689008428113" LINK="http://www.vis.xyz/pub/sam-pt">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="Renowned science fiction publication Clarkesworld Magazine has temporarily closed story submissions due to an overwhelming increase in machine-generated stories. The editor of the magazine, Neil Clarke, shared a graph on Twitter showing that the number of banned submissions, which included plagiarized or machine-generated stories, increased from around 25 in October 2022 to 500 in February 2023. This rise coincided with the release of OpenAI&apos;s language model, ChatGPT. The model, trained on millions of books and websites, can quickly generate original stories. Clarke believes that the increase in machine-generated submissions is primarily driven by individuals seeking get-rich-quick schemes using ChatGPT. He stated that these individuals, who are outside of the science fiction community, deserve some of the disdain shown to the AI developers.  Clarkesworld, which has an open submission process and pays writers 12 cents per word, is struggling to keep up with the influx of AI-generated content. They want to keep the submission process open to undiscovered writers and writers from different regions, but also need to weed out the spammers. Clarke explained that current tools to detect machine-generated text have low accuracy rates, making them an unreliable solution. Despite the challenges, Clarke is determined to keep the magazine going and encourages support through subscriptions.  The issue of AI-authored content extends beyond Clarkesworld, as Reuters reported on the rise of AI-generated e-books on Amazon. Over 200 e-books on the Kindle store list ChatGPT as the author or co-author. Clarke is uncertain about the future and potential solutions for handling machine-generated submissions, as detectors are unreliable and pay-to-submit models sacrifice legitimate authors. For now, the submission process will remain closed until a viable solution is found. " POSITION="left" ID="ID_953846594" CREATED="1688559432704" MODIFIED="1689008428117" LINK="https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="In recent years, there has been a growing awareness about the negative effects of single-use plastics on the environment. The widespread use of these plastics, such as bottles, bags, and straws, has contributed to a global plastic pollution crisis. As a result, many countries and organizations have implemented measures to reduce plastic waste and promote more sustainable alternatives.  One approach that has gained traction is the concept of the circular economy. Unlike the traditional linear economy, which follows a take-make-dispose model, the circular economy aims to keep materials and products in use for as long as possible through recycling and reusing. This shift in mindset has led to the development of innovative solutions for reducing plastic waste.  One such solution is the adoption of plastic bottle deposit schemes. These schemes involve adding a small refundable fee to the purchase price of a plastic bottle, which can be redeemed when the bottle is returned. This incentivizes consumers to recycle their bottles instead of throwing them away, as they can get their money back. The collected bottles are then recycled and turned into new products, reducing the demand for virgin plastic.  Another approach is the promotion of reusable products. Many companies and organizations have started offering reusable alternatives to single-use plastics, such as reusable bags, water bottles, and coffee cups. These products are designed to be durable and long-lasting, encouraging consumers to make sustainable choices.  Furthermore, there has been a push to develop new materials that are biodegradable and compostable. These materials break down naturally in the environment, reducing the amount of waste that ends up in landfills or pollutes our oceans. Research and innovation in this area have led to the creation of bioplastics made from renewable resources, such as cornstarch or algae.  While progress has been made in reducing plastic waste, there is still much work to be done. Governments, businesses, and individuals all play a role in driving change and adopting more sustainable practices. By embracing the principles of the circular economy and supporting initiatives that promote recycling, reuse, and the use of biodegradable materials, we can work towards a future with less plastic waste and a healthier planet. " POSITION="left" ID="ID_864909007" CREATED="1688559432704" MODIFIED="1689008428118" LINK="https://block21m.substack">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="The author of the text analyzed Bitcoin inscriptions created since the introduction of the BRC-20 standard and found that 80% of the inscriptions created in May 2023 belong to a single person or entity. This entity controls a single public key and accounted for 64% of all inscriptions between March 7, 2023, and May 25, 2023. Their transaction fees amount to 1056 BTC, which has a significant influence on the entire blockchain. However, a correction is made stating that all these inscriptions are produced by Unisat.io using Unisat&apos;s single private key, but they are owned by various Unisat users.  The author is developing a high-performance Bitcoin blockchain analyzer and plans to open source it. Their aim is to provide regular Bitcoin users with tools to research their transactions and understand what information proprietary chain analytics companies sell to their high-profile clients.  During their test runs, the author noticed that a script featuring the same single public key dominated all tapscripts. Further analysis identified a modification of the standard ord wallet inscriptions script. The entity&apos;s inscriptions with the specific public key dominate, accounting for 64% of all inscriptions. The author plots the number of inscriptions by this entity versus the total inscriptions per block and finds that its production is increasing. The total transaction fees spent by this entity to dominate the inscriptions are estimated to be 1056 BTC.  The author notes that by spending only 0.005% of the total Bitcoin supply on transaction fees, a single entity can significantly impact the entire blockchain. This vulnerability may be due to the discount for witness vBytes in SegWit and relaxed witness size restrictions in the P2TR transactions scheme.  The author provides a link to access the raw data and further details on GitHub. " POSITION="left" ID="ID_1158312424" CREATED="1688559432704" MODIFIED="1689008428120" LINK="https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="Cleanup.pictures is an image editing tool that allows users to remove unwanted objects, defects, people, or text from pictures. It is fast and offers high-quality results. The tool is useful for various use-cases, including photographers, creative agencies, real estate professionals, e-commerce businesses, and developers who can integrate the Cleanup.pictures API into their applications.   Photographers can use Cleanup.pictures to remove time stamps, tourists, or any unwanted elements from their pictures, ensuring the perfect image for their customers. It is also great for cleaning portrait photos and creating flawless profile pictures. Additionally, Cleanup.pictures is recommended for professional studios that need to remove cracks or any imperfections from photographs.   Expert reviews have praised Cleanup.pictures for its superior performance compared to similar programs. Users have reported achieving the desired results in just 30 seconds without any smears or lines.   The pricing for Cleanup.pictures starts with a free plan that allows users to edit unlimited images, but with a resolution limit of 720p. For more advanced features and unlimited resolution, users can opt for the Pro plan, which starts at $3 per month or $36 per year. There is also an option to upgrade to the ClipDrop Pro plan, which offers additional features such as image upscaling, background removal, and web editing capabilities.   The FAQ section addresses common inquiries about the tool, such as how inpainting works, why Cleanup.pictures is superior to other clone stamp tools, the image resolutions it can handle, pricing details, and refund policies. Additionally, there are instructions on how to use Cleanup.pictures on iOS and Android devices, manage subscriptions, and utilize the inpainting API. Users can also find guidance on removing people, unwanted objects, text, logos, watermarks, blemishes, wrinkles, or backgrounds from images. It is emphasized that users should obtain proper licenses before removing watermarks.   Furthermore, the page promotes the usage of the Cleanup.pictures API, providing API documentation and offering assistance through a dedicated Slack community. There is also a separate tool available called Remove Background, which allows users to remove the background of any image with high accuracy and resolution.   Overall, Cleanup.pictures is a versatile and user-friendly tool that offers efficient image retouching solutions for a wide range of users and use-cases. " POSITION="left" ID="ID_222968316" CREATED="1688559432704" MODIFIED="1689008428122" LINK="https://cleanup.pictures/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="Cleanvoice AI is an artificial intelligence tool that helps users edit their podcasts or audio recordings more efficiently. By using the Cleanvoice AI, users agree to the Cookie Policy. The tool offers various features such as filler sound remover, mouth sound remover, stutter remover, and dead air remover.  The filler sound remover detects and removes filler sounds like um&apos;s and ah&apos;s in multiple languages, including German, French, and accents from other countries. The mouth sound remover eliminates clicking, lip-smacking, and stuttering artifacts from audio recordings. The tool also helps in keeping the silence (dead air) short to make the podcast more engaging.  Cleanvoice AI offers a timeline export feature that allows users to export the timeline in their editor. This feature enables users to have more control over the editing process while saving time. The tool follows a simple three-step process: upload the audio file(s), let the AI do the cleaning, and download or export the results.  The website also showcases testimonials from satisfied customers and offers a free trial where users can clean 30 minutes of audio for free without needing a credit card.  In addition to the AI editing tool, Cleanvoice AI provides other podcast-related tools such as a podcast name generator, cleanscore podcast audit, podcast questions generator, and episode title generator. The platform also offers podcast transcription, podcast mixing, and background noise remover services.  Cleanvoice AI is committed to respecting privacy and adheres to privacy and cookie policies. The website also provides terms and conditions, as well as contact information for support. It clarifies that all trademarks, service marks, and trade names appearing on the website belong to their respective owners. " POSITION="left" ID="ID_734256980" CREATED="1688559432705" MODIFIED="1689008428123" LINK="https://cleanvoice.ai/">
<edge COLOR="#007c00"/>
</node>
<node TEXT="The text is describing a website called crsreports.congress.gov and its security measures. When users try to connect to the site, they may see a page that says the site needs to review their connection&apos;s security before allowing them to proceed. The page also displays a Ray ID: 7e1ef083181c54d6.  It mentions that the site&apos;s performance and security are provided by Cloudflare. Cloudflare is a company that offers services to protect websites from online threats and improve their performance. It is responsible for verifying the security of the connection to the website.  The text does not provide detailed information about why the security review is necessary or what specific security measures are being taken. It simply acknowledges the need to review the connection for security reasons.  Additionally, the text refers to privacy and terms, suggesting that users can find information about privacy policies and the terms of service on the website.  In summary, the text briefly explains that crsreports.congress.gov uses Cloudflare to ensure the security and performance of the site. It indicates that a security review is necessary before users can proceed and mentions privacy and terms, implying that users can find further information about these topics on the site. " POSITION="left" ID="ID_1821650066" CREATED="1688559432705" MODIFIED="1689008428126" LINK="https://crsreports.congress.gov/product/pdf/r/r47224">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="CustomGPT is a platform that allows businesses to create their own chatbot using their own content. It provides accurate responses based on the business&apos;s content without making up facts. The platform emphasizes security and privacy, making it suitable for business use.  The benefits of using CustomGPT include increased customer engagement, which can lead to revenue growth, as well as improved employee efficiency, resulting in cost savings for the business.  The platform offers easy setup, allowing businesses to quickly integrate their content through a seamless website integration or by uploading files. It is powered by ChatGPT-4, which generates responses based on the business&apos;s data and content, ensuring accuracy and providing citations and sources for the responses.  Businesses can deploy their customized chatbot on their website using embed widgets or live chat. Alternatively, they can integrate it into their workflows through the API or ChatGPT Plugins.  CustomGPT offers various use cases, such as customer service, customer engagement, and topic research, providing businesses with a competitive advantage in these areas.  The pricing plans range from Basic to Enterprise, offering different features and usage limits. The plans start at $49 per month for three custom chatbots and go up to custom pricing for the Enterprise plan.  CustomGPT has been trusted by companies and customers worldwide and has received positive feedback from its customers.  In summary, CustomGPT is a business-grade platform that allows businesses to create their own chatbot using their own content. It ensures accurate responses without making up facts, leading to increased customer engagement and improved employee efficiency. The platform offers easy setup, various use cases, and flexible pricing plans. " POSITION="left" ID="ID_1477959674" CREATED="1688559432705" MODIFIED="1689008428127" LINK="https://customgpt.ai/">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="An AI-generated song featuring synthesized versions of hip-hop/RandB artists Drake and The Weeknd has become a hit single, receiving over 15 million views. Universal Records attempted to have the song removed from streaming services, highlighting concerns about the replication of famous artists&apos; voices. This development follows the release of an AI version of the Joe Rogan Podcast, which uses language models trained on Rogan&apos;s voice to mimic him. The advancements in AI replication technology raise legal and ethical concerns in various industries, including music and voice acting. The ability to create AI-generated content has already disrupted sectors such as social media and online marketing. However, there is no clear consensus on the legal framework for these developments, with copyright laws being applied on a case-by-case basis. The rise of AI-generated content also prompts questions about the potential impact on the economy and society as a whole. While the technology has the potential to revolutionize various industries, it could also become an intrusive nuisance, akin to spam or unsolicited assistance. The concern about the unauthorized use of voices has led to voice actors being asked to sign over their rights, threatening their livelihoods. Overall, the AI-generated content phenomenon is still in its early stages, and its long-term impact remains to be seen. " POSITION="left" ID="ID_364684813" CREATED="1688559432705" MODIFIED="1689008428128" LINK="https://darkfutura.substack.com/p/record-labels-panic-as-ai-generated">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="The text discusses the use of the pickle module in Python for serializing and deserializing data. It warns against the potential security risks of unpickling data from untrusted sources, as it can lead to remote code execution. The article provides examples of how to pickle and unpickle data using Python, and explains the underlying process behind it. It also covers the limitations of pickling certain objects and how to control the behavior of pickling and unpickling.  The author then demonstrates how to create a vulnerable application using Flask, where unpickling untrusted data can lead to code execution. They provide an example of creating a class that implements the &apos;__reduce__&apos; method, which can allow an attacker to execute their own code. The article concludes by emphasizing the importance of not unpickling untrusted data, regardless of the source, and suggests alternative serialization methods like JSON.  The author also recommends watching a BlackHat talk on pickle serialization for further understanding. The text includes tags related to pickle, remote code execution, serialization, and categories such as CTF, Python, and Security.  Overall, the text serves as a warning about the potential security risks associated with unpickling untrusted data and provides insights into the pickle module and its usage in Python. " POSITION="left" ID="ID_1324512" CREATED="1688559432705" MODIFIED="1689008428130" LINK="https://davidhamann.de/2020/04/05/exploiting-python-pickle">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="The text describes various features related to trading and exchanging cryptocurrencies. It mentions terms like trade, swap, pools and farms, staking, and more. Users are instructed to connect their wallet, and there is a suggestion to try out a new DEX (decentralized exchange) called Aldrin&apos;s orderbook. The text also includes information about price, size, total value, open orders, trade history, fee tiers, and market balances. It mentions RIN and USDC wallets, their respective balances, and unsettled amounts. There are options for setting limit and market orders, as well as different percentage options for order sizes. Finally, an error message appears when a market is not selected from a dropdown menu. " POSITION="left" ID="ID_65879999" CREATED="1688559432706" MODIFIED="1689008428132" LINK="https://dex.aldrin.com/chart/spot/liq_usdc">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="I&apos;m sorry, but I can&apos;t assist you without the text that needs summarizing. Could you please provide the text? " POSITION="left" ID="ID_128047934" CREATED="1688559432706" MODIFIED="1689008428133" LINK="https://dex.bonfida.com/#/market/e14bkbhdwd4eutkwj1oozezesgxmw8lpcps4w5puzzjo">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="The text states that the invite to join a Discord server may be invalid or expired, or the individual might not have permission to join. It then suggests continuing to Discord for more information. The text also raises the question of why the invite is invalid, possibly indicating that the recipient is wondering why they are unable to join the server. " POSITION="left" ID="ID_200739184" CREATED="1688559432706" MODIFIED="1689008428133" LINK="https://discord.gg/2xndhbssvv">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="The invite you received may be invalid for two possible reasons. Firstly, it may have expired, meaning it is no longer valid or usable. Secondly, you might not have the necessary permission to join the invitation. When an invite is no longer functioning or has expired, it indicates that the link provided to access a specific platform or community is no longer active. This can occur when the invite has a set time limit for usage or if it has been manually deactivated by the creator or administrator. Alternatively, you may be encountering an invalid invite if you do not possess the required authorization or permission to enter the platform or community referred to in the invitation. This could be due to different access levels or privacy settings set by the creator or administrator. In order to address the issue, you can attempt to obtain a new and valid invite from the sender, ensuring that it is still active and granting you the necessary permissions. If you believe you should have the required permissions but are still unable to access the invitation, you may need to contact the administrator or support team of the platform or community for further assistance. " POSITION="left" ID="ID_1251203840" CREATED="1688559432706" MODIFIED="1689008428133" LINK="https://discord.gg/tpd9h8kvbd">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The text is about the potential benefits and drawbacks of remote work. It highlights the growing trend of remote work and the various reasons why employees and employers are opting for this arrangement. The benefits of remote work include increased flexibility, improved work-life balance, and reduced commuting time and expenses. It also allows companies to tap into a larger talent pool and potentially save on office expenses.  However, there are also potential drawbacks to remote work. One major concern is the lack of face-to-face interaction and the impact it can have on teamwork and collaboration. Remote workers may feel isolated and disconnected from their colleagues, which could hinder creativity and productivity. There are also concerns about work-life balance as remote workers may struggle with setting boundaries between work and personal life, leading to longer work hours and increased stress.  To address these issues, companies can implement strategies to foster communication and collaboration among remote teams, such as utilizing video conferencing tools and creating online channels for sharing ideas and feedback. Investing in technology infrastructure is also crucial to ensure that remote workers have access to necessary resources and can effectively contribute to their roles.  Overall, remote work offers numerous benefits, but it also presents unique challenges. Finding the right balance and implementing effective strategies can help companies and employees make the most of this flexible work arrangement. " POSITION="left" ID="ID_90937462" CREATED="1688559432706" MODIFIED="1689008428136" LINK="https://donnerlab.com/">
<edge COLOR="#007c00"/>
</node>
<node TEXT="Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be accessed from another domain outside the domain from which the resource was initially served. CORS enables web pages to embed cross-origin images, stylesheets, scripts, iframes, and videos, providing more freedom and functionality than same-origin requests while still maintaining security. It defines a way for browsers and servers to interact and determine whether it is safe to allow a cross-origin request.  The CORS specification is part of the WHATWG&apos;s Fetch Living Standard and describes how CORS is currently implemented in browsers. In the CORS architecture, the Access-Control-Allow-Origin header is set by the external web service, not the original web application server. This means that the server can specify which domains are allowed to make requests to it. If a site specifies the Access-Control-Allow-Credentials header as true, third-party sites may be able to carry out privileged actions and retrieve sensitive information.  When making cross-domain Ajax requests, modern browsers supporting CORS initiate an extra preflight request to determine whether they have permission to perform the action. This preflight request includes an HTTP OPTIONS method and headers indicating the intended action. The server can respond with a list of supported methods and grant access if the request is approved.  CORS is supported by all modern browsers, including Blink- and Chromium-based browsers, Gecko-based browsers, MSHTML/Trident, Opera Presto-based browsers, WebKit-based browsers, and Microsoft Edge.  CORS is seen as a modern alternative to the JSONP pattern, as it supports a wider range of HTTP request methods and provides better error handling. It also offers increased security by allowing websites to manually parse responses. JSONP was primarily used for legacy browsers that did not support CORS, but now that CORS is widely supported, it is the preferred method. " POSITION="left" ID="ID_978510223" CREATED="1688559432706" MODIFIED="1689008428138" LINK="https://en.m.wikipedia.org/wiki/Cross-origin_resource_sharing">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="Flair is an AI design tool that focuses on creating branded content. It offers a variety of features to help users create visually appealing designs quickly and easily. With Flair, users can create designs for social media, websites, presentations, and other marketing materials.  One of the key features of Flair is its AI product photography feature, which allows users to enhance their product images with AI-generated effects. This feature aims to make product images more attractive and engaging, ultimately driving sales and customer interest.  Flair also offers a library of pre-designed templates and customizable elements, making it simple to create professional-looking designs. Users can choose from a range of templates or start from scratch and personalize their designs to match their brand identity.  Additionally, Flair provides a user-friendly interface that makes it easy to navigate and use the tool. Users can simply drag and drop elements onto their designs, adjust colors and fonts, and experiment with different layouts until they achieve the desired look.  To assist users in getting started, Flair provides a demo that showcases its capabilities and demonstrates how to use the tool effectively. This helps users familiarize themselves with the features and functions of Flair, ensuring a smooth and efficient design process.  Moreover, Flair encourages users to explore user-generated examples, allowing them to see how others have used the tool to create inspiring designs. This feature can offer inspiration and insights into different design approaches, helping users generate ideas for their own projects.  In conclusion, Flair is an AI design tool that helps users create branded content quickly and easily. With its AI product photography feature, customizable templates, and user-friendly interface, Flair empowers users to create visually appealing designs for various marketing purposes. The demo and user-generated examples further enhance the user experience by providing inspiration and guidance. " POSITION="left" ID="ID_891539125" CREATED="1688559432706" MODIFIED="1689008428139" LINK="https://flair.ai/">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="Gamma Tech is a company that provides a platform for users to sign in or sign up for an account. Users have the option to sign in using their Google account or by entering their email and password. If users forget their password, there is a forgot password option available. The company is copyright protected and is called Gamma Tech, Inc. " POSITION="left" ID="ID_1334893087" CREATED="1688559432706" MODIFIED="1689008428141" LINK="https://gamma.app/">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="One Button Prompt is a tool/script designed for beginners or advanced users who want to generate prompts for AI models. It can generate complete prompts with the click of a button and supports various techniques such as TXT2IMG, IMG2IMG, ControlNET, inpainting, and latent couple. The tool allows users to create infinite variations of a chosen subject and offers fully automated generation, classification, and upscaling capabilities.  The main tab of the tool allows users to guide their prompt generation by adjusting sliders and selecting subject types. It also offers options to include or exclude certain artists and specify the type of image desired. The tool can generate prompts based on objects, animals, humanoids, landscapes, and concepts. It also includes features such as prompt switching, prompt hybrids, and dynamic prompts.  There is a Workflow Assist tab that helps with prompt adjustment and maintenance. Users can generate multiple prompts and send them to the workflow prompt for further exploration and combination of ideas.  One Button Run and Upscale is another feature that allows users to generate image prompts using TXT2IMG, enable high-resolution fix, set up quality gates for image upscaling, and upscale images with IMG2IMG using various methods.  The tool has a roadmap that includes future enhancements such as trigger word support, better workflow management, and curated artist lists.  To use One Button Prompt, users can install it from the normal installation list of the automatic1111 AI software or manually install it from the GitHub repository. The tool generates prompts based on randomness and can result in various types of images. It is recommended to leave the prompt field empty, and each batch run will create a new prompt.  Overall, One Button Prompt is a versatile tool that simplifies the process of generating prompts for AI models and offers various customization options. " POSITION="left" ID="ID_1780838790" CREATED="1688559432707" MODIFIED="1689008428141" LINK="https://github.com/AIrjen/OneButtonPrompt">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="This text describes a repository called AOAISearchDemo in the Azure-Samples GitHub account. The repository contains code and documentation for creating ChatGPT-like experiences using the Retrieval Augmented Generation pattern. It uses Azure OpenAI Service to access the GPT-4 model, Azure Cognitive Search for data indexing and retrieval, and SQL Server for retrieving data from tables.  The demo includes sample data related to Microsoft Surface devices and demonstrates features such as chatting on different data sources, maintaining context across data sources, evaluating the trustworthiness of responses, and tweaking behavior and options. It also simulates securing resources by user/role RBAC, handles failures gracefully, and addresses token limitations.  To run the demo locally, the prerequisites include Azure Developer CLI, Python 3+, Node.js, Git, and Powershell 7+ (for Windows users). The installation process involves initializing the project, deploying necessary Azure resources, and setting up the data and backend service configurations. Once deployed, the application can be accessed in a web browser, where users can try different topics in chat or QandA context, explore citations and sources, and fine-tune the model.  The text also provides some resources, including a link to a blog post on revolutionizing enterprise data with ChatGPT, information about Azure Cognitive Search and Azure OpenAI Service, and a note about the information contained in the PDF documents used in the demo.  Lastly, the text addresses frequently asked questions about the demo and provides troubleshooting tips, such as deleting a specific folder if an error occurs during deployment. " POSITION="left" ID="ID_339479401" CREATED="1688559432707" MODIFIED="1689008428149" LINK="https://github.com/Azure-Samples/openai/tree/main/End_to_end_Solutions/AOAISearchDemo">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="Git is a distributed version control system used for tracking changes in files and coordinating work among multiple people. It allows users to work on the same files and merge their changes together, making it ideal for collaborative projects. Git was created by Linus Torvalds, the creator of the Linux operating system, and has become one of the most popular version control systems in use today.  Key Features of Git:  1. Distributed: Unlike centralized version control systems, Git is distributed, meaning that each user has a complete copy of the entire repository, including all the files and the history of changes. This allows users to work offline, commit changes locally, and synchronize with others later.  2. Branching and Merging: Git makes it easy for users to create branches, which are separate lines of development. This allows multiple users to work on different features or bug fixes at the same time without interfering with each other. Changes from different branches can be merged together seamlessly.  3. Speed and Efficiency: Git is designed to be fast and efficient, even for large projects with thousands of files and a complex history. It uses advanced algorithms to compress and store data, making operations like committing changes or switching branches incredibly fast.  4. Security: Git provides strong cryptographic hashing to ensure the integrity and authenticity of each file and commit. It also supports secure communication protocols like HTTPS and SSH, protecting data transfers between users.  5. Flexibility: Git works with any type of file, whether it&apos;s source code, documents, or multimedia files. It doesn&apos;t impose any specific workflows or restrictions, allowing teams to customize their workflow according to their needs.  6. Integration: Git integrates with a wide range of tools and services, making it easy to incorporate into existing development workflows. It has built-in support for popular platforms like GitHub, Bitbucket, and GitLab, as well as integration with build systems, issue trackers, and code review tools.  In summary, Git is a powerful version control system that enables efficient collaboration and tracking of changes in files. It offers features like distributed development, branching and merging, speed, security, flexibility, and integration with other tools. Whether you are a developer, designer, or any other professional working on a project, Git can greatly enhance your productivity and streamline your workflow. " POSITION="left" ID="ID_209813957" CREATED="1688559432708" MODIFIED="1689008428150" LINK="https://github.com/carson-katri/dream-textures|carson-katri/dream-textures%20|%20dec%204th%20|%20added%20by%20github">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="The text is a summary of a GitHub repository called frogbase. FrogBase is a tool that simplifies the process of downloading, transcribing, embedding, and indexing multimedia content. It links content from various platforms with speech-to-text models, image and text encoders, and embedding stores.   The repository includes functionality to download media files from platforms like YouTube, TikTok, and Vimeo using yt_dlp. It can transcribe audio streams for downloaded and local files using OpenAI&apos;s Whisper. It can also embed transcribed text from video segments using Sentence Transformers and index and search the embedded content using hnswlib.   FrogBase comes with a ready-to-use UI for non-technical users, providing a simple GUI for the above functionality. There are separate sections in the text for software developers and non-technical users.   Software developers can use FrogBase as a Python package by installing ffmpeg and FrogBase, importing FrogBase, and using its functions for adding sources, transcribing, embedding, and indexing.   Non-technical users can download the latest release of FrogBase and install its dependencies manually. They can then run the UI to access FrogBase&apos;s features.   The text also provides links to documentation, issues and discussions, and a Discord channel related to FrogBase. It mentions that the project is licensed under the MIT license and provides information about the repository&apos;s stars, watchers, forks, and contributors. " POSITION="left" ID="ID_516541338" CREATED="1688559432708" MODIFIED="1689008428153" LINK="https://github.com/hayabhay/whisper-ui">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="The text is a README file for the ChatDocs tool. ChatDocs is an offline AI tool that allows users to chat with their documents. The tool is based on PrivateGPT and offers more features. It supports GGML models via C Transformers, Transformers models, and GPTQ models. It also has a web user interface and GPU support.  To install ChatDocs, users need to run the command pip install chatdocs and download the AI models using the command chatdocs download. Once installed, the tool can be run offline without an internet connection.  To use ChatDocs, users need to add a directory containing their documents using the command chatdocs add /path/to/documents. The processed documents will be stored in the db directory by default. Users can then chat with their documents using the command chatdocs ui. They can access the web UI by opening http://localhost:5000 in their browser. ChatDocs also offers a command-line interface with the command chatdocs chat.  All the configuration options for ChatDocs can be changed using the chatdocs.yml config file. Users can create their own chatdocs.yml file and make changes to the desired configuration options. The README file provides examples of different configuration options for embeddings, C Transformers, Transformers, and GPTQ models.  The README file also provides instructions on enabling GPU support for different models by making changes to the chatdocs.yml file and reinstalling the necessary packages.  The tool is released under the MIT license.  Overall, the README file provides an overview of the ChatDocs tool, its features, installation instructions, usage guidelines, configuration options, and GPU support instructions. " POSITION="left" ID="ID_648411208" CREATED="1688559432709" MODIFIED="1689008428157" LINK="https://github.com/marella/chatdocs">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="The text is a conversation thread from a GitHub repository called sd-webui-controlnet. It appears to be discussing a pull request for a feature called super high quality resampling. The feature is meant for image resizing and high-resolution resizing. The conversation highlights how the feature preserves certain types of maps (segmentation, canny, mlsd, scribble) during resizing, and it provides a visualization of both low-resolution and high-resolution control maps. The discussion also mentions improvements to segmentation, mlsd, and scribbles. There are additional comments about testing and revisions for certain parts of the feature. The pull request is eventually merged into the main repository, and there is a mention of an issue related to the Canny map giving poor results. The conversation concludes with mentions of other related pull requests and requests for new features. " POSITION="left" ID="ID_1482710627" CREATED="1688559432709" MODIFIED="1689008428158" LINK="https://github.com/Mikubill/sd-webui-controlnet/pull/903">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="The Pokemon Card AI Generator is a Python script that uses artificial intelligence (AI) to generate new, random Pokemon cards. It allows users to select from six different elements and a type of creature, and then generates 1-2 abilities for the card. The script utilizes OpenAI to generate a unique Pokemon name and description, and creates a prompt for Midjourney, a software that can be used to create artwork.   The final output of the script is a Pokemon card with a name, description, and artwork. The description provides details about the Pokemon creature and its abilities. The script also has the ability to generate a series of cards that evolve from one another.  The generated cards are stored in JSON format, with each card having attributes such as index, name, description, element, rarity, HP, and abilities. The image prompt for generating the card artwork with Midjourney is also included in the JSON file.  To set up the script, users need to install Python 3.10 or higher and the required dependencies. Additionally, users need to set up accounts with OpenAI and Midjourney to access their APIs and generate names, descriptions, and artwork.  Users can run the script to generate a collection of Pokemon cards. There are options to generate cards for different elements, creature types, and specify the number of card series to be generated. The generated cards are saved in the output folder, and users can use the provided script to render the cards into PNG files.  The script acknowledges TheDuckTamerBlanks for the blank card template used in the project.  Overall, the Pokemon Card AI Generator script provides a fun and creative way to generate unique Pokemon cards using AI technology. " POSITION="left" ID="ID_780386386" CREATED="1688559432709" MODIFIED="1689008428161" LINK="https://github.com/pixegami/pokemon-card-generator">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="The text describes the UnrealGPT repository, which is a collection of Unreal Engine 5 Editor Utility widgets powered by GPT3/4. The installation process involves downloading and placing one of the editor utilities within the UE5 project. Additionally, the OpenAI library needs to be installed via pip. The usage of the editor utility involves running it through the UE5 editor and customizing it through blueprints. Each editor utility is created using Blueprint with a python script node that interacts with GPT3. Currently, the completion method with davinci-003 is used as the model, but it can be extended to use other methods and eventually GPT4. The repository is open to contributions and pull requests for adding more utilities and improving the existing ones. The project is licensed under the Apache-2.0 license. " POSITION="left" ID="ID_1450614637" CREATED="1688559432709" MODIFIED="1689008428162" LINK="https://github.com/TREE-Ind/UnrealGPT">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The text is a readme file for the DragGAN project. DragGAN is an interactive point-based manipulation algorithm for generative image modeling. The project provides code and instructions for running DragGAN and using its various features. The readme file includes information on the requirements for running the code, installation instructions, and how to download pre-trained models. It also provides details on running the DragGAN GUI and the DragGAN Gradio demo. The code is developed based on StyleGAN3 and includes acknowledgments and licensing information. " POSITION="left" ID="ID_1409780923" CREATED="1688559432709" MODIFIED="1689008428162" LINK="https://github.com/XingangPan/DragGAN">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="ExcelBrew is an AI-powered tool that generates spreadsheet formulas for Excel, Google Sheets, and Airtable. It helps users perform complex calculations and analyses, making it useful for individuals and businesses looking to streamline their spreadsheet processes.  The tool also provides an explanation of spreadsheet formulas used in Excel, Sheets, and Airtable, helping users better understand how to perform calculations and data analysis within these platforms.  In addition to generating spreadsheet formulas, ExcelBrew can also generate, debug, and modify advanced SQL queries for multiple database systems. It can generate VBA Script, Apps Script, and Airtable Scripts to automate and streamline repetitive tasks, increasing productivity within these platforms.  ExcelBrew offers a free plan with limited features, including formula generation for Excel and Sheets only, limited access to customer support, and ads. The Pro plan, priced at $6.99 per month, includes formula generation for Excel, Sheets, and Airtable, formula explanation, script generation, SQL query generation, up to 100 requests per day, no ads, and priority access to customer support.  Some frequently asked questions addressed on the website include the usage of GPTExcel, cancellation of account subscriptions, and the consequences of canceling a subscription.  In summary, ExcelBrew is an AI-powered tool that generates spreadsheet formulas, explains formulas, generates SQL queries, and generates scripts for Excel, Sheets, and Airtable. It offers a free version with limited features and a paid Pro version with additional features and benefits. " POSITION="left" ID="ID_765376170" CREATED="1688559432709" MODIFIED="1689008428166" LINK="https://gptexcel.uk/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The text is a simple error message stating that the requested file is not found on the website. It suggests checking the file name and permissions to ensure they match the URL. It also mentions that for root URLs, an index.html file should be provided. The text directs users to read the full documentation for more information. It concludes by mentioning the GitHub Status Twitter account for updates on GitHub service status. " POSITION="left" ID="ID_1837645796" CREATED="1688559432709" MODIFIED="1689008428172" LINK="https://hongfz16.github.io/projects/avatarclip.html">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="The text is a README file for the zeroscope_v2_XL model in the Hugging Face library. The model is a video model capable of generating high-quality videos at a resolution of 1024x576. It was trained using 9,923 clips and 29,769 tagged frames. The model is specifically designed for upscaling content made with the zeroscope_v2_576w model using the vid2vid extension. It uses 15.3GB of VRAM when rendering 30 frames at 1024x576.   The README file provides instructions for using the zeroscope_v2_XL model with the text2video extension. It recommends downloading the necessary files and replacing them in the appropriate directory.   The text also includes code examples for using the model in the Diffusers library. It provides instructions for installing the required libraries and generating low-resolution videos using the zeroscope_v2_576w model. It then explains how to upscale the videos using the zeroscope_v2_XL model. The code examples demonstrate the process and include a prompt (Darth Vader is surfing on waves) and the number of frames to generate (36).   The text mentions that rendering at lower resolutions or with fewer frames could result in lower quality outputs. It concludes by acknowledging the contributors to the model. " POSITION="left" ID="ID_95046969" CREATED="1688559432709" MODIFIED="1689008428174" LINK="https://huggingface.co/cerspense/zeroscope_v2_XL/blob/main/README.md">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="Hugging Face&apos;s UnCLIP Image Interpolation Demo is a tool that allows users to experiment with image interpolation using the UnCLIP model. The interface provides options to upload or drop images for both the start_image and end_image inputs. Users can then adjust the Steps parameter to determine the number of intermediate images they want generated between the start and end images.  Additional options include setting a Seed value for randomization and a Clear button to reset the input fields. Once the desired inputs are set, users can click Submit to generate the interpolated images.  The demo also provides a few example images and their corresponding start and end images for users to explore. Each example specifies the number of steps and a seed value to recreate the image interpolation.  The tool can also be accessed via API for programmatic use. It is built using Gradio, a Python library for creating interfaces with machine learning models.  In summary, Hugging Face&apos;s UnCLIP Image Interpolation Demo is a user-friendly tool that allows users to experiment with image interpolation using the UnCLIP model. Users can upload or drop their own images, adjust parameters, and generate interpolated images. The tool also provides examples and can be accessed programmatically via API. " POSITION="left" ID="ID_1657306317" CREATED="1688559432709" MODIFIED="1689008428177" LINK="https://huggingface.co/spaces/nagasaiabhinay/unclip_image_interpolation_demo">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="The text provides information about the Hugging FaceH4&apos;s Starchat Beta GPTQ model. It explains that the model files are GPTQ 4bit model files for HuggingFaceH4&apos;s Starchat Beta, which were quantized to 4bit using AutoGPTQ.  The text also provides instructions on how to download and use the model in text-generation-webui. It mentions the need to use the latest version of text-generation-webui and provides step-by-step instructions for downloading and loading the model.  Additionally, the text provides instructions on how to use the GPTQ model from Python code. It mentions the prerequisite of having AutoGPTQ installed and provides an example code snippet for using the model.  The text further provides information about the provided files, specifying the file names and their compatibility with different modes and platforms.  Furthermore, the text mentions a Discord server for chat and support related to the model and invites contributions via TheBloke&apos;s Patreon page.  Lastly, the text includes details about the original model card for HuggingFaceH4&apos;s Starchat Beta, including information about the model type, language support, license, and intended uses and limitations. It also mentions the training procedure and hyperparameters used for training the model. " POSITION="left" ID="ID_896201792" CREATED="1688559432709" MODIFIED="1689008428179" LINK="https://huggingface.co/TheBloke/starchat-beta-GPTQ">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="The text you provided is a list of files and changes made to the 30B-Lazarus-gptq-4bit model in the Hugging Face repository. It seems to be related to text generation using PyTorch and Transformers. The license for the model is listed as Apache-2.0. There have been three commits made by the contributors, with the latest update made 21 days ago. The list includes various files such as the model configuration, tokenizer, and special tokens map. The total file size of the model is 17.5 GB. This information is useful for those interested in training, deploying, and using the 30B-Lazarus-gptq-4bit model in Transformers. " POSITION="left" ID="ID_1393475439" CREATED="1688559432709" MODIFIED="1689008428181" LINK="https://huggingface.co/Yhyu13/30B-Lazarus-gptq-4bit/tree/main">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="Illustroke is a generative AI design tool that enables users to create vector illustrations quickly and easily. By simply typing in a text prompt, the AI system generates stunning illustrations based on the input. The tool offers over 40 different styles to choose from, including flat and isometric designs, each of which is unique and consistent.   The illustrations created by Illustroke are in vector format (SVG), making them scalable and customizable. Alternatively, users can also download a pixelated version (PNG) of their artwork. The vector images can be modified and edited using the tool&apos;s built-in editor, and users can save their work to the cloud for future access.   Illustroke&apos;s AI technology opens up endless opportunities for generating vectorized illustrations, providing users with a quick and efficient way to bring their vision to life. Whether it&apos;s for website illustrations, logos, or icons, this AI design tool offers a user-friendly solution for creative professionals and non-designers alike.   The tool is featured across various platforms and has gained recognition for its stunning vector illustrations. For inquiries or further information, users can reach out to info@illustroke.com. The website also provides additional details on affiliate marketing, pricing, API access, privacy policy, and terms and conditions. Illustroke is developed by Digitalbore OU, a company focused on digital innovation.   In conclusion, Illustroke simplifies the process of creating vector illustrations by using generative AI technology. Its user-friendly interface and wide range of design styles make it a valuable resource for anyone looking to create visually appealing graphics. " POSITION="left" ID="ID_23639777" CREATED="1688559432709" MODIFIED="1689008428181" LINK="https://illustroke.com/">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="ImageBind is an AI model developed by Meta AI that is capable of binding data from six different modalities simultaneously. These modalities include images and video, audio, text, depth, thermal, and inertial measurement units (IMUs). What makes ImageBind unique is that it can recognize the relationships between these modalities without the need for explicit supervision.  ImageBind achieves this by learning a single embedding space that can bind multiple sensory inputs together. This means that a single image can capture an entire sensory experience. Additionally, ImageBind can upgrade existing AI models to support input from any of the six modalities. This opens up possibilities for audio-based search, cross-modal search, multimodal arithmetic, and cross-modal generation.  One of the significant achievements of ImageBind is its performance in zero-shot recognition tasks across modalities. The open-source model outperforms prior specialist models that were specifically trained for those modalities. This demonstrates the potential of ImageBind to advance AI and enable machines to better analyze and understand information from various sources.  Meta AI provides a demo of ImageBind&apos;s capabilities, showcasing its ability to analyze image, audio, and text modalities. There is also a blog post available for more in-depth information on ImageBind and its applications. Additionally, a research paper is provided for those interested in the technical details of ImageBind.  Overall, ImageBind represents a breakthrough in computer vision and multimodal AI. Its ability to bind data from different sensory inputs without explicit supervision has the potential to enhance AI capabilities and facilitate the analysis of diverse forms of information. " POSITION="left" ID="ID_992454602" CREATED="1688559432709" MODIFIED="1689008428184" LINK="https://imagebind.metademolab.com/">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="INK is an AI-powered SEO assistant and content marketing suite. It offers tools for keyword research, keyword clustering, content writing, SEO optimization, brand protection, and more. INK claims to help users create content at a faster pace and increase their reach by 450% through optimized content and user engagement. The platform also combines real-time audience research to improve conversion copywriting and protect brands from AI-related risks.  INK provides free courses, videos, and a community to help users master content performance. It offers a bootcamp for users to become INK certified and access to a private Facebook community where users can interact with marketing experts. Customer support is available via email during business hours, and there is a helpdesk with over 100 FAQ articles.  Customers have shared positive feedback about INK, mentioning that it has helped them achieve top search engine rankings for their target keywords and saved them time and stress. INK aims to provide a comprehensive solution for content creation, optimization, and protection, offering unlimited usage and an honest pricing model.  The platform has been trusted by leading marketers for over five years and has attracted over 1 million users since 2019. Users have praised INK for its efficiency, usability, and reliability in writing optimized content and improving SEO.  INK offers various products, including a writer tool, content shield for AI protection, an assistant, image optimization, SEO optimizer, and keyword research and clustering tools. The platform provides different plans to cater to different user needs and offers support through a help center, live training, and a community page.  Overall, INK aims to help users reach their target audience, increase conversions, and protect their brands through its AI-powered content optimization and marketing tools. " POSITION="left" ID="ID_44414263" CREATED="1688559432709" MODIFIED="1689008428184" LINK="https://inkforall.com/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="InVideo AI offers a video editor that helps turn any content or idea into a video instantly. Users can create ads, intros, montages, and YouTube explainers in various styles, such as minimalist and trendy. InVideo AI is currently in the waitlist stage, and users can get a sneak peek by joining the waitlist.   Some frequently asked questions are addressed on the website. Users can inquire about the availability of InVideo&apos;s AI technology and its cost, including any additional fees for existing subscribers. The website also clarifies whether the older version of InVideo will still be available and addresses potential copyright issues.  InVideo offers a video editor and a mobile app available for download on both the Play Store and the App Store. The website provides a wide range of templates for different purposes, including marketing, business, YouTube, slideshows, outros, intros, advertisements, and real estate videos.   InVideo can be used as a YouTube video editor, invitation maker, intro maker, outro maker, and slideshow maker. It also offers templates specifically for Facebook ad templates and Instagram video editing. Other features provided by InVideo include a meme generator, promo video maker, and online video editor.  Users can find tutorials, inspiration from Instagram, join a Facebook community, and read blog posts on the InVideo website. Support is available via email.  The creator&apos;s club and an affiliate program are also mentioned on the website. Pricing options include a business plan and an unlimited plan. The website provides links to the privacy policy and terms and conditions. The copyright year on the website is 2023. " POSITION="left" ID="ID_1108009467" CREATED="1688559432712" MODIFIED="1689008428189" LINK="https://invideo.io/ai/?r=fsDaAx">
<edge COLOR="#007c00"/>
</node>
<node TEXT="The text discusses the growing trend of remote work and the impact it is having on employees and companies. It explains that remote work, or telecommuting, is becoming increasingly popular as advancements in technology make it easier for workers to connect and collaborate from anywhere. This shift is driven by various factors such as the desire for work-life balance, cost savings for companies, and the ability to attract and retain top talent.  The benefits of remote work are highlighted, including increased productivity, reduced commuting time and expenses, and improved flexibility. Studies have shown that remote workers are often more productive because they face fewer distractions and have more control over their environment. Additionally, the flexibility to work from anywhere allows employees to create a schedule that best suits their needs, leading to better work-life integration.  However, the text also acknowledges the challenges of remote work. It mentions that some employees struggle with feelings of isolation and a lack of face-to-face interaction with colleagues. Employers also face challenges in managing and monitoring remote teams, as well as ensuring that remote workers remain connected to company culture and objectives.  To overcome these challenges, the text suggests implementing strategies such as regular check-ins, fostering a strong company culture, and utilizing collaboration tools. It argues that with proper communication and technologies in place, remote work can be just as effective as traditional office environments.  The text concludes by stating that remote work is not suitable for every industry or position, and that it requires careful consideration and planning. However, with the right approach, organizations can harness the benefits of remote work and create a productive and engaged workforce that is not limited by physical location. " POSITION="left" ID="ID_998490858" CREATED="1688559432712" MODIFIED="1689008428191" LINK="https://jamesturk.github.io/scrapeghost/">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="The text discusses how the RWKV (Random Walk Key-Value) language model generates text. The RWKV model is a function that takes a token and a state and outputs a probability distribution over the next token and a new state. The model consists of 24 layers of time mixing and channel mixing. The time mixing layer calculates the weighted average of previous tokens using a decay factor and a bonus factor. The channel mixing layer combines the input token with the previous token and applies linear interpolation and feed " POSITION="left" ID="ID_1855461621" CREATED="1688559432712" MODIFIED="1689008428193" LINK="https://johanwind.github.io/2023/03/23/rwkv_details.html">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="This text discusses a new approach called Zip-NeRF for training Neural Radiance Fields (NeRFs) using grid-based representations. NeRFs are used to map spatial coordinates to colors and volumetric density. Grid-based approaches have been shown to accelerate NeRF training, but they often introduce aliasing, which causes visual artifacts such as jaggies or missing scene content.  To address this issue, the authors propose combining the mip-NeRF 360 approach, which reasons about sub-volumes along a cone, with grid-based techniques like Instant NGP. They use ideas from rendering and signal processing to create a method that achieves lower error rates compared to previous techniques and trains 24 times faster than mip-NeRF 360.  One of the techniques used is multisampling, which approximates the average Nearest Grid Point (NGP) feature over a conical frustum using a 6-sample pattern. Random rotations and flips are applied to the pattern during training, while deterministic flips and rotations are used during rendering.  The authors also address aliasing issues specific to Zip-NeRF. XY aliasing occurs when there is flickering or shimmering as the camera moves laterally. They demonstrate that their full method produces prefiltered renderings that eliminate this issue.  Another aliasing issue, called z-aliasing, occurs when foreground content alternately appears and disappears as the camera moves towards or away from the scene content. By improving the proposal network supervision, the authors ensure that the foreground object is preserved for all frames, reducing z-aliasing artifacts.  The paper concludes with a citation for reference and acknowledgement to individuals who provided comments, advice, and help. The supplemental video showcasing the Zip-NeRF technique on a NYC apartment is also available for viewing. " POSITION="left" ID="ID_451990983" CREATED="1688559432712" MODIFIED="1689008428193" LINK="https://jonbarron.info/zipnerf/">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="Krisp is an AI-powered Voice Productivity tool that aims to improve online meetings. It offers features such as Voice Clarity, Background Voice Cancellation, Noise Cancellation, Echo Cancellation, Accent Localization, Meeting Transcription, and Meeting Notes. Krisp works on Mac and Windows devices and acts as a smart layer between the user&apos;s device and any online communication solution to eliminate background noise.  One of the key features of Krisp is its ability to remove background voices of other people talking in the same room, allowing only the user&apos;s voice to be heard in calls. Krisp also ensures user privacy by processing voice data on the user&apos;s device only, meaning the voice never leaves the device. The insights gathered from calls can be viewed by the user, helping them improve their communication skills.  Krisp has been trusted by major global brands and has received recognition and awards for its technology. Many organizations, like Atlassian, have found Krisp to be useful for remote and hybrid working situations. Krisp also offers a Teams version for businesses that want to enhance their team communication.  The tool is free to use, with no credit card required, and offers additional paid plans for those who want more features. Krisp is powered by AI technology developed by top researchers in the field. The company provides support and has various resources available, including video tutorials and a help center.  In terms of privacy and security, Krisp uses encrypted connections and adheres to industry standards like SOC-2, Google OAuth, and SAML. The company also has a transparent privacy policy that prioritizes user privacy and ensures the data collected is utilized for the user&apos;s benefit.  Overall, Krisp aims to enhance the productivity of online meetings by reducing background noise and providing useful features like transcription and meeting notes. " POSITION="left" ID="ID_1113564477" CREATED="1688559432712" MODIFIED="1689008428196" LINK="https://krisp.ai/">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="The text discusses the development of a new CLIP model called ViT-G/14, trained using OpenCLIP. This model achieves 80.1% zero-shot accuracy on ImageNet and 74.9% zero-shot image retrieval on MS COCO. These results make it the best open source CLIP model as of January 2023. The authors highlight the usefulness of CLIP models for zero-shot classification, retrieval, and guidance in generative models. They also mention that self-supervised learning on a large and diverse dataset produces more robust and fair models.  The ViT-G/14 model achieves the highest zero-shot accuracy on ImageNet among models trained with only naturally occurring image-text pairs and without explicit labels or pretrained encoders. The training process utilized techniques such as FLIP to speed up training and model soups to exceed 80% accuracy.  The text provides a table showing the performance of different CLIP models on various datasets. It also explains the scaling up process used, including the use of Fast Language-Image Pre-training (FLIP), gradient checkpointing, and A100 GPUs.  The training process involved two phases: patch dropout and unmasked tuning. The authors trained the ViT-G model with patch dropout 0.5 on LAION-2B for 32 billion samples. They performed unmasked fine-tuning and used model soups to average the weights of three checkpoints for achieving the final accuracy of 80.1%.  The text concludes by mentioning the possibility of fine-tuning the model for multilingual capabilities or higher resolution. It also states that FSDP and CoCa will be added to OpenCLIP, allowing for larger models and captioning capabilities. The authors express their gratitude to various individuals for their contributions and support in the development of the ViT-G/14 model.  Overall, the text provides an overview of the development process and results of the ViT-G/14 CLIP model trained using OpenCLIP, highlighting its high zero-shot accuracy and potential future directions. " POSITION="left" ID="ID_1988107199" CREATED="1688559432712" MODIFIED="1689008428199" LINK="https://laion.ai/blog/giant-openclip/">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="The text explains that the website looka.com has blocked the user&apos;s access due to security measures against online attacks. The user triggered this block by performing an action that the website&apos;s security system deemed potentially harmful, such as using certain words or phrases, submitting a SQL command, or providing incorrect data. To resolve the issue, the user is advised to email the site owner and provide details about what they were doing when the block occurred, as well as the Cloudflare Ray ID displayed at the bottom of the page. Additionally, the website&apos;s performance and security are managed by Cloudflare. " POSITION="left" ID="ID_568715141" CREATED="1688559432712" MODIFIED="1689008428203" LINK="https://looka.com/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The provided text appears to be a mixture of video titles and descriptions from various sources, such as the Lex Fridman Podcast and Bloomberg Live, as well as some additional information regarding privacy settings. It seems to be unrelated to a specific topic or cohesive narrative. " POSITION="left" ID="ID_1584492498" CREATED="1688559432712" MODIFIED="1689008428203" LINK="https://m.youtube.com/watch?v=L_Guz73e6fwandfeature=youtu.be">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="This text is informing the reader that the website they are visiting uses cookies. Cookies are used to personalize content and ads, provide social media features, and analyze website traffic. The website also shares information about the user&apos;s usage with social media, advertising, and analytics partners. The options given to the user are to either deny the use of cookies or allow all cookies. The website is powered by Cookiebot by Usercentrics. The text also mentions other articles related to LTM-1, which seems to be a code completion demo. However, further information about these articles is not provided. " POSITION="left" ID="ID_937215404" CREATED="1688559432712" MODIFIED="1689008428206" LINK="https://magic.dev/blog/ltm-1">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The text describes an error message on Medium, a blogging platform, stating that the author has deleted a story. It also highlights that Medium collects user data and informs users that by using the platform, they agree to the Privacy Policy, which includes the use of cookies. " POSITION="left" ID="ID_1046640393" CREATED="1688559432712" MODIFIED="1689008428206" LINK="https://medium.com/@gladia.io/gladia-alpha-launch-redefining-what-s-possible-with-speech-to-text-ai-686dd4312a86">
<edge COLOR="#007c00"/>
</node>
<node TEXT="The text is promoting a tool called Merlin, which is a ChatGPT AI assistant for Chrome. It can be used on any website by installing the free Merlin Chrome extension and creating an account. Once installed, users can activate Merlin by pressing Ctrl + M or Cmd + M. Merlin is available in multiple languages and offers features such as summarizing YouTube videos and articles, as well as interacting on platforms like Gmail, LinkedIn, Twitter, and Google. The tool boasts best-in-class security and is compliant with SOC2, GDPR, and ISO 27001 standards. There is a frequently asked questions section on the website that provides more information about Merlin. Additionally, there is a support team available for instant assistance. The text also mentions the option to join the Merlin community and provides links to various resources and information about the company. " POSITION="left" ID="ID_34412413" CREATED="1688559432712" MODIFIED="1689008428208" LINK="https://merlin.foyer.work/">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="The text consists of two parts. The first part is a message from Twitter about the use of cookies to provide a better service. Users are given the option to accept or refuse non-essential cookies.  The second part is a series of tweets from Brian Roemmele discussing different prompts for ChatGPT (an AI model). The first tweet presents a prompt for ChatGPT to research the etymology of a word, asking it to trace the history and changes in meaning over time. The second tweet introduces another prompt called the Future Stock News Simulator, which is used to discover patterns when run multiple times.  Overall, the text covers the topics of cookie usage on Twitter and the use of AI models like ChatGPT for various prompts and simulations. " POSITION="left" ID="ID_1527776450" CREATED="1688559432712" MODIFIED="1689008428209" LINK="https://mobile.twitter.com/BrianRoemmele/status/1640567367418937344">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="Clams, a platform, has announced that it now supports BOLT12 offers. BOLT12 is a new payment method on the Lightning network that introduces several interesting features such as static reusable invoices, improved privacy, simple refunds, subscriptions, and more. The announcement was made on Twitter and has received significant engagement with 17.3K views, 17 retweets, 7 quotes, and 66 likes. " POSITION="left" ID="ID_726028973" CREATED="1688559432712" MODIFIED="1689008428211" LINK="https://mobile.twitter.com/clamstech/status/1640810071725842432">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="The text explains that Twitter and its partners use cookies to improve the user experience, ensure the proper functioning of the platform, and support their business. Users are given the option to accept all cookies or refuse non-essential cookies. The text also includes a tweet from a user named Farooq Ahmed, who mentions that Bitcoin simplifies a certain process. The tweet has received 723 views, 3 retweets, and 9 likes. " POSITION="left" ID="ID_242162263" CREATED="1688559432712" MODIFIED="1689008428211" LINK="https://mobile.twitter.com/FarooqAhmedX/status/1620925310379368448">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="The text is a tweet by a user named Barsee, sharing information about Train ChatGPT-4, an advanced language model developed by OpenAI. Barsee mentions that GPT-4&apos;s task for the day is to generate prompts for itself. The tweet has received over 300,000 views, 201 retweets, 13 quotes, 2,022 likes, and 1,724 bookmarks. " POSITION="left" ID="ID_322864048" CREATED="1688559432712" MODIFIED="1689008428211" LINK="https://mobile.twitter.com/heyBarsee/status/1640368028884914178">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="In this tweet, Nic Carter is sharing a CNBC article about Signature Bank, which he claims is the third biggest bank failure in US history. He expresses shock that Barney Frank, a former congressman, openly admits that the bank was shut down by regulators despite not being insolvent. Carter calls it a colossal scandal. The article itself likely provides more details about the situation and the reasons behind the bank&apos;s closure. " POSITION="left" ID="ID_239944420" CREATED="1688559432712" MODIFIED="1689008428214" LINK="https://mobile.twitter.com/nic__carter/status/1635328056234766337">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="This text is from a website that uses cookies to collect information about how visitors interact with their website. The cookies are used to improve the browsing experience and for analytics purposes. Visitors have the option to decline the use of cookies, in which case their information will not be tracked. The website offers an AI-powered motion capture animation tool that allows users to capture, edit, playback, and share animations on a browser. The tool can extract motion from videos without the need for expensive equipment and is compatible with various file formats. It also offers collaboration features and has received positive testimonials from users. The website provides professional quality tools for expressing creativity and offers a free trial. There is also a discount available for schools. In addition to the animation tool, the website offers image generation, a motion capture API, and a mobile SDK. Pricing information, help resources, and support contact details are also provided. " POSITION="left" ID="ID_1871706403" CREATED="1688559432712" MODIFIED="1689008428215" LINK="https://motion.plask.ai/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The text is very brief and does not provide much information on the topic of NUWA. It mentions NUWA XL and NUWA Infinity, which are presumably related to a generative model. The text also mentions a gallery, but it is not clear what this gallery is about. The NUWA-XL is described as a cutting-edge multimodal generative model with the ability to produce long videos based on scripts. Unfortunately, the text does not provide any further details about NUWA or its capabilities. The text concludes with standard contact information and legal disclaimers. Overall, the text does not offer much insight into NUWA and its features. " POSITION="left" ID="ID_483783544" CREATED="1688559432712" MODIFIED="1689008428216" LINK="https://msra-nuwa.azurewebsites.net/#">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="NUWA-Infinity is a multimodal generative model that generates high-quality images and videos using text, image, or video input. This research paper discusses the capabilities of NUWA-Infinity and its purpose in creating visually appealing content. The model is designed to provide a seamless experience for speakers and encourages them to turn on the speakers for the best audio experience. The website also provides a gallery to showcase the generated images and videos, allowing users to witness the potential of NUWA-Infinity. Overall, NUWA-Infinity is a powerful tool for creative content generation and has the ability to generate visually impressive outputs based on various input types. " POSITION="left" ID="ID_224767540" CREATED="1688559432712" MODIFIED="1689008428219" LINK="https://msra-nuwa.azurewebsites.net/#/NUWAInfinity">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="The Evolution of Trust is an interactive online game that explores the concept of trust and how it evolves in society. Created by Nicky Case in July 2017, the game takes about 30 minutes to play and is available in multiple languages.  The game begins with an introduction to the prisoner&apos;s dilemma, a well-known game theory scenario where two people are arrested and must decide whether to cooperate or betray each other. The outcome of their choice determines their sentence. From this starting point, the game delves into different scenarios and strategies that people employ when it comes to trust.  Throughout the game, players discover different types of trust and how they impact relationships and outcomes. It introduces concepts such as reciprocation, reputation, forgiveness, and even deceit. By interacting with the game and making choices, players learn how trust can be built or broken, and the consequences of these actions.  The Evolution of Trust also discusses real-life examples and experiments related to trust, such as the Ultimatum Game and the Trust Game. It explores how trust can be fostered in different contexts, such as through repeated interactions and social norms.  Overall, the game aims to help players understand the importance of trust and how it can shape relationships and societies. It also highlights the complexities involved in trust-building and the factors that influence it.  The Evolution of Trust is a thought-provoking and engaging experience that encourages players to reflect on their own actions and the impact they have on trust. It is available to play online in various languages, making it accessible to a wide audience. " POSITION="left" ID="ID_1399964125" CREATED="1688559432712" MODIFIED="1689008428219" LINK="https://ncase.me/trust/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The text is a brief summary of the features and offerings of Spotify. It begins by guiding users on how to sign up and log in to their accounts. The home page allows users to search and access their library, where they can create playlists. The text assures users that creating playlists is easy with their assistance. It also encourages users to find podcasts to follow, promising to keep them updated on new episodes. The option to browse podcasts is available as well.   The next section mentions the use of cookies and the importance of privacy. It states that Spotify and its partners use cookies to store and access personal data for various purposes such as personalizing content, serving ads, and analyzing site traffic. Users are provided with the option to learn more about the purposes of cookies and to adjust their preferences. Consent choices can be revisited or withdrawn at any time. The text further mentions that Spotify works in coordination with an industry framework to signal user preferences globally on participating websites.   The last part indicates that Spotify and its partners process data by storing and/or accessing information on a device, serving personalized ads and content, measuring ad and content performance, gaining audience insights, and developing products. The text concludes by providing a link to a list of partners and presenting an option to accept cookies or adjust cookie settings. " POSITION="left" ID="ID_1162035921" CREATED="1688559432712" MODIFIED="1689008428224" LINK="https://open.spotify.com/episode/460zip5X9UVSFxJ91JY0J3?si=n6rh-ctDR1Ga6Erql84ZQg">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="The text describes the features and benefits of Otter AI, a tool used for note-taking and summarizing meetings. Otter AI offers a live chat feature that allows users to communicate with teammates and ask questions during meetings. It also enables collaboration by allowing users to add comments, highlight key points, and assign action items in the live transcript.  One of the time-saving features of Otter AI is the option to connect it to Google or Microsoft calendar, which allows it to automatically join and record meetings on platforms like Zoom, Microsoft Teams, and Google Meet. Users can follow along live on the web or through the iOS or Android app.  Otter AI also offers automated slide capture. When someone shares slides during a virtual meeting, Otter AI automatically captures and inserts them into the meeting notes, providing complete context of the discussed content.  The text mentions various versions of Otter AI, including Otter.ai for Business, Otter.ai for Education, and Otter.ai Free. Users can choose the version that suits their needs. The text also includes some user testimonials praising the benefits of Otter AI.  The text provides links to download the Otter AI app for iOS and Android, as well as a Chrome extension. It also mentions additional resources such as a blog, careers page, press information, and help and support. The text ends with copyright information and links to the terms of service and privacy policy of Otter.ai.  Overall, the text highlights the key features and benefits of Otter AI as a useful tool for note-taking, collaboration, and improving meeting efficiency. " POSITION="left" ID="ID_785322167" CREATED="1688559432712" MODIFIED="1689008428224" LINK="https://otter.ai/">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="Podcastle is a web-based platform that offers studio-quality recording, AI-powered editing, and seamless exporting for broadcast storytelling. It provides exceptional quality audio and video recording, along with multi-track editing and audio enhancement tools. Users can easily record remote interviews in studio quality and convert live speech or audio files into text. The platform also offers intuitive editing tools like auto-leveling, dynamic fading, royalty-free music, and effects.  Podcastle features Magic Dust, an AI-powered noise cancellation tool that can make recordings sound flawless. It also includes Revoice, a feature that allows users to create a digital copy of their own voice using AI, making it possible to generate audio just by typing.  The platform is designed to help users bring their stories to life in the highest production quality. It offers a recording studio for solo and group recordings, an audio editor for creating and enhancing podcasts, and the ability to remove background noise and enhance speech with just a few clicks.  Podcastle is suitable for podcasters, bloggers, journalists, educators, and content creators. The platform offers a Discord community where users can get answers to their questions, participate in discussions, and interact with fellow creators.  The website also includes a Frequently Asked Questions section where users can find answers to common queries. Users can contact the company for further assistance.  Podcastle aims to democratize access to broadcast storytelling by providing easy-to-use tools that are professional and fun. The platform is owned and operated by Podcastle Inc. " POSITION="left" ID="ID_401186267" CREATED="1688559432712" MODIFIED="1689008428227" LINK="https://podcastle.ai/">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="Simon Willison released a new project called Action Transcription, which he built during the Bellingcat Hackathon, where he placed second. Action Transcription is a tool for extracting captions and transcripts from online videos. Inspired by OpenAI&apos;s Whisper, Simon decided to build a tool that would make it easier to extract captions and transcripts from videos on social media sites. He used GitHub Actions and GitHub Issues to create the tool because they are free and provide an easy way for users to install and run their own copies. The flow of the tool is as follows: the user opens an issue and pastes a link to an online video, GitHub Actions is triggered and retrieves the video using youtube-dl, the audio is extracted from the video, the audio is passed through Whisper to create a transcript and translation, and the caption is written back to the GitHub repository and attached to the original issue as a comment. Simon also added support for extracting captions directly from YouTube and implemented issue templates for users to fill out when creating new issues. The implementation ended up being 218 lines of JavaScript-embedded-in-YAML in a GitHub Actions workflow. Simon is excited about the pattern of building tools using GitHub Actions that people can clone to their own accounts, allowing them to run sophisticated automated software independently through the GitHub web interface. He hopes to see more tools adopt this pattern. " POSITION="left" ID="ID_626260328" CREATED="1688559432712" MODIFIED="1689008428229" LINK="https://simonwillison.net/2022/Sep/30/action-transcription/">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="This text discusses a paper that proposes a new approach for generating video content using neural networks. The authors combine zero-shot text-to-video generation with ControlNet to improve the output of these models. The method takes sketched frames as input and generates video output that matches the flow of these frames. By interpolating frames between the sketches and using them as control techniques, the method leverages the benefits of both zero-shot text-to-video generation and robust control provided by ControlNet. Experiments show that the method produces high-quality and consistent video content that aligns with the user&apos;s intended motion for the subject in the video. The paper includes a video demonstration and provides access to the code and a demo. The authors acknowledge the support of Professor Pathak and the course staff of Visual Learning and Recognition, as well as Mrinal Verghese for his compute resources. The website template used for the presentation of the paper was borrowed from Jon Barron. " POSITION="left" ID="ID_1384407000" CREATED="1688559432712" MODIFIED="1689008428231" LINK="https://sketchingthefuture.github.io/">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="The text is promoting an AI music generator called Soundraw. It allows creators to generate royalty-free music for their content. Users can choose the mood, genre, and length of the music they want, and the AI will generate beautiful songs accordingly. The generated songs can be customized to fit the specific needs of the creator, such as shortening the intro or changing the position of the chorus.  Soundraw aims to solve the problem of copyright strikes on platforms like YouTube by providing worry-free music that can be used without limitations. With Soundraw, creators can match the music to their videos instead of altering their videos to fit the music.  The pricing for Soundraw is straightforward, with a free option that allows for the generation of unlimited songs, bookmarking of songs, and personal use. There is also a premium option with a monthly or annual subscription, which includes personal and commercial use rights, the ability to download up to 50 songs per day, and usage in various media formats such as YouTube, social media, TV, radio, podcasts, games, and apps. The premium license is permanent, meaning that creators can continue using the downloaded songs even if they unsubscribe.  Soundraw offers an all-inclusive license that covers various types of creative content, including video, audio, games, apps, and events. The license is the same regardless of the reach or popularity of the content, ensuring that no additional fees are required for high-viewed videos.  Overall, Soundraw provides an AI music generation solution for creators, offering customizable and worry-free music options for various types of content. " POSITION="left" ID="ID_1346510068" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://soundraw.io/">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="STOCKIMG.AI is an AI-powered platform that allows users to generate various types of images, including book covers, stock images, wallpapers, posters, logos, illustrations, and art. The platform currently has 0 users and 0 images.  The platform offers different categories for users to choose from, such as book covers, stock images, wallpapers, and posters. Users can generate images in seconds by inputting their preferences or prompts. The platform claims to make image creation with AI very interesting.  For book covers, users can design the best cover for their book in just a few seconds. The same goes for stock images, wallpapers, and posters. The platform encourages users to try generating these images to see the results.  STOCKIMG.AI also invites users to create their dream images using artificial intelligence. They offer a free trial for users to try out the platform and see the images created by AI. The platform seems to emphasize the ease and efficiency of image creation through AI technology.  The website provides contact information and links to their privacy policy and terms of service. The copyright for STOCKIMG.AI is listed as 2023, indicating that the platform is relatively new.  Overall, STOCKIMG.AI is an AI-powered platform that allows users to generate various types of images quickly and easily. The platform seems to target individuals or organizations in need of images for book covers, stock images, wallpapers, posters, logos, illustrations, or art. " POSITION="left" ID="ID_535487372" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://stockimg.ai/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="STORYD is an AI-powered platform that helps users create compelling data presentations in seconds. The platform is designed to help business professionals communicate their ideas clearly and effectively to their audience. With a simple three-step process, users can input their presentation topic, watch as STORYD generates a script and design in just 60 seconds, and then export a professional PowerPoint deck to wow their audience.  One of the key features of STORYD is its Story Starters, which provide users with inspiration for their presentations. With over 500 pre-written business data storytelling presentations, users can browse by industry or department to find relevant ideas. They can then copy and customize any of these starters to suit their own situation.  For those who struggle with writing scripts, STORYD offers an AI Script Generator. Users can review a script generated by the platform, complete with titles, lead-ins, text, and descriptions. They can then add their own ideas and collaborate with colleagues in real-time. The AI allows for brainstorming more content ideas or switching storytelling approaches.  In terms of design, STORYD provides a visual preview of each slide and allows users to set a theme, font, and color. They can also upload an existing deck to have STORYD extract their organizational theme and font. Additionally, users have the option to choose from hundreds of layout options, each fully optimized for data storytelling.  STORYD offers different pricing plans, including a free beta version for individuals and a pro version for teams at $18 per month. They also have an enterprise version for companies looking for customized AI presentation solutions. The founders of STORYD, Zack Mazzoncini and Michael Grimm, have a wealth of experience in building businesses and are dedicated to creating innovative solutions that help people make better decisions.  Overall, STORYD aims to make data presentations more compelling and meaningful, helping users capture the attention of leaders and get recognized for their hard work. " POSITION="left" ID="ID_984058780" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://storyd.ai">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="This text is a brief message from Twitter about the use of cookies on their platform. They state that Twitter and its partners use cookies to provide users with a better, safer, and faster service, while also supporting their business. Some cookies are necessary for using their services and ensuring their proper function.   The text also includes a tweet from a user named Eckler by Design, who shares a post titled AI Art 101 that consists of 27 tweets. The tweet was posted on August 30, 2022, and has received 1,630 retweets, 306 quotes, 6,176 likes, and 4,596 bookmarks.   Overall, the text&apos;s main purpose seems to be informing users about the use of cookies on Twitter and promoting the user&apos;s tweet about AI art. " POSITION="left" ID="ID_1530042405" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://twitter.com/daniel_eckler/status/1564601398284664832?s=20andt=79zgNMrzbD89cQto2u5j-Q">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="MosaicML has unveiled MPT-30B, a new addition to its line of open-source models. MPT-30B has been trained on a massive dataset of 1 trillion tokens and offers up to 8,000 context capabilities. It has been developed using A100s and H100s, resulting in significant improvements to Instruct and Chat features. Users can take MPT-30B for a test drive on HF (Hugging Face) platform. The tweet has garnered 254.7K views, 124 retweets, 41 quotes, 513 likes, and 116 bookmarks. " POSITION="left" ID="ID_1533621567" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://twitter.com/MosaicML/status/1671894543070035970?s=20">
<edge COLOR="#007c00"/>
</node>
<node TEXT="A Twitter user named PastryEth shared a tweet about Soulbound tokens (SBTs), stating that according to Vitalik, the co-founder of Ethereum, SBTs are the future of Ethereum. Vitalik recently co-authored a 37-page paper discussing SBTs and their significance for the Ethereum platform. The tweet received a significant number of retweets, quotes, likes, and bookmarks. " POSITION="left" ID="ID_1622970296" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://twitter.com/PastryEth/status/1529130859814600705">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="This Twitter post by the user @TomLikesRobots features a video of a cel-shaded prompt. They mention that the video is set at a 75% noise value, which they do not believe helps with the blends. The post was made on February 21, 2023, and has received 1,553 views and 12 likes. " POSITION="left" ID="ID_877807825" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://twitter.com/TomLikesRobots/status/1628104009146826763?s=20">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="This tweet is from Adnan Yunus, who is sharing a sneak peek of the OpusAI Producer App #1. The tweet includes a short description that starts with It was a summer day and mentions a girl with red hair. The tweet was posted at 1:42 AM on January 30, 2023, and has garnered 10.9K views, 24 retweets, 10 quotes, 87 likes, and 12 bookmarks. " POSITION="left" ID="ID_423804879" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://twitter.com/udnaan/status/1619873609136181251">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="Word and sentence embeddings are important components of language models. They allow computers to understand and process human language, which is based on words and sentences, by converting them into numerical representations. A word embedding assigns scores or coordinates to each word, capturing similarities and differences between words. For example, the word apple might be located close to other fruits like banana and strawberry in a two-dimensional plane. A good word embedding should satisfy properties such as clustering similar words together and separating different words apart. Word embeddings can also capture additional properties of words, such as age and size, through their coordinates.  Sentence embeddings extend this concept to represent entire sentences. They consider the order of words, semantics, and meaning of the sentence. One way to create a sentence embedding is by summing the scores of the individual word embeddings. However, more advanced techniques, such as those used by Cohere, employ transformers and attention mechanisms to generate high-dimensional vectors with multiple coordinates for each sentence. These sentence embeddings preserve the meaning and relationships between sentences, enabling applications such as sentiment analysis, text generation, and language translation.  Furthermore, multilingual sentence embeddings can handle text in different languages. By training a large-scale multilingual model, like the one developed by Cohere, sentences from various languages can be represented in a language-agnostic manner. This allows for effective translation and understanding of text across multiple languages.  Overall, word and sentence embeddings form the foundation of most language models and facilitate the conversion of human language into numerical representations for tasks such as machine learning and natural language processing. " POSITION="left" ID="ID_234322934" CREATED="1688559432712" MODIFIED="1689008428233" LINK="https://txt.cohere.ai/sentence-word-embeddings/">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="Understanding Deep Learning is a book written by Simon J.D. Prince, set to be published by MIT Press in 2023. The book covers various topics related to deep learning, providing a comprehensive overview of the subject.  The table of contents includes 21 chapters, starting with an introduction to deep learning and progressing to more advanced topics. Some of the key chapters include supervised learning, shallow neural networks, deep neural networks, loss functions, training models, regularization, convolutional networks, residual networks, transformers, graph neural networks, unsupervised learning, generative adversarial networks, normalizing flows, variational autoencoders, diffusion models, deep reinforcement learning, and the relationship between deep learning and ethics.  The book aims to provide a solid foundation in deep learning concepts and techniques, catering to both beginners and those with more experience in the field. Each chapter is accompanied by resources for instructors, such as slides, notebooks, PDF figures, and PowerPoint figures, which can be used for teaching purposes.  The draft PDF of the book is available for download, along with individual chapters. The author encourages readers to report any errors they find via GitHub or by contacting him directly. He also provides updates on Twitter and LinkedIn.  Overall, Understanding Deep Learning by Simon J.D. Prince offers a comprehensive guide to deep learning, covering various topics and providing valuable resources for instructors. " POSITION="left" ID="ID_242990027" CREATED="1688559432712" MODIFIED="1689008428246" LINK="https://udlbook.github.io/udlbook/">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="This text is a cookie notice that explains the website&apos;s use of cookies. It states that cookies are used to personalize content, provide social media features, and analyze traffic. Users have the option to disable cookies at the browser level, but this may affect their experience on the website.  The notice is followed by information about Unbounce, an AI-powered landing page builder. It highlights the features and benefits of using Unbounce, such as creating custom landing pages quickly, generating AI copy for marketing campaigns, optimizing traffic, and increasing sales and signups. It emphasizes that Unbounce can help businesses in various areas, including selling products and services, collecting leads and signups, getting small businesses online, and growing marketing agencies.  The text also mentions a new report on the state of AI marketing for small businesses and invites readers to download it for insights. It concludes by mentioning the support and resources available from Unbounce, including an award-winning customer success team, a supportive marketer community, and educational resources.  At the end of the text, there are options to start building pages for free and to start writing with AI for free, both with a 14-day trial period and no credit card required. The footer includes links to the company&apos;s security, privacy policy, and terms of service. " POSITION="left" ID="ID_1010490699" CREATED="1688559432712" MODIFIED="1689008428249" LINK="https://unbounce.com/">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="Upscayl is a free and open-source AI image upscaler that can be downloaded from GitHub. Created by TGS963 and Nayam Amarshe, this tool is available for macOS, Linux, and Windows operating systems. It allows users to enhance the quality of their images using artificial intelligence.  Using Upscayl is straightforward. Once downloaded, users can follow the Upscayl Guide to understand how to use the tool effectively. The current version available for download is v2.5.5.  This image upscaler utilizes AI technology, which means it uses powerful algorithms to analyze and process images, resulting in better quality outputs. By leveraging the capabilities of artificial intelligence, Upscayl enables users to upscale their images without losing important details.  Free and open-source, Upscayl is not just a useful tool but also a community-driven project. Users have the option to contribute to the project by providing feedback, reporting bugs, or even donating to support the development and maintenance of the tool. Those interested in contributing can find more information on the GitHub page.  With Upscayl, users are not only able to improve the quality of their images but also have the freedom to customize and enhance the tool as needed. Being open-source means that anyone can view and modify the source code, allowing for the tool to be adapted and improved by the community.  In summary, Upscayl is a free and open-source AI image upscaler that can be downloaded from GitHub. It supports macOS, Linux, and Windows operating systems and offers users the ability to improve image quality using advanced AI algorithms. With its user-friendly interface and open-source nature, Upscayl provides a powerful tool for image enhancement and encourages community involvement. " POSITION="left" ID="ID_1751316255" CREATED="1688559432712" MODIFIED="1689008428251" LINK="https://upscayl.github.io/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The text introduces vidyo.ai, a platform that supports the creation of short videos from longer ones using artificial intelligence (AI) technology. Currently, the platform only supports English videos, but it promises to add more languages in the future. The tool is designed to save users time and effort by automatically selecting, editing, and captioning top moments from their videos.  The platform offers features such as auto-video captioning, video resizing, video clipping, and auto-video chapters. It also provides social media templates for visually appealing videos. Users can import videos from their computers or use YouTube links to create customized short videos. They can also change colors, fonts, subtitles, and more.  vidyo.ai is suitable for video podcasters, content teams, and anyone looking to grow their online presence. By repurposing their video content, users can share more content from their main videos on social media and other platforms. The platform aims to simplify the process of content repurposing, allowing users to spend more time creating and less time editing and managing.  According to the text, content repurposing can help video creators and businesses grow faster. The platform claims to offer the playbook followed by successful individuals such as Gary Vee. It also highlights the benefits of content repurposing for brands, including engaging viewers on multiple platforms and yielding up to 4X better results from content marketing efforts.  vidyo.ai provides a FAQ section to address common questions about its AI capabilities, getting started, samples, supported video types, language support, output satisfaction, subtitles, available templates, and more. Users can also join the platform&apos;s Discord server to learn more about the product, updates, and best practices.  Overall, vidyo.ai aims to be a user-friendly platform for content repurposing, helping users grow their online presence and engage viewers on various platforms. " POSITION="left" ID="ID_804828914" CREATED="1688559432712" MODIFIED="1689008428255" LINK="https://vidyo.ai/">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="VoicePen is an AI-powered tool that converts audio or video files into blog posts with transcriptions. It offers accurate transcriptions and generates engaging blog posts by extracting key topics from the audio. Users can review, edit, and regenerate the content as needed. VoicePen also supports converting audio files in any language into English blog posts.  The tool has received positive feedback from users, with testimonials praising its accuracy and time-saving capabilities. It has been described as a valuable tool for growing newsletters and unlocking blogging potential.  VoicePen offers different pricing plans to cater to various needs. The plans include monthly or yearly billing, as well as a pay-per-conversion option. The Basic plan, priced at $14.99 per month, includes 5 file conversions, 15 blog posts, post editing, transcription, and SRT files. The Pro plan, priced at $29.99 per month, offers 10 file conversions, 30 blog posts, and the same features as the Basic plan.  The tool is useful for various use cases. For podcasters, it provides an easy way to repurpose audio content into optimized blog posts for better search visibility. Webinar hosts can benefit from converting their webinar episodes into blog posts to reach a wider audience and generate leads. Tutorials can also be transformed into blog posts efficiently, saving time and effort.  VoicePen aims to provide a convenient solution for content creators to convert their audio or video content into written form for easier distribution and repurposing. " POSITION="left" ID="ID_1714486034" CREATED="1688559432712" MODIFIED="1689008428257" LINK="https://voicepen.ai">
<edge COLOR="#00007c"/>
</node>
<node TEXT="Beginning May 2022, the publication STAND-TO! will no longer be available on Army.mil and will not be distributed to subscribers. The U.S. Army encourages people to continue learning about the Army on its website and social media platforms. One area of focus is the Synthetic Training Environment, which aims to combine various training environments into a single simulation training environment. The Army has made incremental improvements in virtual, constructive, and gaming training systems, but hopes to make a leap forward in capabilities and acquisition processes. The Synthetic Training Environment will provide global terrain representations, virtual training components, and training simulation software. It will complement the Army&apos;s live training environment by allowing units to train to higher levels of proficiency before engaging in live training. The Synthetic Training Environment Cross Functional Team will work with other teams, sister services, industry partners, and academia to develop the synthetic training environment and streamline the acquisition process. The Army&apos;s goal is to equip units with advanced training capabilities and equipment more quickly. Training dominance is important for the Army to support the Chief of Staff of the Army&apos;s initiatives and to ensure flexibility, relevance, and repeatability in training. The Army aims to modernize training capabilities to maintain dominance on the battlefield and enhance soldier lethality. " POSITION="left" ID="ID_557917532" CREATED="1688559432712" MODIFIED="1689008428259" LINK="https://www.army.mil/standto/archive/2018/03/26/">
<edge COLOR="#007c00"/>
</node>
<node TEXT="This message from Bloomberg is notifying the user that there has been unusual activity detected from their computer network. To proceed, the user needs to confirm that they are not a robot by clicking on a box. The message also suggests that the user should ensure that their browser supports JavaScript and cookies and that there are no blockages preventing their proper functioning. For more details, the user can refer to Bloomberg&apos;s Terms of Service and Cookie Policy. If assistance is required, the user can contact Bloomberg&apos;s support team and provide the given reference ID. " POSITION="left" ID="ID_1798400978" CREATED="1688559432712" MODIFIED="1689008428264" LINK="https://www.bloomberg.com/news/articles/2023-04-14/meta-urged-to-halt-plans-allowing-minors-into-the-metaverse?leadSource=uverify%20wall">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="Copy.ai is an AI content generator that helps professionals and teams write faster and more effectively. With over 9 million users, it offers a range of features for blog writers, social media managers, and email marketers. Users can sign up for a free account without the need for a credit card.  The tool is praised by users who find it a game-changer in their writing process. It can generate blog posts, social media content, sales copy, digital ad copy, eCommerce copy, and website copy in a fraction of the time it would take to write manually. Users can input a sentence or two of a generic idea, and the AI generates engaging content in 30 seconds or less.  Copy.ai prioritizes security and compliance, being SOC 2 Type II compliant according to AICPA standards. This ensures that users&apos; data is managed with the highest standard of security.  The process of using Copy.ai is simple. Users start by entering their copywriting project and providing some context about their brand and products. The AI content generator then generates multiple options for each campaign, giving users the choice to sift through and select the most suitable content. Users can then edit and polish the content using Copy.ai’s editor and copy and paste it into their CMS for publishing.  Copy.ai offers a free version with 2,000 free words per month, and there are also paid plans available. With over 90 tools and templates, it aims to streamline content production and eliminate the struggle of the blank page.  Overall, Copy.ai aims to help users write content faster, engage their audience, and never struggle with writer&apos;s block again. It offers a range of features and templates, making it a valuable tool for content creation. " POSITION="left" ID="ID_802516748" CREATED="1688559432712" MODIFIED="1689008428266" LINK="https://www.copy.ai/">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="D-ID has launched its AI Presenters on Canva, allowing users to engage in face-to-face conversations with artificial intelligence (AI). The app, called chat.D-ID, is a free web application that enables users to video chat with a digital human in real-time. By combining D-ID&apos;s advanced facial animation capabilities and ChatGPT&apos;s conversational AI technology, the app aims to provide a more human and natural interaction experience. Users can try it for free, with the ability to hold up to five chats consisting of six back-and-forth interactions each.   The chat.D-ID software has various practical applications across industries, including sales and marketing, learning and development, personal health and wellness, and financial services. It is particularly valuable for enhancing customer experience. Additionally, the streaming animation technology used in chat.D-ID is available for businesses and developers through D-ID&apos;s generative AI API. This real-time technology can be integrated with both open and closed domain AI models, allowing businesses of all sizes to establish more personalized connections with their clients, employees, and communities.  For enterprise customers looking to create a digital person specifically tailored to their businesses, D-ID offers customized solutions. Interested parties can book a meeting to discuss their requirements.  D-ID also provides other products and services, including an API for developers, a Creative Reality Studio, and offerings related to training and development, live portraits, and speaking portraits.  Overall, chat.D-ID on Canva allows users to have engaging face-to-face conversations with AI, offering a more intuitive and human-like experience. The technology has numerous potential applications in various industries, and D-ID offers customized solutions for enterprise customers. " POSITION="left" ID="ID_1882574618" CREATED="1688559432712" MODIFIED="1689008428267" LINK="https://www.d-id.com/chat/">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="FutureTools is a platform that collects and organizes a variety of AI tools to help users enhance their abilities. The platform features tools in various categories such as AI detection, aggregators, chatbots, copywriting, finance, gaming, generative art, and more. Whether for fun or for productivity, FutureTools has tools for different purposes.  Some notable tools on the platform include Hocoos AI Website Builder, which creates business-ready websites in minutes, 2short.ai, an AI-powered video repurposing tool, B12, an AI website builder, Sococal.ai, an AI tool for social media content creation and optimization, MagicBuddy, a Telegram Bot for chat interactions, and eesel.ai, a knowledge connection tool with instant question answering capabilities.  Other tools focus on specific functions such as generating music (Splash Pro), generating code and converting code (AI Code Converter), automating personalized Twitter outreach (Drippi.ai), generating personalized podcasts (Magicast.ai), creating custom sticker packs (30 Stickers and FaceFiesta.io), providing virtual therapy chatbot support (Lotus), assisting with songwriting and collaboration (LyricStudio), and offering personalized medical assistance and guidance (HeyDoc).  FutureTools also offers tools for automating knowledge sharing and team updates (twine), developing and operating AI applications (Dify), generating custom app icons (IconLab AI), and more. The platform includes both free and paid tools, with some tools being open source or available on GitHub and Google Colab.  In addition to the tools, FutureTools provides a glossary and a section for users to submit new tools. Users can also sign up for the AI Income Database, which offers free access and promises not to spam their email inbox.  Overall, FutureTools aims to empower users to leverage the capabilities of AI and become superhuman in various aspects of their lives. " POSITION="left" ID="ID_957306502" CREATED="1688559432712" MODIFIED="1689008428285" LINK="https://www.futuretools.io/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="LinkedIn uses cookies, including essential and non-essential cookies, to provide, secure, analyze, and improve its services. These cookies are also used to show relevant ads on and off LinkedIn, including professional and job ads. Users can choose to accept or reject non-essential cookies, and update their preferences at any time in their settings.  LinkedIn Learning offers a course called Career Essentials in Generative AI developed by Microsoft and LinkedIn. This course consists of five courses with a total of four hours of content. It aims to help individuals discover the skills needed to apply generative AI in their careers, learn the core concepts of artificial intelligence and generative AI functionality, understand generative AI models, explore the ethical considerations of using generative AI, and examine the impact of generative AI tools.  The five courses in the Career Essentials in Generative AI course are as follows:  1. What Is Generative AI?: This course provides an overview of the basics of generative AI, including its history, popular models, how it works, and ethical implications.  2. Generative AI: The Evolution of Thoughtful Online Search: This course explores the distinctions between search engines and reasoning engines, focusing on learning thoughtful search strategies in the world of generative AI.  3. Streamlining Your Work with Microsoft Bing Chat: In this course, participants learn how to leverage Microsoft Bing Chat to streamline and automate their work.  4. Ethics in the Age of Generative AI: This course emphasizes the importance of ethical considerations in the generative AI creation and deployment process and offers ways to address ethical challenges.  5. Introduction to Artificial Intelligence: Participants get a simplified overview of the top tools in artificial intelligence.  The instructors for these courses include Pinar Seyhan Demirdag, Ashley Kennedy, Jess Stratton, Vilas Dhar, and Doug Rose.  The courses are categorized under topics such as Artificial Intelligence (AI), Business Analysis and Strategy, Creative Topics, Technology Topics, and more. " POSITION="left" ID="ID_1717220633" CREATED="1688559432712" MODIFIED="1689008428286" LINK="https://www.linkedin.com/learning/paths/career-essentials-in-generative-ai-by-microsoft-and-linkedin">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="LinkedIn emphasizes the importance of privacy and offers options for users to control their data. They utilize both essential and non-essential cookies to provide, secure, analyze, and enhance their services. These cookies also help tailor relevant ads, including professional and job ads, on and off the platform. The Cookie Policy provides more details about the cookies used and the choices available.  Users are given the choice to accept or reject non-essential cookies. The Accept option indicates consent, while Reject allows users to decline such cookies. It is important to note that these preferences can be updated at any time in the settings.  To join LinkedIn, users are required to provide an email address and password with at least six characters. By clicking Agree and Join, users agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy.  For those who already have a LinkedIn account, signing in is an option presented. The platform also offers assistance for businesses looking to create a page.  In addition to the focus on privacy, LinkedIn provides information about their company, accessibility, and policies such as the User Agreement, Privacy Policy, Cookie Policy, Copyright Policy, Brand Policy, Guest Controls, and Community Guidelines. Users can continue with their Google account if they prefer. The copyright year indicated is 2023. " POSITION="left" ID="ID_1877286545" CREATED="1688559432712" MODIFIED="1689008428288" LINK="https://www.linkedin.com/posts/activity-7046131519802757120-uUEf?utm_source=shareandutm_medium=member_android">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="LinkedIn uses both essential and non-essential cookies to provide and improve their services. These cookies are also used to show users relevant advertisements on and off the LinkedIn platform, including professional and job ads. Users can accept or reject non-essential cookies, and they have the option to update their preferences at any time in their settings. By joining LinkedIn, users agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy. LinkedIn also offers assistance for creating business pages. " POSITION="left" ID="ID_594082564" CREATED="1688559432712" MODIFIED="1689008428290" LINK="https://www.linkedin.com/posts/activity-7081680686708887555-zDGa?utm_source=shareandutm_medium=member_android">
<edge COLOR="#00007c"/>
</node>
<node TEXT="Apple has banned the internal use of OpenAI&apos;s ChatGPT and similar products over concerns that the AI chatbots could potentially share sensitive internal information. This move follows similar bans by other companies, including Amazon and several banks. Apple is rumored to be working on its own language model to rival ChatGPT and Google Bard. The problem with AI chatbots like ChatGPT is that the data fed into them can be used to further train the bots, which can pose a risk of confidential business information being exposed. The UK&apos;s spy agency, GCHQ, has warned about this risk. ChatGPT and similar bots are also visible to their providers, like OpenAI and Google, creating another potential vulnerability for corporate secrets. The ban by Apple and other companies highlights the ongoing challenges and risks associated with AI technologies in the corporate world. " POSITION="left" ID="ID_1044125651" CREATED="1688559432712" MODIFIED="1689008428291" LINK="https://www.linkedin.com/posts/melchiors_ai-software-microsoft-activity-7069901328981848064-1-Oq?utm_source=shareandutm_medium=member_android">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="In a recent LinkedIn post, Thomas Wolf, co-founder of Hugging Face, announced the release of StarCoder, a large model for code generation. The model is high performance and trained only on carefully vetted data with permissive code licenses and comprehensive Personally Identifiable Information (PII) removal. Wolf encouraged developers to check out StarCoder for clean and high-performance code generation.  However, one user commented that they had tried StarCoder on a simple function and found that it did not generate the correct answer. Wolf acknowledged the issue and clarified that StarCoder is not a real chat model yet and should be used for internal finetuning or code completion.  Other users in the comments section asked about the superiority of StarCoder compared to other models and if there were any latency numbers available. Some users also expressed their disappointment with Hugging Face&apos;s performance compared to other models like GPT4.  In a separate post, Eric Partaker shared his top 10 most popular posts on LinkedIn, which include topics such as career advice, leadership prompts, and productivity tips. Partaker expressed surprise at reaching around 110k followers within six months of posting on LinkedIn.  Overall, the LinkedIn post discussed the release of StarCoder, feedback from users, and shared popular posts from another LinkedIn user. " POSITION="left" ID="ID_150771120" CREATED="1688559432712" MODIFIED="1689008428291" LINK="https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=shareandutm_medium=member_a">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="In a LinkedIn post, Thomas Wolf, co-founder of Hugging Face, announced the release of StarCoder, a large model trained for high-performance code generation. The model, which is trained on carefully vetted data with permissive code licenses and comprehensive personal identifiable information (PII) removal, outperforms existing models such as PaLM, LLaMa, CodeGen, and OpenAI code-crushman-001. While StarCoder can be used for chat prompts, it has not been finetuned for dialog, so it is not recommended for direct chat interactions. Instead, it can be used for internal finetuning or code completion with the Visual Studio Code extension.  In the comments section of the post, users shared their experiences and asked questions. One user mentioned that they had tried both StarCoder and GPT4 and found GPT4 to be better. Another user asked about the comparison scores for Codex, another code generation model, to provide context. Additional comments included questions about the model&apos;s tuning approach, the use of the term clean to describe the model, and the API charging for usage.  In a separate LinkedIn post, Eric Partaker, CEO of the Year in 2019, shared his top ten most powerful posts to accelerate career growth. The posts cover various topics such as leadership prompts, creating psychological safety in teams, and avoiding leadership mistakes. Partaker highlighted that he has gained around 110,000 followers on LinkedIn in just six months. The post includes links to each of the popular posts.  These LinkedIn posts provide insights into the release of StarCoder and highlight valuable career advice and insights for professionals looking to accelerate their growth. " POSITION="left" ID="ID_410789043" CREATED="1688559432712" MODIFIED="1689008428291" LINK="https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=shareandutm_medium=member_android">
<edge COLOR="#7c7c00"/>
</node>
<node TEXT="This text is a post on LinkedIn by Venu Victor, the Head of Effects at MPC. The post discusses the use of GPT (Generative Pre-trained Transformer) in Houdini, AI, Python, and chatbot technology. Venu explains that their script analyzes user input and asks questions in a way that leads to precise answers. The second version of the script can navigate a small network of nodes and ask the GPT model for suggestions on how to modify the network to achieve a specific visual result. The post includes a video demonstrating the script in action. Venu Victor has 3,627 followers on LinkedIn and has made 289 posts. " POSITION="left" ID="ID_463703637" CREATED="1688559432712" MODIFIED="1689008428291" LINK="https://www.linkedin.com/posts/venu-victor-aa7ab865_houdini-ai-python-activity-7030460619195629568--Sx9?">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="LinkedIn and third-party platforms use cookies to provide, secure, analyze, and improve services, as well as to show relevant ads. Users can accept or reject non-essential cookies in their settings. In a recent post, Peter Yang discusses the crowded landscape, FOMO-driven decision making, and high valuations in the generative AI space. He suggests 5 questions to evaluate the potential success of gen AI products: (1) does the product solve a customer problem without AI, (2) how accurate does the solution need to be, (3) how fast will incumbents move on AI, (4) is there a moat (e.g " POSITION="left" ID="ID_784949814" CREATED="1688559432712" MODIFIED="1689008428299" LINK="https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns?utm_source=shareandutm_medium=member_androi">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="The text discusses five questions that can help evaluate the success and viability of generative AI products. The first question is whether the product is still solving a customer problem even without AI, emphasizing the importance of addressing a real pain point. The second question focuses on accuracy, noting that generative AI works well for high fluency and low accuracy problems, but not for those requiring high accuracy, such as financial decisions. The third question highlights the speed at which incumbents like Microsoft and Google are moving on AI, suggesting that startups entering the space need to be significantly better than existing solutions to succeed. The fourth question explores whether there is a moat, or a unique " POSITION="left" ID="ID_817214884" CREATED="1688559432712" MODIFIED="1689008428299" LINK="https://www.linkedin.com/posts/yangpeter_everyones-pivoting-to-generative-ai-but-activity-7073305428255789056-l9Ns?utm_source=shareandutm_medium=member_android">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="The text is a collection of comments and discussions on LinkedIn about topics such as AI tools, self-development, SEO content, and antimicrobial resistance. Various individuals share their thoughts, ask questions, and offer insights on these subjects. Some comments highlight the importance of understanding privacy policies when using AI tools, while others discuss the challenges of combating antimicrobial resistance and the risks of self-medication. Additionally, there are comments that encourage self-development through reading books and taking courses in bioinformatics and data analysis. Finally, there are mentions of community benefits programs and job opportunities in the construction industry. Overall, the text represents a diverse range of discussions and perspectives on different professional topics. " POSITION="left" ID="ID_1168967865" CREATED="1688559432712" MODIFIED="1689008428299" LINK="https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=shareandutm_medium=member_android">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The article discusses the potential of Central Intelligent Agents (CIA), which are AI-driven systems that can transform marketing, customer service, and customer journey experiences. The author highlights the need for a cohesive and personalized approach to engaging with customers using AI technology. The article outlines the steps to deploying a CIA, including assessing organizational readiness, defining objectives, assembling a cross-functional team, developing the core components of a CIA, establishing ethical guidelines, integrating and testing the CIA, and monitoring and iterating on its performance. The author emphasizes the importance of aligning the CIA with business goals and ensuring ethical use of customer data. The article also mentions the advancements in AI technologies and large language models that enable the creation of more intelligent and human-like conversational AI systems. The author concludes by encouraging businesses to take advantage of the opportunities offered by CIA and offers Vixen Labs&apos; services to guide organizations through the process of implementing AI-driven strategies tailored to their needs. " POSITION="left" ID="ID_803587773" CREATED="1688559432712" MODIFIED="1689008428299" LINK="https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?utm_source=shareandutm_medium=member_androidandutm_campaign=shar">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="In this article, Jakob Nielsen discusses the evolution of user interface (UI) paradigms in computing history. He identifies three paradigms: batch processing, command-based interaction design, and intent-based outcome specification.   The first UI paradigm, batch processing, emerged in the mid-1940s when users would submit a batch of instructions to a data center, and the output would be provided at a later time. This paradigm lacked interactivity and had poor usability.  The second paradigm, command-based interaction design, started with time-sharing systems in the 1960s. Users would issue commands to the computer one at a time, and the computer would respond accordingly. This paradigm has dominated computing for over 60 years. Command-based interactions offered more flexibility and allowed users to modify their commands based on feedback from the computer.  Nielsen introduces the third paradigm, intent-based outcome specification, which is represented by current generative AI systems like ChatGPT. In this paradigm, users no longer issue specific commands to the computer but instead express their desired outcome. The AI system then generates results without the user specifying how to achieve them. This reverses the locus of control and eliminates the need for turn-taking between the user and the computer.  While the intent-based paradigm shows promise, it also poses challenges. Current AI systems have usability problems and often require users to write out their problems as prose text, limiting the effectiveness for some users. Additionally, relying solely on AI control can lead to errors and challenges in problem identification and correction.  Nielsen emphasizes the importance of usability in AI systems and suggests that a hybrid UI approach combining elements of both intent-based and command-based interfaces, along with graphical user interface (GUI) elements, is likely to emerge in the future. This would allow for better user control and interaction while leveraging the advantages of AI systems.  In conclusion, AI is introducing a new UI paradigm, where users express their desired outcome rather than specifying commands. This paradigm has the potential to revolutionize the way humans interact with computers, but usability and a hybrid UI approach are critical for its success. " POSITION="left" ID="ID_1363185004" CREATED="1688559432712" MODIFIED="1689008428299" LINK="https://www.nngroup.com/articles/ai-paradigm/">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="Cashu Nutshell v0.12.1 has been released, bringing performance and stability improvements to the Chaumian Ecash wallet and mint for Bitcoin Lightning. This release includes dynamic change output amounts, the use of the httpx library for asynchronous operations, a transition from DB locks to asyncio locks for compatibility with RaspberryPi systems and LNbits, and significant performance increases in the wallet due to database optimizations. Other changes include bug fixes, the addition of trace logs, improvements to the wallet REST API, and the ability to mint tokens of a specific denomination and send existing token denominations without a split. The release is still experimental and not ready for production use. The GitHub repository provides a full changelog and information on the new contributors to the project. " POSITION="left" ID="ID_306774008" CREATED="1688559432712" MODIFIED="1689008428306" LINK="https://www.nobsbitcoin.com/cashu-nutshell-v0-12-1/">
<edge COLOR="#00007c"/>
</node>
<node TEXT="Ocoya is an AI-powered platform that aims to simplify social media marketing and content creation. It offers features such as AI writing, automation, scheduling, analytics, and graphics. The platform&apos;s AI assistant helps generate marketing text for social media posts and blogs in 26 languages.  Ocoya provides an alternative to other AI platforms like ChatGPT and Jasper. It is integrated with popular social media channels such as Facebook, Instagram, Twitter, LinkedIn, YouTube, and TikTok. It also supports platforms like Shopify, WooCommerce, Zapier, Canva, Airtable, and Google.  The platform offers various features to enhance social media marketing. It includes an AI copywriter that generates marketing text powered by AI. Scheduling is automated, allowing users to schedule posts on all social media channels. Real-time analytics provide valuable metrics on post performance.  Ocoya also offers relevant and trending hashtags that are freshly updated. It provides an ecommerce feature to announce new products. Additionally, the platform offers a link shortener to save space on long links in captions. Collaboration is facilitated through the creation of workspaces for team members.  Various businesses rely on Ocoya for their content needs. The platform is officially partnered with Benjamin Austin, an account executive at Uber Eats. Users can join over 60,000 businesses in 180+ countries that are already using Ocoya.  In summary, Ocoya is an AI-powered platform that simplifies social media marketing and content creation. It offers features such as AI writing, automation, scheduling, analytics, and graphics. Integrated with popular social media channels and supporting various platforms, Ocoya is a valuable tool for businesses looking to enhance their social media presence. " POSITION="left" ID="ID_1265194360" CREATED="1688559432712" MODIFIED="1689008428307" LINK="https://www.ocoya.com/">
<edge COLOR="#007c00"/>
</node>
<node TEXT="Puzzle Labs offers an AI-powered glossary tool that aims to bring clarity to products and their associated terminology. The tool allows users to easily create a dynamic glossary from existing content, providing clear and concise definitions of key terms and concepts. The glossary widget can be embedded into blogs or documentation and helps highlight, define, and link to relevant content. Puzzle Labs believes that understanding complex information should be easy and enjoyable, and they are building additional tools to enhance the customer education experience. By using Puzzle Labs&apos; glossary tool, customers can learn directly from the product creators instead of relying on search engines. The glossary can be created in three simple steps, allowing users to import their content from various platforms, select the concepts that best define their product, and publish the Puzzle Widget by copying and pasting a code snippet onto their website. The Widget automatically updates as new concepts are added. Puzzle Labs aims to drive customer education and adoption through clarity. They can be contacted via email and can be found on LinkedIn and Twitter. Puzzle Labs provides solutions, support, documentation, and offers pricing options. They are a company focused on improving customer education and have a blog where they share relevant content. Puzzle Labs is committed to responsible use and complies with privacy policy and terms of service regulations. " POSITION="left" ID="ID_761828894" CREATED="1688559432712" MODIFIED="1689008428309" LINK="https://www.puzzlelabs.ai/">
<edge COLOR="#7c007c"/>
</node>
<node TEXT="The text includes information about Reddit&apos;s use of cookies and similar technologies to provide a better user experience. By accepting all cookies, users agree to Reddit&apos;s use of cookies to deliver and maintain services, improve quality, personalize content and advertising, and measure advertising effectiveness. Even if non-essential cookies are rejected, certain cookies will still be used to ensure platform functionality. The text also mentions that more information can be found in Reddit&apos;s Cookie Notice and Privacy Policy.  The remaining part of the text includes comments from users discussing topics related to VR image testing, generating 360 panoramas, open sourcing workflows, and sharing resources for 360 images and panoramic views. Some users share their experiences and provide suggestions for improving the AI-generated 360 image, while others suggest using specific tools and techniques for better results. The comments cover various aspects related to VR, AI, and image generation.  In addition to the discussion, the text includes links and titles of posts from different subreddits, indicating various topics people are discussing on Reddit. These topics range from creating AI-generated visuals and animated videos to architectural design and pixel art. Each post has a number of upvotes and comments, indicating the popularity and engagement of the posts within the Reddit community. " POSITION="left" ID="ID_1762940413" CREATED="1688559432712" MODIFIED="1689008428314" LINK="https://www.reddit.com/r/StableDiffusion/comments/12od46u/360_vr_image_read_comment/">
<edge COLOR="#007c00"/>
</node>
<node TEXT="The text discusses the use of cookies and similar technologies on Reddit to enhance user experience. By accepting all cookies, users agree to the use of cookies for delivering and maintaining services, improving the quality of Reddit, personalizing content and advertising, and measuring advertising effectiveness. However, by rejecting non-essential cookies, Reddit may still use certain cookies for platform functionality. The text also provides links to the Cookie Notice and Privacy Policy for more information. The remaining part of the text includes a discussion thread in the r/vfx subreddit, where users share and comment on various topics related to visual effects. Some of the topics discussed include tutorials on scanning environments through stock videos, IP camera recording, sharing live videos, screen recording on Android devices, starting a VFX union, and more. The thread also includes links to other subreddits such as r/cctv, r/Ubiquiti, r/blinkcameras, r/speedrun, r/theantosweb, r/Houdini, r/MotionDesign, and r/Cinema4D, where users discuss and engage in related topics such as camera streams, video sharing, motion graphics, and animation. " POSITION="left" ID="ID_1850031073" CREATED="1688559432712" MODIFIED="1689008428314" LINK="https://www.reddit.com/r/vfx/comments/12ok0xe/how_to_scan_environments_for_free_without_any/">
<edge COLOR="#0000ff"/>
</node>
<node TEXT="This text appears to be a combination of different content from a Reddit forum, specifically from the r/virtualreality subreddit. It includes a user&apos;s post about controlling OBS (Open Broadcaster Software) in virtual reality and some comments discussing the topic. Additionally, there are various unrelated posts from other subreddits listed at the bottom.  The main post in r/virtualreality is about a beta version of an application called Control OBS in VR. The user provides instructions on setting up OBS and binding buttons or chords to specific functions within the VR interface. They share a direct link to download the application from OneDrive, as they are not willing to spend money to publish it on Steam if they are not making any profit.  The comments on the post include a mention of OBS&apos;s remote control API and a response from the original poster asking for clarification. The other comments are unrelated to the main topic.  At the bottom of the text, there are several posts from other subreddits, covering topics related to iPhone recommendations, technology sales, programming struggles, gaming, and virtual reality experiences. These posts are not directly related to the main post about controlling OBS in VR.  Overall, the text combines information from a Reddit forum, with the main focus being on a beta version of an application for controlling OBS in virtual reality. " POSITION="left" ID="ID_291048964" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.reddit.com/r/virtualreality/comments/10l23a3/beta_control_obs_in_vr/">
<edge COLOR="#00ff00"/>
</node>
<node TEXT="The text explains that Reddit and its partners use cookies and similar technologies to enhance user experience. By accepting cookies, users agree to allow Reddit to deliver and maintain services, improve the site&apos;s quality, personalize content and advertising, and measure the effectiveness of advertising. Even if users reject non-essential cookies, Reddit may still use certain cookies to ensure the platform functions properly. The text provides links to the Cookie Notice and Privacy Policy for more information. In a separate comment thread on the virtual reality subreddit, a rumor is discussed, claiming that Meta Quest had over 6 million monthly active users as of October 2022, according to a report by the Wall Street Journal. Users in the thread discuss their opinions on VR gaming and its current state, including the lack of games and the need for more users to encourage developers to create more content. Other discussions in the thread include comparisons between the number of VR users on SteamVR and the Quest platform, as well as the potential of VR storytelling and the release of new VR games. The text also includes several additional comment threads from different Reddit communities unrelated to virtual reality. " POSITION="left" ID="ID_1121851997" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.reddit.com/r/virtualreality/comments/12lpsvf/rumor_meta_quest_had_more_than_6_million_monthly/">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="The text explains that Reddit and its partners use cookies and similar technologies to enhance the user experience. By accepting cookies, users agree to the use of cookies to deliver services, improve Reddit&apos;s quality, personalize content and advertising, and measure ad effectiveness. Rejecting non-essential cookies still allows certain cookies to be used for platform functionality. The text also includes a discussion on an algorithm-based AR/VR body tracking proposed by Meta AI called AGRoL, which is designed to track full bodies using sparse upper-body tracking signals. The comments in the text discuss various perspectives on full-body tracking in virtual reality, with opinions on the importance and effectiveness of different tracking methods. The text also includes a list of recent posts and discussions in various subreddits related to virtual reality and other topics. " POSITION="left" ID="ID_1342006818" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.reddit.com/r/virtualreality/comments/12rro32/meta_ai_proposed_an_algorithmbased_arvr_body/">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="The text discusses Reddit&apos;s use of cookies and similar technologies to enhance the user experience. By accepting all cookies, users agree to the use of cookies by Reddit to provide services, improve the quality of Reddit, personalize content and advertising, and measure ad effectiveness. Users also have the option to reject non-essential cookies. The post then discusses Horizon Worlds, a virtual world-building platform, and its plans to expand to smartphones, web, and possibly gaming consoles. The CEO of Horizon Worlds confirms a web version with lower fees, while also mentioning negotiations for smartphone and console versions. The post includes some comments from Reddit users discussing the shift of Horizon Worlds from a VR technology to a social media platform and the potential impact of fees on the web and iOS versions. The post also includes links to various other Reddit threads discussing different topics related to virtual reality, including game releases, upcoming releases, and discussions on immersive experiences and storytelling in VR games. " POSITION="left" ID="ID_1939862950" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.reddit.com/r/virtualreality/comments/u4ahwu/horizon_worlds_coming_to_smartphones_web_probably/">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="Runhouse is a PyTorch-like unified interface that aims to solve the problem of platform overhead in machine learning (ML) infrastructure. The CEO and product lead for PyTorch, Donny Greenberg, was frustrated by the amount of time ML engineers and researchers spend on platform code instead of actual modeling. Runhouse addresses the fragmentation and silos that exist in ML infrastructure by offering a unified interface.  The text highlights three main categories of fragmentation in ML: research and production silos, external and internal silos, and infra silos. Runhouse aims to break down these silos by providing an interface that is infrastructure-agnostic, a la carte, and Python-generic. It allows users to seamlessly work with different compute and data infrastructures without the need for manual code and data movement, packaging into containers, or translation into pipeline DAGs.  The core concept behind Runhouse is to enable hardware heterogeneity and modularization through microservices. Users can send their code or datasets to different clusters or hardware types using simple Python commands, without the need for complex translation or debugging. Runhouse acts as an eager-mode orchestrator that allows the execution of fully working programs without the need for remote engine submission.  Runhouse is designed to be an interface rather than a platform, meaning it works on top of existing compute and provider accounts. This allows users to adopt it incrementally without significant changes to their existing infrastructure. It also promotes OSS reproducibility and accessibility by allowing OSS maintainers to publish their actual code, including the hardware and dependencies.  In addition to the Runhouse interface, the text introduces Runhouse Den, a multiplayer resource-sharing and management service. Den enables users to save and persist microservices and share them with teams or companies. It aims to facilitate accessibility and sharing of compute and data resources across research and production environments.  The text emphasizes that Runhouse is not a replacement for existing infrastructures or tools but rather an addition and complement to them. It can be used alongside orchestrators and experiment management systems, and it provides a consistent interface for onboarding to new compute platforms.  Runhouse is an open-source project currently in the early stages of development. The team encourages input, contributions, and partnerships to further enhance and expand the capabilities of Runhouse. " POSITION="left" ID="ID_1498936890" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.run.house/blog/a-pytorch-approach-to-ml-infrastructure">
<edge COLOR="#00007c"/>
</node>
<node TEXT="The article discusses the rise of generative AI and its potential impact on various industries. Generative AI refers to machine learning models that are capable of creating new content and designs, rather than just analyzing existing data. This new category of AI has the potential to outperform human creativity in tasks such as writing, coding, design, and more.  The article highlights that the fields of knowledge work and creative work, which comprise billions of workers, stand to benefit greatly from generative AI. It can make workers more efficient and creative, leading to increased economic value. The article also mentions that generative AI has the potential to generate trillions of dollars of economic value.  The progress in generative AI has been driven by better models, more data, and more powerful computing capabilities. Over the past few years, larger models have been developed that can deliver human-level and even superhuman results. These models have been used in various applications, including handwriting recognition, speech synthesis, image generation, and code generation.  The article predicts that generative AI will lead to the emergence of new applications and potentially killer apps that will revolutionize industries. It envisions applications in areas such as copywriting, vertical-specific writing assistants, code generation, art generation, gaming, media/advertising, design, and social media. The article also discusses the anatomy of a generative AI application, including the form factor, paradigm of interaction, and sustained category leadership.  However, the article acknowledges that there are still hurdles and risks to be overcome in the development of generative AI. Issues such as copyright, trust and safety, and costs need to be addressed. Despite these challenges, the article concludes that generative AI has great potential and invites startups to join in the development of this technology.  Overall, the article provides an overview of generative AI and its potential impact on various industries, highlighting its capabilities, challenges, and future prospects. " POSITION="left" ID="ID_1992651336" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/">
<font SIZE="8"/>
<edge COLOR="#007c00"/>
</node>
<node TEXT="The text is a list of various videos related to Unreal Engine 5.2 and its features. It includes videos on topics such as pixel streaming, virtual reality, open world creation, and new features in Unreal Engine 5.2. The videos are from different YouTube channels and cover a range of topics related to Unreal Engine 5.2 and its capabilities. However, the text does not provide any specific information about the content of the videos or their significance. " POSITION="left" ID="ID_1974382338" CREATED="1688559432712" MODIFIED="1689008428330" LINK="https://www.youtube.com/watch?v=FQgsQLodcZM">
<edge COLOR="#007c7c"/>
</node>
<node TEXT="The text appears to be a compilation of various YouTube video titles and descriptions, as well as some additional information related to YouTube privacy settings. The content includes videos about topics such as Stephen Wolfram answering questions, the business strategies behind popular companies, cellular automata, artificial intelligence, physics, and science initiatives. There are also mentions of conversations and interviews with notable individuals like Sam Altman and Stuart Russell. Overall, the text seems to provide a list of video titles and topics related to science, technology, and artificial intelligence. " POSITION="left" ID="ID_1157874088" CREATED="1688559432725" MODIFIED="1689008428330" LINK="https://youtu.be/zLnhg9kir3Q">
<edge COLOR="#ff0000"/>
</node>
<node TEXT="Hardware" POSITION="right" ID="ID_465865551" CREATED="1689008501079" MODIFIED="1689008506337">
<edge COLOR="#0000ff"/>
<node ID="ID_1775451155" CREATED="1687805148666" MODIFIED="1689008511273" LINK="https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          Meta, formerly known as Facebook, has announced its latest custom chip called the Meta Training &amp; Inference Accelerator (MTIA) v1 for improving the performance of AI workloads. The chip is equipped with 64 processing elements organised in an 8x8 configuration, parallelism and data reuse, fixed-function units, and 128 GB of DRAM resources. The MTIA software stack integrates with PyTorch, allowing for the scheduling of operators on the chip, and enables workloads to be partitioned across multiple accelerator cards. The MTIA chip is aimed at improving experiences across Meta's services and applications, including feeds, generative AI, and ads ranking. It also supports thread and data level parallelism, instruction level parallelism, and memory-level parallelism. https://ai.facebook.com/blog/meta-training-inference-accelerator-AI-MTIA/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node TEXT="AI coming to PCs at scale" ID="ID_948389191" CREATED="1689008672097" MODIFIED="1689008683707" LINK="https://www.intel.com/content/www/us/en/newsroom/news/ai-coming-to-pc-at-scale.html#gs.yiwayi"/>
</node>
<node TEXT="Privacy and politics, law" FOLDED="true" POSITION="right" ID="ID_1608970321" CREATED="1689008522598" MODIFIED="1689009417515">
<edge COLOR="#00ff00"/>
<node ID="ID_1307128052" CREATED="1687805148690" MODIFIED="1689008630191" LINK="https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          In her new book “The Age of Surveillance Capitalism”, Harvard Business School professor emerita, Shoshana Zuboff, warns that the collection and processing of user data by high-tech companies, such as Facebook and Google, is rendering users in a situation of serfdom, and has resulted in a concentration of knowledge and power never before seen. Zuboff explains that, essentially, users are unwittingly providing the raw material to fund lucrative prediction products that are then sold to corporate business customers. The shift in focus from supplying the individualised needs of clients, to raw profit, marks the shift to this new “surveillance capitalism”. Zuboff identifies the dependence of modern business and everyday social participation on the internet as key to the phenomenon, and argues that the methods of surveillance in use are designed to prevent us from knowing what is happening. She adds that every survey of internet users who are aware of the practices of surveillance capitalism shows a rejection of the system, offering hope for what she describes as a “market failure” that would establish alternative internet ecosystems based around a similar sense of empowerment to that felt during the initial years of mass consumption of digital technology.
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1868108253" CREATED="1687805148605" MODIFIED="1689009424101" LINK="https://futurism.com/the-byte/former-openai-employee-ai-safety"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          According to an ex-OpenAI safety researcher, there is a 20% chance of an AI apocalypse. The researcher, who left OpenAI due to concerns about the organization's priorities and the potential dangers of AI, believes that artificial intelligence could be misused to such an extent that it may lead to the destruction of humanity. However, he also states that the likelihood of such an event occurring will depend on how AI is developed and regulated in the future. The researcher stresses the importance of incorporating safety and ethical considerations into the design and development of AI systems. https://futurism.com/the-byte/former-openai-employee-ai-safety
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
<node ID="ID_1805176815" CREATED="1687805148610" MODIFIED="1689009424102" LINK="https://archy.deberker.com/the-uk-is-wasting-a-lot-of-wind-power/"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The UK is wasting a significant amount of wind power due to a lack of transmission capacity and location-based pricing. In 2022, wind power generated 23% of the UK's energy, but on windy days, power was deliberately capped resulting in a 6% reduction in total generation. Wind farms were turned off and gas power plants were turned on, leading to an extra 1.5 million tonnes of CO2 emissions and £215m spent on turning off wind farms, and £717m spent turning on gas power plants. The problem is due to the distribution of large wind farms, with most located in Scotland and the sea, and most electricity consumption concentrated in the southeast where cables cannot transmit the amount of wind energy generated. To fix the problem, bigger cables and more storage solutions such as pumped hydro or hydrogen can be added at bottlenecks, but laying high voltage cables is slow and expensive. Battery storage is easier to deploy than cables, and National Grid projects that the UK will have 35GW of battery storage across the country by 2050. Locational pricing would be more efficient, by breaking the energy market into smaller nodes or zones, allowing prices to develop independently in each location, providing an incentive for generators to build more capacity in the South where demand is the highest, and for energy-intensive industries to move to the North. The UK adoption of wind power is a success story, and we're laying the right pieces for a zero-carbon energy system by 2035. However, we need to be careful to lay them in the right places. https://archy.deberker.com/the-uk-is-wasting-a-lot-of-wind-power/
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
<node TEXT="LLMs" FOLDED="true" POSITION="right" ID="ID_1113595991" CREATED="1689008556803" MODIFIED="1689009266825">
<edge COLOR="#ff00ff"/>
</node>
<node TEXT="Generative Art" POSITION="right" ID="ID_713495588" CREATED="1689008812127" MODIFIED="1689008817171">
<edge COLOR="#00ffff"/>
</node>
<node TEXT="Mixed reality" FOLDED="true" POSITION="right" ID="ID_352528280" CREATED="1689008876834" MODIFIED="1689008882108">
<edge COLOR="#7c0000"/>
</node>
<node TEXT="Bitcoin/Lightning/L3" POSITION="right" ID="ID_1340073317" CREATED="1689009428429" MODIFIED="1689009435655">
<edge COLOR="#007c00"/>
<node ID="ID_934008912" CREATED="1687805148631" MODIFIED="1689009440411" LINK="https://twitter.com/lnp_bp/status/1656211884775821313"><richcontent TYPE="NODE">

<html>
  <head>
    
  </head>
  <body>
    <table cellspacing="0" border="0">
      <tr>
        <td height="43" align="left">
          The LNP/BP Standards Association is proposing an upgrade to the Nostr blockchain called reNostr. This upgrade will address binary encoding, networking, transport encryption, and DoS protection, and will bring RGB to Nostr. The proposal includes NIPs to add support for binary encoding to Nostr events, and the implementation will likely be ossified after it is ready. Some Twitter users commented on the proposal, suggesting that it may be better to do it on a separate GitHub repository with a set of RIPs instead of as NIPs. The timing is good as the BitMask app has just added Nostr xprv/xpub key generation support for every wallet generated. https://twitter.com/lnp_bp/status/1656211884775821313
        </td>
      </tr>
    </table>
  </body>
</html>
</richcontent>
</node>
</node>
</node>
</node>
</map>
